{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Phase 4: Train the single models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\zake7\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "C:\\Users\\zake7\\Anaconda3\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:35: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "## import packages\n",
    "########################################\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import codecs\n",
    "import numpy as np\n",
    "np.random.seed(1337)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "import operator\n",
    "import sys\n",
    "\n",
    "from string import punctuation\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from iwillwin.trainer.supervised_trainer import KerasModelTrainer\n",
    "from iwillwin.data_utils.data_helpers import DataTransformer, DataLoader\n",
    "from iwillwin.model.sim_zoos import *\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense, Input, MaxPooling1D, CuDNNLSTM, Embedding, Add, Lambda, Dropout, Activation, SpatialDropout1D, Reshape, GlobalAveragePooling1D, merge, Flatten, Bidirectional, CuDNNGRU, add, Conv1D, GlobalMaxPooling1D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from keras import initializers\n",
    "from keras.engine import InputSpec, Layer\n",
    "from iwillwin.config import dataset_config, model_config\n",
    "from keras.models import Sequential\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.core import Lambda, Dense, Dropout\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.legacy.layers import Highway\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import keras.backend as K\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NB_WORDS = 100000\n",
    "EMBEDDING_DIM = 300\n",
    "MAX_SEQUENCE_LENGTH = 30\n",
    "OUT_SIZE = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\zake7\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.483 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DataHelper] Apply normalization on value-type columns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zake7\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing preprocessing...\n",
      "Transforming words to indices...\n",
      "Shape of data tensor: (320552, 30) (320552, 30)\n",
      "Shape of label tensor: (320552,)\n",
      "Preprocessed.\n",
      "Number of unique words 83265\n"
     ]
    }
   ],
   "source": [
    "data_transformer = DataTransformer(max_num_words=NB_WORDS, max_sequence_length=MAX_SEQUENCE_LENGTH, char_level=False,\n",
    "                                   normalization=True, features_processed=True)\n",
    "trains, tests, labels = data_transformer.prepare_data(dual=False)\n",
    "print(\"Number of unique words\", len(data_transformer.tokenizer.index_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from sklearn.utils import class_weight\n",
    "labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings\n",
      "['.gitkeep', 'sgns.merge.bigram', 'temp.txt', 'Tencent_AILab_ChineseEmbedding.tar', 'Tencent_AILab_ChineseEmbedding.txt']\n"
     ]
    }
   ],
   "source": [
    "print(\"Embeddings\")\n",
    "print(os.listdir(\"../data/wordvec\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 1284313 word vectors.\n",
      "Err on  ['中共中央', '国务院关于完善产权保护制度依法保护产权的意见']\n",
      "Err on  ['杨', '光']\n",
      "Err on  ['王', '琪']\n",
      "Err on  ['食品安全国家标准', '食品添加剂使用标准']\n",
      "Err on  ['共担时代责任', '共促全球发展']\n",
      "Err on  ['三藏不忘本', '四圣试禅心']\n",
      "Err on  ['坚持开放包容', '推动联动增长']\n",
      "Err on  ['陷虎穴金星解厄', '双叉岭伯钦留僧']\n",
      "Err on  ['贾夫人仙逝扬州城', '冷子兴演说荣国府']\n",
      "Err on  ['食品安全国家标准', '食品中污染物限量']\n",
      "Err on  ['尸魔三戏唐三藏', '圣僧恨逐美猴王']\n",
      "Err on  ['情乱性从因爱欲', '神昏心动遇魔头']\n",
      "Err on  ['机动车类型', '术语和定义']\n",
      "Err on  ['我', '末代工农兵学员']\n",
      "Err on  ['财政部', '国家税务总局关于非货币性资产投资企业所得税政策问题的通知']\n",
      "Err on  ['弘扬“红船精神”', '走在时代前列']\n",
      "Err on  ['陈光蕊赴任逢灾', '江流僧复仇报本']\n",
      "Err on  ['蛇盘山诸神暗佑', '鹰愁涧意马收缰']\n",
      "Err on  ['深化伙伴关系', '增强发展动力']\n",
      "Err on  ['猪八戒义激猴王', '孙行者智降妖怪']\n",
      "Err on  ['九九数完魔灭尽', '三三行满道归根']\n",
      "Total 8824309 word vectors.\n"
     ]
    }
   ],
   "source": [
    "data_loader = DataLoader()\n",
    "sgns_bigram_embedding = data_loader.load_embedding('../data/wordvec/sgns.merge.bigram')\n",
    "tencent_ai_embedding = data_loader.load_embedding('../data/wordvec/Tencent_AILab_ChineseEmbedding.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_embedding_matrix(embeddings_index, embedding_size, nb_words=NB_WORDS, word_index=data_transformer.tokenizer.word_index,):\n",
    "    #nb_words = min(nb_words, len(embeddings_index))\n",
    "    embedding_matrix = np.random.rand(nb_words, embedding_size)\n",
    "    word_index = data_transformer.tokenizer.word_index\n",
    "    null_words = open('null-word.txt', 'w', encoding='utf-8')\n",
    "    null_ctr = 0\n",
    "    for word, i in word_index.items():\n",
    "        if i >= nb_words:\n",
    "            null_words.write(word + '\\n')\n",
    "            continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "        else:\n",
    "            print(word)\n",
    "            null_ctr += 1\n",
    "            null_words.write(word + '\\n')\n",
    "    print('Null word embeddings: %d' % null_ctr)\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "两项\n",
      "一款\n",
      "这是\n",
      "过大年\n",
      "多大\n",
      "吃秀\n",
      "一天\n",
      "这会灯\n",
      " \n",
      "爱自\n",
      "楠哥\n",
      "烯碳\n",
      "a股\n",
      "第一股\n",
      "同食\n",
      "信要\n",
      "多个\n",
      "三年\n",
      "这一\n",
      "海试\n",
      "喻言吐槽\n",
      "扎心\n",
      "会变\n",
      "上吐槽\n",
      "喻言狂\n",
      "或成\n",
      "ceodiss\n",
      "一分钟\n",
      "常吃\n",
      "竟能\n",
      "群助\n",
      "第三\n",
      "赌高冰\n",
      "赌出\n",
      "超快\n",
      "一枚\n",
      "手麻\n",
      "天去\n",
      "孕妈\n",
      "屏有\n",
      "mix3\n",
      "这枚\n",
      "1000vs10\n",
      "借水\n",
      "十年\n",
      "上万元\n",
      "找下\n",
      "市偷\n",
      "此国\n",
      "加它\n",
      "三分钟\n",
      "黑如\n",
      "组图\n",
      "霍金的\n",
      "亿年\n",
      "几片\n",
      "养狗场\n",
      "几千只\n",
      "一抹\n",
      "三天\n",
      "十天\n",
      "为市\n",
      "镇有\n",
      "10w\n",
      "最严\n",
      "万左右\n",
      "日系\n",
      "三席\n",
      "最损\n",
      "物可\n",
      "条线\n",
      "人能\n",
      "群会\n",
      "北三县\n",
      "破万\n",
      "燃脂\n",
      "几年\n",
      "一种\n",
      "蒸出\n",
      "号线\n",
      "一分\n",
      "天吃\n",
      "天瘦\n",
      "被切\n",
      "一首\n",
      "吃辣条\n",
      "辣条\n",
      "一百枚\n",
      "会值\n",
      "一万元\n",
      "一层\n",
      "几种\n",
      "一把\n",
      "突都\n",
      "包难消\n",
      "一杯\n",
      "艾草\n",
      "给治好\n",
      "数十万\n",
      "几个\n",
      "好几个\n",
      "治一好\n",
      "稳降\n",
      "请存\n",
      "半个\n",
      "狂降\n",
      "速存\n",
      "欲生\n",
      "日起\n",
      "限重\n",
      "销分\n",
      "被查\n",
      "分罚\n",
      "新交规\n",
      "惊现\n",
      "放车\n",
      "日新规\n",
      "将会\n",
      "考驾照\n",
      "要持\n",
      "双证\n",
      "消分\n",
      "飙戏\n",
      "车购\n",
      "无糖\n",
      "第一次\n",
      "想不长\n",
      "最该\n",
      "有福\n",
      "生吃\n",
      "长出\n",
      "两个\n",
      "包块\n",
      "开喷战\n",
      "我生\n",
      "男宝\n",
      "虐童\n",
      "两证\n",
      "要罚\n",
      "审新规\n",
      "卖不动\n",
      "h6\n",
      "一笔\n",
      "可领\n",
      "120km\n",
      "将成\n",
      "首条\n",
      "四驱带\n",
      "一看\n",
      "比哈弗\n",
      "万要\n",
      "几量\n",
      "没差\n",
      "级车\n",
      "美系\n",
      "逼格\n",
      "加分制\n",
      "曝已\n",
      "颈纹\n",
      "美过\n",
      "因丑\n",
      "一张\n",
      "5g\n",
      "投给\n",
      "25419\n",
      "怀男\n",
      "万公里\n",
      "最脏\n",
      "七天\n",
      "十斤\n",
      "瘦出\n",
      "半年\n",
      "一个月\n",
      "八斤\n",
      "瘦到\n",
      "天减\n",
      "减腰\n",
      "天让\n",
      "一条\n",
      "玩太多\n",
      "狗伤\n",
      "不起\n",
      "三十出头\n",
      "这件\n",
      "奶爸\n",
      "只降\n",
      "家有\n",
      "快存\n",
      "两周\n",
      "肥要\n",
      "養顏茶\n",
      "吃瓜\n",
      "性侵\n",
      "辣妈\n",
      "生完\n",
      "暴瘦\n",
      "狂瘦\n",
      "甩成\n",
      "这几物\n",
      "一副\n",
      "这四物\n",
      "秘制\n",
      "仨月\n",
      "几味\n",
      "老款\n",
      "配全\n",
      "时四驱\n",
      "这才\n",
      "玉娆\n",
      "牛孩\n",
      "吹大\n",
      "撒药治\n",
      "换个\n",
      "拿奖\n",
      "三千年\n",
      "抹平\n",
      "两种\n",
      "消脂\n",
      "宝妈\n",
      "软肥肚\n",
      "两物\n",
      "几款\n",
      "万拍\n",
      "这台\n",
      "一辆\n",
      "达人教\n",
      "能当\n",
      "gl550\n",
      "去味剂\n",
      "已变\n",
      "选股法\n",
      "多只\n",
      "日有\n",
      "冯提\n",
      "多万\n",
      "s400l\n",
      "懂车\n",
      "一碗\n",
      "甩腹\n",
      "几口\n",
      "排宿\n",
      "刮光\n",
      "上百万\n",
      "一次\n",
      "一声\n",
      "岁萝莉\n",
      "晚清\n",
      "八年\n",
      "170508\n",
      "撩妹\n",
      "171008\n",
      "171110\n",
      "首个\n",
      "煅荷\n",
      "物泡\n",
      "一泡\n",
      "几天\n",
      "一场\n",
      "半月\n",
      "已花\n",
      "抖音\n",
      "妖股\n",
      "亿封板\n",
      "下周\n",
      "连板\n",
      "墓主\n",
      "神押题\n",
      "三味\n",
      "快学\n",
      "熬点\n",
      "补脾\n",
      "三物\n",
      "18888888888\n",
      "万买台\n",
      "a6l\n",
      "cs95\n",
      "直降\n",
      "男神\n",
      "五年\n",
      "生神\n",
      "泪洒\n",
      "十万分之一\n",
      "还育\n",
      "仍似\n",
      "千元\n",
      "交了\n",
      "从根\n",
      "三种\n",
      "再虐\n",
      "一班\n",
      "抑癌\n",
      "四点\n",
      "四次\n",
      "这国\n",
      "快成\n",
      "第二个\n",
      "乐视\n",
      "亿都\n",
      "中惊现\n",
      "两座\n",
      "驚現\n",
      "時光\n",
      "講手機\n",
      "朱老总\n",
      "一分钱\n",
      "二次\n",
      "几百倍\n",
      "两元\n",
      "第七\n",
      "快来领\n",
      "五分\n",
      "年版\n",
      "五毛\n",
      "第九\n",
      "第四套\n",
      "再花\n",
      "怪车\n",
      "已翻\n",
      "九岁\n",
      "一双\n",
      "一名\n",
      "献唱\n",
      "埋尸\n",
      "成谜\n",
      "要变\n",
      "一招\n",
      "岁演\n",
      "迎得\n",
      "韩安冉\n",
      "整了\n",
      "三点\n",
      "现车\n",
      "蓝紫色\n",
      "你常\n",
      "能值\n",
      "万多条\n",
      "专克鸡\n",
      "巧治\n",
      "不花\n",
      "一用\n",
      "老军医\n",
      "两粒\n",
      "求药\n",
      "三个\n",
      "百元\n",
      "几千倍\n",
      "会得\n",
      "顶过\n",
      "勺油治\n",
      "好多年\n",
      "用过\n",
      "再野\n",
      "黑似\n",
      "百害\n",
      "一利\n",
      "周速\n",
      "通肠\n",
      "一瓶\n",
      "脸放\n",
      "两滴\n",
      "一周\n",
      "一年\n",
      "一口\n",
      "能巧治\n",
      "别脱\n",
      "次清\n",
      "就治好\n",
      "千副\n",
      "主揍\n",
      "斩恒大创\n",
      "能顶\n",
      "人太少\n",
      "第二条\n",
      "確診\n",
      "奪命\n",
      "你們\n",
      "還敢\n",
      "死多伤\n",
      "第四\n",
      "肾会\n",
      "还排\n",
      "肝毒\n",
      "种食材\n",
      "别看\n",
      "美白淡\n",
      "十大\n",
      "次大\n",
      "牟翠翠\n",
      "最辣\n",
      "一号\n",
      "日交规\n",
      "驾不系\n",
      "没休\n",
      "可评\n",
      "亿条\n",
      "现市\n",
      "液態\n",
      "樹木\n",
      "環繞\n",
      "双旗币\n",
      "能领\n",
      "手们\n",
      "智尚版\n",
      "九大\n",
      "已出\n",
      "领上\n",
      "四种\n",
      "没证\n",
      "粮补\n",
      "四个\n",
      "不发\n",
      "博瑞颜值\n",
      "两类\n",
      "可多涨\n",
      "限行\n",
      "能涨\n",
      "两考\n",
      "二本\n",
      "三本\n",
      "点开\n",
      "颁错\n",
      "六星版\n",
      "和央企\n",
      "符不\n",
      "神车\n",
      "轩逸竟\n",
      "看会\n",
      "证到\n",
      "证年\n",
      "审新\n",
      "一部\n",
      "亿人\n",
      "三月份\n",
      "遭来\n",
      "首破\n",
      "企退\n",
      "不看\n",
      "74318\n",
      "几项\n",
      "买齐\n",
      "四项\n",
      "一亩\n",
      "种人\n",
      "万已\n",
      "三项\n",
      "人领\n",
      "没领\n",
      "总有\n",
      "一项\n",
      "直补\n",
      "太全\n",
      "上千\n",
      "九类\n",
      "第三个\n",
      "能种\n",
      "幼升\n",
      "一图通\n",
      "五种\n",
      "一套\n",
      "能全\n",
      "两大\n",
      "合三大\n",
      "合新\n",
      "已到\n",
      "之喜\n",
      "首超\n",
      "日算起\n",
      "别忘领\n",
      "首支\n",
      "大单\n",
      "抢筹\n",
      "再考\n",
      "一本\n",
      "多地\n",
      "已空\n",
      "能得\n",
      "这句\n",
      "小多校\n",
      "房白\n",
      "四角\n",
      "转农\n",
      "六项\n",
      "分全\n",
      "编教\n",
      "起要\n",
      "五项\n",
      "速去\n",
      "必查\n",
      "周瘦\n",
      "多远\n",
      "三件\n",
      "很准\n",
      "省考\n",
      "第一张\n",
      "如路\n",
      "第一篇\n",
      "藏主\n",
      "第五款\n",
      "最有\n",
      "能考\n",
      "哪类\n",
      "之火\n",
      "20180508\n",
      "丰仕洁\n",
      "五类\n",
      "第六\n",
      "每满\n",
      "名特岗\n",
      "转编\n",
      "涨薪\n",
      "亿名\n",
      "人涨\n",
      "涨得\n",
      "一户\n",
      "几点\n",
      "多换\n",
      "多宅\n",
      "还发\n",
      "一宅\n",
      "听后\n",
      "能补\n",
      "有大\n",
      "这三\n",
      "合要\n",
      "四类\n",
      "几月\n",
      "个证\n",
      "亿人会\n",
      "可多领\n",
      "一大笔\n",
      "亏大\n",
      "最具\n",
      "第五\n",
      "吉视\n",
      "盖新房\n",
      "亿来\n",
      "个省\n",
      "必看\n",
      "最令\n",
      "咖将\n",
      "大秀\n",
      "跨年\n",
      "开年\n",
      "一大批\n",
      "要发\n",
      "几条\n",
      "齐送\n",
      "要配\n",
      "零时\n",
      "九桥\n",
      "日至\n",
      "如懿传\n",
      "定档\n",
      "扣车\n",
      "一日\n",
      "千多\n",
      "刷光\n",
      "c1\n",
      "十几万\n",
      "第一类\n",
      "名原\n",
      "准驾\n",
      "多少岁\n",
      "第二届\n",
      "c1c2\n",
      "有特\n",
      "c2\n",
      "b2\n",
      "a1\n",
      "a2\n",
      "a3\n",
      "b1\n",
      "新老\n",
      "铁齿\n",
      "要富\n",
      "第几\n",
      "五地\n",
      "五月份\n",
      "还会\n",
      "多项\n",
      "要涨\n",
      "还会涨\n",
      "过万\n",
      "六种\n",
      "项新规\n",
      "分户\n",
      "数万\n",
      "几十万\n",
      "恐有\n",
      "领越\n",
      "八项\n",
      "三胎\n",
      "领了\n",
      "种车\n",
      "无牌\n",
      "能省\n",
      "提车\n",
      "月生\n",
      "两大新\n",
      "几件\n",
      "万镑\n",
      "五个\n",
      "万马云\n",
      "有车\n",
      "一位\n",
      "年小本\n",
      "二建\n",
      "停考\n",
      "会涨\n",
      "有话\n",
      "赚够\n",
      "别想\n",
      "收地\n",
      "如针\n",
      "类车\n",
      "云不回\n",
      "曓\n",
      "十拿十稳\n",
      "这部分\n",
      "第三方\n",
      "多人\n",
      "快忙\n",
      "种违\n",
      "第二项\n",
      "新规来\n",
      "立享\n",
      "祝好孕\n",
      "想生\n",
      "优录\n",
      "可加分\n",
      "这三大\n",
      "知否\n",
      "断缴\n",
      "不淡定\n",
      "第一种\n",
      "一夜\n",
      "白修\n",
      "但豪\n",
      "多一笔\n",
      "两年\n",
      "卡友\n",
      "能富\n",
      "证会\n",
      "几万\n",
      "有何\n",
      "带娃\n",
      "化将\n",
      "化已\n",
      "我能\n",
      "分已\n",
      "考新规\n",
      "想学车\n",
      "驾考\n",
      "零分\n",
      "不办\n",
      "三大假\n",
      "已领\n",
      "第一个\n",
      "村通\n",
      "再领\n",
      "完不亏\n",
      "再白交\n",
      "没房\n",
      "合将\n",
      "获近\n",
      "此证\n",
      "数万元\n",
      "再涨\n",
      "可微信\n",
      "地值\n",
      "再穷\n",
      "江铠同\n",
      "手续费收\n",
      "明星阵容\n",
      "那英要\n",
      "朱之文带\n",
      "五位\n",
      "遭大\n",
      "咖们\n",
      "千万富翁\n",
      "电陶炉\n",
      "不饿\n",
      "个小本\n",
      "邱建良\n",
      "王西提\n",
      "一龙\n",
      "两位\n",
      "爆护\n",
      "狗宝宝\n",
      "表是\n",
      "上秋\n",
      "生娃\n",
      "疑提\n",
      "手护\n",
      "自套\n",
      "一金新\n",
      "权待\n",
      "已满\n",
      "未达\n",
      "当属\n",
      "所享\n",
      "做实\n",
      "套花\n",
      "贵不贵\n",
      "个事\n",
      "因出\n",
      "能多领\n",
      "演看\n",
      "一批\n",
      "点赞\n",
      "无工\n",
      "各大\n",
      "只分\n",
      "将会省\n",
      "三成\n",
      "只会\n",
      "哪届\n",
      "將會\n",
      "一颗\n",
      "湿毒\n",
      "q2l\n",
      "二十多条\n",
      "亿大单\n",
      "一架\n",
      "嫌太辣\n",
      "四维\n",
      "两次\n",
      "排不出\n",
      "黑如墨\n",
      "一上台\n",
      "救患\n",
      "下个\n",
      "四十多岁\n",
      "看后\n",
      "整完\n",
      "好几倍\n",
      "别慌\n",
      "一天天\n",
      "需多\n",
      "有妙\n",
      "條飲食\n",
      "規則\n",
      "幫助\n",
      "早用\n",
      "混着\n",
      "压豆\n",
      "天能\n",
      "一人敢\n",
      "送上\n",
      "造不出\n",
      "搭戏\n",
      "莫雷神\n",
      "多部\n",
      "剧不火\n",
      "因演\n",
      "仿妆马云\n",
      "太过\n",
      "情定\n",
      "赵丽颖饰\n",
      "日陕\n",
      "仅排\n",
      "top10\n",
      "护妻\n",
      "迪丽\n",
      "竟入\n",
      "戏太深\n",
      "架苏\n",
      "美媒\n",
      "全灭\n",
      "要逆袭\n",
      "博越\n",
      "首谈\n",
      "八种\n",
      "个小妙\n",
      "八名\n",
      "岁迪丽\n",
      "没颈纹\n",
      "超好\n",
      "谣造\n",
      "两任\n",
      "过成\n",
      "狠批\n",
      "天竟\n",
      "致肝\n",
      "跪地\n",
      "外养\n",
      "拉鸡山\n",
      "爆光\n",
      "2g\n",
      "2k\n",
      "机皇\n",
      "万罐\n",
      "速减\n",
      "说治\n",
      "赛鹿\n",
      "误当\n",
      "一斤\n",
      "上万倍\n",
      "名埃\n",
      "疑因\n",
      "一人\n",
      "越出\n",
      "周晒\n",
      "千万只\n",
      "常吃能\n",
      "天暴\n",
      "吃变\n",
      "女宝下\n",
      "上长\n",
      "太暖心\n",
      "战狼\n",
      "遭酸\n",
      "终说\n",
      "marin\n",
      "flyme7\n",
      "收评\n",
      "十次\n",
      "粘手\n",
      "寻药\n",
      "此方\n",
      "三人以\n",
      "不长心\n",
      "赌石\n",
      "指中\n",
      "淘来\n",
      "一百多万\n",
      "人设\n",
      "爆其\n",
      "多岁\n",
      "味药\n",
      "消平\n",
      "太绝\n",
      "数月\n",
      "脸圆腰\n",
      "已怀\n",
      "大到\n",
      "别乱\n",
      "防三高\n",
      "抗衰\n",
      "长斑\n",
      "一脸\n",
      "岁景\n",
      "甜素颜\n",
      "张继科会\n",
      "迎取\n",
      "吃点\n",
      "其女\n",
      "发博\n",
      "八个\n",
      "可值\n",
      "几亿\n",
      "烟友\n",
      "倒店\n",
      "溺亡\n",
      "藏得\n",
      "大涨\n",
      "刚到\n",
      "闪嫁\n",
      "地将值\n",
      "没敢\n",
      "要生\n",
      "车晓曾\n",
      "获上\n",
      "并配\n",
      "女主\n",
      "显瘦\n",
      "暂退\n",
      "疑遭\n",
      "3cm\n",
      "爆瘦\n",
      "只爱过\n",
      "只过\n",
      "几小时\n",
      "仅售\n",
      "n7\n",
      "4280mah\n",
      "一加\n",
      "天期\n",
      "玲花\n",
      "天美白\n",
      "天秀\n",
      "入上\n",
      "大呼\n",
      "赚大\n",
      "黄渤搭戏\n",
      "曝两人\n",
      "岁玲花\n",
      "亿险\n",
      "对林丹\n",
      "婚内\n",
      "豪车\n",
      "女宝\n",
      "六个月\n",
      "无戏\n",
      "生下白\n",
      "大晒\n",
      "网骗\n",
      "长得帅\n",
      "显嫩\n",
      "脸成\n",
      "同款\n",
      "岁罗晋\n",
      "万提\n",
      "q5\n",
      "x3\n",
      "出男宝\n",
      "我怀\n",
      "亿刘涛\n",
      "比安迪\n",
      "终官\n",
      "两人\n",
      "岁秋瓷\n",
      "两岁\n",
      "陈妈妈\n",
      "中以\n",
      "新戏\n",
      "神准\n",
      "接女宝\n",
      "手往\n",
      "首台\n",
      "不嫁\n",
      "3d\n",
      "称遭\n",
      "后近\n",
      "3vbike\n",
      "求摩拜\n",
      "留口\n",
      "3x3\n",
      "扫空\n",
      "奇快\n",
      "全掉\n",
      "美白法\n",
      "排肝\n",
      "毒防\n",
      "种水\n",
      "亿买\n",
      "中现\n",
      "雨过\n",
      "灵触\n",
      "如碳\n",
      "支个\n",
      "甩脂\n",
      "天掉\n",
      "大超\n",
      "调身\n",
      "大食材\n",
      "超火\n",
      "出小蛮\n",
      "加一物\n",
      "一片\n",
      "宝妈们\n",
      "当水\n",
      "要长\n",
      "王凤雅\n",
      "两娃\n",
      "两胎\n",
      "孕中\n",
      "不愈\n",
      "个妙\n",
      "李晨要\n",
      "招教\n",
      "一只\n",
      "几枚\n",
      "降分\n",
      "行认\n",
      "认贷\n",
      "首套\n",
      "小半碗\n",
      "一喝\n",
      "次胎\n",
      "怀男宝\n",
      "款神\n",
      "几块钱\n",
      "人速\n",
      "胖要\n",
      "感强\n",
      "多吃点\n",
      "往外\n",
      "一步\n",
      "别往\n",
      "想升\n",
      "特爱\n",
      "系胡歌\n",
      "敲碗\n",
      "附股\n",
      "早评\n",
      "一升\n",
      "附男\n",
      "信融\n",
      "贷后\n",
      "p2p\n",
      "多名\n",
      "竟称\n",
      "理不直\n",
      "胖女\n",
      "胖姐\n",
      "喜怀\n",
      "第三胎\n",
      "当妈\n",
      "抹点\n",
      "百件\n",
      "各瘦\n",
      "七个\n",
      "亲上\n",
      "肚凸\n",
      "现狂\n",
      "鲍蕾素\n",
      "换辆\n",
      "这招\n",
      "刘谦近\n",
      "火遍\n",
      "大s\n",
      "微凸\n",
      "丑到\n",
      "辣眼\n",
      "十八岁\n",
      "陈坤忍\n",
      "暗淡淡\n",
      "翁帆近\n",
      "二人\n",
      "同框\n",
      "竟有\n",
      "密恋\n",
      "照秀\n",
      "一句\n",
      "抢食\n",
      "最想\n",
      "不晒\n",
      "比谢娜\n",
      "不婚\n",
      "快本\n",
      "何炅首\n",
      "三次\n",
      "迅素颜\n",
      "真拼\n",
      "港媒\n",
      "其要\n",
      "要怀\n",
      "第四胎\n",
      "别生\n",
      "竟长\n",
      "曝出\n",
      "心如\n",
      "不输\n",
      "一首歌\n",
      "泪崩\n",
      "晒孕\n",
      "前唱\n",
      "这首\n",
      "甜死\n",
      "二代\n",
      "一锅\n",
      "用常\n",
      "红妹\n",
      "脚时\n",
      "毛宁会\n",
      "已见\n",
      "之子\n",
      "抢镜\n",
      "曝怀\n",
      "再怀\n",
      "喜当爹\n",
      "挺个\n",
      "鲁豫近\n",
      "岁鲁豫\n",
      "不生\n",
      "寻旧\n",
      "爱后\n",
      "今傍上\n",
      "一顿\n",
      "十粒\n",
      "被洋\n",
      "今嫁\n",
      "找旧\n",
      "绿到\n",
      "英田震\n",
      "推其\n",
      "疑追生\n",
      "一胖毁\n",
      "四胎\n",
      "给力\n",
      "张伦硕要\n",
      "有颗\n",
      "一事\n",
      "字疑\n",
      "而暴\n",
      "遭吐槽\n",
      "根真\n",
      "得癌\n",
      "想花\n",
      "亿要\n",
      "一地\n",
      "挺孕肚\n",
      "张伦硕生\n",
      "曝有\n",
      "检科\n",
      "疑再\n",
      "做产检\n",
      "传怀\n",
      "微隆嘟\n",
      "疑有\n",
      "美魔\n",
      "皮膚\n",
      "一樣\n",
      "原來\n",
      "锋芝\n",
      "今长\n",
      "4s店\n",
      "一辆车\n",
      "更准\n",
      "带血\n",
      "前有\n",
      "这包\n",
      "亿顶薪\n",
      "泡过\n",
      "自拍\n",
      "王俊凯易\n",
      "千玺\n",
      "饭圈\n",
      "已生\n",
      "日生\n",
      "速看\n",
      "科一科\n",
      "扫码\n",
      "没考\n",
      "日驾\n",
      "两天\n",
      "一轮\n",
      "十种\n",
      "不爱\n",
      "认房\n",
      "没人敢\n",
      "别不信\n",
      "好膚色\n",
      "太脏\n",
      "几斤\n",
      "传好孕\n",
      "男未\n",
      "秀逆\n",
      "早参\n",
      "药明\n",
      "万起售\n",
      "三款\n",
      "500kv\n",
      "这张\n",
      "元变\n",
      "裸车\n",
      "比贵\n",
      "好几万\n",
      "顶配\n",
      "更显\n",
      "㊙\n",
      "种饭\n",
      "尝后\n",
      "仅用\n",
      "加一宝\n",
      "第三次\n",
      "没斑\n",
      "大着\n",
      "一语\n",
      "抵港\n",
      "遭破\n",
      "引群愤\n",
      "没半\n",
      "话表\n",
      "败光霆锋\n",
      "惹人怜\n",
      "壮如牛\n",
      "三胞眙\n",
      "没长\n",
      "暴饮\n",
      "晒照\n",
      "英遭\n",
      "一股\n",
      "一袋\n",
      "人知\n",
      "曝靠\n",
      "张凯丽\n",
      "超巨\n",
      "这队\n",
      "朱之文大婚\n",
      "遇朱\n",
      "遭爆\n",
      "细滑\n",
      "再添\n",
      "曝犯\n",
      "田震近\n",
      "曾红过\n",
      "三句话\n",
      "腰细\n",
      "一支\n",
      "几颗\n",
      "已立\n",
      "美不回\n",
      "这三物\n",
      "上放\n",
      "一曲\n",
      "哭红\n",
      "当爹\n",
      "抛妻\n",
      "华仔要\n",
      "因爱\n",
      "计春华\n",
      "一壶\n",
      "演了\n",
      "开卢本伟\n",
      "开挂\n",
      "开复播\n",
      "有个\n",
      "当爸\n",
      "恐将\n",
      "几十年\n",
      "不改\n",
      "三段\n",
      "小香玉\n",
      "需人\n",
      "亿美元\n",
      "烟不离\n",
      "撞场\n",
      "因撞场\n",
      "十人\n",
      "后气\n",
      "竟全\n",
      "因女\n",
      "美翻\n",
      "三大悔\n",
      "人后\n",
      "三大悔害\n",
      "很拉风\n",
      "排肝毒\n",
      "一万个\n",
      "涨近\n",
      "瞄上\n",
      "半斤\n",
      "暴汗\n",
      "代餐\n",
      "降三高\n",
      "不需\n",
      "陈毒\n",
      "暴多\n",
      "天前\n",
      "能买白\n",
      "超赞\n",
      "过生日\n",
      "几分钟\n",
      "竟因\n",
      "几例\n",
      "组四\n",
      "龙之手\n",
      "激吻\n",
      "一横\n",
      "两纵\n",
      "我治好\n",
      "十多年\n",
      "度尾\n",
      "日晚\n",
      "成失联\n",
      "失联\n",
      "170423\n",
      "换新证\n",
      "币王\n",
      "日助\n",
      "涨助\n",
      "或大涨\n",
      "长高\n",
      "药食\n",
      "荤素\n",
      "榜来\n",
      "菜王\n",
      "开塞路\n",
      "般美白\n",
      "再贵\n",
      "要少\n",
      "种天然\n",
      "益脑\n",
      "紧止\n",
      "第四种\n",
      "太多人\n",
      "速止\n",
      "机模\n",
      "双摄\n",
      "瞬秒\n",
      "双待\n",
      "活婴\n",
      "假卡\n",
      "别买\n",
      "60v\n",
      "试下\n",
      "天狂\n",
      "笔账\n",
      "600km\n",
      "三任\n",
      "为争\n",
      "今成\n",
      "曝刷单\n",
      "撕逼战\n",
      "刷单\n",
      "各打\n",
      "反刷单\n",
      "单争\n",
      "无子\n",
      "越长越\n",
      "不像\n",
      "术后\n",
      "几万元\n",
      "天破\n",
      "亲民价\n",
      "iphone8\n",
      "雪近\n",
      "关牧村\n",
      "重瑞\n",
      "当宝\n",
      "丢过\n",
      "这一波\n",
      "6o\n",
      "万块\n",
      "田黄石\n",
      "克重\n",
      "大漏\n",
      "改款\n",
      "万美元\n",
      "个怀\n",
      "非顶\n",
      "能信\n",
      "四五天\n",
      "带盖\n",
      "天已\n",
      "岁会\n",
      "同吃\n",
      "瘦肚\n",
      "一朝\n",
      "热评\n",
      "重剪\n",
      "过千\n",
      "分将\n",
      "方代扣\n",
      "市卫\n",
      "微信里\n",
      "有项\n",
      "一金\n",
      "六险\n",
      "二金\n",
      "越减\n",
      "越肥\n",
      "回鍋\n",
      "加熱會\n",
      "接者\n",
      "必中\n",
      "乐坏\n",
      "网传\n",
      "百出\n",
      "几岁\n",
      "还生\n",
      "活成\n",
      "黑如碳\n",
      "撞树\n",
      "成股\n",
      "肤白\n",
      "曝因\n",
      "之事要\n",
      "7o\n",
      "宝妈愁\n",
      "亲证\n",
      "天治\n",
      "只花\n",
      "狠击\n",
      "高颜值\n",
      "后驱\n",
      "一键\n",
      "日到\n",
      "翔方\n",
      "日交\n",
      "泪目\n",
      "全限行\n",
      "及交\n",
      "更难\n",
      "更贵\n",
      "亿宝粉\n",
      "加量\n",
      "不瘦\n",
      "成本增加\n",
      "一倍\n",
      "两点\n",
      "有款\n",
      "大屏\n",
      "抗雾\n",
      "鸡村\n",
      "撞飞\n",
      "因為\n",
      "多吨\n",
      "多斤\n",
      "五千元\n",
      "不染\n",
      "天发质\n",
      "明显改善\n",
      "一出场\n",
      "谢贤为\n",
      "谢贤令\n",
      "称靠\n",
      "行逆驶\n",
      "如虎\n",
      "已选好\n",
      "竟获\n",
      "太像\n",
      "二顿\n",
      "这油\n",
      "称受\n",
      "神帮\n",
      "疑欠\n",
      "藏友\n",
      "三倍\n",
      "能卖\n",
      "个赞\n",
      "一包\n",
      "四城\n",
      "限贷\n",
      "吸脂水\n",
      "几千块\n",
      "天治根\n",
      "药不离口\n",
      "祛燥\n",
      "mp4\n",
      "十个\n",
      "九个\n",
      "疯降\n",
      "茶用\n",
      "熏过\n",
      "别约考\n",
      "麻将馆\n",
      "没车\n",
      "日选\n",
      "股宝\n",
      "铁总下\n",
      "混改\n",
      "已死\n",
      "三人\n",
      "别逗\n",
      "更能\n",
      "旺财\n",
      "配它\n",
      "就行\n",
      "曝恋童\n",
      "胎停\n",
      "岁成\n",
      "10kg\n",
      "穿靓靓\n",
      "用深\n",
      "增肌\n",
      "后辣妈\n",
      "五分钟\n",
      "两桶\n",
      "一听\n",
      "气到\n",
      "要加\n",
      "他演\n",
      "后宝妈\n",
      "曝翁帆\n",
      "如初\n",
      "盒烟\n",
      "斤且\n",
      "印反\n",
      "韩红泪\n",
      "一件\n",
      "两倍\n",
      "因跳\n",
      "三招\n",
      "这菜\n",
      "胖成\n",
      "腰突\n",
      "首同框\n",
      "买婚\n",
      "房同\n",
      "车内别\n",
      "助眠\n",
      "sk5\n",
      "超玩会\n",
      "脸书\n",
      "atfx\n",
      "aiili\n",
      "快用\n",
      "为演\n",
      "不带\n",
      "痛批\n",
      "高到\n",
      "一买\n",
      "入摩\n",
      "大变盘\n",
      "支股\n",
      "十支\n",
      "三支\n",
      "第三只\n",
      "压身\n",
      "没退\n",
      "巨亏\n",
      "万股\n",
      "本周\n",
      "九只\n",
      "之势\n",
      "慢牛\n",
      "反涨\n",
      "股将\n",
      "两日\n",
      "这条线\n",
      "只股\n",
      "必超\n",
      "带七架\n",
      "和宙\n",
      "斯盾舰\n",
      "b20\n",
      "水喝\n",
      "为防\n",
      "脱猫\n",
      "这撞\n",
      "脸迪丽\n",
      "杨颖假\n",
      "五次\n",
      "对戏\n",
      "没带\n",
      "binance\n",
      "chiliz\n",
      "b股\n",
      "这波\n",
      "猜个\n",
      "女翻\n",
      "孕妈们\n",
      "c919\n",
      "第一战\n",
      "丁彦雨航\n",
      "新四字\n",
      "首周\n",
      "cctv2\n",
      "股遭\n",
      "五支\n",
      "已过\n",
      "版要\n",
      "手游帅\n",
      "抽烈\n",
      "48h\n",
      "终可\n",
      "一词\n",
      "coinpark\n",
      "万个\n",
      "curr\n",
      "nutr\n",
      "罗恼\n",
      "梅西夺\n",
      "二世\n",
      "小女儿\n",
      "断食法\n",
      "大疆\n",
      "郑重声明\n",
      "欧皇别\n",
      "狗托\n",
      "买卓伟\n",
      "旧照\n",
      "韬疑\n",
      "f22\n",
      "数十枚\n",
      "fanbeauty\n",
      "仪短\n",
      "googl\n",
      "一接\n",
      "fattal\n",
      "android80\n",
      "g20\n",
      "g45\n",
      "大广\n",
      "锦山段\n",
      "宇补位\n",
      "gjsay\n",
      "光晶\n",
      "goldwell\n",
      "可卖\n",
      "狗哥\n",
      "宋智孝要\n",
      "h7n9\n",
      "第八\n",
      "刘明婷\n",
      "老谣\n",
      "hopkins\n",
      "lab2\n",
      "se2\n",
      "不低\n",
      "越晚\n",
      "疑退赛\n",
      "姐好\n",
      "惨失\n",
      "杨茁\n",
      "魏锐\n",
      "s7\n",
      "卓伟渐\n",
      "却造\n",
      "食全食\n",
      "说怕\n",
      "首麦词\n",
      "我爱过\n",
      "喊麦\n",
      "摧人泪\n",
      "白睡\n",
      "爆涨\n",
      "retina15\n",
      "长痘\n",
      "mate9\n",
      "milkshake\n",
      "告別\n",
      "腎病\n",
      "多处\n",
      "亿万年\n",
      "前毁\n",
      "人发\n",
      "用手\n",
      "nba2k\n",
      "绿军\n",
      "g3\n",
      "亿美金\n",
      "二换\n",
      "nbl\n",
      "nejm\n",
      "note7\n",
      "nub\n",
      "自降\n",
      "遭拒\n",
      "o2o\n",
      "美团\n",
      "r11\n",
      "r13\n",
      "r15\n",
      "人买\n",
      "这串\n",
      "ocumetics\n",
      "presto\n",
      "o型\n",
      "个土\n",
      "捕蚊\n",
      "人活\n",
      "厂敬鹏\n",
      "平镇厂\n",
      "sng\n",
      "pg1400\n",
      "人红\n",
      "致其\n",
      "并弃\n",
      "万请\n",
      "薛之谦人设\n",
      "不背\n",
      "解绑\n",
      "qq号\n",
      "这得\n",
      "rav4\n",
      "这趟\n",
      "多贵\n",
      "resellerclub\n",
      "sk6\n",
      "致人\n",
      "snh48\n",
      "灌票\n",
      "团内\n",
      "曝让\n",
      "曾艳芬力\n",
      "取关\n",
      "水太深\n",
      "莫柔米\n",
      "三家\n",
      "疑王俊凯\n",
      "条路\n",
      "最红\n",
      "签走\n",
      "唯饭\n",
      "齐喊\n",
      "却求\n",
      "第二场\n",
      "王源易\n",
      "传王俊凯\n",
      "之约\n",
      "疑要\n",
      "令弃\n",
      "tfb\n",
      "宋祖儿\n",
      "tfbys\n",
      "三小只\n",
      "秀太\n",
      "小可爱\n",
      "王俊凯交\n",
      "吻照\n",
      "再开\n",
      "太雷人\n",
      "付不起\n",
      "没人要\n",
      "浩信\n",
      "疯传\n",
      "要火\n",
      "u23\n",
      "空到\n",
      "已达\n",
      "三微\n",
      "博向\n",
      "小鹏\n",
      "b轮\n",
      "人臨\n",
      "驚人\n",
      "到史\n",
      "2017ufo\n",
      "乐寿寺\n",
      "一座\n",
      "vol98\n",
      "evus\n",
      "比换\n",
      "wpa3\n",
      "wetool\n",
      "淳恩\n",
      "甜得\n",
      "断网\n",
      "按下\n",
      "要关\n",
      "一扫\n",
      "第二种\n",
      "我来\n",
      "几招\n",
      "莫雷欲\n",
      "曝新料\n",
      "xc90\n",
      "数千\n",
      "遭某\n",
      "茶余\n",
      "根能\n",
      "霸戏\n",
      "超像\n",
      "angelbaby\n",
      "护子\n",
      "发微博\n",
      "这点\n",
      "陈赫车\n",
      "晓明哥\n",
      "真是太\n",
      "照首\n",
      "改个\n",
      "话亮\n",
      "贴妈\n",
      "生个\n",
      "两部\n",
      "戏霸\n",
      "返港\n",
      "辞演\n",
      "多到\n",
      "六个\n",
      "狂打\n",
      "能花\n",
      "包假\n",
      "博称\n",
      "微博称\n",
      "素颜美到\n",
      "可破\n",
      "被迪丽\n",
      "感足\n",
      "露正脸\n",
      "爹帅\n",
      "超单\n",
      "beyong\n",
      "elife\n",
      "甩肉\n",
      "糖寿\n",
      "一到\n",
      "三斤\n",
      "神锋\n",
      "绝平\n",
      "ios7\n",
      "向安卓\n",
      "s8\n",
      "很丑\n",
      "note8\n",
      "之高\n",
      "4gb\n",
      "低配\n",
      "太漂亮\n",
      "5s\n",
      "手图\n",
      "p20\n",
      "一台\n",
      "竟配\n",
      "d33\n",
      "s9\n",
      "后壳\n",
      "却史\n",
      "leagoo\n",
      "版谍\n",
      "p11\n",
      "第二代\n",
      "jdi\n",
      "iphone6s\n",
      "r9s\n",
      "iphone6\n",
      "奇高\n",
      "快充\n",
      "mix2\n",
      "心好\n",
      "真机照\n",
      "超神\n",
      "遭疯\n",
      "mate10\n",
      "哪台\n",
      "iphone9\n",
      "iphonexi\n",
      "a12\n",
      "单摄\n",
      "3gb\n",
      "真卖\n",
      "要慢\n",
      "1080p\n",
      "不买\n",
      "x20\n",
      "屏加\n",
      "三摄\n",
      "推多\n",
      "扒光\n",
      "屏国行\n",
      "屏稳\n",
      "xplus\n",
      "起售\n",
      "8p\n",
      "变大到\n",
      "变单\n",
      "a10\n",
      "有电\n",
      "不刷机\n",
      "红米\n",
      "5a\n",
      "前二\n",
      "版微信\n",
      "iphone218\n",
      "lifestone\n",
      "klp\n",
      "mh370\n",
      "引热议\n",
      "韩货\n",
      "摩拜\n",
      "几万几十万\n",
      "张巳丁谈\n",
      "之初\n",
      "喜忧\n",
      "或超\n",
      "2600w\n",
      "已超\n",
      "亿左右\n",
      "更传\n",
      "百万美元\n",
      "一串\n",
      "用久\n",
      "删点\n",
      "万磁王\n",
      "恐成\n",
      "qeemoo\n",
      "群慕\n",
      "lotte\n",
      "x9\n",
      "imx376\n",
      "xplay6\n",
      "vivox21\n",
      "v9\n",
      "大招\n",
      "曝新\n",
      "隔空\n",
      "再用\n",
      "xplay7\n",
      "不卡\n",
      "不给力\n",
      "一秒\n",
      "好用\n",
      "win7\n",
      "霉霉\n",
      "個民間\n",
      "簡單\n",
      "好學\n",
      "經濟\n",
      "實用\n",
      "留著\n",
      "致国足\n",
      "如葱\n",
      "50aa\n",
      "许多次\n",
      "一孕\n",
      "一指弹\n",
      "一滴\n",
      "获批\n",
      "三响\n",
      "一苗\n",
      "断货\n",
      "七大邪\n",
      "更要\n",
      "中有\n",
      "之王\n",
      "不老\n",
      "一脚\n",
      "反打\n",
      "橙王\n",
      "中盐\n",
      "会致\n",
      "几百万\n",
      "落汤机\n",
      "乐视块\n",
      "几代人\n",
      "乐视致\n",
      "视智家\n",
      "传疯\n",
      "要花\n",
      "健腹\n",
      "以形\n",
      "补形\n",
      "背控\n",
      "h5\n",
      "长祝剑\n",
      "网谣\n",
      "冬吃\n",
      "夏吃\n",
      "参汤\n",
      "隐翅虫\n",
      "前长\n",
      "刘明炜\n",
      "请别\n",
      "狠扇\n",
      "外媒\n",
      "九年\n",
      "实车\n",
      "多台\n",
      "大有\n",
      "要步\n",
      "七种\n",
      "微博晒\n",
      "出俩\n",
      "却亮\n",
      "长有\n",
      "呆萌\n",
      "防霾\n",
      "瑞不爱\n",
      "听美\n",
      "看美\n",
      "重瑞首\n",
      "搬口\n",
      "黑鸟\n",
      "爱上你\n",
      "多味\n",
      "火币\n",
      "揭营收\n",
      "无钱\n",
      "获刑\n",
      "多家\n",
      "比新\n",
      "朱之文发\n",
      "姐在\n",
      "朱之文疑\n",
      "终不敌\n",
      "狼虎\n",
      "过情\n",
      "戒疑\n",
      "女戏\n",
      "越能\n",
      "女版\n",
      "女美娘\n",
      "丑母\n",
      "寻得\n",
      "竟花\n",
      "多钱\n",
      "又现\n",
      "全部遭\n",
      "蒋欣称\n",
      "谜案\n",
      "曝是\n",
      "最靠\n",
      "多校\n",
      "孙小头\n",
      "急寻\n",
      "你别\n",
      "对印\n",
      "获马云\n",
      "供到\n",
      "妙龄女\n",
      "七钱\n",
      "快播\n",
      "采儿\n",
      "毒哑\n",
      "恋童\n",
      "移物\n",
      "查微信\n",
      "一根\n",
      "三根\n",
      "能拔\n",
      "挂杯\n",
      "前要\n",
      "方共出\n",
      "万余元\n",
      "大张伟\n",
      "捂秋冻\n",
      "只服\n",
      "这群\n",
      "却力\n",
      "韩红唱\n",
      "第三种\n",
      "第一名\n",
      "脑洞\n",
      "大开\n",
      "说成\n",
      "迷晕\n",
      "搬空\n",
      "桃饱\n",
      "五套\n",
      "太红\n",
      "能防\n",
      "毒中\n",
      "比公\n",
      "而成\n",
      "注胶\n",
      "杰森莫玛\n",
      "毒过\n",
      "吃蔗\n",
      "蔗毒\n",
      "塞到\n",
      "改气\n",
      "气改\n",
      "改电\n",
      "两段\n",
      "腰法\n",
      "万手\n",
      "八句\n",
      "用前\n",
      "五成\n",
      "将发\n",
      "之死\n",
      "诈捐\n",
      "万来治\n",
      "玛卡\n",
      "曹德旺\n",
      "碱孕宝\n",
      "算好\n",
      "生蛇\n",
      "围腰\n",
      "一圈\n",
      "离死\n",
      "男翻\n",
      "率达\n",
      "十根\n",
      "百辆\n",
      "热传\n",
      "恋上\n",
      "做过\n",
      "能治\n",
      "穷养\n",
      "租购\n",
      "同权\n",
      "苏州人\n",
      "第一批\n",
      "养完\n",
      "红冻\n",
      "翰爽\n",
      "爽爸\n",
      "一回\n",
      "开罚\n",
      "十笔\n",
      "反增\n",
      "杯会\n",
      "亿增持\n",
      "赵丽颖成\n",
      "要慎\n",
      "一壁\n",
      "收不付\n",
      "它加\n",
      "系不实\n",
      "第一案\n",
      "蟹膏\n",
      "代指\n",
      "本是\n",
      "打四针\n",
      "视帝\n",
      "已大涨\n",
      "七成\n",
      "三大救市\n",
      "爆错料\n",
      "因伤\n",
      "小骨\n",
      "百艘\n",
      "个群\n",
      "辱母\n",
      "这药\n",
      "一闻\n",
      "喝易\n",
      "喝会\n",
      "酸儿\n",
      "辣女\n",
      "锋菲恋\n",
      "豪到\n",
      "第一炮\n",
      "炮首幕\n",
      "会成\n",
      "顶花\n",
      "撒药治虫\n",
      "饭不香\n",
      "能治好\n",
      "多病\n",
      "前十\n",
      "一顶\n",
      "走多远\n",
      "鱼疗\n",
      "脚放点\n",
      "路人遇\n",
      "发质\n",
      "之夜\n",
      "一文\n",
      "專家\n",
      "建議\n",
      "否則\n",
      "gta6\n",
      "一百岁\n",
      "七仙女\n",
      "演紫儿\n",
      "赵丽颖演\n",
      "董永由\n",
      "出剧版\n",
      "遛粉\n",
      "拍剧版\n",
      "男主\n",
      "三生\n",
      "三世\n",
      "男夜华\n",
      "疑怀\n",
      "迪丽热\n",
      "赵又廷成\n",
      "一波\n",
      "我伦\n",
      "这回\n",
      "rappper\n",
      "一夏\n",
      "有嘻哈\n",
      "放山\n",
      "曝双\n",
      "由复联\n",
      "菜破\n",
      "晏出\n",
      "纪凌尘\n",
      "太作\n",
      "不演\n",
      "弃剧\n",
      "不干\n",
      "他来\n",
      "达康\n",
      "比上\n",
      "平竟\n",
      "三位\n",
      "为沙\n",
      "男主大\n",
      "太强\n",
      "图看\n",
      "第二部\n",
      "民义\n",
      "女主则\n",
      "女主迪丽\n",
      "男主比\n",
      "女主小\n",
      "七岁\n",
      "诗为\n",
      "兄成\n",
      "男主似\n",
      "拒演\n",
      "余罪\n",
      "看颖宝\n",
      "靠蹭秀\n",
      "大改\n",
      "胡歌迪丽\n",
      "传因\n",
      "游无九景\n",
      "孟美岐\n",
      "建官博\n",
      "美岐\n",
      "爆有\n",
      "两遍\n",
      "丑炸天\n",
      "后衣品\n",
      "达叔\n",
      "亿对\n",
      "赌协\n",
      "染回\n",
      "一票\n",
      "演打戏\n",
      "光有\n",
      "火云\n",
      "能超\n",
      "主已定\n",
      "功守道\n",
      "请包\n",
      "黄渤王\n",
      "破战\n",
      "这要\n",
      "徐峥弃\n",
      "弃用\n",
      "用包\n",
      "势要\n",
      "黄渤组\n",
      "黄渤三贱\n",
      "上影\n",
      "热议\n",
      "黄渤宝强\n",
      "再聚\n",
      "三角回归\n",
      "一周年\n",
      "哪有\n",
      "陈世妍\n",
      "陈世妍疑\n",
      "未至\n",
      "追剧\n",
      "男主是\n",
      "咖齐\n",
      "改档\n",
      "金恩淑爆\n",
      "忍伤\n",
      "官宣迪丽\n",
      "胖迪录\n",
      "难组\n",
      "三宗\n",
      "撒狗\n",
      "鹿晗会\n",
      "怒喊\n",
      "几秒\n",
      "两家\n",
      "李晨成\n",
      "胖迪\n",
      "一刀\n",
      "完嘛\n",
      "变周播\n",
      "剧定\n",
      "定挡\n",
      "天连放\n",
      "集疯\n",
      "传网\n",
      "周播\n",
      "狂吐槽\n",
      "未播\n",
      "先红\n",
      "它会\n",
      "剧要\n",
      "未过\n",
      "将定\n",
      "甩锅\n",
      "不播\n",
      "独播\n",
      "第四次\n",
      "集播\n",
      "要定\n",
      "八集\n",
      "曝变\n",
      "孤芳\n",
      "人的尬\n",
      "做富\n",
      "fc54116\n",
      "换作\n",
      "巴清传\n",
      "难上\n",
      "翔要\n",
      "换脸\n",
      "杨洋别\n",
      "肖奈贝\n",
      "女主后\n",
      "女主换\n",
      "郑爽接\n",
      "演贝\n",
      "男二\n",
      "杨洋会\n",
      "弃演\n",
      "造娃\n",
      "二十年\n",
      "何炅泪\n",
      "其会\n",
      "选他\n",
      "因张\n",
      "因谢娜\n",
      "雨蒙蒙\n",
      "女三\n",
      "书桓\n",
      "要演\n",
      "拒台媒\n",
      "药神\n",
      "炒火\n",
      "第三季\n",
      "郑爽颖宝\n",
      "撒糖\n",
      "赵丽颖丁\n",
      "一宇组\n",
      "郑爽组\n",
      "携几对\n",
      "第四季\n",
      "爱豆\n",
      "多位\n",
      "遭疑\n",
      "因虐\n",
      "童罪\n",
      "认马伊\n",
      "女主引\n",
      "君换\n",
      "子君\n",
      "演罗子\n",
      "太火\n",
      "关微博\n",
      "三日\n",
      "早不来\n",
      "确说\n",
      "大卖\n",
      "很燃\n",
      "亿登\n",
      "黑惨\n",
      "爆红\n",
      "四家\n",
      "告上\n",
      "需赔\n",
      "一份\n",
      "吴京四字\n",
      "好会选\n",
      "就免\n",
      "过审\n",
      "用小新肉\n",
      "吴京放话\n",
      "人想\n",
      "吴京仅\n",
      "晏段\n",
      "宏唐\n",
      "愿零\n",
      "就服\n",
      "三分\n",
      "必火\n",
      "吴京因\n",
      "退演\n",
      "第四位\n",
      "男配\n",
      "放狠话\n",
      "跌眼\n",
      "别来\n",
      "任天野\n",
      "太给力\n",
      "必破\n",
      "女主是\n",
      "吴京选\n",
      "吴京余\n",
      "强张\n",
      "马蓉力\n",
      "段宏毅\n",
      "晏定\n",
      "卢靖姗任\n",
      "中霍\n",
      "戰狼\n",
      "年開\n",
      "鄧超\n",
      "擔任\n",
      "將開\n",
      "唐嫣將\n",
      "吳京\n",
      "停拍\n",
      "吴京早\n",
      "斗破\n",
      "新情\n",
      "养蛙\n",
      "追定\n",
      "萝莉脸\n",
      "装不输\n",
      "旗装\n",
      "比岳\n",
      "落个\n",
      "张显宗\n",
      "小红\n",
      "中张\n",
      "一山\n",
      "凤九竟\n",
      "女二竟\n",
      "凄慘\n",
      "因楚乔\n",
      "赵丽颖神\n",
      "赵丽颖林\n",
      "马蓉要\n",
      "演楚\n",
      "乔传\n",
      "男主林\n",
      "还帅\n",
      "女主定\n",
      "共续\n",
      "星玥\n",
      "和颖宝\n",
      "竟换\n",
      "五美\n",
      "第三部\n",
      "五美缺\n",
      "齐聚五美\n",
      "没少\n",
      "五美聚\n",
      "五美难\n",
      "之战\n",
      "十位\n",
      "要划\n",
      "一季\n",
      "似发\n",
      "频遇\n",
      "王莎莎要\n",
      "2sb500\n",
      "退片\n",
      "准妈\n",
      "因戏\n",
      "戏外\n",
      "浙卫\n",
      "群嘲\n",
      "袁立开\n",
      "怒批\n",
      "条微\n",
      "博手\n",
      "浙卫发\n",
      "只留\n",
      "袁立手\n",
      "要凉\n",
      "遭众\n",
      "思谈\n",
      "陈立农\n",
      "曝单\n",
      "开录\n",
      "文千玺\n",
      "靳东景\n",
      "除易\n",
      "孕肚\n",
      "赵丽颖为\n",
      "养狗\n",
      "空天猎\n",
      "围有雷\n",
      "之责\n",
      "双男主\n",
      "助演\n",
      "晒出\n",
      "启月\n",
      "会换\n",
      "要弃剧\n",
      "还强\n",
      "一万倍\n",
      "链热\n",
      "因不敌\n",
      "只爱\n",
      "这剧\n",
      "女主竟\n",
      "嘴下\n",
      "演杀\n",
      "男主霍\n",
      "诗来\n",
      "一出\n",
      "饰子\n",
      "女主小骨\n",
      "李沁来\n",
      "糖宝\n",
      "演小骨\n",
      "版小骨\n",
      "非鹿晗\n",
      "由迪丽\n",
      "之大\n",
      "当不了\n",
      "房差\n",
      "不骂\n",
      "爱豆们\n",
      "之恋\n",
      "两人会\n",
      "若干年\n",
      "秘客\n",
      "后星爷\n",
      "七季\n",
      "第九集\n",
      "刀女\n",
      "群杀\n",
      "行尸\n",
      "迅音\n",
      "退剧\n",
      "陈赫终\n",
      "最尬\n",
      "范丞丞\n",
      "男患\n",
      "第一站\n",
      "男六\n",
      "细思极\n",
      "川普当\n",
      "真该\n",
      "冲得\n",
      "打一星\n",
      "评一星\n",
      "圣贤书\n",
      "唐嫣任\n",
      "e3\n",
      "二号\n",
      "想弃剧\n",
      "演女\n",
      "加戏\n",
      "马小翠近\n",
      "一女\n",
      "家驹\n",
      "百分之三十五\n",
      "添新规\n",
      "fm889\n",
      "180509\n",
      "一群\n",
      "三口\n",
      "第一家\n",
      "违停\n",
      "下道\n",
      "谈竟\n",
      "照谣\n",
      "出户\n",
      "环乌\n",
      "养肝护\n",
      "再乱\n",
      "一堆\n",
      "惊出\n",
      "稳糖\n",
      "五块\n",
      "亏惨\n",
      "两千年\n",
      "江西人\n",
      "喝才\n",
      "数名\n",
      "只卖\n",
      "少吃肉\n",
      "不疼\n",
      "穿涼鞋\n",
      "買點\n",
      "貨塗塗\n",
      "腳丫恢\n",
      "天检荐\n",
      "无癌\n",
      "安娃\n",
      "多会\n",
      "遭抖音\n",
      "为空\n",
      "小编\n",
      "币圈\n",
      "币安\n",
      "带膏\n",
      "三组\n",
      "一箭\n",
      "竖纹\n",
      "辉凉\n",
      "六款\n",
      "妻且\n",
      "提莫\n",
      "履蛋收\n",
      "更多人\n",
      "撷珍\n",
      "发大招\n",
      "美女秀\n",
      "能怪\n",
      "瘦腿术\n",
      "白頭\n",
      "有解\n",
      "八個\n",
      "食療\n",
      "沒幾天\n",
      "回來\n",
      "百日\n",
      "疯转\n",
      "知食\n",
      "寿字币\n",
      "广等\n",
      "纤营\n",
      "撒药灭\n",
      "bp5\n",
      "三名\n",
      "爆火\n",
      "网评\n",
      "跌出\n",
      "老匠\n",
      "老鸣\n",
      "一瓣\n",
      "越香越\n",
      "闻着\n",
      "人快\n",
      "活虫\n",
      "迅解\n",
      "远成\n",
      "一幅\n",
      "静图\n",
      "图在动\n",
      "贷等\n",
      "网贷\n",
      "拒贷\n",
      "闲闻\n",
      "连跌\n",
      "54169\n",
      "吃油\n",
      "需退\n",
      "翔性\n",
      "前名\n",
      "指唐德\n",
      "李晨补\n",
      "\n",
      "不洗\n",
      "穿会\n",
      "喜大普奔\n",
      "增甜剂\n",
      "后罗\n",
      "红毯秀\n",
      "转粉\n",
      "赵丽颖称\n",
      "六类\n",
      "你生\n",
      "六人\n",
      "暴恐\n",
      "城事\n",
      "此招\n",
      "必红\n",
      "含碱\n",
      "完电不拔\n",
      "三方\n",
      "哪般\n",
      "畅姐\n",
      "最缺\n",
      "福布\n",
      "不图名\n",
      "必有\n",
      "诚寻大\n",
      "多辆\n",
      "希沃\n",
      "4g\n",
      "一毒\n",
      "美老\n",
      "就会变\n",
      "二个\n",
      "一两个\n",
      "天必\n",
      "既护\n",
      "吸粉\n",
      "人带\n",
      "太累\n",
      "千万元\n",
      "可治好\n",
      "拾文\n",
      "一栋\n",
      "教它\n",
      "省下\n",
      "前配\n",
      "一擦\n",
      "小秘方\n",
      "九条\n",
      "胡了\n",
      "二条\n",
      "四十岁\n",
      "瘦到斤\n",
      "十公斤\n",
      "七道\n",
      "一治\n",
      "天即\n",
      "三周\n",
      "速瘦\n",
      "人真会\n",
      "美哭\n",
      "尖圆\n",
      "滚一滚\n",
      "一点点\n",
      "一九五三年\n",
      "一九五\n",
      "三版\n",
      "五款\n",
      "第二次\n",
      "一个亿\n",
      "一仗\n",
      "发嫂\n",
      "六年\n",
      "泪别\n",
      "亲述\n",
      "曝买\n",
      "吃活\n",
      "线乱\n",
      "形散\n",
      "三遍\n",
      "一篇\n",
      "一個\n",
      "打麻將\n",
      "能换\n",
      "这到\n",
      "几十倍\n",
      "纸氏\n",
      "十万倍\n",
      "全仓\n",
      "此股\n",
      "看怀\n",
      "还贵\n",
      "已孕\n",
      "一剧\n",
      "5t\n",
      "成热词\n",
      "咖总\n",
      "10gb\n",
      "4k\n",
      "一勺\n",
      "十几年\n",
      "十副药\n",
      "十几种\n",
      "透白\n",
      "一卷\n",
      "太逗\n",
      "四天\n",
      "却治好\n",
      "五步\n",
      "因拍\n",
      "五日\n",
      "十日\n",
      "仙洋\n",
      "一吨\n",
      "获纯\n",
      "两罐\n",
      "五天\n",
      "全捏\n",
      "还信\n",
      "美白小妙\n",
      "大逆袭\n",
      "更配\n",
      "餐餐\n",
      "几分\n",
      "千杯\n",
      "不倒\n",
      "姜胜十副药\n",
      "球球\n",
      "万亩\n",
      "皮竟\n",
      "我信\n",
      "省造\n",
      "如换\n",
      "快来学\n",
      "拉上\n",
      "成一毒\n",
      "几次\n",
      "三餐\n",
      "两包\n",
      "十几粒\n",
      "没瘦\n",
      "一百斤\n",
      "最瘦\n",
      "五顿\n",
      "两勺\n",
      "法教\n",
      "你治好\n",
      "存好\n",
      "狂刷\n",
      "帮人\n",
      "多万元\n",
      "没掉\n",
      "nc250\n",
      "一字\n",
      "二十多\n",
      "变肥婆\n",
      "个备\n",
      "还毒\n",
      "五口\n",
      "泡发\n",
      "八口\n",
      "六口\n",
      "四口\n",
      "第一胎\n",
      "一岁\n",
      "不治而亡\n",
      "而亡\n",
      "却成\n",
      "亿抢筹\n",
      "跌至\n",
      "亿锁\n",
      "人要\n",
      "更会\n",
      "瘦下\n",
      "靠少\n",
      "一年级\n",
      "李莎旻子\n",
      "裸死\n",
      "创年\n",
      "愿出\n",
      "一百块\n",
      "几元\n",
      "刀货\n",
      "买时\n",
      "贰角\n",
      "一德\n",
      "俩头\n",
      "七年\n",
      "百副药\n",
      "一试\n",
      "手邊\n",
      "百试\n",
      "疼手\n",
      "八副药\n",
      "五楼\n",
      "五片\n",
      "留着\n",
      "用个\n",
      "为家\n",
      "专减\n",
      "胖得\n",
      "烟渍牙\n",
      "几十斤\n",
      "含铝\n",
      "永除\n",
      "排肠毒\n",
      "清宿\n",
      "健肾\n",
      "氟斑牙\n",
      "黑牙\n",
      "天有\n",
      "5gb\n",
      "比纸\n",
      "掺胶\n",
      "一换\n",
      "咔响\n",
      "一搓\n",
      "一洗\n",
      "假蛋\n",
      "焕颜变\n",
      "千本\n",
      "选到\n",
      "十味药\n",
      "之美\n",
      "捂紧\n",
      "为国\n",
      "中兵\n",
      "振芯\n",
      "闹梅\n",
      "内盘\n",
      "捂股\n",
      "长阴\n",
      "倒拔\n",
      "十买九涨\n",
      "线后\n",
      "李湘家\n",
      "家比差\n",
      "一有\n",
      "一处\n",
      "赚来\n",
      "蛊虫\n",
      "挺高\n",
      "半小时\n",
      "转黑\n",
      "治个\n",
      "听娇点\n",
      "哥来\n",
      "两杯\n",
      "币面\n",
      "百枚\n",
      "f16i\n",
      "龚场\n",
      "一株\n",
      "水水嫩\n",
      "腰上\n",
      "一棵\n",
      "五架\n",
      "一毛\n",
      "67871\n",
      "q8\n",
      "或售\n",
      "难卖\n",
      "男命易\n",
      "及月子\n",
      "之血\n",
      "血可测\n",
      "恐癌\n",
      "血测\n",
      "血测癌\n",
      "天无痘\n",
      "点千股\n",
      "燃脂治\n",
      "司匹\n",
      "发再\n",
      "一病\n",
      "骨痛\n",
      "一盒\n",
      "亏大咯\n",
      "一百多\n",
      "一皖\n",
      "一盘\n",
      "抽数\n",
      "几包\n",
      "最准\n",
      "越降\n",
      "看能\n",
      "五招\n",
      "问保\n",
      "毒翻\n",
      "汤治好\n",
      "只加\n",
      "竟治好\n",
      "但温\n",
      "没点\n",
      "果治好\n",
      "三十斤\n",
      "种癌\n",
      "蒸着\n",
      "粉敷\n",
      "因降\n",
      "能美白\n",
      "一粒\n",
      "曝料\n",
      "评职\n",
      "证惠若琪\n",
      "朱婷张\n",
      "人进\n",
      "一寺\n",
      "三万元\n",
      "美防长\n",
      "对朝\n",
      "这盆\n",
      "大胃\n",
      "一遇\n",
      "成毒\n",
      "一锅鲜\n",
      "二十斤\n",
      "逆龄\n",
      "一颗颗\n",
      "竟能治\n",
      "战播求\n",
      "再斗\n",
      "杀玉狼\n",
      "播求\n",
      "小怪\n",
      "猜称\n",
      "打二番\n",
      "重腿\n",
      "爆腹\n",
      "遭西提\n",
      "三战播求\n",
      "七八个\n",
      "七八年\n",
      "疼用\n",
      "七十岁\n",
      "七夕\n",
      "提额\n",
      "瘦斤\n",
      "十五斤\n",
      "这注\n",
      "七招\n",
      "七日\n",
      "阴传\n",
      "七款\n",
      "一盆\n",
      "个算\n",
      "最养\n",
      "起涨\n",
      "对刷\n",
      "单零\n",
      "放一物\n",
      "粮官\n",
      "铠同\n",
      "一万亿\n",
      "亿科\n",
      "莫慌\n",
      "准好\n",
      "太好\n",
      "大半年\n",
      "不咳\n",
      "乐视能\n",
      "王思聪会\n",
      "过高\n",
      "买地\n",
      "房企下\n",
      "十五天\n",
      "斤变\n",
      "三丸\n",
      "多野\n",
      "三五年\n",
      "专偷\n",
      "四年\n",
      "三代\n",
      "多来\n",
      "天湿毒\n",
      "全无减\n",
      "多食\n",
      "可清署\n",
      "解烦\n",
      "奉上\n",
      "成吨\n",
      "三十几岁\n",
      "三十多年\n",
      "三十六年\n",
      "壹分\n",
      "三十天\n",
      "三十年\n",
      "三只\n",
      "虽小\n",
      "买个\n",
      "抛房\n",
      "最火\n",
      "排第\n",
      "名因\n",
      "刮肠油\n",
      "年毒\n",
      "五斤\n",
      "变着\n",
      "虐掉\n",
      "不瘦来\n",
      "白如纸\n",
      "还白\n",
      "闻泰龙旗\n",
      "因肿\n",
      "脸卡关\n",
      "三岁\n",
      "四十多\n",
      "看懵圈\n",
      "轰不烂\n",
      "合砍\n",
      "分迎\n",
      "真能值\n",
      "三张\n",
      "一扶\n",
      "生吃会\n",
      "note9\n",
      "s10\n",
      "s3\n",
      "exynos\n",
      "完虐\n",
      "a11\n",
      "酷炫新\n",
      "w2018\n",
      "w2017\n",
      "之殇\n",
      "十周年\n",
      "对标\n",
      "恐再\n",
      "14nm\n",
      "两台\n",
      "三月底\n",
      "才高气清\n",
      "三枚\n",
      "mlcd\n",
      "5000mah\n",
      "看电视\n",
      "三滴\n",
      "三甲\n",
      "三碗\n",
      "最防\n",
      "三秒\n",
      "专伤\n",
      "三缸\n",
      "过得\n",
      "三道\n",
      "三马\n",
      "熏死\n",
      "好几十\n",
      "用凉\n",
      "惊到\n",
      "常吃点\n",
      "13887546807\n",
      "亿婚\n",
      "百天\n",
      "上六星\n",
      "上合\n",
      "套刚\n",
      "需房\n",
      "需买\n",
      "h2\n",
      "多卖\n",
      "哈弗慌\n",
      "万敢\n",
      "低至\n",
      "买途观\n",
      "这辆\n",
      "四人\n",
      "多车\n",
      "昂科威\n",
      "竞品\n",
      "外牌\n",
      "sb250\n",
      "驻济\n",
      "分公\n",
      "更甜\n",
      "北外滩\n",
      "沪牌\n",
      "轨交\n",
      "赣锋\n",
      "锂业\n",
      "必创\n",
      "严限行\n",
      "不教\n",
      "摇号\n",
      "摩拜称\n",
      "辣评\n",
      "之名\n",
      "带人\n",
      "已带\n",
      "曹赟定\n",
      "对增\n",
      "暂未\n",
      "整栋\n",
      "晚半\n",
      "将建\n",
      "限不限\n",
      "可抗\n",
      "上财\n",
      "查载\n",
      "未带\n",
      "五百元\n",
      "两张\n",
      "二十多天\n",
      "農村\n",
      "種人\n",
      "領取\n",
      "農民\n",
      "能領\n",
      "井喷式\n",
      "能达\n",
      "谈灵体\n",
      "似有\n",
      "十万元\n",
      "别点\n",
      "背锅\n",
      "喝胖\n",
      "刷锅\n",
      "图三请\n",
      "不作会\n",
      "有大用\n",
      "怒赞\n",
      "这黑\n",
      "300km\n",
      "9at\n",
      "就长\n",
      "8at\n",
      "骏派\n",
      "cx65\n",
      "好车\n",
      "m3\n",
      "s370\n",
      "斤治\n",
      "不叠\n",
      "思議\n",
      "懷孕\n",
      "古屍\n",
      "冰凍\n",
      "年後產下\n",
      "活嬰\n",
      "曾美过\n",
      "其名\n",
      "第一位\n",
      "十米\n",
      "我用\n",
      "冯珂\n",
      "尚雯婕力\n",
      "我该\n",
      "丹打\n",
      "四招\n",
      "个键\n",
      "不拉黑\n",
      "13444\n",
      "菱宏光\n",
      "哈弗都\n",
      "亲妹\n",
      "之女\n",
      "人信\n",
      "不进\n",
      "治一治\n",
      "降酸\n",
      "慢如龟\n",
      "减越\n",
      "使胶\n",
      "比肉\n",
      "帶寶寶出門\n",
      "马蓉妈\n",
      "宋喆爸\n",
      "张翰掌\n",
      "口病\n",
      "千万倍\n",
      "头撞\n",
      "催费\n",
      "张忠谋急\n",
      "病受\n",
      "一喷\n",
      "再充\n",
      "用点\n",
      "信群发\n",
      "控糖\n",
      "百治\n",
      "养颜护\n",
      "分鐘\n",
      "牙齒\n",
      "更美白\n",
      "减腹\n",
      "新妙\n",
      "洗黑\n",
      "增涨\n",
      "数年\n",
      "六宗\n",
      "咳多\n",
      "速藏\n",
      "喝下\n",
      "排痰\n",
      "黑成\n",
      "hgl\n",
      "漏财\n",
      "醋加\n",
      "不系\n",
      "这名\n",
      "喷增\n",
      "甜剂\n",
      "伤不起\n",
      "南昌人\n",
      "采洁\n",
      "谈白百\n",
      "会闹\n",
      "来斤\n",
      "v15951761774\n",
      "四十五斤\n",
      "狂减\n",
      "一黑\n",
      "几吨\n",
      "天燃脂\n",
      "再养\n",
      "小物\n",
      "大穿\n",
      "不来扰\n",
      "祛黄\n",
      "小痛\n",
      "种小痛\n",
      "蛋加\n",
      "蒜加\n",
      "能吸\n",
      "网聘\n",
      "不设\n",
      "小物配\n",
      "挣一\n",
      "不锁\n",
      "改锁\n",
      "出毒\n",
      "新来\n",
      "一妙\n",
      "巧除\n",
      "黄渍\n",
      "变新锅\n",
      "旧锅\n",
      "这番\n",
      "一上场\n",
      "三字\n",
      "撞名\n",
      "驾罚\n",
      "热聊\n",
      "抢夫\n",
      "今晒\n",
      "宋大嘴\n",
      "露甜\n",
      "微博上\n",
      "冷帅\n",
      "整后\n",
      "专克\n",
      "排净\n",
      "不高\n",
      "地不种\n",
      "熬水\n",
      "排脂\n",
      "清肠宿\n",
      "减脂消\n",
      "瘦掉\n",
      "全扫空\n",
      "碟状\n",
      "之墓\n",
      "犯蒙\n",
      "变胖\n",
      "美白膏\n",
      "脸美白\n",
      "两块钱\n",
      "天可瘦\n",
      "拉筋术\n",
      "筋长\n",
      "一寸\n",
      "这杯\n",
      "称读\n",
      "四味\n",
      "快来查\n",
      "根烟\n",
      "pm25\n",
      "二会\n",
      "数十亿\n",
      "美在\n",
      "后要\n",
      "天可\n",
      "秒方\n",
      "有龙\n",
      "岁划\n",
      "全吃过\n",
      "五十多米\n",
      "伤肝\n",
      "以土\n",
      "女配\n",
      "十女\n",
      "十女配\n",
      "一男配\n",
      "狗们\n",
      "求嫁\n",
      "我连见\n",
      "克就值\n",
      "禁养\n",
      "一趟\n",
      "能绕\n",
      "这人竟\n",
      "上竟\n",
      "第一条\n",
      "第一辆\n",
      "有多缺\n",
      "上酒\n",
      "最後一頭\n",
      "獵者\n",
      "孕事\n",
      "误投\n",
      "滿足\n",
      "二十米\n",
      "1l\n",
      "油能\n",
      "港珠澳\n",
      "很能\n",
      "最难开\n",
      "亿请\n",
      "萌哭\n",
      "阿波菲\n",
      "几百\n",
      "一局\n",
      "需一\n",
      "第一峰\n",
      "東京\n",
      "tokyogirls\n",
      "斩掉\n",
      "一腿\n",
      "超恒大\n",
      "可活\n",
      "款车\n",
      "水跑\n",
      "黑进\n",
      "竟想\n",
      "认爱\n",
      "二点\n",
      "祖孙三代\n",
      "鸣人\n",
      "小新均\n",
      "鸣人路\n",
      "飞均\n",
      "受毀\n",
      "会大涨\n",
      "上千年\n",
      "真吓\n",
      "一跳\n",
      "退单\n",
      "股大涨\n",
      "附混改\n",
      "撞船\n",
      "女贩\n",
      "摔不烂\n",
      "二路\n",
      "干翻\n",
      "五秒\n",
      "再破\n",
      "21d\n",
      "huv\n",
      "要造\n",
      "小悍\n",
      "同吃会\n",
      "能淡斑\n",
      "虽好\n",
      "日会\n",
      "多月\n",
      "拼三\n",
      "疯减\n",
      "就值\n",
      "别拦\n",
      "我要\n",
      "合捐\n",
      "出窍\n",
      "两分钟\n",
      "两只\n",
      "如牛般\n",
      "两名\n",
      "两场\n",
      "旅恐\n",
      "撒药\n",
      "两千元\n",
      "误喝\n",
      "六成\n",
      "两战\n",
      "雄一郎\n",
      "打服\n",
      "两撞\n",
      "两斤\n",
      "两根\n",
      "两架\n",
      "郑爽娜\n",
      "两狗\n",
      "抓匪\n",
      "少拿钱\n",
      "两百多所\n",
      "两米\n",
      "两辣\n",
      "两苦养\n",
      "排体\n",
      "七类\n",
      "五人\n",
      "都播\n",
      "太爽\n",
      "特战\n",
      "一个个\n",
      "太惨\n",
      "半人半\n",
      "人用\n",
      "只露\n",
      "一个头\n",
      "出招\n",
      "税大改\n",
      "中丙\n",
      "人上\n",
      "俄美\n",
      "中伊\n",
      "皮令国足\n",
      "德入\n",
      "官媒刚\n",
      "中俄蒙\n",
      "已卖\n",
      "托市\n",
      "p10\n",
      "巧献\n",
      "巧去\n",
      "美白妙\n",
      "易兴堂\n",
      "一叶\n",
      "多梦\n",
      "别以为\n",
      "多得很\n",
      "必吃\n",
      "勺净\n",
      "肠毒\n",
      "颜嫩\n",
      "肠油\n",
      "排油\n",
      "天重\n",
      "这碗\n",
      "灰制\n",
      "解腻\n",
      "做个\n",
      "容错过\n",
      "祛湿治\n",
      "率高达\n",
      "效方\n",
      "小茶方\n",
      "易胖\n",
      "祛湿调\n",
      "这六物\n",
      "天轻\n",
      "轻到\n",
      "净肠毒\n",
      "内附\n",
      "专症\n",
      "别越治\n",
      "瘦法\n",
      "无斑\n",
      "吸油\n",
      "刮脂\n",
      "养回\n",
      "人常\n",
      "宜多吃\n",
      "当十\n",
      "十文\n",
      "十六年\n",
      "位是\n",
      "称里\n",
      "最牛\n",
      "一选股\n",
      "成一买\n",
      "亿光年\n",
      "数百年\n",
      "十架\n",
      "使美\n",
      "继科\n",
      "互金\n",
      "机都\n",
      "人不愿\n",
      "没建\n",
      "第一村\n",
      "挪亚\n",
      "查询方法\n",
      "big4\n",
      "战亚冠\n",
      "军头\n",
      "美日\n",
      "第二枪\n",
      "6k\n",
      "帮国足\n",
      "离体\n",
      "人死\n",
      "非如灯\n",
      "坠龙\n",
      "由弱\n",
      "趋稳\n",
      "准到\n",
      "直冒\n",
      "不差\n",
      "他生\n",
      "排不上\n",
      "80cm\n",
      "四世\n",
      "对美亮\n",
      "一艘\n",
      "美俄\n",
      "爆外\n",
      "无二\n",
      "死前\n",
      "帮贝\n",
      "卢斯科尼\n",
      "四艘\n",
      "再迎\n",
      "不沉\n",
      "美遭\n",
      "外媒称\n",
      "降准\n",
      "仅花\n",
      "开豪车\n",
      "三千多万\n",
      "修校\n",
      "遭日\n",
      "相太\n",
      "对美\n",
      "对非\n",
      "暗网\n",
      "三十个\n",
      "将造\n",
      "马云求\n",
      "百名\n",
      "入台\n",
      "第十\n",
      "第一拳\n",
      "亿大\n",
      "暴揍\n",
      "打遍\n",
      "第五代\n",
      "第二套\n",
      "第一款\n",
      "六代\n",
      "杀得\n",
      "装嫌\n",
      "几十\n",
      "光卖水\n",
      "杨丙莲\n",
      "选牛\n",
      "专抓\n",
      "大补\n",
      "十分钟\n",
      "最应\n",
      "位女\n",
      "更富\n",
      "最狂\n",
      "四线\n",
      "有能\n",
      "最能\n",
      "李庆远\n",
      "陈俊活\n",
      "李清云活\n",
      "国足进\n",
      "无一\n",
      "没炸\n",
      "有座\n",
      "质价\n",
      "级大单\n",
      "两洋\n",
      "一雪\n",
      "前耻\n",
      "毁车\n",
      "f15\n",
      "万例\n",
      "052e\n",
      "多万吨\n",
      "再浪\n",
      "指因\n",
      "热死\n",
      "核雾染\n",
      "四场\n",
      "急坠\n",
      "数十位\n",
      "找虐\n",
      "竟成\n",
      "10g\n",
      "再进\n",
      "同中\n",
      "删微信\n",
      "实合\n",
      "头都造\n",
      "sim卡\n",
      "建会\n",
      "百架\n",
      "第一座\n",
      "仔卓伟\n",
      "曝张\n",
      "慈禧西\n",
      "之变\n",
      "第三代\n",
      "10c\n",
      "第三艘\n",
      "第五个\n",
      "这座\n",
      "第六代\n",
      "f35\n",
      "微信群\n",
      "金闻\n",
      "腐案\n",
      "坚瑞沃\n",
      "闪崩\n",
      "空留\n",
      "千股\n",
      "百点\n",
      "种大涨\n",
      "先看\n",
      "涨个\n",
      "第一阵\n",
      "五百年\n",
      "能造\n",
      "但造\n",
      "亿增仓\n",
      "巨增\n",
      "成摇钱\n",
      "茶变\n",
      "挖岛\n",
      "第四艘\n",
      "德企\n",
      "设新\n",
      "罗梅西\n",
      "第二款\n",
      "或用\n",
      "性好\n",
      "之位\n",
      "撞人立\n",
      "能破\n",
      "因太过\n",
      "致瘫\n",
      "快过\n",
      "十公里\n",
      "已近\n",
      "三座\n",
      "狠杀\n",
      "不超\n",
      "两款\n",
      "传遭\n",
      "首张\n",
      "多快\n",
      "盼望已久\n",
      "161km\n",
      "超歼\n",
      "首艘\n",
      "赴华\n",
      "能立\n",
      "完涨\n",
      "也將\n",
      "汽車\n",
      "清潔\n",
      "古希伯來語\n",
      "有夠\n",
      "两股\n",
      "地遇\n",
      "第二轮\n",
      "两轮\n",
      "葛宇路\n",
      "元价\n",
      "指收涨\n",
      "微信收\n",
      "翌芙莱\n",
      "十二年\n",
      "中日\n",
      "亿个\n",
      "3g\n",
      "多款\n",
      "增筋剂\n",
      "中美块\n",
      "中美日\n",
      "十万人\n",
      "不扣\n",
      "翻烂\n",
      "针通\n",
      "六瓣\n",
      "内病\n",
      "外治贴\n",
      "一绝\n",
      "队换帅\n",
      "上港\n",
      "新帅\n",
      "掀换帅\n",
      "鲁能成\n",
      "抢分\n",
      "大上\n",
      "第六轮\n",
      "首胜换帅\n",
      "鲁能险\n",
      "中超要\n",
      "换种\n",
      "恒大截\n",
      "中醫\n",
      "天淡斑\n",
      "還不\n",
      "中长款\n",
      "中風\n",
      "那麼\n",
      "津头\n",
      "毛配\n",
      "混动\n",
      "不火\n",
      "十条\n",
      "买君越\n",
      "推豪车\n",
      "suv20\n",
      "v6\n",
      "办齐\n",
      "建了\n",
      "四缸\n",
      "别大\n",
      "化吉\n",
      "大胸\n",
      "建局\n",
      "停汽\n",
      "对人畜\n",
      "后该\n",
      "多条\n",
      "头门港\n",
      "获点\n",
      "张到\n",
      "保仓村\n",
      "吉尔伯\n",
      "我乐\n",
      "请动\n",
      "送房\n",
      "马蓉会\n",
      "扣费\n",
      "林拜\n",
      "触控\n",
      "一个男孩\n",
      "多买\n",
      "几批\n",
      "一入\n",
      "链是\n",
      "吴京张\n",
      "一山要\n",
      "长得萝莉\n",
      "一怒\n",
      "硬如纸\n",
      "第三年\n",
      "万病\n",
      "之源\n",
      "系跌\n",
      "已隐\n",
      "怒扇\n",
      "屡传\n",
      "赢过\n",
      "人敢\n",
      "大省\n",
      "法媒\n",
      "孕圆肚\n",
      "为北回\n",
      "胖到\n",
      "中六人\n",
      "地黑\n",
      "选在\n",
      "亿日元\n",
      "为夫\n",
      "拍抖音\n",
      "一话\n",
      "带新\n",
      "为戏\n",
      "未进\n",
      "为求\n",
      "一嘴\n",
      "数百万\n",
      "情同\n",
      "种下\n",
      "怒得\n",
      "更得\n",
      "by2\n",
      "躲到\n",
      "挡枪\n",
      "为逆袭\n",
      "面给\n",
      "做生\n",
      "抢筹此\n",
      "虐菜\n",
      "补氧\n",
      "行因\n",
      "因癌\n",
      "问于\n",
      "没成\n",
      "问霍\n",
      "二度\n",
      "净肠\n",
      "久置\n",
      "可致\n",
      "传同片\n",
      "八中\n",
      "遭窃\n",
      "香猪妹\n",
      "十跖\n",
      "差易\n",
      "长着\n",
      "似蛇\n",
      "韩系车\n",
      "一注\n",
      "top20\n",
      "乐视会\n",
      "交不起\n",
      "多亿\n",
      "网酒\n",
      "好牌\n",
      "几千万\n",
      "内会\n",
      "贾老板\n",
      "穷到\n",
      "机了\n",
      "传要\n",
      "乐视系\n",
      "实控\n",
      "人会否\n",
      "乐视离\n",
      "帮夫\n",
      "乒联官\n",
      "梁之死\n",
      "其往\n",
      "梁因\n",
      "数十条\n",
      "梁死\n",
      "惊爆\n",
      "乔妈\n",
      "编来\n",
      "维阿\n",
      "该股\n",
      "梦林\n",
      "九价\n",
      "首针\n",
      "何时能\n",
      "已多\n",
      "地断\n",
      "结一瓜\n",
      "尚能育否\n",
      "八百里\n",
      "九块\n",
      "几万块\n",
      "几十块\n",
      "事出\n",
      "桥塌\n",
      "成学霸\n",
      "两级\n",
      "越洗\n",
      "越白\n",
      "九招\n",
      "石胎\n",
      "九次\n",
      "宴遇\n",
      "壹天汇\n",
      "市江益\n",
      "疑在\n",
      "打汤\n",
      "不烂\n",
      "之物\n",
      "九種\n",
      "變身\n",
      "寶物\n",
      "看紧\n",
      "斤逆袭\n",
      "往水里\n",
      "肩颈\n",
      "s450l\n",
      "q3\n",
      "全仓进\n",
      "买会\n",
      "小孙子\n",
      "选它\n",
      "万比\n",
      "知坑\n",
      "买错\n",
      "别选\n",
      "都悔青\n",
      "越住\n",
      "没早\n",
      "条太\n",
      "时可别\n",
      "这层\n",
      "买过\n",
      "最买\n",
      "毛仅\n",
      "买朗逸\n",
      "甜皮\n",
      "薄母\n",
      "挑母\n",
      "挑公\n",
      "一挑\n",
      "若想\n",
      "vvs\n",
      "买途\n",
      "观要\n",
      "买队\n",
      "葡媒\n",
      "葡超\n",
      "唐迪拉\n",
      "万卖\n",
      "龋坏\n",
      "陈皮加\n",
      "不惹癌\n",
      "高脂\n",
      "桔核\n",
      "难考\n",
      "四十年\n",
      "编转成\n",
      "更铁\n",
      "亏不亏\n",
      "新改\n",
      "可转\n",
      "计算方法\n",
      "可刷\n",
      "闹大\n",
      "卖得\n",
      "二三十岁\n",
      "多恶\n",
      "刻润\n",
      "再染\n",
      "二中\n",
      "刘雅婷\n",
      "一封信\n",
      "迎新年\n",
      "二十天\n",
      "二哈\n",
      "二大\n",
      "蚊式\n",
      "女俘\n",
      "死得\n",
      "两颗\n",
      "误炸\n",
      "卖旧\n",
      "6s\n",
      "全系列\n",
      "二甲\n",
      "各大房\n",
      "二维\n",
      "男宝来\n",
      "好字\n",
      "附怀\n",
      "又生\n",
      "生贵子\n",
      "宝妈来\n",
      "生男宝\n",
      "次后\n",
      "往前\n",
      "接好孕\n",
      "全怨\n",
      "接男宝\n",
      "小男宝\n",
      "二货教\n",
      "二货\n",
      "这鱼\n",
      "坑入\n",
      "二选\n",
      "一段\n",
      "音缘\n",
      "办席\n",
      "何以堪\n",
      "唱得\n",
      "朱之文为\n",
      "中说\n",
      "曾患\n",
      "学朱\n",
      "之文\n",
      "这学\n",
      "上于\n",
      "朱之文唱\n",
      "朱之文真\n",
      "成名曲\n",
      "甜到\n",
      "靠前\n",
      "哥挺帅\n",
      "不黑\n",
      "歌事\n",
      "曼丽爱\n",
      "于晓光\n",
      "赵丽颖怒\n",
      "云凯\n",
      "人来\n",
      "凡伟\n",
      "万公顷\n",
      "出蛇\n",
      "坑槽\n",
      "入心\n",
      "之音\n",
      "馆赛\n",
      "为表\n",
      "能加\n",
      "云飞火\n",
      "练大招\n",
      "数亿\n",
      "浪口\n",
      "斑美白\n",
      "实锤后\n",
      "因开\n",
      "古手\n",
      "发挂\n",
      "先干\n",
      "小智小莫\n",
      "丑开\n",
      "三百块\n",
      "五元\n",
      "五十九岁\n",
      "直想\n",
      "五十余米\n",
      "推皮\n",
      "卡新\n",
      "四驱配\n",
      "众尼师\n",
      "五名\n",
      "十块\n",
      "三首\n",
      "亲试\n",
      "休城\n",
      "五岁\n",
      "竟得\n",
      "李小作\n",
      "七秒\n",
      "万去\n",
      "点个\n",
      "五月天\n",
      "五登\n",
      "十几载\n",
      "排光\n",
      "神菜\n",
      "五色\n",
      "变六美\n",
      "八条\n",
      "五道\n",
      "变六险\n",
      "法来\n",
      "再秀\n",
      "遭讽\n",
      "终要\n",
      "亚博\n",
      "投金\n",
      "被雪藏\n",
      "法加尼恐\n",
      "cctv5\n",
      "正赛\n",
      "别卖\n",
      "quidsi\n",
      "仍大涨\n",
      "不交辅\n",
      "习费\n",
      "险费\n",
      "只交\n",
      "最多要\n",
      "詹皇望\n",
      "能逆天\n",
      "改命\n",
      "拦查\n",
      "供扫码\n",
      "四轮\n",
      "分后\n",
      "拿卡时\n",
      "第二年\n",
      "做能\n",
      "拿卡\n",
      "起新规\n",
      "别带\n",
      "元扣\n",
      "已上\n",
      "若经\n",
      "集赞\n",
      "扣证\n",
      "望卡友\n",
      "黄期\n",
      "低卡\n",
      "孕前\n",
      "催胖\n",
      "肥妈\n",
      "偏小\n",
      "长胎\n",
      "连老铁\n",
      "高瓴\n",
      "唯品\n",
      "要联\n",
      "文筱婷\n",
      "唱空\n",
      "返款\n",
      "无闪付\n",
      "日马云\n",
      "几十元\n",
      "非京籍\n",
      "亲一亲\n",
      "从口\n",
      "其罩\n",
      "亲测\n",
      "第二季\n",
      "杨颖疑\n",
      "指是\n",
      "魅友\n",
      "美到\n",
      "九吨\n",
      "总说\n",
      "治癌\n",
      "人住\n",
      "几楼\n",
      "时往\n",
      "伪豪车\n",
      "长新发\n",
      "后微\n",
      "差长\n",
      "开着\n",
      "不富\n",
      "不肥\n",
      "三条\n",
      "去往\n",
      "看少动\n",
      "四成\n",
      "个点\n",
      "惟日股\n",
      "67925\n",
      "69262\n",
      "升破\n",
      "多墨币\n",
      "六千多\n",
      "收贬\n",
      "早盘\n",
      "美指\n",
      "币离\n",
      "再评\n",
      "第一部\n",
      "人有\n",
      "卖瓜\n",
      "之祖\n",
      "水猿\n",
      "s05e02\n",
      "中早\n",
      "这顶\n",
      "现半人\n",
      "有子\n",
      "董璇怀\n",
      "曝虐\n",
      "镇双\n",
      "人过\n",
      "人類\n",
      "六種\n",
      "能记\n",
      "刷安卓\n",
      "吃生\n",
      "熟蒜\n",
      "后乐视\n",
      "曝谢娜\n",
      "更扎心\n",
      "冬病\n",
      "能生\n",
      "天医\n",
      "五鬼\n",
      "绿萝花\n",
      "来杯\n",
      "因要\n",
      "范的\n",
      "这谣\n",
      "造得\n",
      "吃会\n",
      "版来\n",
      "数辆\n",
      "一死\n",
      "九伤\n",
      "中多人\n",
      "五点\n",
      "某店\n",
      "h1z1\n",
      "开博越\n",
      "懂车帝\n",
      "卡死\n",
      "中本聪\n",
      "先到\n",
      "先得\n",
      "我先\n",
      "干为\n",
      "变道\n",
      "起车\n",
      "堵惨\n",
      "只谈\n",
      "拉通\n",
      "推高\n",
      "十几斤\n",
      "最多能\n",
      "四千元\n",
      "新标\n",
      "安置费\n",
      "完年\n",
      "快到\n",
      "证先\n",
      "村有\n",
      "今年夏天\n",
      "没牌\n",
      "但会\n",
      "一咻\n",
      "两份\n",
      "合有\n",
      "张俊凯\n",
      "拆临\n",
      "价无粮\n",
      "贵圈\n",
      "事要\n",
      "称好\n",
      "变多\n",
      "位男神\n",
      "纳因\n",
      "瓜林存\n",
      "佩莱恐\n",
      "签乌神锋\n",
      "梅扬来\n",
      "欲献\n",
      "万余\n",
      "财讯\n",
      "辱华高管\n",
      "祭刀\n",
      "率居\n",
      "今起\n",
      "至全\n",
      "牌车\n",
      "这一物\n",
      "胖妈\n",
      "万跌\n",
      "比迈腾\n",
      "宫看\n",
      "命局\n",
      "却致\n",
      "爆红后\n",
      "帮着\n",
      "从北\n",
      "漂女\n",
      "单场\n",
      "从大\n",
      "脸黑\n",
      "爆火后\n",
      "从恒大\n",
      "卡帅\n",
      "十测\n",
      "九准\n",
      "脸到\n",
      "圈粉\n",
      "抓酒\n",
      "客即\n",
      "五段\n",
      "没人见\n",
      "四只\n",
      "pn6312\n",
      "环京\n",
      "备孕备\n",
      "孕生\n",
      "太准\n",
      "第一口\n",
      "新三花\n",
      "准得\n",
      "一小块\n",
      "从胎\n",
      "从鲁能\n",
      "韩红因\n",
      "金鸿鸣\n",
      "关婷娜\n",
      "吸味\n",
      "今娶\n",
      "第二天\n",
      "因战\n",
      "无数具\n",
      "其母\n",
      "驻澳\n",
      "男版\n",
      "第一代\n",
      "曝患\n",
      "之恩\n",
      "美男\n",
      "葬入\n",
      "男中\n",
      "红过\n",
      "传是\n",
      "所踪\n",
      "中谈\n",
      "最红时\n",
      "真烂\n",
      "他活\n",
      "话疑\n",
      "何炅怒\n",
      "他称\n",
      "竟灭\n",
      "心爱人\n",
      "任静近\n",
      "遭割\n",
      "仙福\n",
      "洗牙会\n",
      "用婧氏牙\n",
      "潛規則\n",
      "刘天绪\n",
      "薛之谦该\n",
      "个实\n",
      "r8\n",
      "交满\n",
      "错缴\n",
      "毁成\n",
      "以史\n",
      "为证\n",
      "别乱用\n",
      "需持\n",
      "以案\n",
      "疑是\n",
      "以身\n",
      "试方\n",
      "竟会致\n",
      "砖家\n",
      "先压\n",
      "韦陀像\n",
      "开个\n",
      "竟值\n",
      "双帆币\n",
      "马路边\n",
      "五万元\n",
      "半水石\n",
      "卖该\n",
      "充钱\n",
      "半明\n",
      "任丘苑\n",
      "杨旭文\n",
      "这门\n",
      "二倍\n",
      "一车\n",
      "数钱数\n",
      "竟隐婚\n",
      "曝隐婚\n",
      "爆隐婚\n",
      "这太坑\n",
      "五万多\n",
      "股获\n",
      "两万元\n",
      "天舟\n",
      "卡会\n",
      "为本\n",
      "可此\n",
      "魔猛\n",
      "两队\n",
      "百余\n",
      "次变\n",
      "齐爆\n",
      "休个\n",
      "喝咖啡\n",
      "养颜美肤\n",
      "狂买\n",
      "力捧岳云鹏\n",
      "受乐视\n",
      "优步\n",
      "免密\n",
      "做美白\n",
      "这狗\n",
      "要成\n",
      "会飞\n",
      "当度\n",
      "瓜帅\n",
      "欲购\n",
      "烟王\n",
      "几十代\n",
      "传余承东\n",
      "度登\n",
      "获邀\n",
      "提至\n",
      "传周迅\n",
      "美炸\n",
      "传大\n",
      "克里琴\n",
      "两男宝\n",
      "累月\n",
      "传应\n",
      "传张杰\n",
      "传张翰\n",
      "传杨\n",
      "传江\n",
      "抓奸\n",
      "下季\n",
      "和空姐\n",
      "香珀特\n",
      "传生\n",
      "剩宴\n",
      "传罗志祥\n",
      "传美团\n",
      "领投\n",
      "金服\n",
      "六星\n",
      "瘦性\n",
      "它长\n",
      "王炸\n",
      "套个\n",
      "中食\n",
      "数十\n",
      "传谢娜\n",
      "传谢贤\n",
      "国汽\n",
      "传韩\n",
      "传鲁能\n",
      "大把大把\n",
      "韩企在华\n",
      "黑得\n",
      "多支\n",
      "小卡必\n",
      "亲叔\n",
      "更多大\n",
      "这几人\n",
      "微凉天\n",
      "iphonese\n",
      "偷怕\n",
      "隔脏\n",
      "可高达\n",
      "洗肝菜\n",
      "更重\n",
      "盛易\n",
      "竞篮\n",
      "色叔\n",
      "纯粮酒\n",
      "何一怒\n",
      "币安割\n",
      "iost\n",
      "张鹤伦\n",
      "打美白针\n",
      "越涂\n",
      "何承熹\n",
      "脸是\n",
      "同回\n",
      "何洁带\n",
      "黑何洁\n",
      "要学\n",
      "何洁疑\n",
      "称何洁\n",
      "我养\n",
      "干得\n",
      "男赫子铭\n",
      "可赫子铭\n",
      "何洁谈\n",
      "樊昊仑\n",
      "曝何洁\n",
      "还陷\n",
      "郝子明\n",
      "何炅上\n",
      "微博发\n",
      "维嘉\n",
      "停录\n",
      "彭昱畅\n",
      "一百多块\n",
      "两千多\n",
      "太牛\n",
      "上拉孟美岐\n",
      "几千元\n",
      "谈隐婚\n",
      "何琳首\n",
      "卡三摄\n",
      "千字\n",
      "拼尽\n",
      "先溜\n",
      "余承动\n",
      "却炸出\n",
      "诞下\n",
      "小志明\n",
      "六叔\n",
      "事妹\n",
      "对孕妻\n",
      "干金\n",
      "二张\n",
      "宝摊\n",
      "宝新规\n",
      "全喝\n",
      "佛系\n",
      "王俊凯成\n",
      "马浩东\n",
      "想当\n",
      "别太\n",
      "蛮负\n",
      "上三大渣\n",
      "门变\n",
      "他会\n",
      "休妻\n",
      "孕相\n",
      "太乱\n",
      "微起\n",
      "韩绿谭\n",
      "微隆\n",
      "称要\n",
      "佟丽娅怀\n",
      "已摘\n",
      "配碗\n",
      "曝正\n",
      "佟丽娅疑\n",
      "有多坏\n",
      "显酷\n",
      "一记\n",
      "很虐\n",
      "连马蓉\n",
      "微博中\n",
      "爱过\n",
      "陈思诚首\n",
      "微博晒照\n",
      "仔们\n",
      "两派\n",
      "咸吃\n",
      "三周年\n",
      "佟亚丽\n",
      "爆为\n",
      "整牙\n",
      "好酒\n",
      "就够\n",
      "无锁机\n",
      "男受\n",
      "15933068468\n",
      "薛之谦会\n",
      "菜别\n",
      "越脏\n",
      "你会用\n",
      "你养\n",
      "先补\n",
      "只知\n",
      "抢角\n",
      "吴谨言\n",
      "三颗\n",
      "分涨\n",
      "加微信\n",
      "15270020984\n",
      "曝高管\n",
      "日系车\n",
      "不换会\n",
      "三套\n",
      "驾入\n",
      "火虫\n",
      "骂迪丽\n",
      "多深\n",
      "越戴越\n",
      "进书里\n",
      "进歌\n",
      "一驾\n",
      "优信\n",
      "能算出\n",
      "还脏\n",
      "降权\n",
      "這些\n",
      "测一测\n",
      "后值\n",
      "我白刷\n",
      "年牙\n",
      "卖楼\n",
      "何猷\n",
      "健齿\n",
      "美國窮\n",
      "哪款\n",
      "子里\n",
      "黑膜\n",
      "做易\n",
      "盐会\n",
      "股发\n",
      "过会\n",
      "中之王\n",
      "我虎躯\n",
      "一震\n",
      "吃个\n",
      "快停\n",
      "翻涨\n",
      "多倍\n",
      "放绿植\n",
      "美成\n",
      "伤着\n",
      "补不上\n",
      "你造\n",
      "更强\n",
      "飞燕式\n",
      "欢瑞\n",
      "一上午\n",
      "動物\n",
      "使人\n",
      "严重者\n",
      "丝滑\n",
      "侃哥\n",
      "季雾\n",
      "放一\n",
      "插上\n",
      "爆票\n",
      "几辆\n",
      "修侯门\n",
      "收何\n",
      "云伟为\n",
      "车吻\n",
      "斤宿\n",
      "年宿\n",
      "黑海舰队\n",
      "俄媒称\n",
      "俄媒\n",
      "弹仓\n",
      "7kg\n",
      "下活\n",
      "俄称\n",
      "ak12\n",
      "ak15\n",
      "prk\n",
      "前女\n",
      "不买别\n",
      "暖床\n",
      "长高达\n",
      "压哈弗\n",
      "人飞\n",
      "可载\n",
      "没买错\n",
      "疑熊为\n",
      "俄驻\n",
      "俄土\n",
      "美牙\n",
      "多天\n",
      "不腐\n",
      "很立秋\n",
      "十余名\n",
      "致三人\n",
      "老不患\n",
      "三不装\n",
      "翔变\n",
      "翔顶\n",
      "赔哭\n",
      "亿靠\n",
      "曝要\n",
      "连损\n",
      "两员\n",
      "于馨\n",
      "郑爽会\n",
      "三分之一\n",
      "日媒\n",
      "推扫码\n",
      "修铁路\n",
      "巨塔\n",
      "两度\n",
      "贷拒\n",
      "还关\n",
      "被诉\n",
      "倩狐\n",
      "养死\n",
      "变虐\n",
      "倪妮虐\n",
      "脸盲\n",
      "传虐\n",
      "管罄\n",
      "飙泪\n",
      "样说\n",
      "倭国\n",
      "错成\n",
      "一吃\n",
      "母欲救\n",
      "非治\n",
      "你存\n",
      "只换\n",
      "女命\n",
      "百分之三十\n",
      "聊会\n",
      "你会选\n",
      "不选\n",
      "假梗\n",
      "看白\n",
      "可骗\n",
      "戏演\n",
      "一例\n",
      "擺脫\n",
      "几句\n",
      "第二件\n",
      "辣不长\n",
      "时忘关\n",
      "要告\n",
      "说月子\n",
      "加个\n",
      "将法\n",
      "陈到\n",
      "令到\n",
      "干些\n",
      "找个\n",
      "先挂\n",
      "健十教\n",
      "瘦去\n",
      "三样\n",
      "细腿\n",
      "美极客\n",
      "八天\n",
      "农残\n",
      "老用\n",
      "人爱\n",
      "五组\n",
      "范丞丞微博\n",
      "周冬\n",
      "进看\n",
      "抱娃疑\n",
      "携富\n",
      "傳中國\n",
      "搭機\n",
      "这物\n",
      "缺岗\n",
      "饿醒\n",
      "入笼\n",
      "上大骂\n",
      "谁行\n",
      "前一天\n",
      "斤整\n",
      "实差\n",
      "一步步\n",
      "前致\n",
      "种辅食\n",
      "球池\n",
      "条该\n",
      "一千倍\n",
      "中含\n",
      "肉毒\n",
      "锁车\n",
      "台一姐\n",
      "拒跌\n",
      "点起\n",
      "同患\n",
      "宝加\n",
      "先不提\n",
      "先定\n",
      "这道\n",
      "爆何洁\n",
      "洗错\n",
      "一桩\n",
      "强长\n",
      "可换\n",
      "一匹\n",
      "有据\n",
      "可依\n",
      "一惊\n",
      "二十文\n",
      "巨涨\n",
      "肽助\n",
      "搞事\n",
      "票游\n",
      "不老颜\n",
      "吸睛\n",
      "斤油\n",
      "因长\n",
      "曝遭\n",
      "受创\n",
      "两枚\n",
      "猜值\n",
      "七朝\n",
      "转疯\n",
      "摩是\n",
      "却排\n",
      "多所\n",
      "查除\n",
      "撤县\n",
      "最服\n",
      "首座\n",
      "arteon\n",
      "a4\n",
      "x5\n",
      "要逆天\n",
      "换豪车\n",
      "最帅\n",
      "领克\n",
      "几家\n",
      "附大照\n",
      "才售\n",
      "gs8\n",
      "停网\n",
      "破骂\n",
      "大比拼\n",
      "亿部\n",
      "最壕\n",
      "第三名\n",
      "十秒钟\n",
      "吃土\n",
      "有图\n",
      "第一例\n",
      "近一半\n",
      "全男宝\n",
      "价降\n",
      "网价\n",
      "屏双\n",
      "车该\n",
      "八九年\n",
      "八十岁\n",
      "易洋千玺\n",
      "日主\n",
      "看日主\n",
      "上婚\n",
      "中婚\n",
      "下婚\n",
      "杀格\n",
      "男命\n",
      "条天规\n",
      "日柱\n",
      "八张\n",
      "五百多\n",
      "涨至\n",
      "因用\n",
      "八款\n",
      "八点\n",
      "少往\n",
      "八问\n",
      "胖人易\n",
      "车桩\n",
      "可涨\n",
      "要速\n",
      "称微信\n",
      "一组\n",
      "卖起\n",
      "加拿当\n",
      "一见\n",
      "第四个\n",
      "最熊\n",
      "六十岁\n",
      "养出\n",
      "更帅\n",
      "几人\n",
      "地遭\n",
      "重换\n",
      "因撞期\n",
      "巨蚊\n",
      "六战\n",
      "总决\n",
      "六岁\n",
      "六招\n",
      "招钓\n",
      "成狂\n",
      "六月份\n",
      "再点\n",
      "养一\n",
      "常吃常\n",
      "多别\n",
      "六片\n",
      "发多\n",
      "六米\n",
      "长森\n",
      "六颗\n",
      "眼会\n",
      "cr200j\n",
      "一坏\n",
      "一大堆\n",
      "免押\n",
      "共玉\n",
      "今直\n",
      "疑关\n",
      "社部\n",
      "关了灯\n",
      "万秒\n",
      "群中\n",
      "变王俊凯\n",
      "戴鹿晗\n",
      "曝非\n",
      "嘟嘴索\n",
      "伴手\n",
      "关晓彤终\n",
      "两人贼\n",
      "拒后\n",
      "列进\n",
      "不佳\n",
      "太不给\n",
      "太多违\n",
      "接个\n",
      "本微信\n",
      "奥司\n",
      "韦断\n",
      "会患\n",
      "眼癌\n",
      "gls450\n",
      "三台\n",
      "爸办\n",
      "曝马蓉妈\n",
      "有条\n",
      "其刀\n",
      "痛有\n",
      "冻出\n",
      "早治早\n",
      "越久\n",
      "关鹿\n",
      "悲来\n",
      "荻垛\n",
      "一偷\n",
      "送警\n",
      "兴秀洲\n",
      "因省\n",
      "育有\n",
      "三步\n",
      "穿青人\n",
      "穿青族\n",
      "变养\n",
      "手游开\n",
      "田飞鸡\n",
      "养宠\n",
      "灭光\n",
      "快长\n",
      "千只\n",
      "体嫩\n",
      "姜毒\n",
      "卡存\n",
      "一千多元\n",
      "养错\n",
      "日入\n",
      "内内\n",
      "内房\n",
      "股大\n",
      "月治好\n",
      "煤贩\n",
      "抢女\n",
      "走山\n",
      "錫盟东\n",
      "胖轩\n",
      "再久\n",
      "昆凌生\n",
      "不去\n",
      "再传\n",
      "再刷\n",
      "再出\n",
      "大幂\n",
      "爆强\n",
      "一纸\n",
      "天逛\n",
      "不送\n",
      "british\n",
      "要收\n",
      "数百元\n",
      "获名\n",
      "瓦良格\n",
      "84405\n",
      "锁仓\n",
      "十连板\n",
      "超士兰微\n",
      "妖王\n",
      "爆增\n",
      "军武\n",
      "张召忠马\n",
      "毒粮\n",
      "越大越\n",
      "越旺\n",
      "万锁\n",
      "种烂\n",
      "养蚁\n",
      "催香\n",
      "合涨\n",
      "新加\n",
      "忘领\n",
      "元能领\n",
      "大怪\n",
      "一摘\n",
      "为十到\n",
      "还灵\n",
      "一怪\n",
      "酒前\n",
      "乐笑\n",
      "采来\n",
      "喝前\n",
      "郁堵\n",
      "根似\n",
      "可保\n",
      "胶毛球\n",
      "除肝毒\n",
      "请速\n",
      "串乡\n",
      "圆样币\n",
      "比去\n",
      "人土\n",
      "挺必\n",
      "十五年\n",
      "你算过\n",
      "人采\n",
      "没涨\n",
      "脚朝西\n",
      "修房子\n",
      "漏领\n",
      "往酒\n",
      "头猪\n",
      "池值\n",
      "走得\n",
      "早会\n",
      "这合\n",
      "一千多\n",
      "得花\n",
      "农保处\n",
      "漏交\n",
      "能差\n",
      "再增\n",
      "千块\n",
      "有证\n",
      "多出\n",
      "证可\n",
      "煤改\n",
      "几毛\n",
      "通淋\n",
      "湿止\n",
      "再种\n",
      "挑瓜\n",
      "人会\n",
      "这钱\n",
      "一千元\n",
      "比粮补\n",
      "别飞\n",
      "太棒了\n",
      "增新\n",
      "近万\n",
      "领过\n",
      "人能领\n",
      "十几块\n",
      "十余种\n",
      "你服\n",
      "法迎\n",
      "权等\n",
      "嫌脏\n",
      "不腻\n",
      "炒来\n",
      "万造\n",
      "可潜\n",
      "两眼\n",
      "疑获\n",
      "猪宝\n",
      "万找\n",
      "仨天\n",
      "还加\n",
      "需一晚\n",
      "香猪\n",
      "不摘\n",
      "摘桃浆\n",
      "教他\n",
      "越到\n",
      "越火\n",
      "没迁\n",
      "必知\n",
      "会缴\n",
      "有房\n",
      "万快\n",
      "富不富\n",
      "买块\n",
      "一摸\n",
      "几千\n",
      "驴王\n",
      "想卖\n",
      "后充\n",
      "巧制\n",
      "养香猪\n",
      "可省\n",
      "几百块\n",
      "防醉\n",
      "有良效\n",
      "几根\n",
      "比用\n",
      "有福享\n",
      "最爱用\n",
      "但些\n",
      "不拿白\n",
      "拆农房\n",
      "地能\n",
      "人有福\n",
      "人白交\n",
      "人丝\n",
      "低筹\n",
      "上订\n",
      "这三证\n",
      "一平\n",
      "神草\n",
      "万换\n",
      "全花光\n",
      "每平\n",
      "三千元\n",
      "当柴\n",
      "退交\n",
      "但断\n",
      "百万元\n",
      "没活\n",
      "月速\n",
      "最嫩\n",
      "多则\n",
      "一宝\n",
      "查一查\n",
      "值多\n",
      "早领\n",
      "早过\n",
      "种货要\n",
      "竟比\n",
      "没缴\n",
      "最广\n",
      "改电有\n",
      "快去\n",
      "万人村\n",
      "专克腰\n",
      "碰断\n",
      "一害\n",
      "猛长\n",
      "需先\n",
      "牌入\n",
      "我泪目\n",
      "多有\n",
      "十项\n",
      "种房\n",
      "可护\n",
      "肝抗\n",
      "之星\n",
      "养肝滋肾\n",
      "祛毒\n",
      "两醋\n",
      "超占\n",
      "化骨水\n",
      "如霜\n",
      "一涨\n",
      "收长\n",
      "催婚\n",
      "可补\n",
      "建补\n",
      "助勃\n",
      "多领\n",
      "早办\n",
      "几十亩\n",
      "竟救\n",
      "一命\n",
      "能护\n",
      "有套\n",
      "大半个\n",
      "老腰\n",
      "三层\n",
      "x92\n",
      "几千年\n",
      "106095\n",
      "地能领\n",
      "还旺财\n",
      "大杀\n",
      "一方\n",
      "排清\n",
      "一降\n",
      "却养\n",
      "核别\n",
      "有近\n",
      "想入行\n",
      "万妥\n",
      "用交\n",
      "个长\n",
      "种农房\n",
      "象要\n",
      "白不领\n",
      "两大类\n",
      "证将\n",
      "过算\n",
      "我输\n",
      "千亿元\n",
      "这味\n",
      "这瓜\n",
      "难洗\n",
      "睡菜\n",
      "种有\n",
      "种上\n",
      "几棵\n",
      "靠养\n",
      "一称\n",
      "挖点\n",
      "采它\n",
      "除火\n",
      "祛脂\n",
      "壮全\n",
      "前未\n",
      "领嘛\n",
      "下可领\n",
      "万多元\n",
      "证能值\n",
      "退地\n",
      "会烂手\n",
      "里常\n",
      "十几元\n",
      "体毒\n",
      "农残高\n",
      "险中求\n",
      "养它\n",
      "挖宝\n",
      "十多万\n",
      "提五统\n",
      "靠证\n",
      "牛卖\n",
      "快产肉量\n",
      "百斤\n",
      "一千块\n",
      "几百年\n",
      "能亩\n",
      "万娶\n",
      "气跑\n",
      "赚发\n",
      "果卖\n",
      "八百多\n",
      "里养\n",
      "一水\n",
      "两收\n",
      "上种\n",
      "几百元\n",
      "二十万元\n",
      "五人同\n",
      "几十万元\n",
      "没人养\n",
      "黑兔\n",
      "看快\n",
      "即享\n",
      "后养\n",
      "找活\n",
      "无房\n",
      "吉工家\n",
      "讨薪\n",
      "种赛\n",
      "别弄\n",
      "挖塌\n",
      "称其\n",
      "要换\n",
      "多缴\n",
      "合新规\n",
      "合里\n",
      "周吃\n",
      "这三大类\n",
      "金娃娃\n",
      "发了\n",
      "合已\n",
      "证别\n",
      "再怕\n",
      "收处\n",
      "没交够\n",
      "算药食\n",
      "地狂\n",
      "人得\n",
      "鱼堪\n",
      "能助\n",
      "令使\n",
      "几句话\n",
      "这几大\n",
      "证能\n",
      "奶米\n",
      "如影\n",
      "几关\n",
      "会过\n",
      "汇理\n",
      "好帅\n",
      "总喝\n",
      "用开\n",
      "坑娃\n",
      "不堵\n",
      "腹胖\n",
      "人瘦\n",
      "胖肚\n",
      "别太厚\n",
      "养颜少\n",
      "三白\n",
      "肚大瘦\n",
      "能暖身\n",
      "地暖会\n",
      "养颜圣品\n",
      "很暖心\n",
      "毁肝\n",
      "防体\n",
      "冬游\n",
      "排湿\n",
      "人越\n",
      "越肿\n",
      "护心养\n",
      "因有\n",
      "强演\n",
      "看战\n",
      "告丫\n",
      "李晨神\n",
      "新戏用\n",
      "指战\n",
      "称放\n",
      "洪晃吐槽\n",
      "甚大\n",
      "骂法\n",
      "喷过\n",
      "本尊\n",
      "这嘴\n",
      "开喷\n",
      "我配\n",
      "黄渤是\n",
      "这届\n",
      "亿打\n",
      "洗不白\n",
      "莫床\n",
      "提莫床\n",
      "睡照\n",
      "男主播\n",
      "轩子\n",
      "曝骗\n",
      "睡门\n",
      "冯柯\n",
      "黑料\n",
      "赵丽颖治\n",
      "冯渣\n",
      "渣别\n",
      "妹花\n",
      "心有\n",
      "早现\n",
      "半小時\n",
      "或助\n",
      "越不化\n",
      "要放\n",
      "梨水\n",
      "画值\n",
      "净网\n",
      "一宗\n",
      "群内\n",
      "样种\n",
      "六点\n",
      "说声\n",
      "种易\n",
      "说准\n",
      "再求\n",
      "宜吃\n",
      "准哭\n",
      "准旗\n",
      "运狼\n",
      "美娇娘\n",
      "准爸\n",
      "点多\n",
      "减不掉\n",
      "分吃\n",
      "分靠\n",
      "天喝\n",
      "后能\n",
      "几物\n",
      "不壹\n",
      "变辣妈\n",
      "愁常\n",
      "两味\n",
      "肉肉全\n",
      "排肠\n",
      "毒治\n",
      "学一学\n",
      "两处\n",
      "餐助\n",
      "瘦少\n",
      "久减\n",
      "天从\n",
      "开森\n",
      "需补\n",
      "补减\n",
      "瘦胃\n",
      "抗饿\n",
      "一遍\n",
      "就致\n",
      "燃脂灭\n",
      "体轻降\n",
      "斤化\n",
      "太赞\n",
      "瘦会\n",
      "当为\n",
      "13500939511\n",
      "好难\n",
      "六斤\n",
      "肠毒抗\n",
      "天祛湿\n",
      "吃治\n",
      "不试\n",
      "喝无糖\n",
      "期别\n",
      "几勺\n",
      "几下\n",
      "内瘦\n",
      "想快\n",
      "不胖\n",
      "天速\n",
      "净毒\n",
      "轻瘦\n",
      "除脂\n",
      "消了\n",
      "几块\n",
      "肚腹\n",
      "种伪\n",
      "可狂\n",
      "能会\n",
      "脸瘦\n",
      "反瘦\n",
      "减脂汁\n",
      "圈变\n",
      "九套\n",
      "我教\n",
      "天少\n",
      "5cm\n",
      "盆骨操\n",
      "体脂率\n",
      "腰秀\n",
      "毒消\n",
      "一席\n",
      "天土\n",
      "补脾是\n",
      "六物\n",
      "一拌\n",
      "祛湿减\n",
      "达人用\n",
      "当饭\n",
      "养颜瘦\n",
      "一贴\n",
      "看史\n",
      "上命\n",
      "健孙怡\n",
      "超甜\n",
      "瓶假\n",
      "几十名\n",
      "几千万年\n",
      "几名\n",
      "天治好\n",
      "旧方\n",
      "三十岁\n",
      "你定\n",
      "几瓣\n",
      "似煤\n",
      "几道\n",
      "因玲花\n",
      "未唱\n",
      "是玲花\n",
      "换女\n",
      "玲花要\n",
      "街歌\n",
      "太扎心\n",
      "完玲花\n",
      "曾毅气\n",
      "用脚\n",
      "吸飞\n",
      "遭谢娜\n",
      "高副帅\n",
      "恐似\n",
      "后肤\n",
      "凤棺\n",
      "x光\n",
      "机一照\n",
      "亿捧\n",
      "肚圆\n",
      "显怀\n",
      "小混混\n",
      "症兆\n",
      "一国\n",
      "黑成翔\n",
      "最火时\n",
      "充上\n",
      "轻断\n",
      "狠话\n",
      "奔溃\n",
      "那英脸\n",
      "王思聪力\n",
      "听十人\n",
      "英唱\n",
      "上献唱\n",
      "唱悔\n",
      "听醉\n",
      "唱刀郎歌\n",
      "唱下\n",
      "刀郎震住\n",
      "刀郎火\n",
      "听悔\n",
      "某英\n",
      "婚誓\n",
      "马云点\n",
      "刀郎要\n",
      "调美\n",
      "上放此\n",
      "爱奇\n",
      "辣阴\n",
      "汪峰力\n",
      "大二\n",
      "院得\n",
      "好物\n",
      "添女\n",
      "风控花\n",
      "好孕\n",
      "张鈞\n",
      "张翰娜\n",
      "露陷\n",
      "越佳\n",
      "最见\n",
      "超华锋\n",
      "对易\n",
      "而害\n",
      "切涨\n",
      "洒金皮\n",
      "列瓦蒂奇\n",
      "刘丹要\n",
      "避谈\n",
      "陪方媛\n",
      "照美翻\n",
      "比卓伟\n",
      "值比\n",
      "飞强\n",
      "网红张\n",
      "辛苑\n",
      "脸周\n",
      "沈梦晨\n",
      "母共侍\n",
      "帮其\n",
      "差太远\n",
      "假一\n",
      "赔十的料\n",
      "遭指\n",
      "刘俊君\n",
      "刘和刚\n",
      "时唱\n",
      "刘俊昊\n",
      "刚唱\n",
      "上唱首\n",
      "阵住\n",
      "拉着\n",
      "刘和岗\n",
      "婚是\n",
      "博送\n",
      "人代生\n",
      "两月\n",
      "这鞋\n",
      "收胡军\n",
      "有后\n",
      "他争\n",
      "仍为\n",
      "仍不离\n",
      "刘天池\n",
      "太敢\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "说养\n",
      "再成\n",
      "我服\n",
      "几百亿\n",
      "妹打\n",
      "想回\n",
      "东太宠\n",
      "东太爱\n",
      "贵马云\n",
      "东娶\n",
      "东携\n",
      "人成\n",
      "马云举\n",
      "下干\n",
      "年三大\n",
      "出个\n",
      "六上\n",
      "将献唱\n",
      "卖冰沙\n",
      "鞭头\n",
      "人乱\n",
      "第二胎\n",
      "针针\n",
      "演不动\n",
      "只选\n",
      "不选贵\n",
      "后放话\n",
      "喝死\n",
      "哭道\n",
      "他养\n",
      "第六次\n",
      "问会\n",
      "挑断\n",
      "雨中\n",
      "睡光\n",
      "越演\n",
      "越烈\n",
      "舒入\n",
      "曝曾\n",
      "惯三\n",
      "王鸥长\n",
      "杨紫秦\n",
      "这事要\n",
      "未到\n",
      "幂家\n",
      "获杨\n",
      "幂力\n",
      "变男神\n",
      "翻旧\n",
      "照疑\n",
      "舒来\n",
      "已和丽虹成\n",
      "吃开\n",
      "带秋菊\n",
      "未受\n",
      "卓伟放话\n",
      "四五次\n",
      "曝杨\n",
      "一月份\n",
      "揭杨\n",
      "当小三\n",
      "中闷\n",
      "妻杨\n",
      "乐杨\n",
      "分乘\n",
      "不戴\n",
      "选杨\n",
      "幂己\n",
      "没王鸥\n",
      "肩夜会\n",
      "难掩\n",
      "其补\n",
      "强睡\n",
      "曝强\n",
      "白演\n",
      "刚帮王\n",
      "曝将\n",
      "手接\n",
      "没人道\n",
      "回怼\n",
      "部戏\n",
      "遭王\n",
      "病犯\n",
      "爆如\n",
      "别洗\n",
      "李晨车\n",
      "震变\n",
      "卓伟冲\n",
      "胡军家\n",
      "多戏\n",
      "食药\n",
      "八岁\n",
      "算白演\n",
      "帮王\n",
      "债后\n",
      "涛姐\n",
      "臀超\n",
      "你露\n",
      "王珂竟\n",
      "智问\n",
      "张翰五任\n",
      "没手\n",
      "有活\n",
      "话癌\n",
      "太能\n",
      "刘涛终\n",
      "王珂疑\n",
      "吐言\n",
      "疑将\n",
      "演不下\n",
      "刚帮\n",
      "刚替\n",
      "竟狂\n",
      "床照\n",
      "撑家\n",
      "手接素\n",
      "情崩\n",
      "太缺\n",
      "多脏\n",
      "因王\n",
      "吐真言\n",
      "王珂要\n",
      "更狠\n",
      "杨紫只\n",
      "借精\n",
      "懒理\n",
      "人妇\n",
      "诗孕肚\n",
      "喜当妈\n",
      "马舒雅竟\n",
      "诗挺孕\n",
      "肚照\n",
      "肚现\n",
      "微博新\n",
      "诗生孩\n",
      "诗生\n",
      "诗红毯\n",
      "诗发\n",
      "狂撒狗\n",
      "真像\n",
      "五五分\n",
      "诗造\n",
      "拖手\n",
      "美呆\n",
      "这小\n",
      "刘谦因\n",
      "在度\n",
      "刘谦给\n",
      "刘谦遭\n",
      "刘雯大\n",
      "维密\n",
      "俯揽\n",
      "001a\n",
      "会大\n",
      "不惊\n",
      "反喜\n",
      "肉里\n",
      "不雅照\n",
      "飞扫\n",
      "望冲\n",
      "没卖\n",
      "十只\n",
      "天要\n",
      "失联前\n",
      "刘仕余\n",
      "春春\n",
      "会限行\n",
      "拉响\n",
      "指暴击\n",
      "七连板\n",
      "心塞\n",
      "爆一\n",
      "价达\n",
      "归马蓉\n",
      "天嫩\n",
      "十颗\n",
      "薛之谦前\n",
      "曝恋\n",
      "刘涛学\n",
      "股要\n",
      "创客\n",
      "马云愿\n",
      "上滴\n",
      "sunnee\n",
      "爆肝点\n",
      "创金合信\n",
      "想过\n",
      "塘主险\n",
      "大妙\n",
      "删光\n",
      "删前速\n",
      "删完\n",
      "微博秀\n",
      "白之路\n",
      "删张杰\n",
      "扫一扫\n",
      "左滑\n",
      "一页\n",
      "別克\n",
      "力压\n",
      "one77\n",
      "假奶\n",
      "第三尊\n",
      "超顺丰\n",
      "利巴韦\n",
      "群日\n",
      "一单\n",
      "完唐\n",
      "利用微\n",
      "还准\n",
      "信小\n",
      "别一\n",
      "强不强\n",
      "浮灵\n",
      "张冠号\n",
      "别信酸儿\n",
      "别信\n",
      "中侧\n",
      "睡个\n",
      "好觉\n",
      "擦点\n",
      "错易\n",
      "大暴\n",
      "伴上\n",
      "斑全\n",
      "排湿毒\n",
      "2a\n",
      "不糊\n",
      "比跑\n",
      "剪个\n",
      "皮薄汁\n",
      "脆甜\n",
      "美白针\n",
      "表了\n",
      "最过\n",
      "有餐\n",
      "十几倍\n",
      "别忘\n",
      "八城\n",
      "喝分\n",
      "帅到\n",
      "一窝灭\n",
      "就切\n",
      "别用\n",
      "特怕\n",
      "它成\n",
      "中王\n",
      "看汉兰达\n",
      "x2\n",
      "别瞎传\n",
      "油见\n",
      "伤车\n",
      "油表\n",
      "别老\n",
      "no12\n",
      "别装\n",
      "先清肠\n",
      "50ml\n",
      "乌如\n",
      "c9\n",
      "酒才\n",
      "那英毁\n",
      "爆实\n",
      "办婚\n",
      "纯粮\n",
      "亿留\n",
      "刷不白\n",
      "总爱用\n",
      "沾点\n",
      "白刷\n",
      "事牙\n",
      "牙黄\n",
      "加些\n",
      "时挤\n",
      "刺苋\n",
      "挤血\n",
      "手党\n",
      "前中國\n",
      "壮牛\n",
      "一学\n",
      "之花\n",
      "宣布独立\n",
      "婚房秀\n",
      "胎梦真能\n",
      "吴京逆袭\n",
      "htycoin\n",
      "之声\n",
      "泥加\n",
      "马云慌\n",
      "第一枪\n",
      "待夫\n",
      "杀器\n",
      "传好\n",
      "孕接\n",
      "太精彩\n",
      "恋现\n",
      "剧版\n",
      "曝女\n",
      "主由\n",
      "担双\n",
      "男主为\n",
      "剧说\n",
      "早看\n",
      "变盾\n",
      "似换\n",
      "同嫁\n",
      "硬刚\n",
      "何妙\n",
      "越乱\n",
      "腰腿速\n",
      "油要\n",
      "比中\n",
      "领彩\n",
      "1270222535\n",
      "领阿迪\n",
      "13841463650\n",
      "总舞\n",
      "研所\n",
      "癌终\n",
      "可治\n",
      "怒告\n",
      "多公里\n",
      "堪比雾\n",
      "三辆\n",
      "跳枪\n",
      "损招\n",
      "幼仔\n",
      "数十米\n",
      "胎梦\n",
      "生男\n",
      "动视\n",
      "助国\n",
      "抓时\n",
      "杨怒\n",
      "领完\n",
      "网观\n",
      "现新\n",
      "会否\n",
      "俄大亮\n",
      "肆掠\n",
      "称下\n",
      "有家\n",
      "变砖\n",
      "毁肤\n",
      "病发\n",
      "能防霾\n",
      "讲真\n",
      "到市\n",
      "或会\n",
      "北乔峰\n",
      "断义\n",
      "起特\n",
      "二批\n",
      "限号\n",
      "弃选率\n",
      "三县\n",
      "季城六区\n",
      "开查\n",
      "赢下\n",
      "泡药\n",
      "进耳竟\n",
      "一养\n",
      "分读\n",
      "多分\n",
      "學者\n",
      "自來\n",
      "或判\n",
      "改公\n",
      "寻人\n",
      "股神仅\n",
      "鹏哥\n",
      "竟含\n",
      "窗后\n",
      "港大\n",
      "义撞\n",
      "逼认\n",
      "app5\n",
      "人超\n",
      "几公里\n",
      "幻速\n",
      "上珍\n",
      "涉传\n",
      "链电\n",
      "医微讯\n",
      "痛述\n",
      "如水\n",
      "三大类\n",
      "先焯\n",
      "种油\n",
      "医看\n",
      "吸筹\n",
      "现再\n",
      "几只\n",
      "超药明\n",
      "药事\n",
      "十万个\n",
      "男怀女\n",
      "男有福\n",
      "天逼\n",
      "先胖腹\n",
      "十人九湿\n",
      "不除\n",
      "十人九胃\n",
      "次治好\n",
      "马蓉愿\n",
      "十张\n",
      "十几亿\n",
      "临商\n",
      "十几个\n",
      "挨坑\n",
      "十多元\n",
      "好几位\n",
      "娃边\n",
      "贪快\n",
      "十岁\n",
      "五改\n",
      "看脸\n",
      "说散\n",
      "疼得\n",
      "种肉\n",
      "十月份\n",
      "十男\n",
      "九虚\n",
      "出少\n",
      "精症\n",
      "十胃\n",
      "九病\n",
      "十类\n",
      "十胖\n",
      "先胖\n",
      "十胖九湿\n",
      "十腰\n",
      "九疼\n",
      "喝留\n",
      "裝水\n",
      "这戏\n",
      "现假\n",
      "可交\n",
      "泡出\n",
      "64g\n",
      "魅蓝\n",
      "去学\n",
      "千呐\n",
      "做会\n",
      "墓里\n",
      "斤活\n",
      "燃花\n",
      "令多地\n",
      "不关脑\n",
      "种人要\n",
      "8g\n",
      "256g\n",
      "半岁\n",
      "半支\n",
      "半碗\n",
      "数十载\n",
      "难定\n",
      "羡煞\n",
      "5x\n",
      "emui90\n",
      "亿借壳\n",
      "配版要\n",
      "mate8\n",
      "安卓机\n",
      "屏来\n",
      "mate11\n",
      "mate7\n",
      "也产\n",
      "电只\n",
      "可跑\n",
      "一千公里\n",
      "这价\n",
      "推快\n",
      "投了\n",
      "怒换\n",
      "亿造\n",
      "z5\n",
      "共分\n",
      "入职\n",
      "好差\n",
      "点下\n",
      "天充\n",
      "次电\n",
      "次能\n",
      "过快\n",
      "多花\n",
      "几秒钟\n",
      "x23\n",
      "x27\n",
      "ex5\n",
      "512g\n",
      "余大嘴\n",
      "威马造\n",
      "想太多\n",
      "总难止\n",
      "全仓干\n",
      "万火到\n",
      "不伦恋\n",
      "剧王\n",
      "套骗\n",
      "创无\n",
      "开卖\n",
      "又立\n",
      "宇携\n",
      "宇邓\n",
      "紫棋\n",
      "美香\n",
      "华豫之门\n",
      "该见\n",
      "传鹿晗\n",
      "卓伟作\n",
      "自辩\n",
      "揭白百何\n",
      "杰迷\n",
      "爆王\n",
      "卓伟出\n",
      "笑里\n",
      "女炮\n",
      "爆新料\n",
      "爆狠料\n",
      "曾性\n",
      "幂确\n",
      "迷案\n",
      "直今\n",
      "不上\n",
      "爆大料\n",
      "曝鹿晗\n",
      "卓伟因\n",
      "大出\n",
      "爆错\n",
      "新料\n",
      "四辆\n",
      "诗要\n",
      "再发\n",
      "卓伟报\n",
      "卓伟收\n",
      "曝下\n",
      "张杰秀\n",
      "照引\n",
      "疑爆\n",
      "蒋欣斥\n",
      "择天记\n",
      "现捉\n",
      "卓伟本\n",
      "卓伟爆\n",
      "姓人妻\n",
      "蒋欣力\n",
      "爆关晓彤\n",
      "蒋欣怒\n",
      "爆完\n",
      "爆张杰\n",
      "一众\n",
      "卓伟猛\n",
      "卓伟疑\n",
      "直称\n",
      "矛指\n",
      "卓伟称\n",
      "卓伟继\n",
      "一实\n",
      "男江\n",
      "爆收\n",
      "王思聪顶\n",
      "雷爆\n",
      "诗里\n",
      "这锅\n",
      "后实\n",
      "计了\n",
      "现持\n",
      "盗刷\n",
      "永绝\n",
      "卖鞋\n",
      "团揍\n",
      "有试\n",
      "炫富称\n",
      "校来\n",
      "三区\n",
      "水游城\n",
      "会醒\n",
      "扩围\n",
      "南何楼\n",
      "彭拐\n",
      "名路\n",
      "用烂\n",
      "读好\n",
      "取票\n",
      "南宁人\n",
      "别吓人\n",
      "大鸡村\n",
      "六组\n",
      "寻狗\n",
      "万加\n",
      "岭路\n",
      "航洋现\n",
      "店卖\n",
      "起底\n",
      "南方人才\n",
      "送餐\n",
      "舜间\n",
      "麦路\n",
      "其系\n",
      "拿针\n",
      "多人梦中\n",
      "这会\n",
      "之秘\n",
      "帮小\n",
      "三打\n",
      "三强\n",
      "其办\n",
      "母森\n",
      "抗的动\n",
      "两条\n",
      "车偷\n",
      "所排\n",
      "半人\n",
      "黑哭\n",
      "黑到\n",
      "机在\n",
      "至水鸣\n",
      "卡佛尼白\n",
      "普货\n",
      "卡有\n",
      "恒大欲签\n",
      "怂发\n",
      "越穷\n",
      "聚气\n",
      "形婚\n",
      "必种\n",
      "疯传会\n",
      "雅万\n",
      "黄了\n",
      "那刻\n",
      "这算\n",
      "比差\n",
      "五头\n",
      "无药\n",
      "看莫迪\n",
      "正有\n",
      "帮其造\n",
      "曾放言\n",
      "因一\n",
      "欲建\n",
      "各邦\n",
      "就亮\n",
      "熊自\n",
      "監視器\n",
      "第二艘\n",
      "亿建\n",
      "大销\n",
      "现做\n",
      "坑到\n",
      "amca\n",
      "这江\n",
      "说变\n",
      "这过\n",
      "美不卖\n",
      "f35a\n",
      "胜选\n",
      "新规会\n",
      "人易\n",
      "卷腹\n",
      "不接\n",
      "遭起底\n",
      "百接\n",
      "它立\n",
      "四具\n",
      "最命\n",
      "仍活\n",
      "要亡\n",
      "另一面\n",
      "一米\n",
      "可防雾\n",
      "帅呆了\n",
      "刚播\n",
      "fcae\n",
      "某宝\n",
      "喷点\n",
      "曝任泉\n",
      "马蓉母\n",
      "桥体\n",
      "压哨\n",
      "两套\n",
      "爱鹿\n",
      "成痴\n",
      "八万元\n",
      "样老\n",
      "現在\n",
      "還不晚\n",
      "大赏\n",
      "背小三\n",
      "得雪\n",
      "因闺蜜\n",
      "最多活\n",
      "力捧迪丽\n",
      "四少王\n",
      "补电\n",
      "生俩\n",
      "猜会\n",
      "几万年\n",
      "作都\n",
      "宁爸\n",
      "关系密切\n",
      "这处\n",
      "即省\n",
      "大主播\n",
      "好乱\n",
      "只补\n",
      "遭实\n",
      "种必\n",
      "一说\n",
      "补肝\n",
      "母瓜\n",
      "玉思隐\n",
      "已碎\n",
      "十八年\n",
      "张翰和娜\n",
      "川字\n",
      "核竟\n",
      "u盘\n",
      "马曼琳\n",
      "云美翻\n",
      "后厨\n",
      "醋里\n",
      "比拔\n",
      "比敷\n",
      "之道\n",
      "安卓锁\n",
      "人泪\n",
      "游个泳\n",
      "一图\n",
      "趕走\n",
      "惱人\n",
      "乱进\n",
      "耗牛\n",
      "上此\n",
      "一响\n",
      "防闺蜜\n",
      "这不死\n",
      "广汽\n",
      "百何\n",
      "薛之谦刚\n",
      "排进\n",
      "前五\n",
      "郭德纲气\n",
      "q7\n",
      "第三款\n",
      "一网\n",
      "别步\n",
      "一豪车\n",
      "独悬\n",
      "满肚\n",
      "称以\n",
      "微突\n",
      "肥季\n",
      "不录\n",
      "张芷溪\n",
      "机歼\n",
      "首缩\n",
      "婚讯\n",
      "爆新\n",
      "d版\n",
      "没颜值\n",
      "车距\n",
      "中不输\n",
      "冯轲成\n",
      "五档\n",
      "抢书\n",
      "供网\n",
      "一必\n",
      "四款\n",
      "日双\n",
      "乱点\n",
      "一辅警\n",
      "飙到\n",
      "镇无牌\n",
      "刨析\n",
      "这篇\n",
      "18021\n",
      "三胆\n",
      "胆码\n",
      "牛人带\n",
      "吸脂养\n",
      "颜月\n",
      "最虐\n",
      "黄荷娜\n",
      "朴有\n",
      "曝郎永淳\n",
      "遭弃\n",
      "瓷儿\n",
      "轻奢版成\n",
      "面里\n",
      "玩客\n",
      "没买\n",
      "因雾\n",
      "中竟\n",
      "线越\n",
      "需和面\n",
      "一个角\n",
      "投联\n",
      "发科\n",
      "自尝\n",
      "tvb50\n",
      "pro3\n",
      "变个\n",
      "看衣识\n",
      "十二多\n",
      "积太多\n",
      "肝有\n",
      "甚烦\n",
      "误吞\n",
      "古人云\n",
      "三片\n",
      "四位\n",
      "四宝\n",
      "今有\n",
      "后恋\n",
      "脸窄\n",
      "窦骁比\n",
      "大吃\n",
      "飞醋\n",
      "黑娜\n",
      "变网\n",
      "张翰刚\n",
      "美空\n",
      "进全\n",
      "张翰成\n",
      "传曾\n",
      "张瀚渣\n",
      "因恋\n",
      "张翰发\n",
      "快结\n",
      "扎首\n",
      "三十一年\n",
      "开棺\n",
      "次元壁\n",
      "百所\n",
      "采洁系\n",
      "最配\n",
      "爱是\n",
      "曝蜜恋\n",
      "土下\n",
      "古斯大\n",
      "一届\n",
      "做些\n",
      "脱春\n",
      "速来\n",
      "另一半\n",
      "配酒\n",
      "vv7s\n",
      "狗友\n",
      "祝唐\n",
      "数百名\n",
      "只想生\n",
      "一个点\n",
      "一万张\n",
      "生没生\n",
      "吃桃\n",
      "瘦回\n",
      "餐后\n",
      "輕松\n",
      "种出\n",
      "曼妥思\n",
      "曼妥\n",
      "思同食\n",
      "妥思\n",
      "喝多\n",
      "喝有\n",
      "喝竟\n",
      "h1\n",
      "配曼\n",
      "可呼出\n",
      "壁清\n",
      "或致\n",
      "三年级\n",
      "没电时\n",
      "岩遇\n",
      "千枚\n",
      "一百多名\n",
      "曝罗志祥花\n",
      "当婚\n",
      "爆罗志祥\n",
      "台媒赞\n",
      "专出\n",
      "菜会\n",
      "有谱\n",
      "重轮\n",
      "挺同\n",
      "更近\n",
      "再办\n",
      "还敢\n",
      "举城\n",
      "建企\n",
      "规来\n",
      "冷叫\n",
      "大降\n",
      "万亿元\n",
      "牛假\n",
      "最猛\n",
      "512gb\n",
      "史月波\n",
      "通难\n",
      "追着\n",
      "八招\n",
      "未系\n",
      "各扣\n",
      "吃块\n",
      "推他\n",
      "出酒\n",
      "茶能\n",
      "说会\n",
      "陈皮能\n",
      "丢命\n",
      "得子\n",
      "宮癌\n",
      "發給\n",
      "身邊\n",
      "变嫩\n",
      "立夏饭\n",
      "有肉\n",
      "准么\n",
      "防脱\n",
      "含乙草胺\n",
      "天穿\n",
      "太多会\n",
      "吃太多\n",
      "太少会\n",
      "吃太撑\n",
      "还神\n",
      "很伤\n",
      "哈夫病\n",
      "疑致\n",
      "咽得\n",
      "还防\n",
      "胡就能\n",
      "吃播\n",
      "好处多多\n",
      "吃杯面\n",
      "胃里\n",
      "留蜡\n",
      "会解\n",
      "大以\n",
      "形补\n",
      "形食\n",
      "吃桃全\n",
      "吃梨有\n",
      "八小时\n",
      "能医\n",
      "熟吃易\n",
      "但触\n",
      "吃烂\n",
      "大大增加\n",
      "必点\n",
      "喝油\n",
      "甜会\n",
      "人变\n",
      "吃碱\n",
      "孕宝生\n",
      "红肉会\n",
      "吃红肉\n",
      "可助\n",
      "别犯\n",
      "疾控\n",
      "无此\n",
      "吃翔\n",
      "吃脑\n",
      "核会\n",
      "清肠毒\n",
      "七问\n",
      "杯面\n",
      "两块\n",
      "条会\n",
      "吃辣能\n",
      "炒肉\n",
      "会害\n",
      "生果\n",
      "人少\n",
      "哪治\n",
      "好期\n",
      "醋会\n",
      "留疤\n",
      "错易成\n",
      "過熟\n",
      "過生\n",
      "经骗\n",
      "第三点\n",
      "内狂\n",
      "喝些\n",
      "出病\n",
      "吃毒\n",
      "鸡国服\n",
      "apink\n",
      "一鸡\n",
      "同煮\n",
      "h799\n",
      "虾头\n",
      "却生\n",
      "六中\n",
      "暗涨\n",
      "已破\n",
      "来辩\n",
      "抢房\n",
      "房企大\n",
      "限地限贷\n",
      "难破\n",
      "难涨\n",
      "难降\n",
      "速抢\n",
      "博瑞\n",
      "德系\n",
      "狂卖\n",
      "128817\n",
      "月销\n",
      "院一\n",
      "药通\n",
      "堂化\n",
      "王志今\n",
      "四少\n",
      "炫妻\n",
      "五十元\n",
      "消皱\n",
      "抗霾\n",
      "同冠号\n",
      "虐成\n",
      "删微博\n",
      "两句话\n",
      "几段\n",
      "同杨\n",
      "马伊利\n",
      "男鹿晗\n",
      "比范丞丞惨\n",
      "李晨疑\n",
      "斤成\n",
      "赵丽颖点\n",
      "赞微\n",
      "博惹\n",
      "人疑\n",
      "车太近\n",
      "爱着\n",
      "有桃\n",
      "睡粉\n",
      "gaile\n",
      "早前\n",
      "坚尼\n",
      "名联\n",
      "对个\n",
      "一束\n",
      "蒋欣去\n",
      "蒋欣扇\n",
      "杜杜太\n",
      "妒悍\n",
      "太厚道\n",
      "买汉兰达\n",
      "射日\n",
      "鱼生致\n",
      "双卡版\n",
      "这四人\n",
      "万佑家军\n",
      "找人\n",
      "亿演\n",
      "今想\n",
      "天果\n",
      "多吃会\n",
      "景甜首\n",
      "含一\n",
      "万亿美元\n",
      "壮腰\n",
      "液会\n",
      "一万次\n",
      "听人\n",
      "说用\n",
      "日加\n",
      "红黑榜\n",
      "小是\n",
      "黄渤气\n",
      "尖生\n",
      "圆生\n",
      "限牌\n",
      "千菌\n",
      "非日\n",
      "吃些\n",
      "ི\n",
      "哥闹\n",
      "有川字\n",
      "疤会\n",
      "糖疤\n",
      "七色\n",
      "有川纹\n",
      "除醛\n",
      "有疤\n",
      "抽是\n",
      "一团\n",
      "千株\n",
      "有川字会\n",
      "再离\n",
      "回應\n",
      "四子\n",
      "刘雯录\n",
      "赵丽颖气\n",
      "扎组\n",
      "大三\n",
      "宠妻\n",
      "出对\n",
      "这劲\n",
      "微博遭\n",
      "赵丽颖言\n",
      "顺在\n",
      "赵丽颖传\n",
      "吴亦凡颖宝\n",
      "飙破\n",
      "某导\n",
      "搜榜\n",
      "吴京为\n",
      "五儿\n",
      "传在\n",
      "吴京怒\n",
      "张翰战\n",
      "没找\n",
      "吴京想\n",
      "拿过\n",
      "几十亿\n",
      "咖却\n",
      "爆鹿晗\n",
      "吴京摊\n",
      "吴京称\n",
      "家大\n",
      "微博炸\n",
      "男主由\n",
      "吴卓林\n",
      "蛮大\n",
      "这妈\n",
      "大伟\n",
      "鞋秀\n",
      "护肚疑\n",
      "吴妈妈\n",
      "坑惨\n",
      "整完容\n",
      "值逆天\n",
      "急回\n",
      "诗报\n",
      "怀小\n",
      "怒驳\n",
      "出护\n",
      "年婚\n",
      "　\n",
      "版刚\n",
      "马舒雅\n",
      "若诗\n",
      "会超\n",
      "这组\n",
      "探班护妻\n",
      "舒破\n",
      "探班护\n",
      "妻疑\n",
      "诗怀\n",
      "各有\n",
      "十万块\n",
      "一男\n",
      "四女\n",
      "吴宣仪\n",
      "石贞善\n",
      "被关\n",
      "吴昕凉\n",
      "狂秀\n",
      "当够\n",
      "新一姐\n",
      "虐狗\n",
      "静姐\n",
      "沈梦辰秀起\n",
      "美照\n",
      "十一年\n",
      "太暖\n",
      "戏精\n",
      "七夕节\n",
      "发糖\n",
      "同睡\n",
      "一间\n",
      "假到\n",
      "看杜\n",
      "小姐姐\n",
      "品都\n",
      "易昕\n",
      "遇渣\n",
      "超蠢\n",
      "真哭\n",
      "杨紫隔空\n",
      "太甜\n",
      "有主\n",
      "吴晰\n",
      "吴秀波疑\n",
      "吴雨约\n",
      "帮唱\n",
      "为馨爷\n",
      "人试\n",
      "彩膜\n",
      "兑点\n",
      "段时间\n",
      "修真者\n",
      "传微信\n",
      "飞友\n",
      "情系\n",
      "爱机\n",
      "时可领\n",
      "暴十连板\n",
      "周伯通\n",
      "看周\n",
      "知有\n",
      "会行\n",
      "两人要\n",
      "揭周\n",
      "很假\n",
      "更亲\n",
      "同获\n",
      "周启元\n",
      "周启元家\n",
      "卷土\n",
      "获王\n",
      "思聪力\n",
      "双男一\n",
      "女一\n",
      "吴京用\n",
      "亿妥\n",
      "揭爱\n",
      "要白\n",
      "林允担\n",
      "会大爆\n",
      "汁断\n",
      "催升\n",
      "附金股\n",
      "昆凌晒\n",
      "成渣\n",
      "好奶\n",
      "爸为\n",
      "金忙\n",
      "壕里\n",
      "壕气\n",
      "避生\n",
      "微博互\n",
      "周海明\n",
      "中闪婚\n",
      "微信发\n",
      "先有\n",
      "周琦会\n",
      "牢饭\n",
      "直骂\n",
      "人乐\n",
      "自健\n",
      "德纲\n",
      "早有\n",
      "多篇\n",
      "年刑\n",
      "高回播\n",
      "持毒\n",
      "藏毒案\n",
      "藏毒\n",
      "案迎\n",
      "立波\n",
      "说得准\n",
      "马云去\n",
      "重判\n",
      "娱圈\n",
      "黄独毒\n",
      "应狠\n",
      "大聊\n",
      "自黑\n",
      "称照\n",
      "幂整\n",
      "神林寺\n",
      "偷娃\n",
      "曝与\n",
      "客紧\n",
      "牵霍\n",
      "疑定\n",
      "迅素\n",
      "颜赶\n",
      "突传\n",
      "看秀\n",
      "如懿\n",
      "传定\n",
      "因无子\n",
      "劈腿成\n",
      "为剧\n",
      "最去\n",
      "味爽\n",
      "能控\n",
      "控好量\n",
      "看王\n",
      "拉鲁\n",
      "人族\n",
      "庞记\n",
      "可代\n",
      "生什麼\n",
      "会受\n",
      "比换个\n",
      "咋算\n",
      "戏刚\n",
      "部剧\n",
      "屠川当\n",
      "命犯\n",
      "大美\n",
      "斗图\n",
      "7p\n",
      "熔光\n",
      "冯乐\n",
      "美主播\n",
      "传会\n",
      "强刷\n",
      "特岗\n",
      "更呆萌\n",
      "幂现\n",
      "因吃\n",
      "干痒\n",
      "肺护\n",
      "絕招\n",
      "緊轉\n",
      "不对会\n",
      "一集\n",
      "哈利波\n",
      "男主哭\n",
      "報恩\n",
      "錢全\n",
      "笑噴\n",
      "這下\n",
      "跪算盤\n",
      "挪车\n",
      "遭差评\n",
      "热盘\n",
      "添头\n",
      "新登哥\n",
      "桐谷\n",
      "玩大\n",
      "这能\n",
      "哪一城会\n",
      "孕相能\n",
      "备孕生\n",
      "养在\n",
      "不渴\n",
      "购彩\n",
      "该定\n",
      "乳防\n",
      "毒奶\n",
      "残奶会致\n",
      "气奶\n",
      "后忌\n",
      "重瑞才\n",
      "继刘诗\n",
      "竟秀起\n",
      "凸得\n",
      "懂罗晋\n",
      "已排\n",
      "孕肚难\n",
      "白浅\n",
      "还亲\n",
      "罗晋定\n",
      "微凸疑\n",
      "抚肚\n",
      "指有\n",
      "大爆\n",
      "宫斗戏\n",
      "幂渐\n",
      "行渐\n",
      "从亲\n",
      "爱到\n",
      "邱泽刷\n",
      "眼泛\n",
      "真毒\n",
      "继杨\n",
      "脸崩\n",
      "赵丽颖互\n",
      "获大\n",
      "瑜会\n",
      "挑戏\n",
      "某大花\n",
      "回杠\n",
      "网爆\n",
      "两人于\n",
      "唐嫣方\n",
      "会定\n",
      "罗晋秀\n",
      "罗晋疑\n",
      "缘来\n",
      "怀罗晋\n",
      "唐山大\n",
      "唐山人\n",
      "场传\n",
      "停收\n",
      "家钢企\n",
      "唐探\n",
      "郑爽恋\n",
      "万配\n",
      "500km\n",
      "纯电\n",
      "很足\n",
      "百米\n",
      "仅要\n",
      "比有\n",
      "法要\n",
      "天团\n",
      "王石疑\n",
      "内一\n",
      "菜涂\n",
      "加两物\n",
      "再狠\n",
      "数十年\n",
      "如漆\n",
      "泡米\n",
      "速转\n",
      "不醉\n",
      "长说\n",
      "啥样\n",
      "竟涨\n",
      "我汗\n",
      "取之不出\n",
      "喊麦哥\n",
      "喊麦界\n",
      "博秒\n",
      "满盆金\n",
      "种些\n",
      "别误\n",
      "买教\n",
      "还省\n",
      "他复\n",
      "美媒称\n",
      "终亮\n",
      "咱爸\n",
      "咱妈\n",
      "红池坝\n",
      "最不伤\n",
      "滴酒\n",
      "别倒\n",
      "喝世\n",
      "喝久\n",
      "不祛湿\n",
      "人终\n",
      "养肤\n",
      "喝太多\n",
      "算酒\n",
      "喝错\n",
      "喝带\n",
      "喝尿\n",
      "喝法\n",
      "第一步\n",
      "白喝\n",
      "大才\n",
      "喝热\n",
      "喝碗\n",
      "精酿\n",
      "只认\n",
      "法媒教\n",
      "肺里\n",
      "喝醋\n",
      "茶有\n",
      "会德\n",
      "种水会\n",
      "种小妙\n",
      "种酒\n",
      "十六招\n",
      "快帮\n",
      "碰车\n",
      "只会害\n",
      "三粒\n",
      "不醉变\n",
      "可中\n",
      "酒同\n",
      "食易\n",
      "喝上\n",
      "醋疗\n",
      "当药\n",
      "一信\n",
      "茶放\n",
      "喷个\n",
      "喷杨\n",
      "干痛\n",
      "一波起\n",
      "可扫码\n",
      "女淡\n",
      "嘉诚评\n",
      "泮头\n",
      "牛吹大\n",
      "疑已\n",
      "嘻哈一族\n",
      "抛夫\n",
      "飙唱\n",
      "卖成\n",
      "四十几岁\n",
      "四十多天\n",
      "四发\n",
      "四字\n",
      "四岁\n",
      "衣娃\n",
      "无大\n",
      "胡燕桃\n",
      "电弹\n",
      "里开\n",
      "算力\n",
      "台矿机\n",
      "已致\n",
      "四巨\n",
      "黑实\n",
      "六期\n",
      "狂拍\n",
      "这得活\n",
      "四张\n",
      "四柱\n",
      "四版\n",
      "别花\n",
      "它会成\n",
      "角币\n",
      "四矿口\n",
      "头腾\n",
      "人早\n",
      "不姓\n",
      "姓康姓\n",
      "三场\n",
      "杀精\n",
      "百寸\n",
      "酷乐视\n",
      "4a\n",
      "因太\n",
      "因小\n",
      "被行\n",
      "因白\n",
      "因误\n",
      "太土\n",
      "因醉\n",
      "国一国\n",
      "国乒惨\n",
      "国三车\n",
      "换国\n",
      "国五才\n",
      "严国六来\n",
      "之作\n",
      "接嫁\n",
      "屏美得\n",
      "比众\n",
      "配全时\n",
      "驱仅售\n",
      "亿没\n",
      "万必成\n",
      "路虎见\n",
      "已海试\n",
      "大冒\n",
      "有十\n",
      "种网\n",
      "globeimposter\n",
      "半条\n",
      "超跑\n",
      "去过\n",
      "161224\n",
      "区有活\n",
      "孔菌\n",
      "云宫讯音\n",
      "种练\n",
      "个胆\n",
      "入华\n",
      "开吃\n",
      "完胖\n",
      "送个\n",
      "爆汗\n",
      "监拍\n",
      "采景时\n",
      "抢纳\n",
      "因戈兰\n",
      "指中超\n",
      "说鲁能\n",
      "推女鲁能\n",
      "抢人\n",
      "截胡恒大\n",
      "山之宝\n",
      "新榜\n",
      "朱之文后\n",
      "出大招\n",
      "没跑\n",
      "已受\n",
      "此歌\n",
      "二妻\n",
      "村干要\n",
      "能建\n",
      "几层楼\n",
      "无片\n",
      "雄安\n",
      "看张\n",
      "爆冯\n",
      "王思聪放\n",
      "朱婷建\n",
      "皮亲\n",
      "国足迎\n",
      "川媒\n",
      "曝里\n",
      "推新\n",
      "规世乒赛\n",
      "猛批\n",
      "评史\n",
      "地炼\n",
      "展真功\n",
      "图个\n",
      "股如\n",
      "打一物\n",
      "第十天\n",
      "圆肚生\n",
      "尖肚生\n",
      "收湿\n",
      "3unshine\n",
      "发新歌\n",
      "正昊\n",
      "爱奇艺\n",
      "两百多万\n",
      "地能值\n",
      "两大证\n",
      "可多\n",
      "称土\n",
      "叙若\n",
      "后埃\n",
      "黑是\n",
      "前涂\n",
      "食会\n",
      "沾到\n",
      "电字\n",
      "大四\n",
      "角料\n",
      "成送\n",
      "买条\n",
      "黄唇\n",
      "比洋\n",
      "签里\n",
      "微博全\n",
      "微博王\n",
      "区炸\n",
      "这七对\n",
      "会痛\n",
      "狗来\n",
      "白给\n",
      "嫁五旬\n",
      "多加\n",
      "还称\n",
      "想买个\n",
      "见后\n",
      "挖河\n",
      "猪能\n",
      "半两\n",
      "盐带\n",
      "顶得\n",
      "放个\n",
      "点至\n",
      "创近\n",
      "跌超\n",
      "张纸\n",
      "馆水\n",
      "展死\n",
      "小主看\n",
      "似鬼似\n",
      "人到\n",
      "打不响\n",
      "内比\n",
      "扁方\n",
      "曝睡\n",
      "新起\n",
      "運動\n",
      "飲料\n",
      "洋蔥\n",
      "電源\n",
      "能給\n",
      "手機\n",
      "充電\n",
      "一儿\n",
      "能交\n",
      "中是\n",
      "弃购\n",
      "地暖\n",
      "对人\n",
      "人竟\n",
      "上七大\n",
      "活在\n",
      "会晕\n",
      "几十亿年\n",
      "仅能\n",
      "快斗\n",
      "有六星\n",
      "超棒\n",
      "收卖\n",
      "宽子\n",
      "摊收\n",
      "宽哥\n",
      "2c\n",
      "4c\n",
      "高人能\n",
      "三换\n",
      "控卫\n",
      "组三\n",
      "补回\n",
      "嫂要\n",
      "过开\n",
      "会怪\n",
      "坐热\n",
      "地掉\n",
      "虐腹\n",
      "出大\n",
      "必富\n",
      "必出\n",
      "坤鹏论\n",
      "丢进\n",
      "坦尚\n",
      "背不背\n",
      "传可引\n",
      "可引\n",
      "女年\n",
      "男满\n",
      "骚年\n",
      "太有\n",
      "一放\n",
      "用此\n",
      "不烂根\n",
      "涉堤\n",
      "猛于\n",
      "晚于\n",
      "闺蜜情\n",
      "战五渣\n",
      "展神\n",
      "一大步\n",
      "骨痛液\n",
      "矢野浩\n",
      "二回\n",
      "日竟\n",
      "周星闻\n",
      "揭好\n",
      "种生\n",
      "备孕常\n",
      "条备\n",
      "备孕时\n",
      "助孕\n",
      "想不生\n",
      "活久见\n",
      "比伯赛\n",
      "推神车\n",
      "露腰\n",
      "要勤\n",
      "喝满\n",
      "种越\n",
      "美肤\n",
      "需一物\n",
      "小脸蛋\n",
      "速瘦法\n",
      "茶方\n",
      "四物\n",
      "吸黑\n",
      "加太满\n",
      "太满\n",
      "稳有\n",
      "性大易致\n",
      "下火\n",
      "反味\n",
      "搁条\n",
      "落病\n",
      "壮如虎\n",
      "清肠排\n",
      "这货\n",
      "强好\n",
      "省上\n",
      "闺蜜教\n",
      "省电妙\n",
      "必喝\n",
      "需涂点\n",
      "美白抗\n",
      "游做\n",
      "两碗\n",
      "伤后\n",
      "后白\n",
      "后白过\n",
      "要存\n",
      "暗沉\n",
      "美白液\n",
      "比买\n",
      "白暂\n",
      "涂涂\n",
      "黄无光\n",
      "不伤肤\n",
      "液小妙\n",
      "耐活\n",
      "养不死\n",
      "两盆\n",
      "整夏\n",
      "苦菊\n",
      "要常\n",
      "越放越\n",
      "当酒\n",
      "驾查\n",
      "夏姜\n",
      "白减\n",
      "两大派\n",
      "二宜\n",
      "三忌\n",
      "能少\n",
      "还慢\n",
      "能排\n",
      "省电宝\n",
      "后美白\n",
      "种当季\n",
      "多获\n",
      "特饮\n",
      "认它\n",
      "十多斤\n",
      "二斤\n",
      "有范\n",
      "喝冰\n",
      "饮会\n",
      "机之\n",
      "这八\n",
      "诗竟\n",
      "经视\n",
      "招美白\n",
      "提亮\n",
      "夏白露\n",
      "会带\n",
      "现急\n",
      "夏钓大\n",
      "夏钓\n",
      "按月结\n",
      "带烟\n",
      "谈差评\n",
      "丢车\n",
      "遭退\n",
      "太困\n",
      "哭述\n",
      "因差评\n",
      "因遭\n",
      "没帮\n",
      "买烟\n",
      "我点\n",
      "接餐\n",
      "有多苦\n",
      "因差\n",
      "评竟\n",
      "漏单\n",
      "血如\n",
      "坐路\n",
      "零晨\n",
      "或增\n",
      "没电用\n",
      "其厚唇\n",
      "不写\n",
      "街偷\n",
      "曝美\n",
      "万英尺\n",
      "曝霉霉\n",
      "美图秀\n",
      "外媒证\n",
      "中俄正\n",
      "第一件\n",
      "干人血\n",
      "团灭\n",
      "充能\n",
      "之力\n",
      "慢放\n",
      "太大太想\n",
      "大古\n",
      "人见\n",
      "通灵女\n",
      "吃大雄\n",
      "没怀\n",
      "或令\n",
      "hadax\n",
      "胡可断\n",
      "遇不上\n",
      "闯禁\n",
      "多力\n",
      "罗普郡\n",
      "可边\n",
      "几回\n",
      "种助孕\n",
      "红肉易\n",
      "能长\n",
      "变越\n",
      "补菌\n",
      "多图\n",
      "炮不爆\n",
      "恐熬\n",
      "手滑\n",
      "她动\n",
      "希曾\n",
      "逼停\n",
      "多省\n",
      "多肉\n",
      "获韬蕴\n",
      "多队\n",
      "太熬\n",
      "不尿尿\n",
      "淘到\n",
      "鬼步\n",
      "沒妈\n",
      "没妈\n",
      "3w\n",
      "一查\n",
      "速进\n",
      "已签\n",
      "韩颖华\n",
      "无汉兰达\n",
      "千公里\n",
      "万比汉兰达\n",
      "5l\n",
      "万仅\n",
      "亿给\n",
      "只回\n",
      "大化\n",
      "大半夜\n",
      "赞下\n",
      "带块\n",
      "可真\n",
      "南环桥\n",
      "马思纯疑\n",
      "别考\n",
      "研招网\n",
      "大墓\n",
      "脸后\n",
      "要取\n",
      "燃脂液\n",
      "婚闹\n",
      "透净\n",
      "为儿\n",
      "开塞\n",
      "露洗\n",
      "揭闺蜜间\n",
      "走后\n",
      "超难\n",
      "清狗\n",
      "纸上\n",
      "千万美元\n",
      "三十四岁\n",
      "各论\n",
      "为妻\n",
      "老妻\n",
      "晨尿测\n",
      "买肉\n",
      "玩抖音\n",
      "远高于\n",
      "梁永涛\n",
      "1587997\n",
      "美判\n",
      "充完\n",
      "电不拔\n",
      "这烟\n",
      "算尖\n",
      "还怀\n",
      "夹钱\n",
      "搅得\n",
      "但网\n",
      "贾乃\n",
      "小寶寶較\n",
      "聰明\n",
      "蓬村\n",
      "发疑\n",
      "八厂\n",
      "认真负责\n",
      "两军\n",
      "很心\n",
      "却令\n",
      "逗食\n",
      "季除\n",
      "邓超外\n",
      "曝料疑\n",
      "八里\n",
      "河钓\n",
      "大海棠\n",
      "之选\n",
      "佛须\n",
      "龙版\n",
      "说点\n",
      "平七钱\n",
      "茯茶\n",
      "多日\n",
      "皮大衣\n",
      "怒问\n",
      "爆杨\n",
      "大玉儿\n",
      "涨不动\n",
      "磨底\n",
      "低吸\n",
      "深幅\n",
      "已久终\n",
      "显老\n",
      "尹能静\n",
      "成墨\n",
      "减不\n",
      "天除\n",
      "别烦\n",
      "液有\n",
      "这五物\n",
      "盒纯\n",
      "黑杯面\n",
      "王密子\n",
      "编要\n",
      "同食会\n",
      "大甜\n",
      "强如牛\n",
      "只会生\n",
      "酸泡\n",
      "身壮\n",
      "如耗\n",
      "如牛\n",
      "肾壮\n",
      "比鹿\n",
      "毒蒜\n",
      "能治根\n",
      "壮如\n",
      "泡醋治\n",
      "锅会\n",
      "十九岁\n",
      "泡进\n",
      "强若\n",
      "后游\n",
      "砍大蛇\n",
      "满屋子\n",
      "歌一唱\n",
      "人怕\n",
      "猪怕\n",
      "后过\n",
      "缘极满\n",
      "有于\n",
      "气哭\n",
      "过税\n",
      "行过\n",
      "终难\n",
      "慕后\n",
      "朱之文自\n",
      "朱之文闹\n",
      "一是\n",
      "看直\n",
      "哥靠\n",
      "嫂闹\n",
      "蹄兔\n",
      "会怕\n",
      "最坑\n",
      "甘井子\n",
      "双双把\n",
      "四名\n",
      "男滚出\n",
      "想换\n",
      "報告\n",
      "影響\n",
      "預期\n",
      "大长\n",
      "曝马蓉\n",
      "大陸\n",
      "傳遭\n",
      "三伤\n",
      "迷是\n",
      "青汁\n",
      "一幢\n",
      "奇味\n",
      "整掉\n",
      "猴菇\n",
      "家军\n",
      "主播们\n",
      "球球开\n",
      "根葱\n",
      "发毒\n",
      "天再\n",
      "贴个\n",
      "清微博\n",
      "天呐\n",
      "已获\n",
      "雷到\n",
      "孙俪泪\n",
      "发晚\n",
      "喊过\n",
      "这妙\n",
      "腰不酸\n",
      "耳不聋\n",
      "反重\n",
      "没宿\n",
      "狂排\n",
      "半個\n",
      "被治好\n",
      "色条\n",
      "天太热\n",
      "曝摩拜\n",
      "九人\n",
      "720p\n",
      "qsv\n",
      "镇水\n",
      "100w\n",
      "投他\n",
      "天拉\n",
      "一任\n",
      "远口\n",
      "这一妙\n",
      "农哥教\n",
      "最伤\n",
      "街用\n",
      "地补\n",
      "旧证\n",
      "天热\n",
      "养肝王\n",
      "色好\n",
      "祛湿王\n",
      "常吃排\n",
      "更护\n",
      "哪领\n",
      "24881\n",
      "天鸽\n",
      "帕卡来\n",
      "风巢\n",
      "曾救\n",
      "双凤有\n",
      "太劲\n",
      "马蓉开\n",
      "两对\n",
      "涉黄\n",
      "千峰\n",
      "多人染\n",
      "公积转\n",
      "悬而\n",
      "未落\n",
      "企称\n",
      "仍调\n",
      "不控\n",
      "起房\n",
      "第三套\n",
      "限售\n",
      "关手\n",
      "蒸错\n",
      "药变\n",
      "利眼\n",
      "一马云\n",
      "拍抖\n",
      "音竟\n",
      "欲分\n",
      "gdp22\n",
      "带个\n",
      "干到\n",
      "大码\n",
      "越老越\n",
      "救一\n",
      "诈捐后\n",
      "并致\n",
      "这几对\n",
      "央妈\n",
      "全仓此\n",
      "哪去\n",
      "营管部\n",
      "曝开\n",
      "成般\n",
      "疑得\n",
      "姐竟\n",
      "因患癌\n",
      "巨毒\n",
      "一主播\n",
      "次患\n",
      "巨震\n",
      "已播\n",
      "假盐案\n",
      "假盐\n",
      "曝捆\n",
      "捆菜\n",
      "就别\n",
      "红时\n",
      "圈中\n",
      "称用\n",
      "董卿争\n",
      "邀鹿晗\n",
      "多梦别\n",
      "多梦气\n",
      "多梦试\n",
      "真患\n",
      "疑患\n",
      "酒算\n",
      "生新发\n",
      "天不洗\n",
      "早白\n",
      "后长\n",
      "招土\n",
      "时放点\n",
      "叶配\n",
      "别乱染\n",
      "别染\n",
      "越掉\n",
      "酸胀\n",
      "礼疑\n",
      "瓜友\n",
      "要剖\n",
      "土食材\n",
      "七里\n",
      "夺子\n",
      "天不坏\n",
      "人宝能\n",
      "凯翼\n",
      "竟向\n",
      "有多强\n",
      "十三岁\n",
      "因在\n",
      "留灯\n",
      "原石切\n",
      "管致\n",
      "五辆\n",
      "竟撞\n",
      "张继科景\n",
      "奔五\n",
      "已失\n",
      "glc300\n",
      "亿后\n",
      "进何猷\n",
      "发照\n",
      "奚猷\n",
      "我快\n",
      "攒够\n",
      "中超成\n",
      "罗和梅西\n",
      "创三大\n",
      "梅杨\n",
      "差宁泽涛\n",
      "败光\n",
      "载不离\n",
      "a4l\n",
      "迈腾君\n",
      "销冠\n",
      "a7\n",
      "系卖\n",
      "a8l\n",
      "a6\n",
      "缤智\n",
      "几月份\n",
      "q2\n",
      "x1\n",
      "v10\n",
      "纽北\n",
      "前自\n",
      "320km\n",
      "睡晚\n",
      "泰迪竟\n",
      "大肿\n",
      "拒让\n",
      "越长\n",
      "称腿\n",
      "可养颜\n",
      "养颜显\n",
      "戴银饰\n",
      "只手\n",
      "还变\n",
      "越近\n",
      "藏人\n",
      "法配\n",
      "养颜使\n",
      "吃酸能\n",
      "养颜变\n",
      "之相\n",
      "之命\n",
      "做坏\n",
      "三黑\n",
      "两红\n",
      "臀越\n",
      "大越\n",
      "养颜淡斑\n",
      "养颜永葆\n",
      "竟易\n",
      "既想\n",
      "量少\n",
      "很显\n",
      "别愁\n",
      "有美白\n",
      "防抗\n",
      "活越\n",
      "颜更\n",
      "少老\n",
      "入体\n",
      "尽享\n",
      "不忧\n",
      "越湿\n",
      "少穿\n",
      "显腿长\n",
      "八样\n",
      "越招\n",
      "越小\n",
      "命越\n",
      "福越\n",
      "祛湿后\n",
      "还显\n",
      "四度\n",
      "纷传要\n",
      "马蓉后\n",
      "照遭\n",
      "二千元\n",
      "获捐\n",
      "万帮\n",
      "小儿子\n",
      "请魂\n",
      "不愿牌\n",
      "养颜常\n",
      "临带\n",
      "带玉\n",
      "竟装\n",
      "同吃同\n",
      "斤养\n",
      "月染\n",
      "为治\n",
      "告御状\n",
      "卡进\n",
      "发微信\n",
      "看小三\n",
      "很爱丽颖\n",
      "自磨\n",
      "因养\n",
      "因嫌\n",
      "猪难\n",
      "过个\n",
      "疑成\n",
      "未生\n",
      "后称\n",
      "快炸\n",
      "看多\n",
      "邻楼\n",
      "淤伤\n",
      "今患\n",
      "玩自\n",
      "和生\n",
      "大蛇游\n",
      "太浓致\n",
      "成杨颖\n",
      "误切\n",
      "孙玉婷\n",
      "装瞎陪\n",
      "敢认\n",
      "第二点\n",
      "第四条\n",
      "山空\n",
      "淫性\n",
      "中要\n",
      "少患\n",
      "超全\n",
      "杨颖未\n",
      "没人信\n",
      "一色\n",
      "抢本主\n",
      "孕照\n",
      "5kg\n",
      "多胖\n",
      "整残\n",
      "一渣\n",
      "深过\n",
      "邓莎未\n",
      "女有\n",
      "男有\n",
      "刚拉出\n",
      "亿岁\n",
      "千萬別\n",
      "喝越\n",
      "如遇\n",
      "六只\n",
      "点哟\n",
      "撞期\n",
      "款能\n",
      "动保\n",
      "捕狗\n",
      "林志林\n",
      "很火\n",
      "男闺蜜教\n",
      "食因\n",
      "女票\n",
      "救子\n",
      "白死\n",
      "男丑母\n",
      "男好\n",
      "男宝时\n",
      "继孙俪\n",
      "天祛掉\n",
      "传雅培正\n",
      "越活\n",
      "穷丑\n",
      "岁险\n",
      "美画\n",
      "赵丽颖同\n",
      "签入\n",
      "时嫁\n",
      "时美过\n",
      "岁长\n",
      "戏富\n",
      "挑粪\n",
      "三度\n",
      "赵丽颖疑\n",
      "长残\n",
      "高小琴\n",
      "演遍\n",
      "英好\n",
      "曾狂\n",
      "比鲁豫\n",
      "伤得\n",
      "幸福美满\n",
      "分豪车\n",
      "英火\n",
      "大麟子\n",
      "处滴\n",
      "韩红向\n",
      "做阔\n",
      "生而\n",
      "遭群嘲\n",
      "为情\n",
      "秀豪车\n",
      "酒字\n",
      "曝斥\n",
      "仇元甲兄\n",
      "会为\n",
      "人财\n",
      "两失\n",
      "风百\n",
      "戴美瞳\n",
      "组亲肤\n",
      "张证\n",
      "油市\n",
      "再建\n",
      "微信放\n",
      "没钱治\n",
      "盟市\n",
      "推一刷\n",
      "第四名\n",
      "情后\n",
      "美妈们\n",
      "数着\n",
      "太清奇\n",
      "曝定\n",
      "要播\n",
      "传怕\n",
      "燃到\n",
      "两艘\n",
      "烧汤\n",
      "好养\n",
      "天纹\n",
      "难长\n",
      "种盆\n",
      "pancoat\n",
      "撕张\n",
      "艺兴\n",
      "窦骁娜\n",
      "张翰会\n",
      "论出\n",
      "这架\n",
      "泰森太\n",
      "点怀\n",
      "含肉毒\n",
      "滑胎\n",
      "科不\n",
      "太宠\n",
      "过多致\n",
      "宝惊\n",
      "盐加\n",
      "这补\n",
      "只出\n",
      "妈要\n",
      "没拉住\n",
      "妙龄少女\n",
      "两起\n",
      "直叫\n",
      "竟致\n",
      "男发\n",
      "整胸\n",
      "赠其\n",
      "朱丹回\n",
      "李湘为\n",
      "遭批\n",
      "诗龄\n",
      "不护\n",
      "博掉\n",
      "看衰\n",
      "却入\n",
      "因吹\n",
      "狂泼\n",
      "有过\n",
      "玩狠\n",
      "姜切片\n",
      "绝味\n",
      "如墨\n",
      "姜配\n",
      "黑量\n",
      "趴地\n",
      "菜泡\n",
      "东到\n",
      "称迪丽\n",
      "爆禁\n",
      "用脏手\n",
      "扎开\n",
      "张翰要\n",
      "终没人\n",
      "窦骁新\n",
      "张翰罚\n",
      "张翰秀\n",
      "张翰帅\n",
      "真怀\n",
      "张庭孕\n",
      "张翰因\n",
      "三重\n",
      "不死\n",
      "后变\n",
      "三婚\n",
      "邓超竟\n",
      "一人设\n",
      "继谢娜\n",
      "张蓝心\n",
      "诗美\n",
      "神爹\n",
      "挺配\n",
      "继张馨予\n",
      "谢娜疑\n",
      "求宝强\n",
      "该告\n",
      "似海\n",
      "赵丽颖要\n",
      "退圈\n",
      "强花\n",
      "比马蓉强\n",
      "会信\n",
      "微速览\n",
      "鹏疑\n",
      "老铁们\n",
      "何炅见\n",
      "礼裙\n",
      "林宥\n",
      "娱姐\n",
      "娱见\n",
      "关晓彤糊\n",
      "娱讯\n",
      "王思聪米\n",
      "娱评\n",
      "吴清功\n",
      "娱闻\n",
      "王俊凯迪丽\n",
      "健要\n",
      "说太辣\n",
      "招洗\n",
      "手台费\n",
      "获重判\n",
      "曝周\n",
      "迅高\n",
      "圣远\n",
      "小志出\n",
      "岁潮\n",
      "或变\n",
      "音触\n",
      "恒大新帅\n",
      "我活\n",
      "十赌\n",
      "喊妈\n",
      "嫁个\n",
      "豪命\n",
      "十几岁\n",
      "虽过\n",
      "怎看\n",
      "六位\n",
      "七位\n",
      "想家\n",
      "粉会\n",
      "可零\n",
      "晒娃\n",
      "郑裕美\n",
      "刘爆\n",
      "宋选\n",
      "十二个\n",
      "怒怀\n",
      "长不高\n",
      "仔丸\n",
      "酸食\n",
      "旧谣\n",
      "一昧\n",
      "减胎\n",
      "枣有\n",
      "虽易\n",
      "吃酸\n",
      "太爱\n",
      "长会\n",
      "魔胎\n",
      "华让\n",
      "那怀\n",
      "跟怀\n",
      "斑真\n",
      "大又圆\n",
      "八人\n",
      "孕好\n",
      "事上\n",
      "更白\n",
      "孕妈常\n",
      "那可要\n",
      "时乱\n",
      "孕妈生\n",
      "孕妻\n",
      "别抱\n",
      "肚型\n",
      "接女\n",
      "养颜去\n",
      "比脑\n",
      "比穿\n",
      "服靠\n",
      "太值\n",
      "发奶\n",
      "长高个\n",
      "低人\n",
      "更美\n",
      "常做\n",
      "男宝帅\n",
      "女宝美\n",
      "五样\n",
      "白走\n",
      "接男\n",
      "巧吃\n",
      "快人\n",
      "条怀\n",
      "接大\n",
      "女宝妈\n",
      "选不对\n",
      "孕妈别\n",
      "因准\n",
      "却别\n",
      "睡会\n",
      "要防\n",
      "胎火\n",
      "要禁\n",
      "表查\n",
      "服就够\n",
      "会伤\n",
      "字道\n",
      "孕症\n",
      "头相\n",
      "姜似\n",
      "脏手\n",
      "邓超要\n",
      "黑蒜\n",
      "赵丽颖竟\n",
      "做配\n",
      "弃夫\n",
      "大吼\n",
      "撩汉\n",
      "陈晓任\n",
      "时难\n",
      "批太\n",
      "爆黑\n",
      "16620781034\n",
      "藏友们\n",
      "当刀\n",
      "孙杨劳\n",
      "现小\n",
      "姚晨办\n",
      "给江\n",
      "放着\n",
      "这长\n",
      "位出\n",
      "一高\n",
      "差是\n",
      "改摇号\n",
      "多刀\n",
      "几刀\n",
      "专将成\n",
      "以应\n",
      "别错\n",
      "几所\n",
      "学渣成\n",
      "关晓彤疑\n",
      "学鲁能\n",
      "超换个\n",
      "凭此\n",
      "里生\n",
      "你速\n",
      "减衣\n",
      "只靠\n",
      "伤脑\n",
      "泡个\n",
      "吃此\n",
      "好长\n",
      "多转\n",
      "跳错\n",
      "高不高\n",
      "聪不\n",
      "被拉到\n",
      "却装\n",
      "长不高该\n",
      "长高靠\n",
      "妈别\n",
      "河沥溪\n",
      "吴忠至\n",
      "两女\n",
      "市住\n",
      "队规\n",
      "私接\n",
      "拒游\n",
      "坑村\n",
      "曝微\n",
      "博说\n",
      "六公里\n",
      "肾如\n",
      "三高稳\n",
      "身壮似\n",
      "它堪\n",
      "人不爱\n",
      "放锅里\n",
      "一蒸\n",
      "保肝护\n",
      "害草\n",
      "超爱\n",
      "减脂王\n",
      "no1\n",
      "喝能\n",
      "却常\n",
      "个通\n",
      "更粉\n",
      "常吃固\n",
      "茶中\n",
      "中之果\n",
      "之宗\n",
      "它配\n",
      "林洗\n",
      "多房\n",
      "不拿钱\n",
      "万亿度\n",
      "稳进\n",
      "一队\n",
      "可成\n",
      "德帅\n",
      "四侠\n",
      "几成\n",
      "若去\n",
      "彭胡弯\n",
      "搞基\n",
      "越用\n",
      "越卡\n",
      "锁屏\n",
      "干过\n",
      "要会\n",
      "七百万\n",
      "人必\n",
      "证上\n",
      "焚屋\n",
      "遭人割\n",
      "四六级\n",
      "七口\n",
      "百丈\n",
      "有多准\n",
      "便知\n",
      "凤祥银\n",
      "比巴图\n",
      "图可要\n",
      "几千几万\n",
      "马蓉求\n",
      "疑向\n",
      "我定\n",
      "博放狠话\n",
      "之苦\n",
      "并放话\n",
      "会输\n",
      "宋喆放话\n",
      "马蓉称\n",
      "其毁\n",
      "宋喆疑\n",
      "豪掷\n",
      "疑涉\n",
      "会判\n",
      "最多会判\n",
      "可宝强\n",
      "涉此\n",
      "马蓉禁\n",
      "重查\n",
      "微博求\n",
      "脸求\n",
      "心大\n",
      "宋喆要\n",
      "他气\n",
      "程野大\n",
      "巨火\n",
      "重疾\n",
      "太大要\n",
      "活一活\n",
      "认真听讲\n",
      "首秀\n",
      "f4\n",
      "曝暂\n",
      "小撒\n",
      "宋爆\n",
      "小s\n",
      "又力\n",
      "宋祖得\n",
      "几首\n",
      "想红想\n",
      "坠桥\n",
      "算出去\n",
      "可长\n",
      "骂遍\n",
      "单替\n",
      "生不动\n",
      "舞力\n",
      "揭施\n",
      "一公\n",
      "称施\n",
      "分小\n",
      "再伤\n",
      "全倒\n",
      "virgil\n",
      "abloh\n",
      "前国足\n",
      "美加墨\n",
      "一站\n",
      "三检\n",
      "乐遭\n",
      "而致\n",
      "优畅\n",
      "街夏联\n",
      "宝奶\n",
      "有接\n",
      "易使\n",
      "一员\n",
      "流黄\n",
      "胖越\n",
      "重越\n",
      "第八天\n",
      "总吃\n",
      "断夜奶\n",
      "粘人\n",
      "一喝立\n",
      "越治越\n",
      "立退\n",
      "一百倍\n",
      "澡后\n",
      "酸爽\n",
      "全不\n",
      "溶豆\n",
      "选存\n",
      "四宗\n",
      "脑后\n",
      "别因\n",
      "咬出\n",
      "期吃\n",
      "磨娘\n",
      "越难\n",
      "被裁\n",
      "身睡\n",
      "x7\n",
      "宝马新\n",
      "案刚\n",
      "案大\n",
      "4l\n",
      "比宝骏\n",
      "我开\n",
      "多平\n",
      "取卵\n",
      "似港\n",
      "匪片\n",
      "疑现\n",
      "放瓶水\n",
      "拿水\n",
      "黑拳\n",
      "捕到\n",
      "光人\n",
      "人出\n",
      "爆怀\n",
      "实拍用\n",
      "整颗\n",
      "几十只\n",
      "太辣眼\n",
      "实拍超\n",
      "棍状\n",
      "杀后\n",
      "数十斤\n",
      "秒速\n",
      "开秀\n",
      "韩姨爆\n",
      "会恋\n",
      "诗双\n",
      "宣宝\n",
      "芳儿\n",
      "椒园\n",
      "多座\n",
      "喷一\n",
      "宪哥\n",
      "热足\n",
      "一万只\n",
      "活多大\n",
      "绿植能\n",
      "七只\n",
      "两把\n",
      "半患\n",
      "从何\n",
      "种能\n",
      "吸雾\n",
      "再脏\n",
      "杨紫林\n",
      "吸废排\n",
      "第二名\n",
      "很卡\n",
      "边放上\n",
      "全给\n",
      "宜忌\n",
      "扔教\n",
      "套上\n",
      "难擦\n",
      "发钝\n",
      "如新\n",
      "牛人教\n",
      "需放点\n",
      "丢点\n",
      "数十倍\n",
      "土壳\n",
      "一刷\n",
      "称能\n",
      "喂活\n",
      "injuv\n",
      "莹久\n",
      "招清宿\n",
      "众鑫活\n",
      "羊馆\n",
      "盛悦府\n",
      "白白嫩\n",
      "亿成\n",
      "24h\n",
      "万招\n",
      "养着\n",
      "马踏\n",
      "贩婴案\n",
      "补氧神水\n",
      "何孟怀\n",
      "买艘\n",
      "曾酒\n",
      "美中印\n",
      "最逗\n",
      "好防\n",
      "王凯版\n",
      "雪姨有\n",
      "耍个\n",
      "对飙\n",
      "五三年\n",
      "王思聪家\n",
      "被象\n",
      "象夫\n",
      "象尾\n",
      "追人\n",
      "再存\n",
      "赵丽颖何\n",
      "董洁王\n",
      "进户\n",
      "不愿用\n",
      "盛一伦小妾\n",
      "将准\n",
      "泡入\n",
      "家長\n",
      "送豪车\n",
      "小七暴\n",
      "这颜值\n",
      "王俊凯学\n",
      "五百公里\n",
      "三发\n",
      "食人蜂\n",
      "炫酷\n",
      "已年\n",
      "有奇招\n",
      "网来\n",
      "只住\n",
      "不租\n",
      "千头\n",
      "本想\n",
      "这活\n",
      "倒些\n",
      "那该\n",
      "问岳云鹏\n",
      "竟射出\n",
      "小六子\n",
      "总感\n",
      "小凡\n",
      "要建\n",
      "他怕\n",
      "埋路\n",
      "打生\n",
      "招太好\n",
      "能减\n",
      "一打\n",
      "驾位\n",
      "驾扣\n",
      "侗家\n",
      "玩雪\n",
      "小帅哥\n",
      "说药\n",
      "坐过\n",
      "越站\n",
      "点力\n",
      "小提示\n",
      "防掉\n",
      "没整\n",
      "第一年\n",
      "变程野\n",
      "文松面\n",
      "却面\n",
      "没摊\n",
      "好爹\n",
      "照终\n",
      "喷惨\n",
      "爆红到\n",
      "网红猪\n",
      "音界里\n",
      "遭短\n",
      "佩琪\n",
      "小甜馨\n",
      "夹式\n",
      "6x\n",
      "s2\n",
      "孔引\n",
      "miui9\n",
      "真机谍\n",
      "仅差\n",
      "做安卓\n",
      "2s\n",
      "max3\n",
      "刷出\n",
      "第一支\n",
      "单雷军\n",
      "乐视存\n",
      "拼红米\n",
      "note5\n",
      "买贵补\n",
      "只售\n",
      "大促\n",
      "直怼\n",
      "孕味足\n",
      "店买\n",
      "消不掉\n",
      "冷凍\n",
      "发多狠\n",
      "墨碳\n",
      "似墨\n",
      "三千尺\n",
      "多小妙\n",
      "tace\n",
      "161002\n",
      "花开花\n",
      "小钱币\n",
      "心都化\n",
      "魏教\n",
      "其滚出\n",
      "称钱\n",
      "露个\n",
      "四千块\n",
      "开怼\n",
      "或大降\n",
      "不认\n",
      "男不离\n",
      "家上\n",
      "里怀\n",
      "俩个\n",
      "驱蟹\n",
      "巧招\n",
      "跨项\n",
      "这八本\n",
      "旷世奇\n",
      "只值\n",
      "豪高鑫\n",
      "己生\n",
      "改费\n",
      "多印\n",
      "几万倍\n",
      "周琦再\n",
      "中工\n",
      "能进\n",
      "几十万倍\n",
      "天就治好\n",
      "莽荒记\n",
      "昆凌为\n",
      "迎婴\n",
      "怒指\n",
      "坂东永辉\n",
      "天排\n",
      "万在华\n",
      "三非\n",
      "人干\n",
      "天终\n",
      "双龙纹\n",
      "个食\n",
      "只落\n",
      "招煞\n",
      "未超\n",
      "黑臭\n",
      "炸天\n",
      "比瞬秒\n",
      "屡招\n",
      "传摩拜\n",
      "万奖\n",
      "北沂堂\n",
      "用警\n",
      "m15\n",
      "评制\n",
      "鲁媒\n",
      "四换\n",
      "三鲁能\n",
      "坑能\n",
      "杨润达\n",
      "通血补\n",
      "湿毒治\n",
      "时可加\n",
      "十用\n",
      "九好\n",
      "几十户\n",
      "长像\n",
      "山渣加\n",
      "临晋\n",
      "佛母\n",
      "同舟\n",
      "编的民\n",
      "喝治\n",
      "山陽\n",
      "一塊\n",
      "開價\n",
      "不名\n",
      "认父\n",
      "互怼\n",
      "我妈\n",
      "小岳岳\n",
      "输惨\n",
      "后秀\n",
      "群演\n",
      "赔惨\n",
      "狂损\n",
      "于谦忙\n",
      "认岳云鹏\n",
      "于谦成\n",
      "几百几百\n",
      "压只\n",
      "一载\n",
      "岳阳三荷\n",
      "带飞\n",
      "嘿哈\n",
      "天岳幕\n",
      "时冲过\n",
      "震烂\n",
      "大鑫城\n",
      "峰菲恋\n",
      "崔天临\n",
      "没教\n",
      "仅卖\n",
      "数千元\n",
      "三万多\n",
      "csc8952\n",
      "3u8633\n",
      "未谈过\n",
      "谈三大\n",
      "工信\n",
      "部怒\n",
      "好大\n",
      "银瑞信\n",
      "卧睡\n",
      "过奈\n",
      "托孟婆\n",
      "左旗林\n",
      "量效\n",
      "酒加\n",
      "似碳\n",
      "显白显\n",
      "六分钟\n",
      "很灵\n",
      "巨尊\n",
      "二十一年\n",
      "造壹仙\n",
      "吞人\n",
      "還能\n",
      "卖员\n",
      "竟高达\n",
      "十多天\n",
      "难安\n",
      "百分之六十\n",
      "数天\n",
      "微博放话\n",
      "甜秀\n",
      "恩阳\n",
      "集够\n",
      "赞换\n",
      "美以\n",
      "基孔\n",
      "数百人\n",
      "句话解\n",
      "之恨\n",
      "或造\n",
      "币安买岛\n",
      "币安在\n",
      "长侯\n",
      "继刚\n",
      "多为\n",
      "水浸泡\n",
      "美白显\n",
      "肉上\n",
      "两吨\n",
      "粒大\n",
      "系在\n",
      "帅丕张\n",
      "当张\n",
      "翰面\n",
      "张翰大\n",
      "师范毕业\n",
      "迎三大\n",
      "帕托\n",
      "愿鲁能\n",
      "帅掉\n",
      "协勤\n",
      "菩洱\n",
      "猫饭\n",
      "倒输\n",
      "帮转\n",
      "杨延广\n",
      "一豆\n",
      "配一宝\n",
      "人多\n",
      "四段\n",
      "原凶\n",
      "调脂\n",
      "肝护\n",
      "点来\n",
      "可有福\n",
      "ak47\n",
      "黄难\n",
      "七届\n",
      "不晕\n",
      "会令\n",
      "叶做\n",
      "常给\n",
      "常跷\n",
      "可起\n",
      "之效\n",
      "剩胸\n",
      "较发\n",
      "不炼\n",
      "瞎炼\n",
      "不愿收\n",
      "再卷\n",
      "要进\n",
      "黑吉\n",
      "辽蒙\n",
      "宴上\n",
      "遭狂\n",
      "里巧放\n",
      "得交\n",
      "比老\n",
      "好美\n",
      "易塞\n",
      "买大\n",
      "胃不痛\n",
      "摘点\n",
      "胸强\n",
      "疑发\n",
      "稳超\n",
      "从三楼\n",
      "冬春\n",
      "急生\n",
      "男一女\n",
      "现扫\n",
      "交违\n",
      "库平七钱\n",
      "尼美\n",
      "下现\n",
      "转死\n",
      "电到\n",
      "第二课\n",
      "上强\n",
      "恒大来\n",
      "罗韦世豪\n",
      "恒大签\n",
      "连缴\n",
      "肉战\n",
      "十几天\n",
      "人因\n",
      "长隆\n",
      "广東\n",
      "占福\n",
      "几十个\n",
      "多大恨\n",
      "娱令\n",
      "烂剧\n",
      "第二批\n",
      "吞物\n",
      "热游\n",
      "没拉下\n",
      "一档\n",
      "禁播\n",
      "出单\n",
      "吞物门\n",
      "称可供\n",
      "设市\n",
      "仅为\n",
      "再断\n",
      "庆元旦\n",
      "无数只\n",
      "就养\n",
      "莫隐婚\n",
      "遭石锤\n",
      "稿齐\n",
      "系类\n",
      "最短\n",
      "应易璐\n",
      "想醉\n",
      "某网\n",
      "疑自\n",
      "机得\n",
      "一两月\n",
      "羊睾\n",
      "康震为\n",
      "pro2\n",
      "锤粉\n",
      "5c\n",
      "更薄\n",
      "网约车\n",
      "办称\n",
      "十部\n",
      "人受\n",
      "延过\n",
      "你够\n",
      "建个\n",
      "开抢\n",
      "网约\n",
      "冲上\n",
      "好领\n",
      "按月付\n",
      "救蛇保\n",
      "要降\n",
      "几百个\n",
      "新用式\n",
      "局在\n",
      "第一列\n",
      "一笑\n",
      "当大\n",
      "别秀\n",
      "冲蛋\n",
      "下会\n",
      "别慌有\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "弃车\n",
      "毒狗\n",
      "省出\n",
      "杨紫周\n",
      "二十多年\n",
      "礼上\n",
      "亲姑\n",
      "曾痛\n",
      "姜汉娜\n",
      "姑侄\n",
      "因患\n",
      "反杀\n",
      "实锤图\n",
      "秀同款\n",
      "这女\n",
      "大爆光\n",
      "曝实\n",
      "杨紫微\n",
      "博晒\n",
      "很配\n",
      "大美妞\n",
      "藏得够\n",
      "张一山恋\n",
      "曝生\n",
      "杨紫要\n",
      "被抛弃了\n",
      "很多年\n",
      "爹坑\n",
      "传患\n",
      "新晋\n",
      "别笑\n",
      "宠妹\n",
      "张予\n",
      "张伦硕带\n",
      "十口\n",
      "张伯芝\n",
      "想灭\n",
      "完候\n",
      "活要\n",
      "疯来\n",
      "51a\n",
      "动它\n",
      "美朝\n",
      "五部\n",
      "装逼\n",
      "爸人脉\n",
      "蒋欣遇\n",
      "截胡小\n",
      "鞠婧\n",
      "持棍\n",
      "还进\n",
      "吊缆\n",
      "局狂\n",
      "脖卡\n",
      "谈个\n",
      "玩过\n",
      "陈晓退\n",
      "张有良\n",
      "想离\n",
      "亨离\n",
      "正脸\n",
      "杰哥\n",
      "张杰录\n",
      "照为\n",
      "叫炅炅\n",
      "图竟\n",
      "亿购\n",
      "三处\n",
      "开黑\n",
      "杰粉\n",
      "删博\n",
      "中谢娜\n",
      "还合开\n",
      "传着\n",
      "二十个\n",
      "说事\n",
      "十月底\n",
      "喧称\n",
      "交新\n",
      "遭霆锋\n",
      "不输于\n",
      "字引\n",
      "港力\n",
      "追生\n",
      "新戏定\n",
      "锋芝恋\n",
      "愈像\n",
      "亿想\n",
      "可退\n",
      "亿争\n",
      "带俩\n",
      "锋菲\n",
      "接三人\n",
      "谢贤笑\n",
      "度入\n",
      "不缺\n",
      "没谈过\n",
      "要争\n",
      "携新\n",
      "子不当\n",
      "程冠希\n",
      "个官\n",
      "再多生\n",
      "耍酷\n",
      "多金\n",
      "别想用\n",
      "不悔\n",
      "现港\n",
      "竟放话\n",
      "谢贤因\n",
      "累到\n",
      "要大婚\n",
      "曝想\n",
      "疑反\n",
      "怒称\n",
      "被富\n",
      "谢贤回\n",
      "谢贤竟\n",
      "全随\n",
      "张伦硕姓\n",
      "已无路\n",
      "不亏\n",
      "下输\n",
      "李晨泪\n",
      "之家终\n",
      "护女\n",
      "孙上\n",
      "不活\n",
      "张檬妆容\n",
      "沉银\n",
      "张琼辉\n",
      "曝不雅\n",
      "科甜\n",
      "戴上\n",
      "位炮友\n",
      "酷黑\n",
      "迷妹\n",
      "很傲\n",
      "科姗恋\n",
      "没替\n",
      "跟景甜\n",
      "害惨\n",
      "成渣现\n",
      "有颜\n",
      "戏里\n",
      "张翰快\n",
      "两字\n",
      "比前\n",
      "另择\n",
      "张翰出\n",
      "博隔空\n",
      "跟爽\n",
      "话成\n",
      "大剧\n",
      "郑爽疑\n",
      "扎气\n",
      "塘主\n",
      "引众\n",
      "塘主心\n",
      "称娜\n",
      "扎配\n",
      "虐到\n",
      "戏生情\n",
      "微博传\n",
      "张翰微\n",
      "博秀花\n",
      "张翰想\n",
      "张翰新\n",
      "接张翰\n",
      "八比\n",
      "张翰有\n",
      "张翰暗\n",
      "两人快\n",
      "张翰爱\n",
      "张翰用\n",
      "连爽\n",
      "用花\n",
      "纯到\n",
      "穿花\n",
      "张翰怒\n",
      "床战\n",
      "冯铭潮\n",
      "前旧\n",
      "曝与娜\n",
      "尽撒狗\n",
      "要塘\n",
      "扎粉\n",
      "郑爸\n",
      "张翰首\n",
      "王思聪怒\n",
      "最渣\n",
      "爆恋\n",
      "疑想\n",
      "红亮\n",
      "疑求\n",
      "首档\n",
      "秀将播\n",
      "张加帅\n",
      "有伴\n",
      "可鹿晗\n",
      "离组\n",
      "只带\n",
      "兴罗志祥\n",
      "兴罗志祥要\n",
      "坑成\n",
      "两嫁\n",
      "而鲁豫\n",
      "唐艺昕发\n",
      "五婚\n",
      "指蹭秀\n",
      "马思纯秀\n",
      "跑友\n",
      "男神配\n",
      "约影\n",
      "这有\n",
      "晏疑\n",
      "甜晒\n",
      "晏有何\n",
      "袁立会\n",
      "曝欠\n",
      "张雨绮生\n",
      "七零后\n",
      "发个\n",
      "多好\n",
      "博疑\n",
      "婚烟\n",
      "业有成\n",
      "微博点\n",
      "称非\n",
      "比何洁\n",
      "冯柯未\n",
      "新恋\n",
      "男情\n",
      "没戴\n",
      "手照\n",
      "戏真多\n",
      "没提\n",
      "说些\n",
      "几字\n",
      "称有\n",
      "获实\n",
      "发些\n",
      "有敢\n",
      "窦骁同\n",
      "予步\n",
      "瘦至\n",
      "频看\n",
      "暴瘦致\n",
      "张鹤伦当\n",
      "面儿\n",
      "过病\n",
      "減肥法\n",
      "也治好\n",
      "彈指\n",
      "台坛\n",
      "爱要\n",
      "f3\n",
      "面唱\n",
      "巨友门\n",
      "并种\n",
      "得值\n",
      "亿夺\n",
      "那颗\n",
      "眼妆太\n",
      "会得眼\n",
      "补身\n",
      "吃蒜法\n",
      "当有\n",
      "信刷\n",
      "当男神\n",
      "大吐槽\n",
      "差遭\n",
      "掺上\n",
      "彩王\n",
      "彪哥\n",
      "打后\n",
      "有爱互\n",
      "继应\n",
      "丫是\n",
      "换座\n",
      "演个\n",
      "晏因\n",
      "遭击\n",
      "晏惊\n",
      "登热\n",
      "我出\n",
      "哔柜\n",
      "神级\n",
      "晏要\n",
      "街吻\n",
      "一幕幕\n",
      "一百亩\n",
      "或少\n",
      "来代餐\n",
      "两瓣\n",
      "除醛法\n",
      "会越\n",
      "变皱\n",
      "时到\n",
      "一醉驾\n",
      "很想\n",
      "演杨过\n",
      "微博骂\n",
      "深八王\n",
      "添新证\n",
      "五胎\n",
      "豪赏\n",
      "而港\n",
      "可女\n",
      "主是\n",
      "加杨\n",
      "进错\n",
      "不信谣\n",
      "会火\n",
      "途三\n",
      "女主太\n",
      "男主铁\n",
      "称包\n",
      "三贱客\n",
      "黄渤宝\n",
      "萌路\n",
      "聚共演\n",
      "窃卖\n",
      "天打\n",
      "四择\n",
      "比药\n",
      "梁论\n",
      "真会学\n",
      "思聪\n",
      "我学\n",
      "顏色\n",
      "判斷\n",
      "身體\n",
      "能查\n",
      "前放\n",
      "粉于\n",
      "四月份\n",
      "一雪前\n",
      "很赞\n",
      "用后\n",
      "加客\n",
      "回服\n",
      "48111577\n",
      "会因\n",
      "提可\n",
      "安卓狗\n",
      "登入\n",
      "赞扣\n",
      "码可得\n",
      "粉小\n",
      "微信点\n",
      "白删\n",
      "包够\n",
      "测中\n",
      "钱码\n",
      "事大\n",
      "群里\n",
      "删后\n",
      "三十秒\n",
      "看微信\n",
      "两招\n",
      "转错\n",
      "开后\n",
      "担责\n",
      "tttim\n",
      "卡碟\n",
      "微博之夜\n",
      "sscc\n",
      "微博博主\n",
      "微博微信\n",
      "微博热\n",
      "微博留\n",
      "韩姨\n",
      "微商们\n",
      "微整\n",
      "newa\n",
      "二是\n",
      "美上\n",
      "徳裔\n",
      "阿玛松\n",
      "大犁\n",
      "带德系\n",
      "德媒\n",
      "德牧\n",
      "这路\n",
      "德系车\n",
      "6l\n",
      "越来越近\n",
      "烧车\n",
      "人钱\n",
      "喝好\n",
      "曝鲁能\n",
      "有籽\n",
      "法拿针\n",
      "血淌\n",
      "王源粉\n",
      "太堵\n",
      "赵丽颖想\n",
      "心知元\n",
      "极藻\n",
      "带尖\n",
      "红里\n",
      "心真大\n",
      "蹲墙\n",
      "护心\n",
      "不患\n",
      "林姐姐\n",
      "姐疑\n",
      "旭旭要\n",
      "七样\n",
      "请张\n",
      "或换\n",
      "三水\n",
      "好几张\n",
      "易到\n",
      "快束\n",
      "题亮\n",
      "这三人\n",
      "文怒\n",
      "堂复牌\n",
      "加微\n",
      "信称\n",
      "寄个\n",
      "不揽收\n",
      "一敲\n",
      "姜加\n",
      "天爆\n",
      "天祛湿毒\n",
      "二周\n",
      "即白\n",
      "快领\n",
      "元换\n",
      "无毛鸡\n",
      "男宝后\n",
      "忻动\n",
      "至人\n",
      "怀不上\n",
      "改了\n",
      "留长\n",
      "前多\n",
      "既抗\n",
      "产活\n",
      "竟产活\n",
      "绕颈\n",
      "后孕妈\n",
      "第几个\n",
      "说会生\n",
      "这根\n",
      "四吃\n",
      "孕妈晨\n",
      "对胎\n",
      "多宝妈\n",
      "孕妈来\n",
      "强少\n",
      "阿碧假\n",
      "说酸儿\n",
      "图来\n",
      "第三周\n",
      "胎宝会\n",
      "算多\n",
      "希素颜\n",
      "实记\n",
      "知怀\n",
      "怀男怀\n",
      "女早\n",
      "必接\n",
      "上己\n",
      "不鲜\n",
      "直断\n",
      "有宿\n",
      "悦蕾\n",
      "辟个\n",
      "快加\n",
      "一俩\n",
      "却领\n",
      "胎中\n",
      "品了\n",
      "做点\n",
      "粮时\n",
      "怎麼\n",
      "養肌\n",
      "一人成\n",
      "还助\n",
      "骚然\n",
      "急报\n",
      "18570268587\n",
      "侵靓绝\n",
      "外药\n",
      "补得\n",
      "长豆\n",
      "太干\n",
      "爱吃酸\n",
      "第一天\n",
      "穿同\n",
      "竟生\n",
      "鬼桥\n",
      "十七岁\n",
      "专吃\n",
      "恐袭\n",
      "恒大古\n",
      "亿战\n",
      "收涨\n",
      "一签\n",
      "前拜仁\n",
      "通吃安卓\n",
      "八具\n",
      "接打\n",
      "全靠演\n",
      "学渣\n",
      "一个半月\n",
      "泰艾\n",
      "能离\n",
      "之量\n",
      "音酿\n",
      "剃除\n",
      "周琦恐成\n",
      "四米\n",
      "张一山亲\n",
      "指數\n",
      "規模值\n",
      "万多亿\n",
      "宋喆同\n",
      "连猪\n",
      "诗认\n",
      "只招\n",
      "杨颖怒\n",
      "曝跑\n",
      "爆摩拜\n",
      "贪掉\n",
      "爆马云\n",
      "一个多\n",
      "金假\n",
      "粮撒多\n",
      "可买\n",
      "五蛇\n",
      "七八岁\n",
      "醋治好\n",
      "不养颜\n",
      "已拟\n",
      "第一任\n",
      "川陕\n",
      "做迪丽\n",
      "想减\n",
      "三顿\n",
      "想建\n",
      "网红惨\n",
      "五所\n",
      "想治好\n",
      "三块\n",
      "快吃点\n",
      "生不出\n",
      "在备\n",
      "先祛湿\n",
      "穆晓光\n",
      "需选\n",
      "铲肉\n",
      "大养\n",
      "九字\n",
      "当茶\n",
      "大眼长\n",
      "做速白\n",
      "看马云\n",
      "穿太多\n",
      "肠寿\n",
      "想长\n",
      "投美团\n",
      "曝马云\n",
      "对纳\n",
      "队欲签\n",
      "外媒闹\n",
      "当恒大\n",
      "挖笋\n",
      "一床\n",
      "会盖\n",
      "输多\n",
      "几把\n",
      "无汗\n",
      "称会\n",
      "不取\n",
      "无一人敢\n",
      "遮日\n",
      "夜不散\n",
      "价超\n",
      "小二生\n",
      "会到\n",
      "含着\n",
      "有段\n",
      "人侍\n",
      "类好\n",
      "恩替\n",
      "yefine\n",
      "烟烟\n",
      "摘瓜\n",
      "懂球帝\n",
      "茶妹\n",
      "黑构\n",
      "挂霜\n",
      "平腹\n",
      "時鐘\n",
      "既快\n",
      "平了\n",
      "懒熊\n",
      "现爱\n",
      "懒癌\n",
      "戏假\n",
      "戏如\n",
      "你行\n",
      "精主播\n",
      "戏过\n",
      "表一\n",
      "造一\n",
      "成德同\n",
      "城大\n",
      "城化\n",
      "忘关\n",
      "两贼\n",
      "多站\n",
      "20161225\n",
      "三人成\n",
      "两三天\n",
      "石犀\n",
      "过大\n",
      "改拉人\n",
      "幼崽\n",
      "豪购\n",
      "豪买\n",
      "开无牌\n",
      "粉衣\n",
      "怒刷\n",
      "现视\n",
      "但座\n",
      "喊累\n",
      "对亲\n",
      "疑张\n",
      "吴绮莉前\n",
      "龙太子\n",
      "王凯王\n",
      "一大帮\n",
      "如画\n",
      "无份\n",
      "光迪丽\n",
      "我哥\n",
      "吃面\n",
      "小面\n",
      "种活\n",
      "守好\n",
      "最机\n",
      "地外\n",
      "五座\n",
      "狗成\n",
      "能发\n",
      "老后\n",
      "沉珂\n",
      "年办\n",
      "穿大码\n",
      "新出\n",
      "牵错\n",
      "胸小\n",
      "我花\n",
      "能套\n",
      "个现\n",
      "天戒\n",
      "戒不掉\n",
      "前三天\n",
      "碰烟\n",
      "美对\n",
      "七周年\n",
      "三架\n",
      "酬薪\n",
      "骑熊\n",
      "杀破\n",
      "看够\n",
      "战狼二高\n",
      "战狼二\n",
      "战狼高\n",
      "戚玉婷\n",
      "女模\n",
      "人患\n",
      "江阴人\n",
      "字版\n",
      "可遇\n",
      "新证\n",
      "四五个\n",
      "证入\n",
      "名酿\n",
      "证有\n",
      "还争\n",
      "只涨\n",
      "中弘\n",
      "每分钟\n",
      "不谈\n",
      "告母\n",
      "租不起\n",
      "换标\n",
      "除清\n",
      "川字会\n",
      "按好\n",
      "可除\n",
      "地放\n",
      "一匙\n",
      "告死\n",
      "能直\n",
      "电时\n",
      "一格电\n",
      "上放根\n",
      "一千多个\n",
      "充不\n",
      "几十秒\n",
      "找人修\n",
      "充不进\n",
      "完惊出\n",
      "两下\n",
      "剩一格\n",
      "一百遍\n",
      "变卡\n",
      "埋进\n",
      "iphonese2\n",
      "新样\n",
      "已连\n",
      "刮花\n",
      "屏炸\n",
      "iphone6p\n",
      "更大是\n",
      "能为\n",
      "没快\n",
      "宝等\n",
      "拼一\n",
      "旧机\n",
      "比满格强\n",
      "比买个\n",
      "越强\n",
      "可帮\n",
      "一开\n",
      "常州人\n",
      "服为\n",
      "多道\n",
      "次用\n",
      "玩一\n",
      "阿饱教\n",
      "充错\n",
      "家网\n",
      "控都\n",
      "防蚊\n",
      "進水裡\n",
      "兩種\n",
      "手機入\n",
      "處理\n",
      "速乾法\n",
      "輻射\n",
      "离过\n",
      "短者\n",
      "手贱\n",
      "需点\n",
      "魏一宁\n",
      "范世琦\n",
      "靳东怕\n",
      "获力\n",
      "吴佩慈要\n",
      "扒爷\n",
      "癖许\n",
      "某星\n",
      "遭何洁\n",
      "打卓伟\n",
      "别养\n",
      "赵又廷现\n",
      "四针\n",
      "九输\n",
      "赌九输\n",
      "放此宝\n",
      "十句\n",
      "老输\n",
      "身帮\n",
      "财小\n",
      "打麻\n",
      "將口\n",
      "厲害\n",
      "执金\n",
      "大价\n",
      "首克\n",
      "扫一\n",
      "扫交\n",
      "可缴\n",
      "扬武坊\n",
      "领啦\n",
      "批刀郎\n",
      "多少级\n",
      "省电有\n",
      "处冰\n",
      "切半\n",
      "粉治\n",
      "早越\n",
      "出現\n",
      "卧蚕\n",
      "现太惨\n",
      "三千枚\n",
      "投完\n",
      "布着\n",
      "证大\n",
      "投错票\n",
      "碰高\n",
      "成小迷弟\n",
      "射墨\n",
      "股全览\n",
      "留个\n",
      "抖友们\n",
      "猪精\n",
      "慢燃\n",
      "药奥司\n",
      "防衰促\n",
      "只排\n",
      "最棒\n",
      "码提\n",
      "育女\n",
      "勇当\n",
      "抢恒大\n",
      "挖纳\n",
      "辅警致\n",
      "截金晨\n",
      "抢领\n",
      "爱茜茜里\n",
      "护命素\n",
      "之薇\n",
      "何炅尬\n",
      "恒大够\n",
      "以一敌\n",
      "噎食\n",
      "纸竟\n",
      "徹底\n",
      "喝罐\n",
      "烟帮\n",
      "抽哈\n",
      "烟是\n",
      "一个三天\n",
      "伤手\n",
      "拉羊车\n",
      "死羊\n",
      "投成\n",
      "三趟\n",
      "杨颖带\n",
      "当网\n",
      "片会\n",
      "拒拜\n",
      "为师\n",
      "拒絕\n",
      "份全\n",
      "脸招\n",
      "下句\n",
      "恐致\n",
      "記憶力\n",
      "減退\n",
      "嫂有\n",
      "别太狂\n",
      "三娘\n",
      "高佣\n",
      "拼手速\n",
      "一千年\n",
      "买糖\n",
      "外送\n",
      "大梦力\n",
      "拿点\n",
      "转黑成\n",
      "地长\n",
      "染头\n",
      "润似\n",
      "事补\n",
      "桥弓\n",
      "后大\n",
      "轻拢\n",
      "选不出\n",
      "墙后\n",
      "挖龙\n",
      "挤金晨\n",
      "打赏\n",
      "莫拒\n",
      "二番\n",
      "战欲以\n",
      "不哭\n",
      "自黑王\n",
      "勿试\n",
      "或值\n",
      "猫养\n",
      "没打\n",
      "取不取\n",
      "外屏\n",
      "抄表数\n",
      "走快\n",
      "换新表后\n",
      "找帅\n",
      "已分\n",
      "纪凌尘疑\n",
      "狗学\n",
      "却告\n",
      "小谢贤\n",
      "领投方\n",
      "名高管\n",
      "换安卓\n",
      "请点\n",
      "腊八\n",
      "吴磊演\n",
      "点颗\n",
      "翔演\n",
      "万可买\n",
      "授人予\n",
      "过万有\n",
      "翻一翻\n",
      "吃学\n",
      "新长\n",
      "掉速\n",
      "挖机\n",
      "识机\n",
      "掏耳\n",
      "排清宿\n",
      "差要\n",
      "054b\n",
      "远输\n",
      "一尾\n",
      "掘港\n",
      "七人\n",
      "侯耀文墓\n",
      "涨请\n",
      "吸费\n",
      "男主辞演\n",
      "能救\n",
      "控住\n",
      "挪到\n",
      "第十七\n",
      "张神图\n",
      "栽易\n",
      "一点一点\n",
      "微信会\n",
      "房证\n",
      "为妙\n",
      "诵会\n",
      "错伤\n",
      "插电式\n",
      "张翰扇\n",
      "不红\n",
      "emcbet\n",
      "韩姨发\n",
      "迅怀\n",
      "重收\n",
      "小三姚\n",
      "逃至\n",
      "连卓伟\n",
      "阿宝和\n",
      "近状\n",
      "鹅肥\n",
      "做鹅肝酱\n",
      "有手\n",
      "灰产\n",
      "成烤\n",
      "竟连人\n",
      "搞个\n",
      "全删\n",
      "搞机\n",
      "版上\n",
      "这声\n",
      "一百分\n",
      "搞趣\n",
      "胖迪有\n",
      "澳媒\n",
      "9l\n",
      "携号\n",
      "只教\n",
      "雪嫩\n",
      "绿联\n",
      "摩拜史\n",
      "神补刀\n",
      "邀唱\n",
      "撒好\n",
      "摊事\n",
      "长到\n",
      "十五岁\n",
      "别当\n",
      "毒唯们\n",
      "撕遍\n",
      "成迪丽\n",
      "人问\n",
      "金句\n",
      "胸门\n",
      "称买\n",
      "互刷\n",
      "快拿起\n",
      "大招教\n",
      "再作\n",
      "马云开\n",
      "立减\n",
      "宝粉\n",
      "涨分\n",
      "太欢\n",
      "发招\n",
      "好开\n",
      "开收\n",
      "蓝瘦\n",
      "降额\n",
      "专享\n",
      "ios8\n",
      "网怒\n",
      "后必\n",
      "没停\n",
      "就关\n",
      "没人领\n",
      "酷骑\n",
      "q1\n",
      "恩仇录\n",
      "约车\n",
      "12866\n",
      "竟靠\n",
      "機車\n",
      "沒靈感\n",
      "备孕大招\n",
      "阴气森\n",
      "森连\n",
      "六名\n",
      "公瓜\n",
      "滑显\n",
      "斤小妙\n",
      "干喝\n",
      "知锈\n",
      "最简\n",
      "涂一涂\n",
      "用安卓\n",
      "粉篇\n",
      "连死\n",
      "教宝\n",
      "妈们\n",
      "九笔\n",
      "必毁\n",
      "深喊\n",
      "水包水\n",
      "找马\n",
      "掌眼\n",
      "教瘦哥\n",
      "三科\n",
      "喝后\n",
      "f10\n",
      "数千名\n",
      "数千年\n",
      "只考\n",
      "系车\n",
      "背词\n",
      "李湘大\n",
      "四杯\n",
      "精鼻\n",
      "腰细到\n",
      "快断\n",
      "二十岁\n",
      "脸女\n",
      "整上\n",
      "两小物\n",
      "无点\n",
      "2700mm\n",
      "渣渣辉\n",
      "闷尖\n",
      "缩招\n",
      "比海阔\n",
      "姚笛时\n",
      "谈旧\n",
      "卢本伟见\n",
      "赵梦玥\n",
      "网红要\n",
      "能管\n",
      "蛇哥\n",
      "韦神同\n",
      "张琪格\n",
      "挑粪工\n",
      "发站\n",
      "内信\n",
      "断直\n",
      "演依萍\n",
      "之夏\n",
      "想放\n",
      "哪放\n",
      "千里\n",
      "一机\n",
      "新一季\n",
      "范丞丞上\n",
      "已涨\n",
      "停新规\n",
      "触线\n",
      "两件\n",
      "和币\n",
      "后令\n",
      "透车\n",
      "驾记\n",
      "新代\n",
      "危废\n",
      "狮岗路\n",
      "有病\n",
      "合年\n",
      "合是\n",
      "别多交\n",
      "交不交\n",
      "浅恋\n",
      "sr9\n",
      "扫扫\n",
      "一插\n",
      "强喜\n",
      "股之王\n",
      "结就\n",
      "这婚\n",
      "不结\n",
      "新媒\n",
      "富养\n",
      "新季\n",
      "吃致\n",
      "一堂\n",
      "倍显\n",
      "限签\n",
      "多养\n",
      "几盆\n",
      "第一波\n",
      "潮来\n",
      "立信德豪\n",
      "5k\n",
      "出锅\n",
      "日发\n",
      "mix2s\n",
      "演小七\n",
      "哪来\n",
      "没换\n",
      "男主后\n",
      "雪姨\n",
      "演尔豪\n",
      "豪方瑜\n",
      "最受\n",
      "四千年\n",
      "男主太\n",
      "关晓彤排\n",
      "终定\n",
      "需停\n",
      "玉原石\n",
      "大盆鸡\n",
      "人滴\n",
      "群狼\n",
      "为棚\n",
      "人靠\n",
      "两字疑\n",
      "九中\n",
      "18530797265\n",
      "零充\n",
      "需上\n",
      "扬州人\n",
      "拉一拉\n",
      "拉指\n",
      "完万\n",
      "不拉会\n",
      "过首保\n",
      "打要\n",
      "珠里\n",
      "剧外\n",
      "过纸\n",
      "可扫\n",
      "首考\n",
      "有字\n",
      "书无字\n",
      "喝真能\n",
      "161122\n",
      "新麦\n",
      "曝含\n",
      "茶协\n",
      "茶真\n",
      "之人抖\n",
      "三抖\n",
      "一检\n",
      "换不起\n",
      "已创\n",
      "养只\n",
      "能空\n",
      "有以\n",
      "购已\n",
      "我爱你\n",
      "粉有\n",
      "我学过\n",
      "巧借\n",
      "扎胃\n",
      "几公斤\n",
      "无辣\n",
      "不欢\n",
      "领投美团\n",
      "五爱路\n",
      "太悦\n",
      "人长\n",
      "日企\n",
      "发不雅\n",
      "日媒称\n",
      "日拟\n",
      "vape\n",
      "组实\n",
      "群愤\n",
      "放射激光\n",
      "人下\n",
      "没洞\n",
      "亿零\n",
      "此赖\n",
      "想炸\n",
      "旅上\n",
      "哥狂\n",
      "161106\n",
      "装在\n",
      "出昏招\n",
      "炸个\n",
      "要炸\n",
      "拟购\n",
      "帅爆\n",
      "欲花\n",
      "断货王\n",
      "侵案\n",
      "日版\n",
      "可对陆\n",
      "吃粒\n",
      "此国肯\n",
      "无蚊\n",
      "万平方米\n",
      "不歇\n",
      "对陆\n",
      "旧屋\n",
      "旧爱霍\n",
      "爆哭\n",
      "这版\n",
      "淘出\n",
      "九点\n",
      "可大有\n",
      "真晚\n",
      "千万年\n",
      "人一闻\n",
      "需不需\n",
      "刷错\n",
      "毒似\n",
      "扶站\n",
      "五十岁\n",
      "第一杯\n",
      "学白富\n",
      "重理\n",
      "不僅養\n",
      "生還\n",
      "招病\n",
      "别上\n",
      "喝白\n",
      "时下生\n",
      "再袭\n",
      "旷视\n",
      "采玉\n",
      "昆凌刚\n",
      "周浩民\n",
      "杰伦是\n",
      "开黑组\n",
      "小周周\n",
      "二孩\n",
      "圆是\n",
      "昆凌晒照\n",
      "昆凌说\n",
      "信备\n",
      "四间\n",
      "未采\n",
      "内大狗\n",
      "有大招\n",
      "范小瘦\n",
      "二通\n",
      "证才行\n",
      "人回\n",
      "收跌\n",
      "还告\n",
      "遭掌\n",
      "爆张馨予\n",
      "别瞎学\n",
      "一桌\n",
      "拒见\n",
      "房拼\n",
      "劲宝\n",
      "出迟\n",
      "遭查\n",
      "轨霍\n",
      "赵丽颖家\n",
      "鹿晗择\n",
      "天记\n",
      "某电该\n",
      "天启大\n",
      "个区\n",
      "本書\n",
      "此告\n",
      "別語\n",
      "無倫次\n",
      "一封\n",
      "美空露\n",
      "宠成\n",
      "刷到\n",
      "这酷\n",
      "爆想\n",
      "说车\n",
      "尽毁\n",
      "跪亲\n",
      "比心\n",
      "赵丽颖冻\n",
      "遭性\n",
      "严正声明\n",
      "带盆带\n",
      "带桶\n",
      "要标\n",
      "男主罗志祥\n",
      "必瘦\n",
      "肠净\n",
      "春夏季\n",
      "弹口\n",
      "养颜季\n",
      "喜甜\n",
      "爱盐\n",
      "来个\n",
      "猛长个\n",
      "钓龄\n",
      "还来\n",
      "预透\n",
      "甜炸\n",
      "现美\n",
      "趣店\n",
      "二十一分\n",
      "推新歌\n",
      "速听\n",
      "吸浮\n",
      "这伤\n",
      "二角\n",
      "友们\n",
      "二十五日\n",
      "四日\n",
      "晒娃狂\n",
      "不晒娃\n",
      "改晒\n",
      "博晒照\n",
      "姜真\n",
      "没骗\n",
      "白蛋\n",
      "泡脚往\n",
      "姜即\n",
      "对战\n",
      "刷脂\n",
      "减出\n",
      "病来\n",
      "消滞\n",
      "好文\n",
      "亮枪\n",
      "奔求\n",
      "清脂\n",
      "达到最佳\n",
      "一大口\n",
      "万到\n",
      "我爸\n",
      "过百\n",
      "孕态\n",
      "景甜带\n",
      "张继科见\n",
      "竟连\n",
      "瓜众\n",
      "景甜微\n",
      "景甜怀\n",
      "张继科要\n",
      "解到\n",
      "不假\n",
      "前药\n",
      "曝会\n",
      "路征\n",
      "张继科终\n",
      "带张\n",
      "继科见\n",
      "照是\n",
      "景甜要\n",
      "凸肚\n",
      "超鹿晗\n",
      "潘思宁\n",
      "华胜天\n",
      "随用\n",
      "随充\n",
      "年望\n",
      "67374\n",
      "要拔\n",
      "拔不拔\n",
      "还拔\n",
      "暖炸\n",
      "暗拍\n",
      "薛之谦渣\n",
      "闺蜜家\n",
      "斗才\n",
      "但此\n",
      "攻乎\n",
      "斯害\n",
      "论雷\n",
      "系旧谣\n",
      "会浊\n",
      "跳真\n",
      "蔡家现\n",
      "若冲超\n",
      "新世俱杯\n",
      "皇萨仁\n",
      "亿欧\n",
      "曝京鲁\n",
      "最吸粉\n",
      "软瓶\n",
      "第九期\n",
      "营转\n",
      "p20plus\n",
      "ئ\n",
      "ا\n",
      "پ\n",
      "ت\n",
      "م\n",
      "ب\n",
      "ى\n",
      "ل\n",
      "ش\n",
      "ق\n",
      "ۇ\n",
      "ر\n",
      "ن\n",
      "ڭ\n",
      "ج\n",
      "د\n",
      "ي\n",
      "第七十七\n",
      "第七十\n",
      "第三十二\n",
      "第三十四\n",
      "第九十\n",
      "第二期\n",
      "第十一\n",
      "第十四\n",
      "第十期\n",
      "第四十七\n",
      "第四期\n",
      "曝关晓彤\n",
      "曝吴\n",
      "爆星爷\n",
      "曝周迅\n",
      "曝在\n",
      "抢金晨\n",
      "若昀\n",
      "第二局\n",
      "所晒\n",
      "曝杜\n",
      "沈梦辰疑\n",
      "曝李易峰\n",
      "江璐\n",
      "曝杜淳\n",
      "曝杨子\n",
      "依怀\n",
      "曝某\n",
      "幻乐\n",
      "曝罗\n",
      "李晨喜\n",
      "季黄子\n",
      "曝迪丽\n",
      "曝邓\n",
      "150618\n",
      "驾系\n",
      "曝霍\n",
      "曝韩红\n",
      "曝黄太吉\n",
      "要出\n",
      "曹三玲\n",
      "曹云金染\n",
      "太足\n",
      "未红时\n",
      "轰炮\n",
      "三关\n",
      "要交\n",
      "剩一\n",
      "不树\n",
      "未尊\n",
      "疑冢\n",
      "微博撒狗\n",
      "必可死\n",
      "成胡静\n",
      "曾卖\n",
      "他现\n",
      "英师出\n",
      "疯婆\n",
      "以死\n",
      "韩姨写\n",
      "因性\n",
      "有多乱\n",
      "莫辨\n",
      "指性\n",
      "曝性\n",
      "认被\n",
      "笑称\n",
      "硬上\n",
      "做曲\n",
      "未孕\n",
      "出柜成\n",
      "求渣\n",
      "男别\n",
      "后亲\n",
      "认不识\n",
      "销破\n",
      "惨到\n",
      "6at\n",
      "曾毅刚\n",
      "边唱边\n",
      "今因\n",
      "一脱\n",
      "晏苦\n",
      "上卖\n",
      "现爆降\n",
      "换个标\n",
      "火过\n",
      "十分之一\n",
      "那英会\n",
      "首晒\n",
      "无匙\n",
      "传小三\n",
      "次成\n",
      "夏沫侨\n",
      "微博早\n",
      "今为\n",
      "曾视\n",
      "求戏\n",
      "曾饰\n",
      "人销分\n",
      "萌宝\n",
      "几袋\n",
      "万级家\n",
      "416km\n",
      "这纯\n",
      "脚筋\n",
      "众泰圆\n",
      "一万发\n",
      "鹿晗首\n",
      "鲜炖\n",
      "不磨\n",
      "能装\n",
      "跳涨\n",
      "九十斤\n",
      "养易活\n",
      "季何猷\n",
      "用块\n",
      "佩上\n",
      "最悲\n",
      "最护\n",
      "快本出\n",
      "要大涨\n",
      "珠中\n",
      "江澳\n",
      "爆富\n",
      "多开\n",
      "复联\n",
      "竟排\n",
      "归小璐\n",
      "丰十连板\n",
      "孔照\n",
      "一百年\n",
      "十四日\n",
      "李晨大婚\n",
      "马蓉疑\n",
      "恐让\n",
      "百平\n",
      "可少\n",
      "完鹿晗\n",
      "吴亦凡们\n",
      "凌松\n",
      "烧多狠\n",
      "犯过\n",
      "脸先\n",
      "mufon\n",
      "好火\n",
      "堪比换\n",
      "眼术\n",
      "天住\n",
      "酥点\n",
      "其生\n",
      "款纯\n",
      "s60l\n",
      "法欲\n",
      "聂树斌案\n",
      "再享\n",
      "圆之夜\n",
      "月子期\n",
      "月安馨\n",
      "长为\n",
      "第一面\n",
      "探月\n",
      "极似\n",
      "还量\n",
      "吃凉\n",
      "尸工\n",
      "不爱坏\n",
      "月面\n",
      "韩红怒\n",
      "之称\n",
      "赵筱葳\n",
      "赖弘国\n",
      "宝叫\n",
      "它涨\n",
      "财汇\n",
      "速览\n",
      "深户\n",
      "宝算\n",
      "有交\n",
      "民可得\n",
      "拿毒\n",
      "专骗\n",
      "与生\n",
      "有传\n",
      "美度\n",
      "多酸爽\n",
      "开扒托奶\n",
      "阔腿裤\n",
      "微信分\n",
      "而北控\n",
      "踏准\n",
      "照后\n",
      "测男宝\n",
      "我测\n",
      "要放上\n",
      "时水里\n",
      "有福之人\n",
      "必生\n",
      "合二\n",
      "有聊\n",
      "护肝养\n",
      "神雾\n",
      "有花\n",
      "有融\n",
      "随餐\n",
      "想不红\n",
      "还会降\n",
      "最易\n",
      "会选\n",
      "知多坑\n",
      "某京\n",
      "万黑稿\n",
      "某猫\n",
      "万为\n",
      "有闭\n",
      "传洁\n",
      "厕块\n",
      "传一\n",
      "现神药\n",
      "售药\n",
      "桥惊现\n",
      "点次\n",
      "正佳\n",
      "竟上\n",
      "昆四任\n",
      "农佟\n",
      "生吃能\n",
      "泡久\n",
      "易评\n",
      "不入行\n",
      "条已\n",
      "会率\n",
      "可敌\n",
      "能住\n",
      "四双\n",
      "磁药\n",
      "第五套\n",
      "下一波\n",
      "狙神\n",
      "再能\n",
      "本兮以\n",
      "花沫\n",
      "五号\n",
      "本兮未\n",
      "本兮\n",
      "本应\n",
      "千到\n",
      "erx5\n",
      "再变\n",
      "还长\n",
      "跟汉兰\n",
      "达斗\n",
      "七座\n",
      "哈弗和宝俊\n",
      "3l\n",
      "车太惨\n",
      "朱丹因\n",
      "喜当\n",
      "服他\n",
      "朱之文于\n",
      "抱气\n",
      "朱之文竟\n",
      "办大席\n",
      "十七年\n",
      "中强\n",
      "上秀\n",
      "嫂妇\n",
      "朱之文因\n",
      "带于\n",
      "上拉于\n",
      "坟前\n",
      "朱之文熊\n",
      "抱于\n",
      "嫂会\n",
      "玉米地\n",
      "今发\n",
      "牵于\n",
      "朱之文要\n",
      "活切\n",
      "小尼小撒\n",
      "炒成\n",
      "一老\n",
      "亲够\n",
      "嫩妹\n",
      "步罗京\n",
      "初愈后\n",
      "忍泪\n",
      "朴信惠为\n",
      "朴智宪晒\n",
      "天写\n",
      "r4obqbp\n",
      "光鲜亮丽\n",
      "rbqxu80\n",
      "退不起\n",
      "一帝\n",
      "权健恒大\n",
      "处一看\n",
      "二丫终\n",
      "限卖\n",
      "证满\n",
      "次近\n",
      "上校军官\n",
      "李书沸\n",
      "李书福要\n",
      "亿做\n",
      "四驱仅\n",
      "男不愿\n",
      "致王祖\n",
      "蓝真要\n",
      "蓝愿\n",
      "多点\n",
      "男现\n",
      "男疑\n",
      "他娘\n",
      "小三微博\n",
      "遇旧\n",
      "六字\n",
      "抢回\n",
      "抽闷\n",
      "心真\n",
      "许晴约\n",
      "首爆\n",
      "墓下\n",
      "十一岁\n",
      "十三年\n",
      "李司棋\n",
      "李咏携\n",
      "這八本\n",
      "多讀\n",
      "這幾本\n",
      "彎路\n",
      "看手機\n",
      "李大毛教\n",
      "连竿\n",
      "李大毛\n",
      "漂钓法\n",
      "钓获\n",
      "成鸡\n",
      "获超快\n",
      "李太太\n",
      "春哥\n",
      "李宵鹏\n",
      "首笔\n",
      "黑警\n",
      "很刚\n",
      "pgone1400\n",
      "替上\n",
      "仔成\n",
      "两晚\n",
      "王思聪暗\n",
      "1400w\n",
      "反黑\n",
      "疑花\n",
      "大得\n",
      "万拉王\n",
      "有多贵\n",
      "手戴\n",
      "秦奋怒\n",
      "真乱\n",
      "学白百何\n",
      "行且\n",
      "桌伟\n",
      "王思聪大\n",
      "画上\n",
      "亮哥\n",
      "后以\n",
      "隔空秀\n",
      "曝以\n",
      "图门\n",
      "做件\n",
      "传共\n",
      "甚欢\n",
      "赖着\n",
      "很壮\n",
      "带甜馨\n",
      "只现\n",
      "戏太多\n",
      "做辣妈\n",
      "一丝\n",
      "看甜馨\n",
      "乃亮\n",
      "删微\n",
      "博秀\n",
      "甜馨锁\n",
      "李湘备\n",
      "整怪\n",
      "嘻哈范儿\n",
      "微博用\n",
      "穿成\n",
      "疑陪\n",
      "锅侠\n",
      "大欲\n",
      "有本\n",
      "乃爸\n",
      "万雇\n",
      "嘻哈范\n",
      "可忙\n",
      "追爱\n",
      "另一方\n",
      "破锅\n",
      "大打\n",
      "牌为\n",
      "不毁\n",
      "万试\n",
      "养小三\n",
      "简餐\n",
      "九菜\n",
      "一汤\n",
      "观舌象\n",
      "卓伟点\n",
      "继鹿晗\n",
      "陈伟霆发\n",
      "自评\n",
      "有多豪\n",
      "猛秀\n",
      "峰哥\n",
      "丽颖\n",
      "好配\n",
      "jiyunhudong\n",
      "6395653190230278401\n",
      "李易峰斥\n",
      "李易峰方\n",
      "场同\n",
      "继张\n",
      "继科景\n",
      "甜后\n",
      "敏俊演\n",
      "人太甜\n",
      "好太多\n",
      "微博要\n",
      "白新招\n",
      "比景甜\n",
      "之感\n",
      "韬鲁豫\n",
      "七冠\n",
      "吻帅\n",
      "问景甜\n",
      "催婚团\n",
      "发图\n",
      "而范爷\n",
      "变渣\n",
      "杀甜\n",
      "已凉\n",
      "晨哥\n",
      "李晨开\n",
      "可卓伟\n",
      "图补\n",
      "婚址\n",
      "做何\n",
      "一城\n",
      "李晨头\n",
      "被准\n",
      "像护\n",
      "吴亦凡林\n",
      "万婚\n",
      "组个\n",
      "添料\n",
      "战西提\n",
      "火不火\n",
      "增寿\n",
      "李沁发\n",
      "女本\n",
      "为母\n",
      "今微博\n",
      "李沁新\n",
      "晒多图\n",
      "李易峰录\n",
      "李沁口\n",
      "李浩菲疑\n",
      "李浩菲\n",
      "配叫\n",
      "养娃\n",
      "李湘富养\n",
      "某三字\n",
      "一改\n",
      "艳惊\n",
      "四座\n",
      "好几条\n",
      "这唱\n",
      "韩红刀\n",
      "年疑\n",
      "李玮珉\n",
      "男五\n",
      "薛之谦是\n",
      "曝其\n",
      "因得\n",
      "瘦脱\n",
      "现为\n",
      "妮长\n",
      "曝得\n",
      "活炖\n",
      "台四小\n",
      "直点\n",
      "曝命\n",
      "上犯\n",
      "现腿病\n",
      "马云视\n",
      "他私\n",
      "赔判\n",
      "遭利智\n",
      "说离\n",
      "一阵阵\n",
      "微博狂\n",
      "闺蜜发\n",
      "其闺蜜\n",
      "放锤\n",
      "期想\n",
      "薛之谦想\n",
      "王思聪神\n",
      "霍季奇\n",
      "李靓蕾\n",
      "孕照首\n",
      "杏熟\n",
      "村中\n",
      "巨棺\n",
      "棺内现\n",
      "拉人后\n",
      "买吨\n",
      "但经\n",
      "加陈醋\n",
      "湖人前\n",
      "再显\n",
      "为妹\n",
      "发狗\n",
      "沈梦辰结\n",
      "壕出\n",
      "时撒狗\n",
      "化大\n",
      "拆家\n",
      "没地\n",
      "桑拿室\n",
      "杠上\n",
      "硬广\n",
      "第几天\n",
      "说个\n",
      "i9\n",
      "重谈\n",
      "依带\n",
      "只拔\n",
      "颗牙\n",
      "位闺蜜\n",
      "差天别\n",
      "太近\n",
      "斥叛\n",
      "要个\n",
      "孕肚照\n",
      "掩孕\n",
      "疑受\n",
      "汪曼春成\n",
      "坐实怀\n",
      "160428\n",
      "原灭\n",
      "自泄瘾\n",
      "170910\n",
      "过床\n",
      "前演\n",
      "刘空青\n",
      "坐豪车\n",
      "群接\n",
      "摆过\n",
      "王思聪该\n",
      "所如\n",
      "赵丽颖夺\n",
      "比宫\n",
      "竞圈\n",
      "引迷弟\n",
      "幂斥\n",
      "获乐嘉力\n",
      "因俩\n",
      "只替\n",
      "真给\n",
      "揭靠\n",
      "同穿\n",
      "两人带\n",
      "假戏\n",
      "一区\n",
      "绣春刀\n",
      "幂生\n",
      "好萌\n",
      "半亿\n",
      "开五黑\n",
      "四层\n",
      "图师\n",
      "曝小\n",
      "太扯\n",
      "传拍\n",
      "没个\n",
      "宋茜钟\n",
      "楚曦\n",
      "太有福\n",
      "探小\n",
      "李易峰家\n",
      "获小\n",
      "看个\n",
      "分完\n",
      "好狠\n",
      "小白虫\n",
      "预排\n",
      "携妻\n",
      "徐少华\n",
      "负评\n",
      "太虐\n",
      "杨洋带\n",
      "郑爽秀\n",
      "杨洋恋\n",
      "杨洋用\n",
      "女主颜值\n",
      "杨洋要\n",
      "求小爽\n",
      "后终\n",
      "杨紫刚\n",
      "杨紫吃\n",
      "天只\n",
      "黑上\n",
      "杨紫张\n",
      "打个\n",
      "杨紫断\n",
      "杨紫晒\n",
      "应勤生\n",
      "杨紫晒验\n",
      "孕棒\n",
      "王丽坤全\n",
      "话令\n",
      "爆用\n",
      "太欠\n",
      "照脸\n",
      "肌有\n",
      "肌好\n",
      "写些\n",
      "杨蓉步\n",
      "情难\n",
      "一朵\n",
      "走秀旧\n",
      "没一看\n",
      "波叔\n",
      "要斥\n",
      "画卖\n",
      "现带\n",
      "杨颖为\n",
      "杨晓月\n",
      "缘差\n",
      "却争\n",
      "吃瓜纷\n",
      "杨颖戏\n",
      "多人来\n",
      "波哥\n",
      "我带\n",
      "需带\n",
      "豪配\n",
      "竟带\n",
      "遭胡歌\n",
      "杨颖接\n",
      "人放\n",
      "杨颖旧\n",
      "天未\n",
      "阚清\n",
      "万周迅\n",
      "孕后\n",
      "带肉\n",
      "中假\n",
      "脑王\n",
      "杭州人\n",
      "洗牙有\n",
      "绿汀路\n",
      "文一街\n",
      "多万辆\n",
      "通办\n",
      "比马云\n",
      "更能防\n",
      "食人者\n",
      "瞬涨\n",
      "之眼\n",
      "fluxion\n",
      "艺脸\n",
      "史大起\n",
      "一土\n",
      "高秀玉\n",
      "模后\n",
      "林丹带\n",
      "骨形\n",
      "袁湘琴\n",
      "长角\n",
      "整牙换\n",
      "全腿\n",
      "淤青向\n",
      "林允大秀\n",
      "迷出\n",
      "复播\n",
      "已患\n",
      "奉子\n",
      "霍如恋\n",
      "狂撒糖\n",
      "心在\n",
      "相戏里\n",
      "狂接\n",
      "头七在\n",
      "已哭成\n",
      "素颜晒\n",
      "因太宅\n",
      "芭莎\n",
      "证怀\n",
      "神离\n",
      "吵炸天\n",
      "小尖\n",
      "准嫁\n",
      "一袭\n",
      "维密秀\n",
      "已隐婚\n",
      "密婚\n",
      "心摇神动\n",
      "比志玲\n",
      "比伯和赛\n",
      "凸肚疑\n",
      "娜姐\n",
      "二月份\n",
      "必嫁\n",
      "获赞\n",
      "直亏\n",
      "字藏\n",
      "做爹\n",
      "病后\n",
      "脸圆\n",
      "终在\n",
      "刘畊宏发\n",
      "千帆\n",
      "蜜会\n",
      "要画\n",
      "最铁\n",
      "同购\n",
      "换八女\n",
      "黑史\n",
      "一箩筐\n",
      "预做\n",
      "火人\n",
      "甜不甜\n",
      "公和母\n",
      "咖旁\n",
      "打马云\n",
      "天猛\n",
      "有白\n",
      "六副药\n",
      "两虚\n",
      "保肝养\n",
      "虚上\n",
      "加虚\n",
      "硬如\n",
      "单吃\n",
      "腰膝\n",
      "某东\n",
      "其连\n",
      "网红上\n",
      "sbitch5\n",
      "喝能治\n",
      "皮熬\n",
      "水可治\n",
      "消腹\n",
      "祛湿养\n",
      "几大美白\n",
      "助排\n",
      "脂能\n",
      "地太早\n",
      "浓美白\n",
      "个富\n",
      "因买\n",
      "搭顺\n",
      "柴桑区\n",
      "亿拍\n",
      "后大涨\n",
      "栗阳\n",
      "李天翰要\n",
      "思梅桥\n",
      "唱刀郎\n",
      "望十连板\n",
      "称莫因\n",
      "恐核\n",
      "很近\n",
      "机是\n",
      "它切\n",
      "喷完\n",
      "喷威少\n",
      "九屋\n",
      "无穿\n",
      "吃杏时\n",
      "果肴\n",
      "公桃\n",
      "我常\n",
      "母桃\n",
      "混吃会\n",
      "还分\n",
      "公的\n",
      "桃打\n",
      "ktv2\n",
      "抓人\n",
      "五公里\n",
      "路二\n",
      "13945671177\n",
      "定个\n",
      "嘉玲生\n",
      "好棋\n",
      "性为\n",
      "心凌\n",
      "梅婷前\n",
      "梅婷暖心\n",
      "镇雁\n",
      "影村\n",
      "追钟\n",
      "无艳\n",
      "竟作此\n",
      "大光边\n",
      "梅西率\n",
      "二百元\n",
      "长高菜\n",
      "油用\n",
      "比绿萝\n",
      "斑美\n",
      "暗助\n",
      "去化\n",
      "早话\n",
      "需族\n",
      "不限贷\n",
      "河因\n",
      "没熟\n",
      "槐轩\n",
      "贾晓晨\n",
      "爆小三\n",
      "曝赫子铭\n",
      "郝子铭\n",
      "颗毒\n",
      "五课\n",
      "蛋惊现\n",
      "不碎\n",
      "淳中\n",
      "亚夏\n",
      "次重\n",
      "付辛博颖儿\n",
      "欧冠队\n",
      "超队\n",
      "终对\n",
      "以得\n",
      "很缺\n",
      "万颗\n",
      "必涨\n",
      "美妆博主\n",
      "范辰辰\n",
      "继迪丽\n",
      "赞其\n",
      "自远\n",
      "两线\n",
      "美新\n",
      "九登\n",
      "遭下\n",
      "更博\n",
      "阿娇飞\n",
      "十三名\n",
      "13137037109\n",
      "正黄\n",
      "为护刀\n",
      "千平方公里\n",
      "其怀\n",
      "此国女\n",
      "数千亿\n",
      "fc31\n",
      "上千亿\n",
      "此女\n",
      "动则\n",
      "而异\n",
      "两百年\n",
      "1g\n",
      "如铁\n",
      "如刚\n",
      "此队\n",
      "盼迎\n",
      "铁腿\n",
      "一虎\n",
      "高扫\n",
      "遭高人\n",
      "武旭霞\n",
      "二番战\n",
      "战坦克\n",
      "五拳\n",
      "称败\n",
      "残武僧\n",
      "猜播求\n",
      "扬国威\n",
      "生泪\n",
      "打残\n",
      "郭晨东\n",
      "抢面\n",
      "sb6\n",
      "十五个\n",
      "需缴\n",
      "歪妹\n",
      "前十有\n",
      "款日\n",
      "k2\n",
      "十款\n",
      "尸兄\n",
      "不挂\n",
      "压美\n",
      "11d\n",
      "数十架\n",
      "开味\n",
      "失女\n",
      "渐冻症\n",
      "下泡\n",
      "逗翻\n",
      "扎恋\n",
      "廖佳琳\n",
      "低转\n",
      "没花过\n",
      "每一顆\n",
      "記憶\n",
      "走心\n",
      "能要\n",
      "每体\n",
      "神招\n",
      "每到\n",
      "凌晨时分\n",
      "两三次\n",
      "三四次\n",
      "次水\n",
      "玉米须\n",
      "准快\n",
      "总靠\n",
      "天清肠\n",
      "喜失\n",
      "憋胀\n",
      "洗个\n",
      "泡错\n",
      "肺变\n",
      "排血毒\n",
      "毒排\n",
      "肿消\n",
      "鼾症\n",
      "粉粉\n",
      "天暖胃\n",
      "毒促\n",
      "巧喝\n",
      "推一\n",
      "哪件\n",
      "tst\n",
      "瘦上\n",
      "不當恐\n",
      "个小物\n",
      "越养颜\n",
      "全没\n",
      "印全\n",
      "一拉\n",
      "越拉越\n",
      "150120\n",
      "累上\n",
      "加一\n",
      "偷乐\n",
      "进解\n",
      "2017q1\n",
      "爆大\n",
      "笑报\n",
      "一嚼\n",
      "撒上\n",
      "消痘\n",
      "排尽\n",
      "多活\n",
      "每村\n",
      "有爹\n",
      "每点\n",
      "看手\n",
      "比一比\n",
      "ev360\n",
      "阴养颜\n",
      "宝快\n",
      "比播求\n",
      "比一龙输\n",
      "比王\n",
      "很无语\n",
      "30s\n",
      "韩红见\n",
      "最狠\n",
      "考完试\n",
      "美妆达\n",
      "人教\n",
      "别乱治\n",
      "越变\n",
      "天做\n",
      "费功夫\n",
      "爱长\n",
      "招帮\n",
      "同献唱\n",
      "脾肾\n",
      "互称\n",
      "大渣\n",
      "毛晓彤疑\n",
      "戏多\n",
      "宗亲会\n",
      "套组\n",
      "鄂造\n",
      "懂货\n",
      "仅带\n",
      "肺咳\n",
      "巧治腰\n",
      "治腰\n",
      "覆土机\n",
      "哪一条\n",
      "猪病\n",
      "血饵\n",
      "获竟\n",
      "李传芳\n",
      "元造\n",
      "有准\n",
      "两组\n",
      "徐元晦\n",
      "专做\n",
      "三股\n",
      "十抓\n",
      "认真学习\n",
      "藏事\n",
      "五千年\n",
      "国足来\n",
      "七斤\n",
      "五条\n",
      "水悦\n",
      "太瘦\n",
      "后易\n",
      "多吃易致\n",
      "受人\n",
      "之分\n",
      "之气\n",
      "脏度\n",
      "升糖\n",
      "越甜\n",
      "蛰伤\n",
      "水逆\n",
      "马云急\n",
      "葛国栋\n",
      "坂东店\n",
      "四局\n",
      "求不来\n",
      "兴迪丽\n",
      "能破窗\n",
      "150719\n",
      "撒药治白\n",
      "求转\n",
      "汪秀萍案\n",
      "致多人\n",
      "一叠叠\n",
      "一串串\n",
      "登华\n",
      "之未解\n",
      "开炫富\n",
      "太会装\n",
      "一帮\n",
      "好贵\n",
      "睡颜王\n",
      "语数外\n",
      "新腾\n",
      "割头\n",
      "第一台\n",
      "laferrari\n",
      "首辆\n",
      "分上\n",
      "卷不分\n",
      "时偷\n",
      "之林\n",
      "小三黑\n",
      "贯三\n",
      "孙骁\n",
      "骁神\n",
      "陈翔江\n",
      "同疑\n",
      "光腿\n",
      "陷小三\n",
      "超吸睛\n",
      "败光路\n",
      "我忍\n",
      "我太想\n",
      "孙志浩\n",
      "中秀\n",
      "过生\n",
      "鲁韵\n",
      "中称\n",
      "八组\n",
      "必换\n",
      "减配\n",
      "车傲\n",
      "占雾\n",
      "对雾\n",
      "比雾\n",
      "两三年\n",
      "几处\n",
      "乱换\n",
      "6w\n",
      "或加\n",
      "油好\n",
      "界要\n",
      "皮越\n",
      "越厚\n",
      "闯卡\n",
      "车企对\n",
      "沂案\n",
      "800w\n",
      "火密\n",
      "xc60\n",
      "同杜\n",
      "新照\n",
      "被力\n",
      "沈腾录\n",
      "沈腾气\n",
      "作大死\n",
      "比嫩\n",
      "二校\n",
      "稻梦\n",
      "买串\n",
      "连微博\n",
      "paraben\n",
      "抓小三\n",
      "sk2\n",
      "王天楚\n",
      "四十天\n",
      "轨过\n",
      "胡可孕\n",
      "沙溢竟\n",
      "狂输\n",
      "版埃尔法\n",
      "esp12\n",
      "l8\n",
      "泡杯\n",
      "斩头\n",
      "能治癌\n",
      "没报\n",
      "帮马\n",
      "条新规\n",
      "没标\n",
      "gb18186\n",
      "有包\n",
      "没籽\n",
      "沾药\n",
      "没红时\n",
      "没红\n",
      "买乖\n",
      "规大\n",
      "衡阳人\n",
      "众大\n",
      "一没过\n",
      "人真要\n",
      "坏车\n",
      "野钓年\n",
      "钓友们\n",
      "飞边\n",
      "街艳泉\n",
      "连加分\n",
      "四妻\n",
      "其族\n",
      "撕衣\n",
      "跌回\n",
      "吹得\n",
      "雨灾\n",
      "多伤\n",
      "一监\n",
      "假病\n",
      "保不实\n",
      "群致\n",
      "扩土\n",
      "天中市\n",
      "干会\n",
      "双肾\n",
      "孔慌\n",
      "十多人\n",
      "先找\n",
      "crispr\n",
      "几付\n",
      "泡脚方\n",
      "整条\n",
      "疼到\n",
      "两酒\n",
      "劲椎\n",
      "醫絕\n",
      "專治\n",
      "怎麼治\n",
      "千个\n",
      "治霾\n",
      "即降\n",
      "助其\n",
      "房险\n",
      "法媒称\n",
      "完庭\n",
      "法澜秀\n",
      "众谈\n",
      "马蓉难\n",
      "箱种\n",
      "泡脚时\n",
      "可逼出\n",
      "泡脚水\n",
      "湿快\n",
      "趁鲜\n",
      "拒录\n",
      "洗才\n",
      "这七\n",
      "车哟\n",
      "害到\n",
      "洋蔥千萬\n",
      "嚴重\n",
      "會導致\n",
      "生着\n",
      "秘婚\n",
      "闺蜜赛\n",
      "静站\n",
      "堪比磨\n",
      "变鬼\n",
      "小头症\n",
      "泰良路\n",
      "北向南\n",
      "三四名\n",
      "一景\n",
      "雅桑\n",
      "风首秀\n",
      "约战\n",
      "造不起\n",
      "水逆年\n",
      "要入\n",
      "破墙\n",
      "校飞\n",
      "震断\n",
      "全溶光\n",
      "片放\n",
      "八分钟\n",
      "黑柔\n",
      "堪比荣整\n",
      "看加\n",
      "八轮\n",
      "这食材\n",
      "能抗\n",
      "十五元\n",
      "能清\n",
      "比钙快\n",
      "能额\n",
      "配一宝堪\n",
      "更棒\n",
      "雖好\n",
      "烟牙\n",
      "人错\n",
      "加着\n",
      "脂溢\n",
      "时先用\n",
      "变乌润\n",
      "去染\n",
      "止脱\n",
      "染法\n",
      "时放上\n",
      "乌润似\n",
      "两片\n",
      "牙美白\n",
      "太长易\n",
      "美白三大\n",
      "洗牙加\n",
      "加牙套\n",
      "洗牙能\n",
      "洗牙要\n",
      "蜕色\n",
      "除斑\n",
      "亮白\n",
      "后小白片\n",
      "脸越\n",
      "洗越\n",
      "配点\n",
      "这几宝\n",
      "往水\n",
      "洗茶\n",
      "洗頭\n",
      "加點\n",
      "防脫\n",
      "治頭\n",
      "洛阳人\n",
      "营某\n",
      "知是\n",
      "津一骑\n",
      "而出\n",
      "枪去\n",
      "傻货\n",
      "不尿多\n",
      "能分\n",
      "活吃\n",
      "款伪\n",
      "真慌\n",
      "十余天\n",
      "省卫\n",
      "周硬\n",
      "限行令\n",
      "尸河\n",
      "以卖\n",
      "场雨\n",
      "勒断\n",
      "新交规速\n",
      "未入\n",
      "恐遭\n",
      "某强\n",
      "一节\n",
      "会开\n",
      "炸坝\n",
      "千口\n",
      "亿加仓\n",
      "飙长\n",
      "28481\n",
      "适不\n",
      "海四达\n",
      "暴炸\n",
      "浙湘\n",
      "陕造\n",
      "有学\n",
      "霸来\n",
      "城投\n",
      "梦辰\n",
      "指禅\n",
      "大受\n",
      "七武海\n",
      "一扯\n",
      "内开\n",
      "两小\n",
      "调气\n",
      "治阳事\n",
      "三百年\n",
      "称乐视\n",
      "几瓶\n",
      "染黄\n",
      "配资\n",
      "遭黑\n",
      "中公\n",
      "建艺\n",
      "备孕准\n",
      "竹民\n",
      "下竟\n",
      "客微\n",
      "信养\n",
      "需洗\n",
      "天洗\n",
      "十五分钟\n",
      "油除\n",
      "六十天\n",
      "国购\n",
      "问乐\n",
      "深国改\n",
      "深土\n",
      "致两人\n",
      "但离\n",
      "限外\n",
      "限外车\n",
      "扩至\n",
      "昨起\n",
      "地车\n",
      "看人\n",
      "流油\n",
      "水贝村\n",
      "内致\n",
      "牌留\n",
      "我下\n",
      "微博开\n",
      "李晨差\n",
      "深新\n",
      "深汕\n",
      "深穗排\n",
      "第三第四\n",
      "亿吸筹\n",
      "二百多年\n",
      "添新料\n",
      "仿品\n",
      "没算\n",
      "送美\n",
      "竟转\n",
      "看才准\n",
      "图是\n",
      "只怪\n",
      "出宫\n",
      "人依\n",
      "而终\n",
      "三帝\n",
      "大婚夜\n",
      "该常\n",
      "这一注\n",
      "麦围\n",
      "巨鱼\n",
      "变火人\n",
      "招冰\n",
      "连有角\n",
      "女骂\n",
      "男之首\n",
      "瓯通\n",
      "店内\n",
      "艾美多\n",
      "还收\n",
      "两辆\n",
      "二杯\n",
      "泽特\n",
      "吃性\n",
      "男买\n",
      "遭王祖\n",
      "吴婉华夫\n",
      "许晋享\n",
      "港媒爆\n",
      "阿朱卖\n",
      "港珠港\n",
      "麻醉枪\n",
      "孙杨战\n",
      "能游\n",
      "胖树\n",
      "c200\n",
      "开不起\n",
      "锁颈后\n",
      "村全\n",
      "因烟炎\n",
      "卖炸\n",
      "垮坝\n",
      "比岳阳\n",
      "最空\n",
      "还空\n",
      "涉罪\n",
      "沅益\n",
      "遭爱狗\n",
      "抄牌\n",
      "重别\n",
      "重吃\n",
      "祛湿药\n",
      "病生\n",
      "重能\n",
      "湿猴\n",
      "已崩\n",
      "现一\n",
      "之兆\n",
      "养鹅户\n",
      "滁城\n",
      "跳湖\n",
      "缑庄\n",
      "爱牙护牙\n",
      "胃火大\n",
      "榆四脉\n",
      "发别\n",
      "半杯\n",
      "撒点\n",
      "条需\n",
      "三分之二\n",
      "薛佳怡\n",
      "疑交新\n",
      "光嫩\n",
      "滴个\n",
      "买贵\n",
      "批其\n",
      "嘟嘴\n",
      "任嘉伦\n",
      "有多差\n",
      "曝黑料\n",
      "这档\n",
      "无问\n",
      "斤堪\n",
      "阿q\n",
      "侠美队\n",
      "全在力\n",
      "其蜜\n",
      "央子港\n",
      "奸生子\n",
      "炒糊\n",
      "两人同\n",
      "潘傻\n",
      "嘻哈妹\n",
      "毯甜\n",
      "现与\n",
      "吴昕称\n",
      "沸扬\n",
      "他学\n",
      "吴昕求\n",
      "只租楼\n",
      "董洁要\n",
      "求伴\n",
      "潘美人\n",
      "曝凤姐\n",
      "互泼\n",
      "十几米\n",
      "两英\n",
      "两死\n",
      "一伤\n",
      "几级\n",
      "过多会\n",
      "cool1\n",
      "有门\n",
      "现双\n",
      "一万多\n",
      "28f4\n",
      "胜成\n",
      "第三支\n",
      "靠此\n",
      "万大\n",
      "助莫雷\n",
      "一迎\n",
      "只待\n",
      "但恐\n",
      "却陷\n",
      "戈登难\n",
      "登炮\n",
      "莫雷苦\n",
      "已不惧\n",
      "莫雷有\n",
      "卡戴\n",
      "内送\n",
      "阵中\n",
      "他进\n",
      "再谈\n",
      "马基夫\n",
      "勇骑\n",
      "能夺\n",
      "g5\n",
      "大减\n",
      "莫雷点\n",
      "神塔要\n",
      "亿将\n",
      "和保罗\n",
      "首胜\n",
      "同吃易\n",
      "实指\n",
      "親測\n",
      "一具\n",
      "胃及\n",
      "罗家英\n",
      "增晰酷\n",
      "炒币\n",
      "放太多油\n",
      "将现\n",
      "股神大\n",
      "买新锅\n",
      "别盖\n",
      "论看\n",
      "真炸\n",
      "还大涨\n",
      "增近\n",
      "点盘\n",
      "颗烟\n",
      "什麼\n",
      "雅瑪人\n",
      "預言\n",
      "有三種\n",
      "希伯來語\n",
      "可亏\n",
      "但用\n",
      "抽才\n",
      "烟里\n",
      "纸丝\n",
      "一排\n",
      "闹崩\n",
      "郭德纲面\n",
      "后别\n",
      "全乱\n",
      "继林丹\n",
      "热拉提\n",
      "一个班\n",
      "日漫\n",
      "改看\n",
      "焦曼婷\n",
      "恒大准\n",
      "焰楠\n",
      "别放\n",
      "香弹\n",
      "粘壳\n",
      "王渣\n",
      "提王\n",
      "对马蓉\n",
      "比马蓉\n",
      "强太多\n",
      "更毒\n",
      "熏醋防\n",
      "补觉\n",
      "几期\n",
      "觉补\n",
      "不长个\n",
      "吸六包\n",
      "避堵\n",
      "忧难\n",
      "侠会\n",
      "爆帅\n",
      "萌照\n",
      "萌翻\n",
      "太仓促\n",
      "有多累\n",
      "爆李\n",
      "爆照\n",
      "别太拼\n",
      "爆看\n",
      "爆娱\n",
      "带货\n",
      "糊得\n",
      "爆马蓉妈\n",
      "帮马蓉\n",
      "肉会\n",
      "爱吃西\n",
      "爱吃鹅肝者\n",
      "爱大爱\n",
      "爱尚轻\n",
      "凉要\n",
      "吃狗娘\n",
      "水与身\n",
      "爱芯\n",
      "两席\n",
      "爱酒\n",
      "爱黛儿\n",
      "我成\n",
      "寻子\n",
      "破壶\n",
      "四弟\n",
      "三权\n",
      "按置\n",
      "父皇要\n",
      "点想长\n",
      "好眠\n",
      "吴京包\n",
      "毕雯珺\n",
      "遭知乎\n",
      "越低\n",
      "撕娜\n",
      "亿小\n",
      "招辅警\n",
      "没块\n",
      "表贵\n",
      "牙太黄\n",
      "宝妈变\n",
      "脸变\n",
      "刷鞋\n",
      "混在\n",
      "巧加\n",
      "伤牙\n",
      "挤太多会\n",
      "完别\n",
      "黄别\n",
      "上满\n",
      "洗牙强\n",
      "黑渍\n",
      "买美白\n",
      "渐白\n",
      "太黄\n",
      "王奶奶\n",
      "美白仪\n",
      "牛三犇\n",
      "牛人用\n",
      "能堆\n",
      "混喝\n",
      "还伤\n",
      "igf\n",
      "促癌\n",
      "喝奶\n",
      "美白变\n",
      "暗黄变\n",
      "连袋\n",
      "机没造\n",
      "消癣\n",
      "简版\n",
      "妖龙\n",
      "猛干\n",
      "有美人\n",
      "牧院\n",
      "再聘\n",
      "员转\n",
      "业会\n",
      "或遇\n",
      "为降\n",
      "四季度\n",
      "拉至\n",
      "万内\n",
      "男宝要\n",
      "时遭\n",
      "亲承\n",
      "愿回\n",
      "曝汪峰\n",
      "会学\n",
      "亿送\n",
      "比天\n",
      "十号\n",
      "折回来\n",
      "进雪里\n",
      "仔列沙\n",
      "胡可要\n",
      "狗尿会\n",
      "六登\n",
      "喜忌\n",
      "精会\n",
      "而刀郎\n",
      "半狗\n",
      "生崽\n",
      "喊人\n",
      "附超\n",
      "粮来\n",
      "装一\n",
      "七海\n",
      "证可领\n",
      "领吧\n",
      "多分钟\n",
      "八只\n",
      "超优德\n",
      "猎云\n",
      "新英\n",
      "安个\n",
      "太硬\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "天不烂\n",
      "传首\n",
      "猪价\n",
      "先备\n",
      "首安茶\n",
      "卖多\n",
      "肉能\n",
      "往家\n",
      "肉堪\n",
      "少吃点\n",
      "猫成\n",
      "一两天\n",
      "难有\n",
      "那烂陀寺\n",
      "为博\n",
      "几十人\n",
      "红沙皮\n",
      "需一剪\n",
      "剪后\n",
      "百分之四十\n",
      "百分之八十\n",
      "百分之五十\n",
      "米须\n",
      "追美合\n",
      "王一博美合\n",
      "王三喜\n",
      "无湿\n",
      "王丽坤林\n",
      "爆林\n",
      "我特\n",
      "逆袭成\n",
      "手残\n",
      "王源成\n",
      "他成\n",
      "护易\n",
      "男大\n",
      "再摊\n",
      "往死里整\n",
      "已马\n",
      "问马云\n",
      "捐后\n",
      "疑骗\n",
      "该负\n",
      "因钱\n",
      "他选\n",
      "蒋欣发\n",
      "微博甜\n",
      "走虐\n",
      "同框照\n",
      "将生\n",
      "网传王\n",
      "六小时\n",
      "同逛\n",
      "关系暧昧\n",
      "打鲁能\n",
      "王如峰\n",
      "文男\n",
      "不归路\n",
      "领家\n",
      "博谈\n",
      "宋喆该\n",
      "强交新\n",
      "马蓉强\n",
      "强替\n",
      "宋喆养\n",
      "网传宝强\n",
      "中泪点\n",
      "强泪\n",
      "熊乃瑾秀\n",
      "很正\n",
      "眷侣\n",
      "讽其\n",
      "188c\n",
      "强前\n",
      "称若\n",
      "比马蓉靓\n",
      "宋喆恐\n",
      "微博疑\n",
      "长点\n",
      "强宝强\n",
      "宋喆会\n",
      "宋喆终\n",
      "终进\n",
      "宋喆进\n",
      "强摊\n",
      "发博称\n",
      "超马蓉\n",
      "胜马蓉\n",
      "熊乃瑾疑\n",
      "称马蓉\n",
      "爆宝强\n",
      "京金联\n",
      "赵薇版\n",
      "强案\n",
      "曾祝\n",
      "引马蓉\n",
      "爆遭\n",
      "发博表\n",
      "马上会\n",
      "却长\n",
      "看博\n",
      "赞宝强\n",
      "待议\n",
      "有宝强\n",
      "归宝强\n",
      "分归\n",
      "微博向\n",
      "我错\n",
      "遭女\n",
      "悔青\n",
      "马蓉案\n",
      "下才\n",
      "能办\n",
      "万寻\n",
      "凌杨\n",
      "最暖\n",
      "脑残粉\n",
      "豆得儿\n",
      "寻赏\n",
      "三尺\n",
      "王思聪为\n",
      "马云思聪\n",
      "王思聪出\n",
      "张翰神\n",
      "嫁富\n",
      "能年入\n",
      "雪莉富\n",
      "带妆\n",
      "有胜\n",
      "发冯\n",
      "这该\n",
      "病治好\n",
      "王思聪友\n",
      "王思聪发\n",
      "莫怒\n",
      "却花\n",
      "送车\n",
      "称鹿晗\n",
      "脸景甜\n",
      "英放狠话\n",
      "非奸\n",
      "王思聪带\n",
      "后王\n",
      "微博怒\n",
      "喷马云\n",
      "妹凭\n",
      "王思聪手\n",
      "李晨白\n",
      "章泽天口\n",
      "东怒\n",
      "王太太\n",
      "比豆\n",
      "得儿\n",
      "张小蒙\n",
      "王思聪欲出\n",
      "王思聪欲花\n",
      "而花\n",
      "讽冯\n",
      "红狗\n",
      "王思聪狂\n",
      "真绝\n",
      "王思聪疑\n",
      "讽鹿晗\n",
      "面说\n",
      "王思聪称\n",
      "改叫\n",
      "竟出\n",
      "字扎心\n",
      "王思聪竟\n",
      "东杠\n",
      "为父\n",
      "王思聪约\n",
      "王思聪维密秀\n",
      "之手\n",
      "发床\n",
      "王思聪要\n",
      "我愿用\n",
      "英滚出\n",
      "王思聪讽\n",
      "红靠\n",
      "王思聪道\n",
      "杨紫丑\n",
      "内在美\n",
      "清纯玉女\n",
      "清竟\n",
      "亲脚\n",
      "变哑\n",
      "内必\n",
      "他备\n",
      "撩者\n",
      "博人\n",
      "看行\n",
      "易祥千玺\n",
      "图露\n",
      "李晨发\n",
      "不忘秀\n",
      "源哥\n",
      "真唱过\n",
      "照超\n",
      "馨爷\n",
      "王珂刚\n",
      "第二任\n",
      "王珂靠\n",
      "朴珺\n",
      "竟变\n",
      "他应\n",
      "买太多\n",
      "叹言\n",
      "多宝\n",
      "日服\n",
      "浪个\n",
      "铠说\n",
      "必入\n",
      "天美请\n",
      "变高\n",
      "王艳兵\n",
      "疑恋\n",
      "锋会\n",
      "问霆锋\n",
      "碰才\n",
      "祝你幸福\n",
      "携女\n",
      "再孕\n",
      "大挺\n",
      "不拒\n",
      "四合\n",
      "曾闹\n",
      "可据\n",
      "美若\n",
      "宗萨钦哲\n",
      "窦唯哭\n",
      "不丑\n",
      "谢贤要\n",
      "流產\n",
      "謝霆鋒\n",
      "張柏芝\n",
      "應該\n",
      "用四字\n",
      "养胖\n",
      "这胎\n",
      "数千万\n",
      "爆孽缘\n",
      "导锁\n",
      "甜过\n",
      "共游\n",
      "复炽\n",
      "多痛\n",
      "柏芝选\n",
      "离港\n",
      "开吵\n",
      "英忙\n",
      "盆满\n",
      "肚大如筐\n",
      "爱情真\n",
      "有三爹\n",
      "谢贤怒\n",
      "窦唯之女\n",
      "疑帮\n",
      "肚大\n",
      "眼含\n",
      "峰芝\n",
      "曝上\n",
      "要结\n",
      "谢贤则\n",
      "称如\n",
      "摆席\n",
      "戏忙\n",
      "次孕\n",
      "真孕\n",
      "爆签\n",
      "放料\n",
      "克屎\n",
      "如歌\n",
      "但苦\n",
      "家四\n",
      "两亲\n",
      "王岳伦为\n",
      "万遭\n",
      "更招\n",
      "更牛\n",
      "一个八岁\n",
      "娃招\n",
      "字气坏\n",
      "李湘竟\n",
      "李湘上\n",
      "一课\n",
      "遭怒\n",
      "当惯\n",
      "还艳压\n",
      "曝借\n",
      "却大爱\n",
      "带图\n",
      "竟现\n",
      "更渣\n",
      "领涨\n",
      "做市\n",
      "知讯\n",
      "现切\n",
      "乐疯\n",
      "后能值\n",
      "任总说\n",
      "测底\n",
      "切石\n",
      "能大涨\n",
      "爆岳云鹏\n",
      "第三类\n",
      "现应\n",
      "韩星长\n",
      "玲琅满\n",
      "珠晖\n",
      "某涛\n",
      "致一人\n",
      "取卡\n",
      "库兹马\n",
      "高迪榜\n",
      "替佑家军\n",
      "圈称\n",
      "第一场\n",
      "磕太多\n",
      "方物\n",
      "粉们\n",
      "验出\n",
      "网播剧\n",
      "前不敬\n",
      "再忆\n",
      "差有\n",
      "吴京后\n",
      "真应学\n",
      "打哭\n",
      "揭两人\n",
      "甘姿\n",
      "三起\n",
      "甘敬闹\n",
      "格桑加\n",
      "甜哭\n",
      "甜成\n",
      "人太多\n",
      "萌态\n",
      "发穿\n",
      "甜馨成\n",
      "曝沈梦辰\n",
      "异尖\n",
      "灌喉\n",
      "丝加\n",
      "没湿毒\n",
      "马上转\n",
      "切丁\n",
      "还治\n",
      "如雪\n",
      "六天\n",
      "可全\n",
      "脂治\n",
      "速黑\n",
      "祛寒\n",
      "错似\n",
      "水加个\n",
      "育发\n",
      "一晚治\n",
      "倾墨\n",
      "毒调\n",
      "比贴\n",
      "轮似\n",
      "前内腺\n",
      "有位\n",
      "看肚型\n",
      "卡到\n",
      "小达\n",
      "脏鱼\n",
      "每升\n",
      "生男先\n",
      "宝妈会\n",
      "爸们\n",
      "好孕来\n",
      "看孕妈\n",
      "哪条\n",
      "超看\n",
      "或生\n",
      "别瞎想\n",
      "我选\n",
      "晨尿\n",
      "生酮\n",
      "我试\n",
      "锅来\n",
      "场均\n",
      "速醒\n",
      "油对\n",
      "好几岁\n",
      "全扫\n",
      "及用\n",
      "这重\n",
      "五宝\n",
      "侧伯叶\n",
      "天不掉\n",
      "肌膚\n",
      "教花\n",
      "它治\n",
      "再染头\n",
      "患脑癌\n",
      "人告\n",
      "变乌\n",
      "泡脚治\n",
      "用蒜加\n",
      "获多\n",
      "洗一洗\n",
      "人不信\n",
      "脱发剂\n",
      "根皮\n",
      "毒藥\n",
      "換掉\n",
      "每個\n",
      "裡都\n",
      "用運動\n",
      "一菜\n",
      "多忙\n",
      "用雪碧做\n",
      "做别\n",
      "二天\n",
      "籽熏出\n",
      "天漆\n",
      "李湘怒\n",
      "揭家丑\n",
      "揭到\n",
      "这颗\n",
      "田馥\n",
      "甄微博\n",
      "上用\n",
      "周可住\n",
      "专赶\n",
      "专驱\n",
      "搬新家\n",
      "百用\n",
      "数百亿美元\n",
      "百亿元\n",
      "申家坡\n",
      "五年级\n",
      "争三\n",
      "天多地\n",
      "数十亿元\n",
      "主请\n",
      "牌费\n",
      "处上\n",
      "省能\n",
      "传马云\n",
      "马云神\n",
      "电塔上\n",
      "合宿\n",
      "转越\n",
      "头靠头\n",
      "女主会\n",
      "骨骨\n",
      "按亮\n",
      "好几年\n",
      "竞马蓉\n",
      "绿植来\n",
      "剧方\n",
      "女主由\n",
      "超周\n",
      "不美\n",
      "一宿\n",
      "越衰\n",
      "越吃会\n",
      "越弱\n",
      "一酒\n",
      "一木\n",
      "吃惯\n",
      "与性\n",
      "失戀次數\n",
      "凶若\n",
      "身累\n",
      "一抓\n",
      "这七大\n",
      "处越\n",
      "淫羊\n",
      "卵洒\n",
      "被生\n",
      "剪头\n",
      "自断\n",
      "狗人\n",
      "偶得开\n",
      "偷进\n",
      "活吞\n",
      "整只\n",
      "因像\n",
      "曾毅齐\n",
      "卖雄安\n",
      "七分\n",
      "数百\n",
      "狂扇\n",
      "蛙头\n",
      "黄埔江\n",
      "电伤\n",
      "灯一看\n",
      "拍不雅\n",
      "这脸\n",
      "更拉风\n",
      "小画\n",
      "救蛇\n",
      "冲卡\n",
      "确曾\n",
      "五十多万\n",
      "画换个\n",
      "桌大怒\n",
      "赔坏\n",
      "成捆\n",
      "堆如墙\n",
      "用验\n",
      "孩抓\n",
      "自去\n",
      "成鹿晗\n",
      "骗进\n",
      "弄开\n",
      "养育之恩\n",
      "遭拍\n",
      "可防霾\n",
      "半头\n",
      "我长\n",
      "卷当\n",
      "搜街\n",
      "脑肺\n",
      "泼油\n",
      "测法\n",
      "克氏征\n",
      "男尖\n",
      "女圆\n",
      "俱残\n",
      "李沁送\n",
      "别顾\n",
      "全校师生\n",
      "读检时\n",
      "遭狠\n",
      "男神们\n",
      "混搭风\n",
      "直辣\n",
      "常喊\n",
      "胎梦准\n",
      "附女宝\n",
      "男该\n",
      "男蛇\n",
      "女龙\n",
      "频受\n",
      "宝贝女儿\n",
      "接小\n",
      "磨坝\n",
      "n6\n",
      "x30\n",
      "网红地\n",
      "卓伟要\n",
      "马蓉点\n",
      "赞王宝\n",
      "疑宋喆\n",
      "曝杨洋\n",
      "疑某\n",
      "群内收\n",
      "博直\n",
      "竟断\n",
      "前半年\n",
      "四条\n",
      "唐筛\n",
      "肚形\n",
      "肉球\n",
      "风友\n",
      "数十个\n",
      "天痛\n",
      "崖冈芝\n",
      "百答\n",
      "干上\n",
      "腹方\n",
      "湿引\n",
      "瘦不掉\n",
      "瘦不去\n",
      "黑涩\n",
      "必做\n",
      "可瘦\n",
      "苗妈\n",
      "第六天\n",
      "這才\n",
      "這樣\n",
      "小招教\n",
      "缠不上\n",
      "登登\n",
      "凳登\n",
      "食材加\n",
      "成碳\n",
      "越拔\n",
      "好治\n",
      "不学亏\n",
      "猖绝\n",
      "多狠\n",
      "切底\n",
      "天乌\n",
      "变不黑\n",
      "花大钱\n",
      "黑如炭\n",
      "多别染\n",
      "要选\n",
      "发更\n",
      "天乌润\n",
      "反变\n",
      "药肝\n",
      "然发\n",
      "几大百\n",
      "越染越\n",
      "比新刷\n",
      "需涂\n",
      "白太多\n",
      "削完\n",
      "会拔\n",
      "更易长\n",
      "半罐\n",
      "快试\n",
      "六次\n",
      "天准\n",
      "前吃点\n",
      "太多能\n",
      "不学真\n",
      "拔不到\n",
      "发后\n",
      "甭染\n",
      "三勺\n",
      "再拔\n",
      "发如\n",
      "它用\n",
      "时滴\n",
      "面大骂\n",
      "蒋总统\n",
      "比鹿晗\n",
      "岑宁儿\n",
      "用天\n",
      "张爱朋\n",
      "其手\n",
      "翻篇\n",
      "探班送\n",
      "歌到\n",
      "怀陈羽\n",
      "完歌\n",
      "凡会\n",
      "没离\n",
      "怒谈\n",
      "美肌\n",
      "吃伤\n",
      "降三高特\n",
      "半扇\n",
      "许仕林\n",
      "出塔\n",
      "美衣\n",
      "穿久\n",
      "冲生\n",
      "痛全\n",
      "天身\n",
      "不浊\n",
      "人颈\n",
      "身如\n",
      "可顶\n",
      "一草\n",
      "变密\n",
      "天天见\n",
      "上加\n",
      "天祛皱\n",
      "美白除\n",
      "天润\n",
      "第二遍\n",
      "有长\n",
      "如纸\n",
      "如雨下\n",
      "学着\n",
      "宝妈似\n",
      "天帮\n",
      "速美白\n",
      "大媽\n",
      "青秀有\n",
      "比华利\n",
      "未作\n",
      "进婚\n",
      "百张\n",
      "不二\n",
      "奇云\n",
      "结竹米\n",
      "百白何\n",
      "百白\n",
      "百盈\n",
      "索任\n",
      "皂角加\n",
      "同娶\n",
      "黄虾\n",
      "完笑\n",
      "冤呀\n",
      "黄又糙\n",
      "起痘\n",
      "学准\n",
      "掺小\n",
      "白到\n",
      "前加个\n",
      "吐漏\n",
      "撑大\n",
      "好肤质\n",
      "正住\n",
      "鞋胶\n",
      "皱兆龙\n",
      "补虚\n",
      "以菌治菌\n",
      "五桥\n",
      "一桥\n",
      "人会变\n",
      "盐配\n",
      "而入\n",
      "实怕\n",
      "这幕\n",
      "恶灵袭\n",
      "一阵发\n",
      "毛骨悚人\n",
      "巨震大\n",
      "博主孙\n",
      "不杀\n",
      "寻龙诀\n",
      "今年年底\n",
      "消霾\n",
      "差到\n",
      "快招\n",
      "几任\n",
      "有恋足\n",
      "盛刷\n",
      "证领\n",
      "四架\n",
      "第一架\n",
      "目瞪狗\n",
      "猛一看\n",
      "最能生\n",
      "比马云挡\n",
      "暗怼\n",
      "直击限行\n",
      "正唱得\n",
      "原石籽料\n",
      "侯耀文葬\n",
      "收新徒\n",
      "之徒\n",
      "万淘回\n",
      "gw4b15\n",
      "万而\n",
      "脸祁同伟\n",
      "十多块\n",
      "这小腰\n",
      "真替\n",
      "前不愿\n",
      "终知\n",
      "碎屏\n",
      "几幅\n",
      "看刀郎\n",
      "谢贤点\n",
      "完泪\n",
      "rx5\n",
      "张宇教\n",
      "猪价会\n",
      "d170727\n",
      "一个多月\n",
      "樣子\n",
      "个准\n",
      "重不重\n",
      "飞哥\n",
      "热成\n",
      "看耳知\n",
      "按耳\n",
      "看見\n",
      "德牧獨\n",
      "自開車\n",
      "問路\n",
      "嚇壞\n",
      "图会动\n",
      "看马伊\n",
      "腎臟\n",
      "骚浪\n",
      "十三发\n",
      "未响\n",
      "2116w\n",
      "惨忍\n",
      "糖友们\n",
      "王思聪点\n",
      "六十根\n",
      "伊面\n",
      "鲁蜜\n",
      "马云长\n",
      "有酸儿\n",
      "刘丹笑\n",
      "会以\n",
      "孕妈怀\n",
      "认识一下\n",
      "袁立变\n",
      "男加\n",
      "浓会\n",
      "再带\n",
      "眼妆画\n",
      "茶快\n",
      "有多脏\n",
      "一刮\n",
      "总打\n",
      "太显\n",
      "消不去\n",
      "千万条\n",
      "吴磊妈\n",
      "一穴\n",
      "美白平\n",
      "能拉出\n",
      "斤毒\n",
      "黑宿\n",
      "无痘\n",
      "睡够\n",
      "一睡\n",
      "睡覺\n",
      "時別\n",
      "機放\n",
      "床頭\n",
      "無線\n",
      "危機\n",
      "腦細胞\n",
      "癌變\n",
      "前放点\n",
      "前用\n",
      "为宜\n",
      "股受\n",
      "知乎\n",
      "另一人\n",
      "爆某\n",
      "曝刘诗\n",
      "季鹿晗\n",
      "爆白百何\n",
      "知行易\n",
      "戊戌年\n",
      "哪张\n",
      "冷巴\n",
      "待涨\n",
      "底村\n",
      "某豫\n",
      "尚城名\n",
      "二号楼\n",
      "九层\n",
      "亿举牌\n",
      "六连板\n",
      "日限行\n",
      "赵二街\n",
      "辣性\n",
      "指至\n",
      "压成\n",
      "根在\n",
      "較聰明\n",
      "提了\n",
      "亿道\n",
      "愈颜圣品\n",
      "空模\n",
      "睡错\n",
      "碰酒\n",
      "磨桂梅\n",
      "磁链\n",
      "巷一\n",
      "一个四岁\n",
      "塘镇\n",
      "三死二伤\n",
      "传之秘\n",
      "胜雪\n",
      "还会伤\n",
      "更伤\n",
      "祝傻根\n",
      "無數\n",
      "之果\n",
      "力念\n",
      "油拔法\n",
      "市中\n",
      "鸡镇\n",
      "五死\n",
      "广生堂\n",
      "地画\n",
      "配超\n",
      "豪型\n",
      "演部\n",
      "丽地\n",
      "亿变\n",
      "电人\n",
      "跳江\n",
      "三号\n",
      "城一\n",
      "调涨\n",
      "元药事\n",
      "改市\n",
      "家输\n",
      "福清人\n",
      "说易\n",
      "一万一千\n",
      "福羲\n",
      "以藏养\n",
      "曝龙珠\n",
      "赖种\n",
      "写部\n",
      "人落\n",
      "填新证\n",
      "白百对\n",
      "最苦\n",
      "黄渤带\n",
      "今演\n",
      "我接\n",
      "吴佳尼\n",
      "念稿\n",
      "可耐\n",
      "女爱豆\n",
      "五层\n",
      "县食\n",
      "看何洁\n",
      "已全\n",
      "种药\n",
      "种药同\n",
      "吃太辣\n",
      "多渴\n",
      "重不除\n",
      "祛湿毒\n",
      "正扬\n",
      "房求\n",
      "飞方\n",
      "红芯\n",
      "根可\n",
      "觉厉\n",
      "亿倍\n",
      "之快\n",
      "两具\n",
      "陨坑\n",
      "常吃肉\n",
      "来测\n",
      "水确\n",
      "科學家\n",
      "更為\n",
      "点半\n",
      "可带\n",
      "请网\n",
      "湖人当\n",
      "分位\n",
      "此位\n",
      "项驾\n",
      "终获\n",
      "三驾\n",
      "车抖\n",
      "天刮肉\n",
      "既能治\n",
      "幅新\n",
      "三指\n",
      "袁冰妍\n",
      "开锤\n",
      "冬儿\n",
      "偷药\n",
      "没练成\n",
      "药竟\n",
      "锁子峡\n",
      "只奸\n",
      "墓乐坏\n",
      "李静谈\n",
      "唯老\n",
      "已现\n",
      "程晓玥\n",
      "雅康\n",
      "不种\n",
      "劲咽\n",
      "箱来\n",
      "無束\n",
      "ryt\n",
      "教培\n",
      "众判亲离\n",
      "二十多辆\n",
      "一筐\n",
      "两餐\n",
      "糖会\n",
      "就常\n",
      "第五期\n",
      "只会开\n",
      "先选\n",
      "克金有\n",
      "接娃时\n",
      "乱服\n",
      "神卫伤\n",
      "两届\n",
      "马上开\n",
      "后致\n",
      "红坎坡\n",
      "山大主\n",
      "钢市\n",
      "二百文\n",
      "初长成\n",
      "美照秀\n",
      "窦唯两\n",
      "窦家媛长\n",
      "上师\n",
      "闺蜜团\n",
      "袁立信\n",
      "宗萨上\n",
      "离窦\n",
      "骁远\n",
      "当养\n",
      "可常\n",
      "养藏\n",
      "立夏前\n",
      "边降\n",
      "长个\n",
      "猛窜\n",
      "亿陪\n",
      "爆患\n",
      "邵小珊\n",
      "王思聪成\n",
      "歌甜\n",
      "美如\n",
      "互送\n",
      "看抖音\n",
      "赵丽颖化\n",
      "好妆换\n",
      "发苦\n",
      "幸不\n",
      "第一套\n",
      "有多神\n",
      "第一章\n",
      "今遭\n",
      "角十连\n",
      "二版\n",
      "角券\n",
      "角版别\n",
      "愿弃\n",
      "球权\n",
      "新援\n",
      "第三版\n",
      "四章\n",
      "城能\n",
      "谈压色\n",
      "第二集\n",
      "第六十四章\n",
      "第六场\n",
      "元冠号\n",
      "一百元\n",
      "当折白\n",
      "一变\n",
      "王翻\n",
      "已值\n",
      "买半\n",
      "第四根\n",
      "第四版\n",
      "福耳币\n",
      "区之迷\n",
      "鸡下\n",
      "才护\n",
      "祛痛\n",
      "第一双\n",
      "管它\n",
      "切根\n",
      "和衡\n",
      "波神\n",
      "俱杯\n",
      "肾元\n",
      "米报\n",
      "miui10\n",
      "r27\n",
      "类药\n",
      "籽陷\n",
      "需交\n",
      "互揭\n",
      "吴昕面\n",
      "吴昕献\n",
      "欲迪丽\n",
      "贾爸\n",
      "多证\n",
      "持用\n",
      "万颜值\n",
      "上脑\n",
      "糖友常\n",
      "却易\n",
      "备着\n",
      "胖会\n",
      "找药\n",
      "不飙\n",
      "当菜\n",
      "友必\n",
      "菜助\n",
      "选菜\n",
      "情过\n",
      "一吃顿\n",
      "食譜\n",
      "直飙\n",
      "見效\n",
      "伪论\n",
      "列汀能\n",
      "材才\n",
      "升不高\n",
      "几杯\n",
      "尿不甜\n",
      "不药\n",
      "紅糖\n",
      "養顏\n",
      "臉部\n",
      "肌膚會\n",
      "越發\n",
      "紅糖加\n",
      "勝過\n",
      "吃肉会\n",
      "抢关\n",
      "夺旗\n",
      "微章\n",
      "暗动\n",
      "好忙\n",
      "秀体\n",
      "反闹出\n",
      "李嫣接\n",
      "不回\n",
      "绿壳\n",
      "玉猪\n",
      "会尿出\n",
      "h7\n",
      "vv7\n",
      "锐评\n",
      "最补\n",
      "样吃\n",
      "还易\n",
      "斑减\n",
      "断命\n",
      "伤肠\n",
      "沒过\n",
      "肥而\n",
      "男白女\n",
      "水真能\n",
      "天紧肤\n",
      "这用\n",
      "如玉\n",
      "司康\n",
      "iphone7\n",
      "补中\n",
      "归脾经\n",
      "酒脚\n",
      "酒泪\n",
      "眼膏\n",
      "小白片\n",
      "越稳\n",
      "戈兰为\n",
      "转投\n",
      "说本\n",
      "纯靠\n",
      "纳斯尼\n",
      "保持足够\n",
      "风婚\n",
      "判重\n",
      "绿凯\n",
      "个治\n",
      "袁立设\n",
      "中不受\n",
      "6g\n",
      "nienie\n",
      "无侧\n",
      "造辆\n",
      "造好\n",
      "哪开\n",
      "三高绕\n",
      "消菌\n",
      "完林丹\n",
      "变笨\n",
      "确是\n",
      "毒食\n",
      "泡法\n",
      "更养\n",
      "觉能\n",
      "109388230\n",
      "亲承博卡\n",
      "没选\n",
      "晏离\n",
      "喜当哥\n",
      "爆盆\n",
      "喝仟佰宠\n",
      "菜而手\n",
      "有三人\n",
      "七场\n",
      "小福加\n",
      "会快\n",
      "暴拉\n",
      "涨破\n",
      "疼一病\n",
      "晕系\n",
      "三大高管\n",
      "论后\n",
      "继一\n",
      "天茂\n",
      "继乐视\n",
      "继冯\n",
      "继卓伟\n",
      "继刘涛\n",
      "继吴\n",
      "继双宋\n",
      "爆婚\n",
      "跟迪丽\n",
      "携子录\n",
      "继微信\n",
      "崔英道\n",
      "二孩后\n",
      "继方静\n",
      "继景甜\n",
      "拒吻\n",
      "继李\n",
      "爆睡\n",
      "撤档\n",
      "如面\n",
      "继港\n",
      "继王俊凯\n",
      "王嘉成\n",
      "继白百何\n",
      "继白\n",
      "继罗\n",
      "继胡歌\n",
      "婚讯后\n",
      "继袁立\n",
      "继裹\n",
      "增瘦\n",
      "继郑恺\n",
      "继郑爽\n",
      "搜说\n",
      "亲鹿晗\n",
      "继阿娇\n",
      "继韩庚\n",
      "继马蓉\n",
      "续林丹\n",
      "续白百何\n",
      "免摇号\n",
      "不限行\n",
      "续鹿晗\n",
      "添实\n",
      "维嘉隐婚\n",
      "维小保\n",
      "乱补\n",
      "对美白\n",
      "重注\n",
      "绿专\n",
      "看绿凯\n",
      "绿凯会\n",
      "绿厂\n",
      "绿媒\n",
      "需送\n",
      "缅商\n",
      "转爆\n",
      "赌料\n",
      "高冰飘绿\n",
      "图能\n",
      "缠中\n",
      "一万名\n",
      "人去\n",
      "多遭\n",
      "虽香\n",
      "大壳\n",
      "青用\n",
      "嘴流\n",
      "毒倒\n",
      "贝江到\n",
      "新修\n",
      "能播\n",
      "请迪丽\n",
      "高伟光组\n",
      "桃农\n",
      "网传余承东\n",
      "棠樂\n",
      "选房\n",
      "网传卓伟\n",
      "携儿\n",
      "事因\n",
      "氢罐\n",
      "码酿\n",
      "遭雪藏\n",
      "高坠\n",
      "豪不雅\n",
      "市坝\n",
      "两户\n",
      "二十几年\n",
      "网传望\n",
      "撕八组\n",
      "网传棚\n",
      "一村\n",
      "称系\n",
      "网传泉港\n",
      "红疑\n",
      "户称\n",
      "网传海湖\n",
      "一博\n",
      "耀莱\n",
      "綦美合\n",
      "拍过\n",
      "网传现\n",
      "网传玲花\n",
      "夜跑\n",
      "已中枪\n",
      "网传葛军\n",
      "写新歌\n",
      "试毒\n",
      "临天八弄\n",
      "邓超花\n",
      "液含\n",
      "粉是\n",
      "拿命\n",
      "网传雷\n",
      "恐赔\n",
      "死过\n",
      "微凸似\n",
      "惨成\n",
      "获马蓉点\n",
      "去度\n",
      "太骚\n",
      "转性\n",
      "曝窦\n",
      "唯再\n",
      "曝胡歌\n",
      "最会\n",
      "室办\n",
      "极有\n",
      "虽近\n",
      "拒罚\n",
      "问卓伟\n",
      "张翰马\n",
      "真能生\n",
      "网售\n",
      "液能\n",
      "网宿\n",
      "飞鸡\n",
      "名鸡\n",
      "真鸡\n",
      "150330\n",
      "河田飞\n",
      "当哥\n",
      "微讯\n",
      "曝一\n",
      "称未\n",
      "好痒\n",
      "私宴\n",
      "后活\n",
      "翰娜\n",
      "为小爽\n",
      "向娜\n",
      "曝恒大\n",
      "欧签\n",
      "锋霸\n",
      "艺考照\n",
      "曝沙\n",
      "曝王\n",
      "思聪称\n",
      "人伤\n",
      "立帖\n",
      "曝白百何\n",
      "曝罗志祥\n",
      "曝罗晋\n",
      "微博晒动\n",
      "疑携新\n",
      "家引\n",
      "僵到\n",
      "有育\n",
      "曝雷\n",
      "曝马蓉现\n",
      "认爱则\n",
      "涉谣\n",
      "约炮\n",
      "热话\n",
      "激似\n",
      "为栓住\n",
      "求符\n",
      "王思聪谈\n",
      "马蓉带\n",
      "网疯\n",
      "网称\n",
      "网红主播\n",
      "孙志立\n",
      "网红黑\n",
      "重手\n",
      "充新\n",
      "小贷\n",
      "网转\n",
      "购婚\n",
      "已买\n",
      "白衬衫\n",
      "女值\n",
      "能受\n",
      "包炫富\n",
      "罗志祥斥\n",
      "亿为\n",
      "青买\n",
      "罗周\n",
      "爆连\n",
      "罗志祥花\n",
      "爆斥\n",
      "购正\n",
      "罗志祥要\n",
      "罗志祥豪\n",
      "罗胖坑\n",
      "两人该\n",
      "唐嫣信\n",
      "嫣疑\n",
      "唐嫣会\n",
      "赞有\n",
      "夸惨\n",
      "上红毯\n",
      "罗玉凤发\n",
      "紧悟\n",
      "罗胖\n",
      "罪之美\n",
      "早破\n",
      "必亡\n",
      "高纤\n",
      "嘴来\n",
      "手影\n",
      "比歼\n",
      "几百人\n",
      "轰塌\n",
      "俄苏\n",
      "美前\n",
      "美双\n",
      "嚎声\n",
      "图教\n",
      "军变\n",
      "ewg\n",
      "退群\n",
      "中俄能\n",
      "非说\n",
      "人先\n",
      "两国杠\n",
      "他害\n",
      "aiss\n",
      "事非\n",
      "季不看\n",
      "日惊现\n",
      "两异象\n",
      "多艘\n",
      "竟早\n",
      "层度\n",
      "年耗\n",
      "入常\n",
      "其别\n",
      "惨虐\n",
      "之危\n",
      "伯克级\n",
      "没人能\n",
      "不佳易\n",
      "出前\n",
      "某颗\n",
      "我招\n",
      "空天军\n",
      "打不沉\n",
      "好点\n",
      "迦顿\n",
      "曝见\n",
      "上射出\n",
      "再动\n",
      "洞朗\n",
      "美國\n",
      "預測\n",
      "美墨\n",
      "ucer\n",
      "诊出\n",
      "孕脉\n",
      "取光\n",
      "现欠\n",
      "欲用\n",
      "竟十女配\n",
      "大醋方\n",
      "股神放话\n",
      "附选\n",
      "美妆师\n",
      "美妆博主长\n",
      "曝詹皇\n",
      "三双\n",
      "湖人要\n",
      "先问\n",
      "称美\n",
      "草可治乳\n",
      "易早\n",
      "怡美\n",
      "香焖\n",
      "師洩密\n",
      "美机\n",
      "淡痘\n",
      "水光针\n",
      "齒將\n",
      "這物\n",
      "嘴裡\n",
      "仔女\n",
      "抵韩\n",
      "缩表\n",
      "若飞\n",
      "二十多岁\n",
      "五十年\n",
      "谢娜生\n",
      "不食\n",
      "翁帆用\n",
      "因偷\n",
      "实小三\n",
      "骁要\n",
      "李依伊\n",
      "亿堪\n",
      "耀江\n",
      "养颜治\n",
      "密茶\n",
      "养阴生\n",
      "血燥\n",
      "内治好\n",
      "虽能\n",
      "醫說\n",
      "通過\n",
      "看過\n",
      "說准\n",
      "竟种\n",
      "百株\n",
      "离远\n",
      "一叠\n",
      "说十胖九湿\n",
      "这一宝\n",
      "揽责\n",
      "不归\n",
      "玄案\n",
      "不溜车\n",
      "又学\n",
      "药驾\n",
      "比酒\n",
      "s600\n",
      "憶起\n",
      "過程\n",
      "上争\n",
      "企料\n",
      "送套\n",
      "从心\n",
      "绝除\n",
      "很潮\n",
      "屡发\n",
      "遍街\n",
      "如雨般\n",
      "人不爱登\n",
      "大开疑\n",
      "爱红歌\n",
      "最宜\n",
      "老杜在\n",
      "改设\n",
      "找范伟\n",
      "可范伟\n",
      "不爆\n",
      "老梁观\n",
      "真得值\n",
      "你会信\n",
      "要单\n",
      "区竟\n",
      "有枪\n",
      "枪锈管\n",
      "生苍\n",
      "已嫁\n",
      "寻儿\n",
      "挨穷\n",
      "老玩\n",
      "百挑百准\n",
      "七枚\n",
      "老罗说\n",
      "胃会\n",
      "老钓友\n",
      "窝料\n",
      "全死\n",
      "尸毒\n",
      "所造\n",
      "九室\n",
      "墓内\n",
      "狗气\n",
      "南充人\n",
      "还气\n",
      "耍帅\n",
      "肉厚\n",
      "不招\n",
      "致一\n",
      "孕妈防\n",
      "澄不清\n",
      "联糖\n",
      "配车\n",
      "即锁机\n",
      "肉多\n",
      "肉嫩\n",
      "减皱\n",
      "肖圈\n",
      "送糖\n",
      "男宝及\n",
      "一捏\n",
      "两捆\n",
      "大太\n",
      "五六个\n",
      "拿瓶\n",
      "大扣\n",
      "消胀\n",
      "太大别\n",
      "太大愁\n",
      "一煮\n",
      "提不上\n",
      "肉太多\n",
      "招瘦\n",
      "拿片\n",
      "多要\n",
      "鼓得\n",
      "吃二片\n",
      "肚尖生\n",
      "男肚\n",
      "别太慌\n",
      "不排\n",
      "时撒点\n",
      "肝毒排\n",
      "根可排\n",
      "毒益\n",
      "一清\n",
      "二对\n",
      "天肝毒\n",
      "能促\n",
      "病不扰\n",
      "肝药\n",
      "解肝毒\n",
      "剧震\n",
      "封板\n",
      "迎限售\n",
      "低拉响\n",
      "两阳\n",
      "一阴\n",
      "线上\n",
      "股必\n",
      "捂谷必\n",
      "底量\n",
      "超顶量\n",
      "一卖\n",
      "前会\n",
      "骑上\n",
      "越涨\n",
      "千万次\n",
      "抓大\n",
      "上万次\n",
      "肤黄\n",
      "肥人\n",
      "肥唐\n",
      "一疼\n",
      "药鸡门\n",
      "催大\n",
      "肾友\n",
      "肾是\n",
      "精蓄锐\n",
      "肾好\n",
      "药到\n",
      "虚除\n",
      "那胃\n",
      "有治好\n",
      "常泡\n",
      "可暖\n",
      "讨薪博\n",
      "晨尿变\n",
      "男变\n",
      "粉为\n",
      "胎寶寶和\n",
      "親吻\n",
      "感動\n",
      "億萬父\n",
      "親母親\n",
      "瞬間\n",
      "低生\n",
      "胎梦能\n",
      "胎梦真\n",
      "胖人先\n",
      "胖腹\n",
      "胖叔\n",
      "扣不上\n",
      "太气\n",
      "胖是\n",
      "最是\n",
      "其渣\n",
      "史遭\n",
      "胡可说\n",
      "爱沙溢\n",
      "王莫涵\n",
      "爽粉\n",
      "土创\n",
      "孰真\n",
      "赵丽颖迪丽\n",
      "修果\n",
      "五米\n",
      "先火\n",
      "胡歌江\n",
      "小少爷\n",
      "不专\n",
      "三部\n",
      "恋上富\n",
      "胡歌版\n",
      "第五集\n",
      "萧薰儿\n",
      "第十集\n",
      "药尘\n",
      "我幸\n",
      "胡歌疑\n",
      "看江\n",
      "这罗\n",
      "严枫\n",
      "曝与江\n",
      "伙中\n",
      "曝拍\n",
      "薛佳颖\n",
      "却大呼\n",
      "男主云\n",
      "迷热议\n",
      "胡歌进\n",
      "变迷妹\n",
      "偷亲\n",
      "时该\n",
      "胡歌领\n",
      "同食易\n",
      "8m\n",
      "胡蘿\n",
      "白蘿\n",
      "l25\n",
      "肯本\n",
      "一白\n",
      "减脂餐\n",
      "建议您\n",
      "脐绕\n",
      "成王俊凯\n",
      "干皮\n",
      "这中\n",
      "要治\n",
      "脚痒\n",
      "眼斜\n",
      "谈鹿晗\n",
      "庞博吐槽\n",
      "印难\n",
      "黄多斑\n",
      "洗一\n",
      "亮白显\n",
      "祛掉\n",
      "有斑\n",
      "斑别\n",
      "留痘\n",
      "这粒\n",
      "献招\n",
      "不净\n",
      "心别\n",
      "脸长\n",
      "七白散\n",
      "大穴\n",
      "神蒜子\n",
      "豆烧\n",
      "必买\n",
      "根一壶\n",
      "天跳起\n",
      "俩把\n",
      "痛泪\n",
      "两行\n",
      "记着\n",
      "直不起\n",
      "一些丝\n",
      "幅药\n",
      "蹄配\n",
      "七次\n",
      "刺血\n",
      "草教\n",
      "贴药\n",
      "半块\n",
      "一捧\n",
      "腰凸\n",
      "条明路\n",
      "有够\n",
      "敷法\n",
      "喝此\n",
      "芯系\n",
      "女取\n",
      "错名\n",
      "起得\n",
      "服来\n",
      "封群\n",
      "还开\n",
      "规中\n",
      "疼别\n",
      "几十天\n",
      "疼选\n",
      "痛者\n",
      "剂会\n",
      "上罗晋\n",
      "谁动\n",
      "地往\n",
      "5v\n",
      "燃脂宿\n",
      "粘鞋\n",
      "小腰\n",
      "后先\n",
      "奇好\n",
      "醫教\n",
      "幾招\n",
      "氯会\n",
      "油易\n",
      "已粉\n",
      "天才儿童\n",
      "遇外\n",
      "卖蛋\n",
      "粉泡\n",
      "成癌\n",
      "心之苗\n",
      "假哏\n",
      "认了\n",
      "发博要\n",
      "笑侃\n",
      "微博倡\n",
      "四十几年\n",
      "也造\n",
      "鸡准\n",
      "车晓要\n",
      "艳伟\n",
      "痛走\n",
      "三四天\n",
      "都治好\n",
      "禅洗\n",
      "艾滋针\n",
      "这条经\n",
      "专去\n",
      "劲椎痛\n",
      "过才\n",
      "两连板\n",
      "省电王\n",
      "13730400322\n",
      "四百多\n",
      "中沈腾\n",
      "为选\n",
      "最易复\n",
      "最脑\n",
      "娄艺\n",
      "潇起\n",
      "很装\n",
      "撑台\n",
      "数分钟\n",
      "分越\n",
      "之母\n",
      "夸买\n",
      "高衣品\n",
      "亿只\n",
      "购公\n",
      "诗鹿晗\n",
      "优孰劣\n",
      "选靠\n",
      "等泛\n",
      "飙汗\n",
      "天脸\n",
      "一百次\n",
      "天行\n",
      "肠毒治\n",
      "放醋\n",
      "天可治\n",
      "天抹平\n",
      "几辈\n",
      "lll555\n",
      "爆含\n",
      "排片\n",
      "千百种\n",
      "太香\n",
      "湖有\n",
      "比中美\n",
      "吐饼\n",
      "伊哈洛\n",
      "美妻\n",
      "未守\n",
      "之约成\n",
      "今其\n",
      "摸样\n",
      "苏牙身\n",
      "中吐饼\n",
      "十九年\n",
      "间生\n",
      "九名\n",
      "万平方公里\n",
      "苏见\n",
      "信遭\n",
      "指早\n",
      "苟芸慧捞\n",
      "暴肥\n",
      "若孕妈\n",
      "会死保\n",
      "夸是\n",
      "财季\n",
      "大秀新\n",
      "退欧\n",
      "亿于\n",
      "暖化\n",
      "杯数\n",
      "最多反\n",
      "三连助\n",
      "这图\n",
      "两成\n",
      "肾疼\n",
      "黑五\n",
      "误接\n",
      "会盗\n",
      "3k\n",
      "传将\n",
      "胸大\n",
      "般好\n",
      "导到\n",
      "比安卓\n",
      "变满格\n",
      "充爱奇艺\n",
      "比安卓贵\n",
      "不玩\n",
      "懵圈\n",
      "配版\n",
      "夜入\n",
      "万是\n",
      "感少\n",
      "范丞丞出\n",
      "秀网\n",
      "范丞丞初\n",
      "范丞丞唱\n",
      "遭剪\n",
      "男史\n",
      "范丞丞开\n",
      "范丞丞微\n",
      "博发\n",
      "博设\n",
      "范丞丞是\n",
      "与富\n",
      "哇瑟\n",
      "范丞丞疑\n",
      "范大美人\n",
      "范丞丞赢\n",
      "范丞丞跑\n",
      "成跑\n",
      "能放\n",
      "一入题\n",
      "竟遇\n",
      "这逼装\n",
      "不笑\n",
      "遭退剧\n",
      "李晨来\n",
      "翔成\n",
      "想毁\n",
      "人可住\n",
      "说范\n",
      "脸太\n",
      "默姐\n",
      "李晨婚\n",
      "两女互\n",
      "李晨敢\n",
      "亿备\n",
      "等常\n",
      "婚房疑\n",
      "变帅\n",
      "不输范\n",
      "微博晒素\n",
      "颜照\n",
      "竟发\n",
      "录上\n",
      "他爸\n",
      "喜发\n",
      "似要\n",
      "红本秀\n",
      "今非夕比\n",
      "予酸气\n",
      "六十多\n",
      "爆买\n",
      "晒美照\n",
      "曝李晨\n",
      "当奶\n",
      "显孕味\n",
      "他苦\n",
      "李晨刚\n",
      "崩开\n",
      "粉装捞\n",
      "不忘捞\n",
      "要亮\n",
      "为助\n",
      "曝瘦\n",
      "照疯传\n",
      "只演\n",
      "天戏\n",
      "其真烂\n",
      "一沉斥\n",
      "剪光\n",
      "满墙\n",
      "送娜\n",
      "李晨换\n",
      "161125\n",
      "万降\n",
      "三面\n",
      "撕白\n",
      "内供\n",
      "再恋\n",
      "茶友\n",
      "泡来\n",
      "老茶\n",
      "茶里\n",
      "梗加\n",
      "王二妮现\n",
      "洗后\n",
      "大如\n",
      "病是\n",
      "恐会\n",
      "区昌元\n",
      "终成空\n",
      "揭胡歌\n",
      "火炸\n",
      "之光\n",
      "火透\n",
      "磨皮\n",
      "显年\n",
      "小膏\n",
      "火疯\n",
      "过白\n",
      "眼纹\n",
      "净白逆龄\n",
      "这盒\n",
      "火死\n",
      "小白瓶\n",
      "白滑\n",
      "套王\n",
      "莆永\n",
      "爽感\n",
      "后定\n",
      "莫雷慌\n",
      "雪藏恐\n",
      "哪年\n",
      "炒到\n",
      "切不动\n",
      "极恐\n",
      "随吃\n",
      "随取\n",
      "老粘锅\n",
      "久放\n",
      "萌宠成\n",
      "湿治\n",
      "导图\n",
      "因钙\n",
      "快线\n",
      "细面\n",
      "营改\n",
      "增后\n",
      "萨德后\n",
      "小尾巴\n",
      "妹纸们\n",
      "三红三黑\n",
      "请圈\n",
      "出爱自\n",
      "光尾\n",
      "艺根\n",
      "新材\n",
      "转板\n",
      "玩久\n",
      "烤色\n",
      "小川\n",
      "盼贷\n",
      "五人组\n",
      "泰莱托\n",
      "窗擦出\n",
      "发会\n",
      "亮银版\n",
      "甩功\n",
      "这一说\n",
      "元骗\n",
      "微信圈\n",
      "跨济青\n",
      "该桥\n",
      "急求\n",
      "a型\n",
      "用狗求\n",
      "过院\n",
      "送狗\n",
      "一微\n",
      "信公号\n",
      "涉汛\n",
      "亲宝来\n",
      "小马拉\n",
      "费油\n",
      "轻才\n",
      "六不喝\n",
      "拉用\n",
      "谣记\n",
      "少肉\n",
      "传夺\n",
      "日耳\n",
      "神潭\n",
      "假假\n",
      "规土委\n",
      "霍雨馨\n",
      "首访\n",
      "晚茶\n",
      "狂逃\n",
      "泳到\n",
      "留秒\n",
      "来颗\n",
      "大低\n",
      "男主而\n",
      "尸油\n",
      "谢娜孕\n",
      "一百万元\n",
      "refinance\n",
      "人买错\n",
      "买扬\n",
      "灰层\n",
      "传学车\n",
      "加片\n",
      "原男主非\n",
      "年裁\n",
      "邓伦成\n",
      "需做\n",
      "非死\n",
      "即生\n",
      "此系\n",
      "代消分\n",
      "销分者\n",
      "分要\n",
      "ufoufo\n",
      "被常来\n",
      "之地\n",
      "马云败\n",
      "军改\n",
      "长高必\n",
      "耻可雪\n",
      "涉军\n",
      "地非\n",
      "称宜信\n",
      "币能\n",
      "配四驱\n",
      "全坏\n",
      "配小版汉兰达\n",
      "最逼格\n",
      "来辟\n",
      "井柏然方\n",
      "郭冠樱\n",
      "须办\n",
      "藏古\n",
      "需交药\n",
      "市未\n",
      "二十六元\n",
      "央媒\n",
      "市人\n",
      "社局\n",
      "按原\n",
      "没配\n",
      "挨罚\n",
      "两道\n",
      "网传图\n",
      "分可达\n",
      "岁生\n",
      "先爱\n",
      "骗嫩\n",
      "模生\n",
      "孙宁后\n",
      "姚貝娜\n",
      "斥收\n",
      "中甲\n",
      "收上\n",
      "卓伟怒\n",
      "小虎\n",
      "正强\n",
      "开虐\n",
      "甩斤\n",
      "交够\n",
      "药泡\n",
      "万出头\n",
      "比帝\n",
      "铁扎\n",
      "小里\n",
      "网第\n",
      "活摘\n",
      "人骗\n",
      "撒药系\n",
      "系旧\n",
      "网传市\n",
      "一所\n",
      "神花\n",
      "pivm\n",
      "hqp88jszlmfz7kgvw\n",
      "但放\n",
      "白放\n",
      "竟降\n",
      "大货\n",
      "根断\n",
      "播完\n",
      "另位\n",
      "袁立敢\n",
      "袁立输\n",
      "师留\n",
      "博怒\n",
      "浙卫玩大\n",
      "袁立斥\n",
      "拖薪\n",
      "该信\n",
      "肚上\n",
      "怒诉\n",
      "时怒\n",
      "喻言太狂\n",
      "童年时代\n",
      "半吨\n",
      "发耳沙\n",
      "溺亡系\n",
      "扮瘦\n",
      "人请\n",
      "速传\n",
      "不学车\n",
      "规要\n",
      "半回\n",
      "虚肉\n",
      "不扰\n",
      "清血凉\n",
      "五张\n",
      "没得癌\n",
      "上采\n",
      "对防\n",
      "滋血\n",
      "这茶\n",
      "最香\n",
      "逢接\n",
      "每元\n",
      "當十\n",
      "mrsa\n",
      "川医\n",
      "必用\n",
      "婉妹\n",
      "会大放\n",
      "缴满\n",
      "再缴\n",
      "微市\n",
      "增考\n",
      "网报\n",
      "标化\n",
      "离月供\n",
      "金亦波\n",
      "殊灭\n",
      "日开\n",
      "测癌\n",
      "暴降\n",
      "首提\n",
      "2900mm\n",
      "虐哭\n",
      "50w\n",
      "客是\n",
      "闲鱼\n",
      "版樊胜美\n",
      "mp412\n",
      "真幸福\n",
      "王嘉俩\n",
      "请宝妈\n",
      "曝早\n",
      "这艘\n",
      "进购\n",
      "抓超\n",
      "剪肥\n",
      "fema\n",
      "菲玛\n",
      "虽远必\n",
      "二十三年\n",
      "编门\n",
      "一半分\n",
      "邓超带\n",
      "说怀\n",
      "毕滢\n",
      "洪欣成\n",
      "南阳人\n",
      "又系\n",
      "改分\n",
      "略增\n",
      "油泼面\n",
      "版高\n",
      "曝戚\n",
      "对何\n",
      "越冷越\n",
      "信部\n",
      "先热车\n",
      "美白大长\n",
      "背法\n",
      "问药\n",
      "爸虎妈\n",
      "君来\n",
      "就会少\n",
      "赵伟健\n",
      "神儿\n",
      "植森式\n",
      "缩肚法\n",
      "尹同\n",
      "观致\n",
      "百万条\n",
      "备点\n",
      "此树\n",
      "喝八\n",
      "虽护\n",
      "周除\n",
      "一下脸\n",
      "毁脸\n",
      "暗黄靠\n",
      "钱小白片\n",
      "調理治\n",
      "儲存\n",
      "耳内\n",
      "招辈传\n",
      "大物\n",
      "奖中超\n",
      "八位数\n",
      "亚冠赛\n",
      "场暂\n",
      "签新帅\n",
      "埃神博\n",
      "亚冠上\n",
      "恒大亚冠\n",
      "留力\n",
      "残阵\n",
      "波耶特\n",
      "小法\n",
      "脸大\n",
      "几枪\n",
      "免体\n",
      "炒会\n",
      "背绿\n",
      "投全\n",
      "汁加\n",
      "美链\n",
      "币会\n",
      "指卖\n",
      "理综第\n",
      "秒定\n",
      "红指\n",
      "天椒\n",
      "社厅\n",
      "肩显\n",
      "中青院\n",
      "促法\n",
      "二个月\n",
      "显瘦特\n",
      "小仁村\n",
      "气代煤\n",
      "买电\n",
      "armature\n",
      "ps4\n",
      "版为\n",
      "上煌\n",
      "神东\n",
      "太陽\n",
      "怒减\n",
      "露肉\n",
      "减肉\n",
      "microled\n",
      "194027\n",
      "加全满\n",
      "乳包\n",
      "自补\n",
      "但个\n",
      "糖量\n",
      "九项\n",
      "春考\n",
      "丘卡堡\n",
      "天审车\n",
      "背锅侠\n",
      "漂满\n",
      "ymg\n",
      "六句话\n",
      "直付\n",
      "纸糊房\n",
      "停贷\n",
      "养颜能\n",
      "畜博\n",
      "两百元\n",
      "标清\n",
      "摔门\n",
      "工救\n",
      "领补\n",
      "迟早会\n",
      "淡溪\n",
      "之悦\n",
      "迁校\n",
      "柯桥区\n",
      "第四篇\n",
      "深松\n",
      "要修\n",
      "据树\n",
      "千遍\n",
      "百遍\n",
      "付线\n",
      "十一月份\n",
      "二项\n",
      "镇堤\n",
      "两则\n",
      "降税\n",
      "继借\n",
      "马云摊\n",
      "下狠手\n",
      "马云过\n",
      "该吐槽\n",
      "棚改\n",
      "趋严\n",
      "房企散\n",
      "比当\n",
      "分够\n",
      "不在染\n",
      "半袋\n",
      "黑露\n",
      "时加些\n",
      "快评\n",
      "周创兵\n",
      "别转\n",
      "接中\n",
      "传男宝\n",
      "停旧\n",
      "发新\n",
      "波场\n",
      "思语\n",
      "青水镇\n",
      "狂嚣\n",
      "遭迷烟\n",
      "雷寒\n",
      "没好\n",
      "临牌\n",
      "挖心\n",
      "网传分\n",
      "分新规\n",
      "热帖系\n",
      "受网\n",
      "没本数\n",
      "分系\n",
      "避坑\n",
      "微说\n",
      "弃考\n",
      "爆走\n",
      "薛之谦疑\n",
      "薛之谦能\n",
      "薛之谦遭\n",
      "歌忙\n",
      "升小\n",
      "新校\n",
      "各招\n",
      "共助\n",
      "返进\n",
      "由扣\n",
      "严新交规\n",
      "条新交规\n",
      "未检\n",
      "日新交规\n",
      "改区市\n",
      "打户工\n",
      "百分之九十九\n",
      "之策\n",
      "图准\n",
      "表看\n",
      "图一查\n",
      "表之\n",
      "图帮算\n",
      "说备\n",
      "图靠\n",
      "白娅倩\n",
      "别年\n",
      "这则\n",
      "立补立\n",
      "所留\n",
      "如车\n",
      "首篇\n",
      "别乐\n",
      "想吐槽\n",
      "三评\n",
      "制及\n",
      "能过\n",
      "张修维醉\n",
      "天雪\n",
      "起酒\n",
      "互检\n",
      "没定\n",
      "不罚\n",
      "品之\n",
      "納宝力\n",
      "1号店\n",
      "二娃\n",
      "花口贝\n",
      "必领\n",
      "类种\n",
      "进国网\n",
      "这五\n",
      "物熬\n",
      "官微发\n",
      "麻吉宝\n",
      "发币\n",
      "链反\n",
      "链下\n",
      "链币\n",
      "非美图\n",
      "新规要\n",
      "疑视\n",
      "二要\n",
      "不面\n",
      "签将\n",
      "倒库\n",
      "估损师\n",
      "需交缴\n",
      "过江\n",
      "走会收\n",
      "动图\n",
      "李队\n",
      "造人论\n",
      "比家\n",
      "有三大\n",
      "走天\n",
      "其为\n",
      "给害\n",
      "没年\n",
      "a轮\n",
      "涉黑涉\n",
      "获塔塔\n",
      "阎焱购\n",
      "数千万元\n",
      "会力\n",
      "派单\n",
      "泥料\n",
      "未年\n",
      "审扣\n",
      "繁入\n",
      "马云教\n",
      "比看\n",
      "四样\n",
      "多吃些\n",
      "需备\n",
      "助降\n",
      "果配\n",
      "永防\n",
      "扫净\n",
      "杨凌限行\n",
      "将限行\n",
      "比变\n",
      "好破\n",
      "肿着\n",
      "八千元\n",
      "不装罚\n",
      "能缴\n",
      "一绿\n",
      "三高显\n",
      "快算\n",
      "退不退\n",
      "能盖\n",
      "蒋欣骗\n",
      "蒋欣假\n",
      "小苹果\n",
      "杜思远\n",
      "思远\n",
      "子得\n",
      "干要\n",
      "没人会\n",
      "类违\n",
      "媳难\n",
      "左拐\n",
      "去不去\n",
      "大缺\n",
      "女多\n",
      "男少\n",
      "这三大假\n",
      "你会生\n",
      "几百头\n",
      "一洞\n",
      "人不交\n",
      "无胶\n",
      "可年入\n",
      "卡下\n",
      "ic卡\n",
      "还少\n",
      "万高二\n",
      "增反降\n",
      "王兴田\n",
      "斥为\n",
      "1b\n",
      "英媒称\n",
      "无商\n",
      "可经\n",
      "第五次\n",
      "最多省\n",
      "过该\n",
      "尼比鲁\n",
      "二建要\n",
      "顺走\n",
      "以货\n",
      "抵费\n",
      "哪番\n",
      "码要\n",
      "只装\n",
      "严交规\n",
      "无新规\n",
      "交规大\n",
      "内算酒\n",
      "逗死\n",
      "中榕\n",
      "高科城\n",
      "图带\n",
      "证为\n",
      "一万多元\n",
      "baby8000\n",
      "这阵\n",
      "却持\n",
      "资管\n",
      "鑫岸\n",
      "用洁\n",
      "厕宝易\n",
      "美记\n",
      "陪跑员\n",
      "跑员称\n",
      "水助\n",
      "但国\n",
      "持照\n",
      "天白过\n",
      "后抹点\n",
      "再白\n",
      "美白太难\n",
      "越细越\n",
      "素颜要\n",
      "黄美白\n",
      "越白滑\n",
      "倒点\n",
      "百分之九十\n",
      "中放点\n",
      "比雪\n",
      "没几人\n",
      "水乳霜加\n",
      "会知\n",
      "半勺\n",
      "美白逆龄\n",
      "脸斑\n",
      "越白过\n",
      "液帮\n",
      "越雪嫩\n",
      "没皱\n",
      "可真大\n",
      "能越\n",
      "美嫩\n",
      "嫩似\n",
      "只会用\n",
      "七子粉\n",
      "亮白细\n",
      "后涂\n",
      "贴点\n",
      "水嫩亮\n",
      "暗黄有\n",
      "加滴\n",
      "更嫩\n",
      "新奔\n",
      "ev260\n",
      "从交\n",
      "车不装\n",
      "致四车\n",
      "遭扣\n",
      "店空\n",
      "旅发委\n",
      "刘东强\n",
      "最马云\n",
      "分才\n",
      "东喘\n",
      "年宝妈\n",
      "中安\n",
      "金股\n",
      "万小散\n",
      "换新卡\n",
      "m9636\n",
      "入辅\n",
      "这扣\n",
      "肺里会\n",
      "丢证\n",
      "分不高\n",
      "查否\n",
      "脑补求\n",
      "三连\n",
      "起新\n",
      "复胖\n",
      "要摇号\n",
      "赵又廷演\n",
      "壹圆\n",
      "下能\n",
      "类要\n",
      "博对\n",
      "村支\n",
      "一胎化\n",
      "这户\n",
      "跨级\n",
      "相给力\n",
      "以诗\n",
      "吟得\n",
      "抢票\n",
      "驾规\n",
      "气乐\n",
      "沃展\n",
      "雪迪龙\n",
      "需面\n",
      "致沪上\n",
      "驾不查\n",
      "免分\n",
      "亿是\n",
      "更脏\n",
      "切法\n",
      "拼妈\n",
      "闯大\n",
      "一虎要\n",
      "一龙后\n",
      "竟感\n",
      "避战\n",
      "有批\n",
      "如花\n",
      "他力\n",
      "四夜\n",
      "拉不开\n",
      "桂在\n",
      "临储\n",
      "年医\n",
      "dnf90ss\n",
      "卡牌\n",
      "mgd\n",
      "网投\n",
      "坑大\n",
      "黑像\n",
      "帝们\n",
      "欧风麦\n",
      "草是\n",
      "老布什\n",
      "按位\n",
      "净月区\n",
      "贾跃亭力\n",
      "一大部分\n",
      "染艾\n",
      "超百人\n",
      "今网\n",
      "热帖\n",
      "必背\n",
      "实考\n",
      "合返\n",
      "小峰\n",
      "备孕要\n",
      "提至语\n",
      "数外\n",
      "制系\n",
      "左雾\n",
      "青训生\n",
      "画因\n",
      "发邮\n",
      "停哨\n",
      "连豪车\n",
      "十三天\n",
      "购税\n",
      "年安在\n",
      "eiracube\n",
      "brett\n",
      "谷歌云\n",
      "领克用\n",
      "辟除\n",
      "二粒\n",
      "墨拒\n",
      "关晓彤发\n",
      "王均瑶\n",
      "亿嫁\n",
      "扎迪丽\n",
      "看迪丽\n",
      "剧旧\n",
      "她整\n",
      "胖迪暴\n",
      "场中\n",
      "股已\n",
      "山毁\n",
      "内限行\n",
      "爆翻\n",
      "全治好\n",
      "奖现\n",
      "中伊战\n",
      "官宣引\n",
      "投权健\n",
      "上港发\n",
      "遭大梦\n",
      "爆砍\n",
      "汇福\n",
      "转升\n",
      "购经\n",
      "适房\n",
      "演小三\n",
      "遭闺蜜\n",
      "鱼鳞状\n",
      "看朵\n",
      "想测\n",
      "频蹭\n",
      "最土\n",
      "网传洁\n",
      "锋味\n",
      "曝为\n",
      "越厚越\n",
      "互留\n",
      "味似\n",
      "遮百丑\n",
      "同屏\n",
      "季四人\n",
      "能撑\n",
      "就定\n",
      "最暖心\n",
      "六季\n",
      "再组\n",
      "关晓彤成\n",
      "男开\n",
      "录迪丽\n",
      "男新\n",
      "男官\n",
      "宣迪丽\n",
      "无真\n",
      "爆是\n",
      "一吻\n",
      "比玉好\n",
      "大余来\n",
      "集抄\n",
      "樱园\n",
      "为查\n",
      "间暗\n",
      "杨紫和周\n",
      "病太\n",
      "国乒让\n",
      "重做\n",
      "要重\n",
      "吸能\n",
      "董洁大婚\n",
      "内购\n",
      "这国仅\n",
      "十一天\n",
      "第三天\n",
      "李沁为\n",
      "点怕\n",
      "吃易\n",
      "借豪车\n",
      "太杀\n",
      "杨紫撞\n",
      "疑晒出\n",
      "退网\n",
      "它治尿\n",
      "加骁龙\n",
      "6gb\n",
      "下升\n",
      "茶教\n",
      "假赛\n",
      "剑魂\n",
      "ff91\n",
      "获恒大\n",
      "撼树\n",
      "es6\n",
      "侧切\n",
      "活可產生\n",
      "屍傳\n",
      "传埃\n",
      "敷于\n",
      "咖从\n",
      "亿降\n",
      "案烧\n",
      "胖丫\n",
      "限酬\n",
      "事是\n",
      "为发\n",
      "斤虫\n",
      "条虫\n",
      "活虾\n",
      "庆婚\n",
      "生狗\n",
      "没骂\n",
      "上单\n",
      "theshy\n",
      "手伤\n",
      "号重\n",
      "德云色\n",
      "寒开测\n",
      "马崴\n",
      "15plus\n",
      "过拔\n",
      "百次\n",
      "多怒\n",
      "防狼\n",
      "三急\n",
      "补骨\n",
      "半颗\n",
      "出高冰阳\n",
      "冰阳\n",
      "早好\n",
      "必长\n",
      "坑过\n",
      "罗晋陷\n",
      "网传罗晋\n",
      "只发\n",
      "托腰\n",
      "斗美\n",
      "秦书培\n",
      "同返\n",
      "延更\n",
      "老嚼\n",
      "变大脸\n",
      "抢景甜\n",
      "亿航\n",
      "拖库\n",
      "撞库\n",
      "想戒\n",
      "教过\n",
      "携发\n",
      "因顿\n",
      "还助眠\n",
      "七分钟\n",
      "根别\n",
      "前常\n",
      "收腰\n",
      "能练\n",
      "腰十\n",
      "三下\n",
      "前练\n",
      "上肉\n",
      "莫弯\n",
      "基满色\n",
      "沙匀\n",
      "打灯\n",
      "秋梨皮\n",
      "原石过\n",
      "师之手\n",
      "起鸡油\n",
      "线手\n",
      "级籽料\n",
      "赌石大\n",
      "胖易\n",
      "全患\n",
      "新聞\n",
      "喝無糖\n",
      "可樂\n",
      "同樣\n",
      "别要\n",
      "唐嫣生\n",
      "年娜\n",
      "还成\n",
      "没和娜\n",
      "蒋欣疑\n",
      "称仅\n",
      "三十八岁\n",
      "母队\n",
      "向郎导\n",
      "艺去\n",
      "该来\n",
      "多晚\n",
      "胡喷\n",
      "同程\n",
      "周鸿祎发\n",
      "称别\n",
      "盲约\n",
      "开现\n",
      "神评\n",
      "t3\n",
      "t3x\n",
      "r1\n",
      "比非\n",
      "精日\n",
      "万假\n",
      "21w\n",
      "遭天\n",
      "李晨大怒\n",
      "股债\n",
      "明股\n",
      "实债\n",
      "抛债\n",
      "如获\n",
      "usdt\n",
      "微博心\n",
      "穿白\n",
      "其点\n",
      "罗玉凤凤姐\n",
      "突删\n",
      "杰来\n",
      "房日\n",
      "栋房\n",
      "亿因\n",
      "万拥\n",
      "肺唱\n",
      "小娇娘\n",
      "称太累\n",
      "生女宝\n",
      "重了\n",
      "大是\n",
      "允晒照\n",
      "破老\n",
      "晒素\n",
      "颜力\n",
      "称想\n",
      "能作\n",
      "十三个\n",
      "意有\n",
      "暗有\n",
      "前度\n",
      "比范爷\n",
      "六物膏\n",
      "终走\n",
      "网红圈\n",
      "一人妻\n",
      "曾放话\n",
      "喷遍\n",
      "白叫\n",
      "got7\n",
      "bambam\n",
      "难时\n",
      "继王\n",
      "帮妈\n",
      "关系融洽\n",
      "后华哥\n",
      "潮下\n",
      "梦靠\n",
      "投令\n",
      "电踏车\n",
      "造过\n",
      "很委\n",
      "树瘤\n",
      "信过\n",
      "不样\n",
      "一个二十岁\n",
      "般嫩\n",
      "缠脸\n",
      "关限\n",
      "肿得\n",
      "吸霾\n",
      "币安一姐\n",
      "网传币\n",
      "买岛\n",
      "币安何\n",
      "币安下\n",
      "虾帝\n",
      "建不起\n",
      "演新戏\n",
      "说生\n",
      "未称\n",
      "停贷系\n",
      "可寻\n",
      "卖高\n",
      "人挤\n",
      "汤久\n",
      "足贴\n",
      "再貴\n",
      "多數\n",
      "德云色协\n",
      "十万美元\n",
      "日线\n",
      "微博热传\n",
      "阿帕替\n",
      "融信\n",
      "不大呼\n",
      "快靠\n",
      "人老孟\n",
      "松野莉奈\n",
      "猝逝\n",
      "当十有\n",
      "颜近\n",
      "常掉\n",
      "换后\n",
      "好几部\n",
      "变护\n",
      "妻狂\n",
      "翁帆会\n",
      "称该\n",
      "四千多年\n",
      "实锤蛇哥\n",
      "疑何\n",
      "高圣运\n",
      "夜未\n",
      "继谢娜生\n",
      "管妻\n",
      "产了\n",
      "黑周杰\n",
      "出月子\n",
      "第三任\n",
      "因美过\n",
      "之陆判\n",
      "剩胡歌\n",
      "晏单\n",
      "第五天\n",
      "与江\n",
      "夸林\n",
      "儿付\n",
      "姐徐\n",
      "二套\n",
      "传成\n",
      "仍爱\n",
      "还拉上\n",
      "同遭\n",
      "合大\n",
      "半爷\n",
      "半娘\n",
      "入错\n",
      "六问\n",
      "称假\n",
      "人显\n",
      "传嫁\n",
      "育网\n",
      "将产\n",
      "雇托\n",
      "军为\n",
      "只食\n",
      "七粒\n",
      "美是\n",
      "两万多\n",
      "过误\n",
      "舒想\n",
      "张伦硕早\n",
      "张伦硕为\n",
      "拼生\n",
      "做孕检\n",
      "太拼\n",
      "张伦硕怀\n",
      "引谢贤\n",
      "柏芝乐\n",
      "挺大孕肚\n",
      "峰菲芝\n",
      "狂点\n",
      "服字\n",
      "张伦硕揽\n",
      "第五组\n",
      "万多倍\n",
      "角变\n",
      "盼生\n",
      "天为\n",
      "大媽教\n",
      "小時\n",
      "皮赘\n",
      "小裤\n",
      "碰瓷者\n",
      "明经国\n",
      "四字道\n",
      "张拍芝\n",
      "谢贤会\n",
      "肥到\n",
      "破不老\n",
      "显大\n",
      "人老得\n",
      "10s\n",
      "二十分钟\n",
      "茶要\n",
      "打帕奎\n",
      "表女宝\n",
      "福州人\n",
      "网传驾\n",
      "规下\n",
      "一和四需\n",
      "一和四\n",
      "要贵\n",
      "考大变\n",
      "规属\n",
      "考更难\n",
      "一免\n",
      "人仅\n",
      "附驾考\n",
      "五为\n",
      "开考\n",
      "瑶言\n",
      "一为\n",
      "分是\n",
      "梨城\n",
      "科三\n",
      "练车会\n",
      "正考\n",
      "领币\n",
      "晚排\n",
      "晚治\n",
      "肚臍上\n",
      "祛濕\n",
      "苗條\n",
      "中仅\n",
      "被代\n",
      "天因\n",
      "品正\n",
      "雪蛤炖\n",
      "毒越\n",
      "蒋欣刚\n",
      "比惨\n",
      "比乱\n",
      "中酒\n",
      "协站\n",
      "冻多效\n",
      "青島\n",
      "漁民\n",
      "及大\n",
      "官宣将\n",
      "链引\n",
      "正邦\n",
      "占股\n",
      "因良率\n",
      "招太牛\n",
      "僻谣\n",
      "用生\n",
      "菜要\n",
      "一语表\n",
      "懂球\n",
      "光兵\n",
      "妹发\n",
      "万字文\n",
      "ios113\n",
      "ios12\n",
      "据美\n",
      "拿牌\n",
      "大筒\n",
      "木桃式\n",
      "迎春节\n",
      "晚讯\n",
      "叶企孙\n",
      "好命\n",
      "求别\n",
      "donny\n",
      "王思聪告\n",
      "曼琳\n",
      "涉恐\n",
      "柳荣\n",
      "完刀郎\n",
      "渐冻\n",
      "偏强\n",
      "拿食\n",
      "心月\n",
      "传已\n",
      "素颜近\n",
      "180101\n",
      "气颖姐\n",
      "澹生\n",
      "20171118132212\n",
      "老炮儿\n",
      "退贵圈\n",
      "牛莉为\n",
      "洛瑞怒\n",
      "赔朱\n",
      "之文练\n",
      "杨子姗连\n",
      "听鹿晗\n",
      "阿杜患\n",
      "清桃\n",
      "小姑姑\n",
      "细肤\n",
      "愈传\n",
      "吴京非\n",
      "晒证\n",
      "傍身\n",
      "不声\n",
      "美媒惊\n",
      "曝泰伦卢\n",
      "朝伟嘉玲\n",
      "笑坏\n",
      "生会\n",
      "素颜上\n",
      "曝不生\n",
      "疑用\n",
      "称太大\n",
      "发博晒\n",
      "微博已\n",
      "腎結石\n",
      "目驚心\n",
      "主实\n",
      "封停\n",
      "死刚\n",
      "为蛇哥\n",
      "卢本伟骗\n",
      "开钱\n",
      "忘买\n",
      "亿已\n",
      "iheart\n",
      "微博一\n",
      "留来\n",
      "龙弃\n",
      "马云闹\n",
      "弃军\n",
      "我司\n",
      "称前\n",
      "逼数\n",
      "挽不回\n",
      "露全\n",
      "百位\n",
      "3gpp\n",
      "乌骨\n",
      "麻能\n",
      "称壹佰\n",
      "卖料\n",
      "因选\n",
      "圆变\n",
      "身白\n",
      "餐单\n",
      "燃脂法\n",
      "养颜防\n",
      "没减\n",
      "减水\n",
      "天秒\n",
      "颈期\n",
      "减近\n",
      "招绝\n",
      "脂称\n",
      "上称\n",
      "测值\n",
      "宝妈用\n",
      "暴汗服\n",
      "好牙\n",
      "有要\n",
      "驾苏\n",
      "嘴致\n",
      "发推\n",
      "阅球\n",
      "莫雷为\n",
      "脸说\n",
      "金证\n",
      "认芯\n",
      "认磁\n",
      "卡不认\n",
      "时卡险\n",
      "点为\n",
      "不传\n",
      "警叔\n",
      "专票\n",
      "能结\n",
      "装逼新\n",
      "信勿传\n",
      "可非\n",
      "旧换\n",
      "测过\n",
      "法外\n",
      "六棵\n",
      "碎会\n",
      "黑妮\n",
      "地空\n",
      "炒洋\n",
      "传假\n",
      "braman\n",
      "含肉\n",
      "食尸\n",
      "飞洋\n",
      "你入\n",
      "市监局\n",
      "有虫\n",
      "二十大\n",
      "老梗\n",
      "再信\n",
      "需出\n",
      "手变\n",
      "森族\n",
      "柯南七大\n",
      "人微信\n",
      "1v1\n",
      "市食\n",
      "市产\n",
      "屡热传\n",
      "避除\n",
      "惠安崇\n",
      "武惊传\n",
      "贡贡\n",
      "法斗步\n",
      "被定\n",
      "希晒\n",
      "想白\n",
      "一晒\n",
      "管够\n",
      "获鱼\n",
      "有太多\n",
      "内下\n",
      "因大\n",
      "高逼格\n",
      "震驚\n",
      "俄懷孕\n",
      "年後竟\n",
      "產活\n",
      "伪卡\n",
      "做边\n",
      "募投\n",
      "12492\n",
      "控糖用\n",
      "榜刷单\n",
      "众筹\n",
      "已发\n",
      "称刷\n",
      "万起定\n",
      "万不费\n",
      "仔乱\n",
      "骑小\n",
      "地现\n",
      "年夏普\n",
      "之痛\n",
      "偏治\n",
      "大梅沙\n",
      "越扫\n",
      "王石陷\n",
      "比翁帆\n",
      "胸会\n",
      "养鹅场\n",
      "王大哥\n",
      "八百元\n",
      "红罐\n",
      "很扎心\n",
      "两人用\n",
      "用泪\n",
      "枣同\n",
      "没转\n",
      "专瘦\n",
      "黄恒泰\n",
      "飞防真\n",
      "打谢娜\n",
      "谢娜讽\n",
      "现张杰\n",
      "a9\n",
      "128g\n",
      "两周岁\n",
      "愿宝\n",
      "附肚型\n",
      "规后\n",
      "否者\n",
      "天喻\n",
      "创局\n",
      "区片\n",
      "更别\n",
      "低开\n",
      "探低\n",
      "之拥\n",
      "能养颜\n",
      "种算\n",
      "人真\n",
      "不餐\n",
      "黑会\n",
      "陈醋加\n",
      "抽根烟\n",
      "某微博\n",
      "什们\n",
      "蓉江\n",
      "无主之地\n",
      "有前\n",
      "给霆锋\n",
      "谢贤立\n",
      "买首\n",
      "有楼\n",
      "没奶\n",
      "斑多\n",
      "常吃此\n",
      "吹霉\n",
      "十七斤\n",
      "为大婚\n",
      "十二斤\n",
      "通审\n",
      "四五年\n",
      "市驾考\n",
      "园方\n",
      "波新\n",
      "和准\n",
      "起交\n",
      "额有\n",
      "这起\n",
      "化限行\n",
      "号限行\n",
      "行新规\n",
      "卡友圈\n",
      "五系\n",
      "第三轮\n",
      "天弘\n",
      "没招\n",
      "变瓜\n",
      "一美\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "整月\n",
      "原子城\n",
      "九景衢\n",
      "宝兰客\n",
      "联试\n",
      "留放\n",
      "可防脱\n",
      "传造\n",
      "恋再\n",
      "现又陷\n",
      "变虚\n",
      "偷排\n",
      "百余辆\n",
      "谢贤疑\n",
      "八十多岁\n",
      "谢贤刚\n",
      "谢贤谈\n",
      "十六岁\n",
      "沛纳海\n",
      "财產归\n",
      "交个\n",
      "谢贤想分\n",
      "吃味传\n",
      "谢贤称\n",
      "埋于\n",
      "曝加\n",
      "车油\n",
      "拟运向\n",
      "指系\n",
      "行牛\n",
      "控水\n",
      "互呛\n",
      "过高要\n",
      "茶越\n",
      "无降配\n",
      "多市\n",
      "五象\n",
      "始作\n",
      "谣者\n",
      "蓝鸥\n",
      "还处\n",
      "三考\n",
      "立辨\n",
      "很乱系\n",
      "周超快\n",
      "全了\n",
      "附超全\n",
      "已诞下\n",
      "好孕气\n",
      "重男\n",
      "生宝状\n",
      "数十秒\n",
      "美羊羊\n",
      "人吃生\n",
      "从许\n",
      "看恋童\n",
      "网红许\n",
      "指恋童\n",
      "踏俩\n",
      "组间\n",
      "晨重\n",
      "第二阶段\n",
      "辣妈用\n",
      "练鬼步\n",
      "速码\n",
      "天脱\n",
      "猛瘦\n",
      "亲荐\n",
      "可减\n",
      "日减\n",
      "甩肚\n",
      "脂茶\n",
      "三十九天\n",
      "每招\n",
      "姜蜜水\n",
      "第四天\n",
      "好几斤\n",
      "第七天\n",
      "美拍\n",
      "甩油\n",
      "共瘦\n",
      "莫暴\n",
      "精脸\n",
      "大呼求\n",
      "神舞\n",
      "极塑\n",
      "体轻\n",
      "单腿\n",
      "特减\n",
      "第二十三\n",
      "半根\n",
      "中圣品\n",
      "知爽\n",
      "含屎\n",
      "没响\n",
      "推伤\n",
      "大卧\n",
      "姜泡\n",
      "每早\n",
      "无三高\n",
      "遭许\n",
      "晴批\n",
      "小威威\n",
      "宋雨洪\n",
      "对车\n",
      "政解\n",
      "越高越\n",
      "高鑫磊\n",
      "现神\n",
      "癌犯\n",
      "以微博\n",
      "薛之谦个\n",
      "周杰互\n",
      "最靓\n",
      "四摄\n",
      "崩人设\n",
      "坑夫\n",
      "没睡\n",
      "安和桥\n",
      "谦谦爱\n",
      "业之峰\n",
      "玩得\n",
      "王小鸥\n",
      "真忙\n",
      "鼓不起\n",
      "内要\n",
      "网剧令\n",
      "几十载\n",
      "怪孩\n",
      "返本型\n",
      "油会\n",
      "美系车\n",
      "万近\n",
      "还享\n",
      "曝卖\n",
      "领弹\n",
      "王一博自\n",
      "消保委约\n",
      "alpd\n",
      "而生\n",
      "人练\n",
      "老铁要\n",
      "里会\n",
      "粘肠\n",
      "错得\n",
      "英签\n",
      "青微博\n",
      "无墅\n",
      "罗曼尼\n",
      "喝多会\n",
      "分变\n",
      "痴汉脸\n",
      "lms\n",
      "拖米\n",
      "karsa\n",
      "已好\n",
      "4am\n",
      "放人\n",
      "任栋\n",
      "没说\n",
      "koro1\n",
      "带妹\n",
      "怪用\n",
      "ziv\n",
      "查飞单\n",
      "许知\n",
      "am4\n",
      "矿圈\n",
      "禁挖\n",
      "f2pool\n",
      "吴评鑫\n",
      "转势\n",
      "删路\n",
      "反招\n",
      "比脸\n",
      "被尬\n",
      "黑假\n",
      "其言尽\n",
      "拍吻\n",
      "戏用\n",
      "撒内宁\n",
      "翻路\n",
      "辱华\n",
      "凭颜值\n",
      "该查\n",
      "脱库\n",
      "轩墨\n",
      "之扣\n",
      "中毅\n",
      "况丽任\n",
      "元股\n",
      "pmma\n",
      "科通\n",
      "芯城\n",
      "中酒协\n",
      "灿笑\n",
      "附选股\n",
      "无应\n",
      "或迎\n",
      "被否\n",
      "更严\n",
      "日要\n",
      "假米\n",
      "含微\n",
      "杨颖太像\n",
      "显矮\n",
      "一人带\n",
      "曝假\n",
      "这大招\n",
      "安迪竟\n",
      "依乐\n",
      "脸贴\n",
      "变政\n",
      "upit\n",
      "币安将\n",
      "称中美\n",
      "资色\n",
      "比安迪豪\n",
      "测下\n",
      "超有\n",
      "看孕囊\n",
      "超五\n",
      "凑好\n",
      "旦下\n",
      "速接\n",
      "家获\n",
      "数百架\n",
      "没料\n",
      "商飞用\n",
      "问西\n",
      "媒脸\n",
      "队不换\n",
      "看自\n",
      "第一发\n",
      "高宇翔\n",
      "根茶\n",
      "根可治癌\n",
      "涉癌\n",
      "雷臻\n",
      "链网\n",
      "qklw\n",
      "罗又陷\n",
      "鲁尼梅格\n",
      "伊瓜\n",
      "难平\n",
      "怎敌\n",
      "已互\n",
      "冷讽\n",
      "误造\n",
      "亿追内\n",
      "济奥\n",
      "罗转\n",
      "欧冠要\n",
      "曝齐祖\n",
      "罗表\n",
      "西媒报\n",
      "梅西发\n",
      "大竟\n",
      "其原\n",
      "罗送\n",
      "内马尔回\n",
      "▹\n",
      "被旭旭\n",
      "必掉\n",
      "狂出\n",
      "未锁抗\n",
      "机盗\n",
      "150426\n",
      "黄子稻\n",
      "系富\n",
      "加新\n",
      "嘴炮\n",
      "十几架\n",
      "帅炸\n",
      "35b\n",
      "密爱\n",
      "iovine\n",
      "东晒\n",
      "店卷款\n",
      "万跑\n",
      "1440cc\n",
      "行能\n",
      "博为\n",
      "宇不\n",
      "姐退赛\n",
      "姐将\n",
      "茶界\n",
      "偏慨全\n",
      "拉低\n",
      "姐赴\n",
      "姐要\n",
      "出炫酷\n",
      "未现\n",
      "有动\n",
      "帮白娅婧\n",
      "杨雷雷\n",
      "网传高\n",
      "何时休\n",
      "护考\n",
      "刷遍\n",
      "魏伟健\n",
      "病会\n",
      "我敢\n",
      "多公斤\n",
      "越聰明\n",
      "當夜\n",
      "貓族\n",
      "三個\n",
      "第三期\n",
      "姐唱\n",
      "博努奇\n",
      "浙媒\n",
      "wba\n",
      "猛超\n",
      "打考\n",
      "地泪\n",
      "他放\n",
      "接战\n",
      "一惨\n",
      "喊娘\n",
      "郭晨冬\n",
      "喝多酒\n",
      "假醉\n",
      "飞闹\n",
      "mxlg\n",
      "小智称\n",
      "若风\n",
      "中单\n",
      "贼海\n",
      "啪姐\n",
      "出装\n",
      "牌牌琦\n",
      "说牌\n",
      "牌琦\n",
      "炮哥\n",
      "缺啥\n",
      "谈癌\n",
      "恩爱有加\n",
      "连麦散\n",
      "变人全\n",
      "完牙要\n",
      "okb\n",
      "兰微\n",
      "骆歆\n",
      "雨童\n",
      "赛见\n",
      "爱德\n",
      "泽元\n",
      "x21\n",
      "8gb\n",
      "10gt\n",
      "马蓉终\n",
      "曝对\n",
      "暴扣\n",
      "未向\n",
      "周琦发\n",
      "nba6\n",
      "遭否\n",
      "告赢\n",
      "乐视称\n",
      "提币\n",
      "条微博\n",
      "降配\n",
      "已稳\n",
      "版遭\n",
      "pro7\n",
      "戴越\n",
      "最招\n",
      "病对\n",
      "血有\n",
      "集邦\n",
      "fnc\n",
      "mlxg\n",
      "看得开\n",
      "没边\n",
      "没际\n",
      "骚猪\n",
      "传伍\n",
      "开壶\n",
      "爆得\n",
      "180320\n",
      "ymc\n",
      "替演\n",
      "遭热议\n",
      "某博主\n",
      "zax\n",
      "微博热文\n",
      "清爆\n",
      "频用\n",
      "频晒\n",
      "明升车\n",
      "爆个料\n",
      "emba\n",
      "发推称\n",
      "pieliedie\n",
      "qq144\n",
      "fifaol3\n",
      "五将\n",
      "无反\n",
      "没挂\n",
      "京奥港\n",
      "通证\n",
      "蛇队\n",
      "队霸\n",
      "引战\n",
      "karasa\n",
      "精盾\n",
      "打势\n",
      "可组\n",
      "孤存\n",
      "推特谈\n",
      "张骋宇\n",
      "爆招\n",
      "其官\n",
      "陈问言\n",
      "盼易\n",
      "宝们\n",
      "现与九好\n",
      "后疑\n",
      "孤立系\n",
      "170708\n",
      "以易\n",
      "脸破\n",
      "别脑\n",
      "tfrboys\n",
      "后易祥千玺\n",
      "170714\n",
      "神尾\n",
      "天合光\n",
      "雷集\n",
      "战悬\n",
      "王源陷\n",
      "王蒙芳\n",
      "传致\n",
      "disspg\n",
      "绿休团\n",
      "骗粉\n",
      "170224\n",
      "峰峻\n",
      "弃医\n",
      "从文\n",
      "财新\n",
      "和国\n",
      "三连胜\n",
      "真不看\n",
      "陕甲\n",
      "甚殊\n",
      "脸会\n",
      "男票\n",
      "逆领\n",
      "拍于\n",
      "kristina\n",
      "戏暴\n",
      "良茶\n",
      "毒通\n",
      "学讯网\n",
      "招助\n",
      "净瘦\n",
      "天刮肠治\n",
      "人害\n",
      "回小蛮\n",
      "通督法\n",
      "大绳\n",
      "甩油操\n",
      "350km\n",
      "dev1\n",
      "颜值帝\n",
      "控大屏\n",
      "档杆\n",
      "买哈弗\n",
      "万多台\n",
      "锁配\n",
      "却堪\n",
      "买苏\n",
      "多坑\n",
      "六十多万\n",
      "35s\n",
      "几起\n",
      "飞棍\n",
      "下輩子\n",
      "談靈體\n",
      "轉世\n",
      "tiobe\n",
      "r9\n",
      "点众\n",
      "偶练\n",
      "没系\n",
      "根草\n",
      "码截屏\n",
      "错信\n",
      "离台\n",
      "戊仁\n",
      "玩不起\n",
      "嘲像\n",
      "变僵\n",
      "直男癌\n",
      "杨颖宠\n",
      "竟买\n",
      "杨颖大\n",
      "直夸\n",
      "欠裸贷\n",
      "想斥\n",
      "能红\n",
      "刚发糖\n",
      "300w\n",
      "产女\n",
      "晒孕照\n",
      "曝送\n",
      "验身\n",
      "prp\n",
      "吴秀波方\n",
      "称何\n",
      "震亚\n",
      "曝带\n",
      "进组\n",
      "秀波\n",
      "一次次\n",
      "颜做\n",
      "佳女\n",
      "懷男寶最\n",
      "大特徵\n",
      "備孕\n",
      "图骗\n",
      "两千人\n",
      "市规\n",
      "土委\n",
      "一居卖\n",
      "越传越\n",
      "群里发\n",
      "黑机\n",
      "idropnews\n",
      "曹德旺成\n",
      "l5\n",
      "帽是\n",
      "z17\n",
      "n1\n",
      "vcsel\n",
      "c盘\n",
      "ios80\n",
      "伪玩家\n",
      "e2\n",
      "机照\n",
      "率高\n",
      "ufs21\n",
      "iphone11\n",
      "iphonex1\n",
      "九月份\n",
      "ufo37\n",
      "大欖\n",
      "如飞\n",
      "四步\n",
      "丑爆\n",
      "真丑\n",
      "浅金\n",
      "南波儿\n",
      "怒回\n",
      "称全\n",
      "卓伟方\n",
      "一诉\n",
      "度秘\n",
      "追投\n",
      "贾跃亭系\n",
      "互粉\n",
      "论为\n",
      "早讯\n",
      "获新\n",
      "称摩拜\n",
      "中艺\n",
      "汉可达\n",
      "称此\n",
      "告紧\n",
      "搭网\n",
      "非网\n",
      "难渡\n",
      "合乘\n",
      "张松声\n",
      "城小\n",
      "成转商\n",
      "亿港元\n",
      "街电\n",
      "有细针\n",
      "王兴靠\n",
      "两充\n",
      "磁吸\n",
      "妻美\n",
      "笑颖\n",
      "人皇\n",
      "赞高\n",
      "只捧林\n",
      "王智产女\n",
      "直破\n",
      "俊凯\n",
      "获封\n",
      "破虚红\n",
      "数千只\n",
      "打系\n",
      "提雅\n",
      "看球系\n",
      "魅红\n",
      "瑞麦\n",
      "线坏\n",
      "曾哥悟悟\n",
      "专坑\n",
      "霉霉和赛\n",
      "小虎铁\n",
      "大东翔\n",
      "李凯文\n",
      "竞有料\n",
      "俞巍勇\n",
      "依春\n",
      "多万斤\n",
      "z4\n",
      "遭枪\n",
      "市卫计\n",
      "已进\n",
      "致万人\n",
      "市二\n",
      "别止\n",
      "疾治\n",
      "手后\n",
      "涉藏\n",
      "网传皂\n",
      "角巷\n",
      "多联\n",
      "妈有\n",
      "名博主\n",
      "贴文\n",
      "遭起\n",
      "称马航\n",
      "晚读\n",
      "食方\n",
      "医聊\n",
      "清肠治\n",
      "名庄\n",
      "打其脸\n",
      "雪中放\n",
      "喷脸\n",
      "此词\n",
      "信谣\n",
      "健今\n",
      "显胖\n",
      "比往\n",
      "之妻\n",
      "房算白\n",
      "慌教\n",
      "乐视要\n",
      "监局\n",
      "这多\n",
      "妥滴\n",
      "传梦老\n",
      "好几回\n",
      "不借\n",
      "网传酒\n",
      "弑母\n",
      "网传龙\n",
      "遭偷\n",
      "erc20\n",
      "王力辉\n",
      "离乳\n",
      "一条条\n",
      "奶比\n",
      "要调\n",
      "桂风起\n",
      "心热时\n",
      "想不美\n",
      "top2\n",
      "东塍\n",
      "东一环\n",
      "畸高\n",
      "拒做\n",
      "箱中\n",
      "偷后\n",
      "昨传\n",
      "箱偷\n",
      "照火遍\n",
      "网安\n",
      "百人团\n",
      "说春白\n",
      "中春尾寿眉\n",
      "画水\n",
      "城要\n",
      "抢包\n",
      "可杀\n",
      "肾系\n",
      "明后天\n",
      "警抓\n",
      "一百多年\n",
      "个查\n",
      "祝剑\n",
      "误发\n",
      "盛华堂\n",
      "西牛岭\n",
      "烧炮\n",
      "侯继刚\n",
      "营有\n",
      "鹤警\n",
      "火灾死\n",
      "因霍\n",
      "血能\n",
      "暂不收\n",
      "半箱\n",
      "多排\n",
      "形补形\n",
      "沈月英\n",
      "水贝买\n",
      "元购\n",
      "编个\n",
      "半小\n",
      "一问\n",
      "证要\n",
      "办办\n",
      "前将现\n",
      "照光\n",
      "祖玛珑\n",
      "香颜值\n",
      "看剧\n",
      "晃脑\n",
      "freetime\n",
      "咕汇\n",
      "发微斥\n",
      "批要\n",
      "難得\n",
      "一見\n",
      "瀕\n",
      "危物種\n",
      "万疑\n",
      "能防雾\n",
      "咳进\n",
      "挣大\n",
      "喝鼠\n",
      "对瓶\n",
      "ddr4\n",
      "手留\n",
      "变国\n",
      "乃不实\n",
      "爱航\n",
      "发推文称\n",
      "暖文有\n",
      "心文\n",
      "删长\n",
      "借卖\n",
      "药来\n",
      "油墩\n",
      "震前\n",
      "拍自\n",
      "前现\n",
      "屋斜\n",
      "双滦事\n",
      "天现\n",
      "担何责\n",
      "报君\n",
      "中受\n",
      "万系\n",
      "女慢\n",
      "171013\n",
      "第三篇\n",
      "top1\n",
      "top3\n",
      "jpms\n",
      "用火\n",
      "纷传\n",
      "热传后\n",
      "急查\n",
      "电诈\n",
      "推短\n",
      "食安\n",
      "第八期\n",
      "案判\n",
      "该止\n",
      "刷过\n",
      "特破此\n",
      "condi\n",
      "传烧\n",
      "双榜来\n",
      "比原\n",
      "主网\n",
      "再收\n",
      "能烧\n",
      "亿次\n",
      "中吃出\n",
      "十个月\n",
      "lucas1\n",
      "货期\n",
      "虐子\n",
      "类系\n",
      "韩玉印\n",
      "鲁中网\n",
      "安胖\n",
      "挖莱万\n",
      "莱万\n",
      "曝蒂\n",
      "莱万亲\n",
      "鲁梅尼\n",
      "r3\n",
      "xrp\n",
      "众筹刷单\n",
      "何一称\n",
      "遭多\n",
      "网传豪\n",
      "网心\n",
      "币之父\n",
      "用大\n",
      "6sp\n",
      "五周年\n",
      "jgg88885\n",
      "近半\n",
      "曝偷\n",
      "姐已\n",
      "其称\n",
      "删孕\n",
      "深得于\n",
      "很多遍\n",
      "姐装\n",
      "万分之一\n",
      "几眼\n",
      "付之东水\n",
      "王丽坤苦\n",
      "同林\n",
      "网红莉哥\n",
      "就会松\n",
      "上现\n",
      "蛭富\n",
      "麝取\n",
      "养鹅有\n",
      "万株\n",
      "卖鹿\n",
      "养虾\n",
      "盖菇\n",
      "上万只\n",
      "蒋欣才\n",
      "后帅\n",
      "王凯称\n",
      "或系\n",
      "g4\n",
      "绝矿\n",
      "还护\n",
      "撤场\n",
      "删不实\n",
      "群传雪\n",
      "群流\n",
      "太鼓\n",
      "抓系\n",
      "若风为\n",
      "六日\n",
      "亚服\n",
      "四连辟\n",
      "放洁\n",
      "赵雅欣\n",
      "程笑颖\n",
      "便论\n",
      "映客\n",
      "通付\n",
      "国通星\n",
      "手刷\n",
      "一清机\n",
      "滚远点\n",
      "之五\n",
      "不雅未\n",
      "葱须\n",
      "已回\n",
      "家店\n",
      "云到\n",
      "h1n9\n",
      "上安\n",
      "省疾控\n",
      "贝嫂\n",
      "高鑫情\n",
      "粉馆\n",
      "东谈\n",
      "频降\n",
      "图会\n",
      "监发\n",
      "吃片\n",
      "超瘦\n",
      "我怕\n",
      "伤农\n",
      "舌上\n",
      "别太凉\n",
      "早吃金\n",
      "午吃\n",
      "晚吃毒\n",
      "伤膝\n",
      "称微博\n",
      "点到\n",
      "十点\n",
      "一两年\n",
      "读点\n",
      "能验\n",
      "茶压\n",
      "遣责\n",
      "总听\n",
      "竟信\n",
      "挺易\n",
      "传其\n",
      "桃梨橙柿\n",
      "金宇车\n",
      "想红\n",
      "微博为\n",
      "辛芷蕾陷\n",
      "乘网\n",
      "脸照\n",
      "剂致\n",
      "唐艺昕互\n",
      "mlcc\n",
      "路肉串\n",
      "毛串\n",
      "安卓网\n",
      "建区\n",
      "瑞世佳典\n",
      "表就会\n",
      "美一城\n",
      "上顿\n",
      "身中\n",
      "终为\n",
      "夺尸\n",
      "闹丧\n",
      "网传湖\n",
      "汤比肉\n",
      "体脂会\n",
      "剧升\n",
      "路虎车\n",
      "途虎卖\n",
      "美宇\n",
      "割头案\n",
      "黄阳司\n",
      "豪德\n",
      "宝胜村\n",
      "人系\n",
      "拒入\n",
      "太清\n",
      "人入\n",
      "筹旧\n",
      "阴滋病\n",
      "带错\n",
      "圈七大\n",
      "造财库\n",
      "半女宝\n",
      "案续\n",
      "津京冀\n",
      "点有\n",
      "这不王\n",
      "因微信\n",
      "摩企\n",
      "纸店\n",
      "沙颍河\n",
      "瓦岗镇\n",
      "剧招\n",
      "注胶门\n",
      "红棕色\n",
      "禁右\n",
      "三色鸽\n",
      "未标\n",
      "李书沸徐\n",
      "三院\n",
      "热转\n",
      "t800\n",
      "亡神\n",
      "领个\n",
      "个值\n",
      "要拉黑\n",
      "只租\n",
      "不售\n",
      "为实\n",
      "转商\n",
      "毒战\n",
      "别为\n",
      "光看\n",
      "制钢\n",
      "暗黄长\n",
      "那血病\n",
      "肾护\n",
      "肾越\n",
      "满暖心\n",
      "积点\n",
      "喜哥\n",
      "恒大有\n",
      "赵丽颖方\n",
      "卖惨\n",
      "赵丽颖用\n",
      "治蛾\n",
      "纪台桥\n",
      "加泰\n",
      "马斯切\n",
      "坠崖\n",
      "之鹰\n",
      "d850\n",
      "蓝帖\n",
      "橙装\n",
      "时健\n",
      "孙安佐案\n",
      "日晨\n",
      "因儿\n",
      "遭撞\n",
      "街要\n",
      "用锅\n",
      "含氯\n",
      "大毒\n",
      "但会致\n",
      "热文\n",
      "别扯\n",
      "吃产\n",
      "汤肴\n",
      "国燕委\n",
      "人微\n",
      "信群\n",
      "发防骗\n",
      "器及\n",
      "那刷\n",
      "锋霸亲\n",
      "一驳\n",
      "组驻\n",
      "后合\n",
      "房查\n",
      "却组\n",
      "美债\n",
      "全仓该\n",
      "亿股\n",
      "人闹\n",
      "对乐视\n",
      "中茂\n",
      "传辉山\n",
      "n年\n",
      "放黑血\n",
      "蹲久\n",
      "眼黑\n",
      "只会令\n",
      "魂十\n",
      "从手\n",
      "搞车\n",
      "战帕奎\n",
      "可吸\n",
      "无根粉\n",
      "茶交所\n",
      "逐梦之音\n",
      "后成\n",
      "七万多\n",
      "最扎心\n",
      "郑爽方\n",
      "传市\n",
      "莫吃\n",
      "治蛾别\n",
      "疯传明\n",
      "撒药治蛾\n",
      "粉梅\n",
      "浙土梅\n",
      "古亭山\n",
      "4w\n",
      "微博送\n",
      "哥为\n",
      "安卓版\n",
      "白鸠川\n",
      "魔刹石\n",
      "放圈\n",
      "推特开\n",
      "赵丽颖变\n",
      "鬼门开\n",
      "大年初三\n",
      "毁剧\n",
      "照系\n",
      "两作媒\n",
      "当阔\n",
      "151023\n",
      "中乙\n",
      "推常旅\n",
      "当演\n",
      "女唱\n",
      "李昂发\n",
      "分有\n",
      "演侯亮\n",
      "演候\n",
      "已换\n",
      "男主陆毅\n",
      "靳东换\n",
      "陆毅版\n",
      "表为\n",
      "不太火\n",
      "造双\n",
      "旗币\n",
      "演大\n",
      "女主选\n",
      "王俊凯担\n",
      "凯靳东\n",
      "剧荒期\n",
      "剧透下\n",
      "维秘秀\n",
      "昆凌请\n",
      "频上\n",
      "姿疑怀\n",
      "爆小\n",
      "演女主\n",
      "女主比\n",
      "更仙\n",
      "曝收\n",
      "拍新\n",
      "农没\n",
      "蒋媛\n",
      "三页\n",
      "张翰开\n",
      "倪秋云家\n",
      "没删\n",
      "健华\n",
      "它险\n",
      "完出\n",
      "解救法\n",
      "为省\n",
      "会出\n",
      "配着\n",
      "同食变\n",
      "混个\n",
      "男一罗志祥\n",
      "之梦\n",
      "加蓝条\n",
      "欠星爷\n",
      "马云组\n",
      "飞常\n",
      "没拍\n",
      "徐峥怒\n",
      "能火\n",
      "没王\n",
      "黄渤王宝\n",
      "徐峥强\n",
      "黄渤铁\n",
      "称其为\n",
      "万救\n",
      "太冤\n",
      "依穿\n",
      "长看\n",
      "命藏\n",
      "黑着\n",
      "神烦\n",
      "姚译\n",
      "胖迪遭\n",
      "不攻\n",
      "驾仅\n",
      "哪七大\n",
      "上大秀\n",
      "遭禁\n",
      "图播\n",
      "好剧\n",
      "拒播\n",
      "称好剧\n",
      "说空\n",
      "天猎\n",
      "180102\n",
      "赔巴清传\n",
      "撕不烂\n",
      "近三年\n",
      "肖奈是\n",
      "微博道\n",
      "但别\n",
      "钓手\n",
      "入水后\n",
      "后鱼\n",
      "肝钓\n",
      "之雨\n",
      "闷鱼\n",
      "放此\n",
      "章奔\n",
      "溃泪\n",
      "日录\n",
      "照无\n",
      "发博破\n",
      "超暖心\n",
      "传吸粉\n",
      "赵丽颖能\n",
      "赵丽颖版\n",
      "日复牌\n",
      "微商教\n",
      "佟丽娅会\n",
      "对耳窃语\n",
      "真渣\n",
      "同天\n",
      "疑入\n",
      "阚清子面\n",
      "网传纪\n",
      "凌尘\n",
      "系维密\n",
      "纪尘凌\n",
      "赞纪\n",
      "疑坐\n",
      "实纪\n",
      "传有\n",
      "纪凌\n",
      "霍汶希为\n",
      "霍汶希生\n",
      "是霆锋\n",
      "三对\n",
      "郑爽配\n",
      "熊梓淇组\n",
      "网议\n",
      "郑爽力\n",
      "杨颖成\n",
      "这三对\n",
      "用史\n",
      "脸术\n",
      "先炸\n",
      "靳东弃\n",
      "查宁阁\n",
      "烙下\n",
      "罗何\n",
      "娘式\n",
      "入榜\n",
      "喷战\n",
      "影史\n",
      "王思聪表\n",
      "中暗\n",
      "不请\n",
      "空有\n",
      "吴京终\n",
      "瓜不甜\n",
      "只任\n",
      "咖来\n",
      "选贵\n",
      "生想\n",
      "已备\n",
      "俩家\n",
      "晏任\n",
      "立止\n",
      "能不传\n",
      "七名\n",
      "财新及\n",
      "怂包\n",
      "虽远\n",
      "必捉\n",
      "图太\n",
      "甘区\n",
      "嫌钱少\n",
      "迅称\n",
      "按灯\n",
      "那英怒\n",
      "艾斯会\n",
      "盼儿\n",
      "会死系\n",
      "竟存\n",
      "图才\n",
      "坑钱\n",
      "为促\n",
      "真裕子\n",
      "玩养\n",
      "调完\n",
      "蛙妈们\n",
      "爸蛙\n",
      "妈莫慌\n",
      "能浪\n",
      "很久很久\n",
      "演若白\n",
      "麗穎迎\n",
      "無盡\n",
      "天燈\n",
      "爆屏\n",
      "之劇\n",
      "之剧\n",
      "郑爽首\n",
      "排石\n",
      "玩滴\n",
      "不博\n",
      "最臭\n",
      "竟演\n",
      "萧策\n",
      "说周\n",
      "萧元启\n",
      "位粉\n",
      "衣美人\n",
      "演元淳\n",
      "开怕\n",
      "淳儿\n",
      "不甜\n",
      "我颖宝\n",
      "男二让\n",
      "五美来\n",
      "曲筱绡\n",
      "姐来\n",
      "不喜\n",
      "宇微\n",
      "博有\n",
      "宇微博\n",
      "正主\n",
      "宇秒\n",
      "创研\n",
      "亲破\n",
      "总导\n",
      "咖已\n",
      "吴亦凡告\n",
      "浙卫输\n",
      "该散\n",
      "批戏\n",
      "遭禁播\n",
      "这坑\n",
      "无数次\n",
      "转签\n",
      "又择\n",
      "还止\n",
      "吴总说\n",
      "咋治才\n",
      "某蛙\n",
      "拟邀\n",
      "女要\n",
      "登爸\n",
      "季力\n",
      "怒冲\n",
      "两千块\n",
      "前摄\n",
      "致敌命\n",
      "鹿晗疑\n",
      "以官\n",
      "祸祸\n",
      "最娘\n",
      "brak\n",
      "剧大热\n",
      "马思纯用\n",
      "站边\n",
      "长狗\n",
      "8x8\n",
      "nb211\n",
      "等系\n",
      "坑苦\n",
      "官博君\n",
      "不充\n",
      "果凝多\n",
      "邓超装\n",
      "邓超接\n",
      "之别\n",
      "大口赞\n",
      "邓超用\n",
      "男主换\n",
      "男主变\n",
      "苏变身\n",
      "赵丽颖组\n",
      "将组\n",
      "胡歌组\n",
      "几版\n",
      "第二位\n",
      "只记\n",
      "尼尼\n",
      "顶好\n",
      "五朝\n",
      "而迪丽\n",
      "巴铁歼\n",
      "醋同\n",
      "他逆袭\n",
      "爱张\n",
      "不相\n",
      "白背\n",
      "白凤九\n",
      "陪妻\n",
      "蓝竟\n",
      "邓超成\n",
      "李晨称\n",
      "接新\n",
      "千算\n",
      "万算\n",
      "没算到\n",
      "一书\n",
      "女主唐\n",
      "网红高仿\n",
      "杀来\n",
      "演聂风\n",
      "部烂剧\n",
      "作配\n",
      "段浪成\n",
      "完狂\n",
      "消保委\n",
      "无一人\n",
      "最误\n",
      "反萨德\n",
      "坠河\n",
      "一案\n",
      "天不换\n",
      "频会\n",
      "辣能\n",
      "更久\n",
      "控盐\n",
      "无门\n",
      "沁人\n",
      "水餐\n",
      "之六\n",
      "转一转\n",
      "乱传\n",
      "昆滇早\n",
      "遭多人\n",
      "现偷\n",
      "网传卖\n",
      "吴梦月\n",
      "大孩带\n",
      "金卉\n",
      "在吾悦\n",
      "二道\n",
      "很值\n",
      "哪用\n",
      "款裸车\n",
      "这一撞\n",
      "吸合门\n",
      "比卡宴\n",
      "2l\n",
      "六座\n",
      "比宋\n",
      "手自\n",
      "ga4\n",
      "现跌\n",
      "红卖\n",
      "含胶\n",
      "鹿迪\n",
      "与己\n",
      "先背\n",
      "肥油\n",
      "肾出\n",
      "穷送\n",
      "胖哥\n",
      "餐速\n",
      "曳步\n",
      "养颜小\n",
      "天法润\n",
      "遭霸凌\n",
      "第二句\n",
      "人东迁\n",
      "真退赛\n",
      "成币安\n",
      "注胶系\n",
      "虾籽\n",
      "日限牌\n",
      "不相谣\n",
      "信遥\n",
      "撞公\n",
      "证均\n",
      "多动儿\n",
      "缠玉烧\n",
      "可办\n",
      "徐州人\n",
      "传勿信\n",
      "动保站\n",
      "网传台\n",
      "十几人\n",
      "系为\n",
      "煤苑\n",
      "别晒\n",
      "信网\n",
      "安卓微信\n",
      "池旁\n",
      "失智\n",
      "眼周\n",
      "能盗\n",
      "多放\n",
      "净烟器\n",
      "淘影\n",
      "借种\n",
      "住楼\n",
      "瓜蛙\n",
      "瞎养\n",
      "佛系养\n",
      "蛙爸\n",
      "鹅子\n",
      "城环\n",
      "挂户\n",
      "收想\n",
      "审是\n",
      "审只\n",
      "验癌\n",
      "建厅\n",
      "省住\n",
      "名女\n",
      "6x2\n",
      "需在\n",
      "称未受\n",
      "液真能\n",
      "哥雷\n",
      "军刺\n",
      "中茶\n",
      "协发\n",
      "予中交\n",
      "药同\n",
      "打谣\n",
      "第十二\n",
      "装茶\n",
      "战痘\n",
      "谣之花\n",
      "数版\n",
      "十二届\n",
      "皮泡\n",
      "油表亮\n",
      "m31\n",
      "请止\n",
      "拦门\n",
      "汁治癌\n",
      "矿震系\n",
      "割脸\n",
      "十二级\n",
      "飞发\n",
      "食到\n",
      "旅发\n",
      "张翰斥\n",
      "六亩\n",
      "名刚\n",
      "网传临\n",
      "盈镇\n",
      "网传坤\n",
      "坠冰\n",
      "养犬\n",
      "处行\n",
      "查明真相\n",
      "外之地\n",
      "我涨\n",
      "购画\n",
      "剩晴\n",
      "张艺兴方\n",
      "返到\n",
      "机蜜\n",
      "为免\n",
      "购气\n",
      "中所传\n",
      "烦伊思\n",
      "限摩\n",
      "禁停\n",
      "阿祖苗药\n",
      "sb5\n",
      "法伴\n",
      "人医\n",
      "太坑\n",
      "因救\n",
      "青荐\n",
      "蟹市\n",
      "多会变\n",
      "迷晕路\n",
      "扎人\n",
      "imeos\n",
      "南和史\n",
      "召村\n",
      "消雨\n",
      "多系\n",
      "李宸\n",
      "路之机\n",
      "城疑\n",
      "化系\n",
      "看雪\n",
      "拐系\n",
      "新氧\n",
      "请友商\n",
      "县任\n",
      "禁燃\n",
      "附警情\n",
      "宝美街\n",
      "闭群\n",
      "信呐\n",
      "塔溪镇\n",
      "甘溪村\n",
      "到湾井\n",
      "楠市子\n",
      "桃坑\n",
      "河王村\n",
      "已行\n",
      "e8l446\n",
      "二广\n",
      "专抢\n",
      "日罚\n",
      "重坊\n",
      "铁北圈\n",
      "鬼楼\n",
      "道州\n",
      "拆县\n",
      "市功\n",
      "马嵬驿\n",
      "互斗为\n",
      "网传大\n",
      "网传学车\n",
      "桥处\n",
      "漂在\n",
      "桥厢\n",
      "杜阮\n",
      "拆改\n",
      "人死系\n",
      "网传洛江\n",
      "两为\n",
      "趁店\n",
      "肾后\n",
      "电死系\n",
      "个系\n",
      "一伤系\n",
      "网传雪\n",
      "姚村北\n",
      "同传\n",
      "一人狂\n",
      "瞎传\n",
      "台现\n",
      "肖皮口\n",
      "龙山庄\n",
      "元系\n",
      "群在\n",
      "宝二爷\n",
      "其免\n",
      "可休\n",
      "内裁\n",
      "号文\n",
      "说裁\n",
      "mx7\n",
      "魅族官\n",
      "微疑\n",
      "note6\n",
      "内用\n",
      "次会\n",
      "蔡甸人\n",
      "癌源\n",
      "微博可\n",
      "新饰代\n",
      "大张\n",
      "小迪当\n",
      "邓超称\n",
      "火成\n",
      "多件\n",
      "杀狂\n",
      "撩迪丽\n",
      "手洗\n",
      "胜比\n",
      "借卓伟名\n",
      "三少\n",
      "脸林\n",
      "某鱼府\n",
      "峡垮方\n",
      "增粉\n",
      "四车\n",
      "区庆远\n",
      "死十伤\n",
      "致五人\n",
      "网红拿刀\n",
      "刀互\n",
      "人亡\n",
      "特协\n",
      "菌六人\n",
      "有六人\n",
      "致六人\n",
      "微博疯\n",
      "五女\n",
      "胎真能\n",
      "传多地\n",
      "十招\n",
      "作女\n",
      "以一\n",
      "敌百\n",
      "群老转\n",
      "锋菲恋现\n",
      "遭谢贤\n",
      "沙蚤\n",
      "同服会\n",
      "同服\n",
      "要慎服\n",
      "豆币\n",
      "巧辨\n",
      "别乱进\n",
      "陈晓要\n",
      "陈晓自\n",
      "曝全\n",
      "人宋\n",
      "家好\n",
      "妻弃\n",
      "万掉\n",
      "为亲\n",
      "陈晓唱\n",
      "精劲\n",
      "80g\n",
      "烟戒\n",
      "咳热\n",
      "咳速\n",
      "小三越\n",
      "如壮\n",
      "不信来\n",
      "法新规\n",
      "三熟\n",
      "论肥宅\n",
      "見影\n",
      "尖作\n",
      "两百斤\n",
      "力挺称\n",
      "昊然俊凯\n",
      "真爱粉\n",
      "刀郎歌\n",
      "喝女\n",
      "瘦腹\n",
      "万闹\n",
      "地为\n",
      "君拍\n",
      "追拍\n",
      "尖是\n",
      "实锤来\n",
      "冤嘛\n",
      "三料\n",
      "却害\n",
      "其是\n",
      "人查\n",
      "因忙\n",
      "拿个\n",
      "会退\n",
      "劈人\n",
      "墙内\n",
      "博阿\n",
      "回欧冠\n",
      "名太硬\n",
      "我必\n",
      "狂拉\n",
      "陈大夫\n",
      "喝活\n",
      "你活\n",
      "老仙\n",
      "三空\n",
      "赢牌\n",
      "变净白\n",
      "消斑\n",
      "不痒\n",
      "奖变\n",
      "高速行驶\n",
      "pd5208\n",
      "杨紫自\n",
      "赵丽颖手\n",
      "得太深\n",
      "腰照\n",
      "搭颖\n",
      "火虫们\n",
      "更引\n",
      "微博暖\n",
      "嘴太快\n",
      "一毛錢\n",
      "需一個\n",
      "間盤\n",
      "症方\n",
      "老中醫\n",
      "試用過\n",
      "挺大孕\n",
      "肚出\n",
      "6t\n",
      "假剧\n",
      "死侍\n",
      "collider\n",
      "还酷\n",
      "堀北\n",
      "真希逛\n",
      "四十口\n",
      "痛别\n",
      "贴条\n",
      "元帮\n",
      "李耀阳\n",
      "黄渤用\n",
      "快来加\n",
      "xy520897\n",
      "获众\n",
      "ttunes\n",
      "t3a\n",
      "活更久\n",
      "斗酒\n",
      "富中\n",
      "之富\n",
      "祛疤\n",
      "频换\n",
      "抱得\n",
      "石锤碎\n",
      "加钱换\n",
      "币成\n",
      "remi\n",
      "quirion\n",
      "雷军微\n",
      "矿商\n",
      "爆痘\n",
      "视它\n",
      "除美白\n",
      "堪比去\n",
      "过万不去\n",
      "格列\n",
      "鸡油\n",
      "已急召\n",
      "索萨当\n",
      "催着\n",
      "肿是\n",
      "枣来\n",
      "吃枣\n",
      "食事\n",
      "药闻\n",
      "第六款\n",
      "雪纺衫\n",
      "克干\n",
      "支小白\n",
      "上治\n",
      "狂购\n",
      "5w\n",
      "卡上\n",
      "王志称\n",
      "嘟拉舞\n",
      "最胖\n",
      "天它\n",
      "易孕\n",
      "个生\n",
      "肉真得\n",
      "吃瓜要\n",
      "谴圈\n",
      "晒化\n",
      "刀早\n",
      "豪车试\n",
      "借眼伤\n",
      "生男神药\n",
      "益生碱\n",
      "佟俪娅\n",
      "驻以\n",
      "首现\n",
      "央改\n",
      "继鸡\n",
      "二三百块\n",
      "广汽等\n",
      "依美多\n",
      "满版\n",
      "籽玉\n",
      "还会变\n",
      "疯传集\n",
      "赞赠\n",
      "哪版\n",
      "争着\n",
      "比钱\n",
      "八百块\n",
      "收个\n",
      "被讽\n",
      "先讽\n",
      "刀郎后\n",
      "听刀郎\n",
      "中骂\n",
      "那英放\n",
      "继刀郎\n",
      "人点\n",
      "视物\n",
      "五十多年\n",
      "醒肤\n",
      "用绝\n",
      "存给\n",
      "高血壓\n",
      "頂過\n",
      "十副藥\n",
      "血壓\n",
      "記得存\n",
      "籽治\n",
      "伤大\n",
      "15336438788\n",
      "暴瘦妙\n",
      "要开\n",
      "样才\n",
      "天止\n",
      "脂溢性\n",
      "辣害\n",
      "要露\n",
      "bei0220147\n",
      "牌才\n",
      "他绝\n",
      "若美朝\n",
      "买锅\n",
      "变糙\n",
      "水检法\n",
      "欧纳德\n",
      "变颜\n",
      "仅学\n",
      "暗哑\n",
      "粗超\n",
      "十买\n",
      "频现\n",
      "因吃鸡\n",
      "必逆市\n",
      "四连板\n",
      "民超\n",
      "弗爵\n",
      "致小七\n",
      "乌顺\n",
      "盐洗\n",
      "似沾墨\n",
      "地去\n",
      "条术\n",
      "兑出\n",
      "穷水\n",
      "90w\n",
      "有枚\n",
      "破康\n",
      "十万多\n",
      "鄂字版\n",
      "因颜值\n",
      "无槽\n",
      "枭龙要\n",
      "调工\n",
      "两央\n",
      "企再\n",
      "三大央企\n",
      "三央企\n",
      "亿多\n",
      "包敷治\n",
      "服吃\n",
      "想害\n",
      "淘游\n",
      "端游\n",
      "开测\n",
      "医破\n",
      "肺小\n",
      "血可\n",
      "如豆\n",
      "杨紫霍\n",
      "切末加\n",
      "十轮\n",
      "菜能\n",
      "移炉\n",
      "山垭口\n",
      "皮别\n",
      "天转\n",
      "年秀\n",
      "熏晕\n",
      "熏艾条\n",
      "还会致\n",
      "比二宝\n",
      "生二宝\n",
      "剖生\n",
      "下大胖\n",
      "比花\n",
      "这棵树\n",
      "能治老\n",
      "粉睡\n",
      "想治\n",
      "时救\n",
      "迅已\n",
      "传周\n",
      "书来\n",
      "送五杀\n",
      "h股\n",
      "谈三\n",
      "遇血后\n",
      "要拉人\n",
      "能拉人入\n",
      "水泊中\n",
      "异星\n",
      "第二张\n",
      "两栋\n",
      "tr3b\n",
      "wellbet\n",
      "克去\n",
      "他治\n",
      "太多毁\n",
      "加他\n",
      "b52\n",
      "瓶酒\n",
      "款酷\n",
      "路泽\n",
      "探界者\n",
      "有面\n",
      "烟钱\n",
      "三厢家\n",
      "弹个\n",
      "如炭\n",
      "增患\n",
      "六王\n",
      "网传领\n",
      "扫微信\n",
      "内桶\n",
      "版人\n",
      "镀晶液\n",
      "镀晶\n",
      "油放\n",
      "中乳协\n",
      "朱正廷\n",
      "拳迷\n",
      "一龙疑\n",
      "怒用\n",
      "为梅\n",
      "康二番\n",
      "猜太过\n",
      "腹高扫\n",
      "電腦族\n",
      "抗輻射\n",
      "應常\n",
      "能刷\n",
      "黑中介\n",
      "毁过\n",
      "那英真\n",
      "助农\n",
      "因涂\n",
      "放味\n",
      "两三个\n",
      "越猛\n",
      "时呼出\n",
      "无锡人\n",
      "曝一常\n",
      "二驴\n",
      "梦于\n",
      "从口入\n",
      "吃防\n",
      "被誉\n",
      "韩红竟\n",
      "不擦\n",
      "保办\n",
      "一冲\n",
      "腌水\n",
      "iveryone\n",
      "起复牌\n",
      "亿英镑\n",
      "网科\n",
      "冲超后\n",
      "吴京战\n",
      "告战\n",
      "喝稀\n",
      "爆向\n",
      "鼓将\n",
      "蒋欣当\n",
      "妻竟\n",
      "可王\n",
      "坑妻\n",
      "带王\n",
      "那句\n",
      "三十多岁\n",
      "我演\n",
      "不轻传\n",
      "发色\n",
      "三到\n",
      "会得癌\n",
      "玩雪会\n",
      "林如海\n",
      "怎可\n",
      "包过费\n",
      "拉象\n",
      "驅寒\n",
      "天補血\n",
      "數月\n",
      "出伤\n",
      "情是\n",
      "重瑞开\n",
      "看迟\n",
      "会爱上\n",
      "萌新\n",
      "使人患\n",
      "发学\n",
      "减交\n",
      "掺纸\n",
      "喝降\n",
      "四高\n",
      "堂饼\n",
      "超话\n",
      "三大主播\n",
      "不皮\n",
      "970w\n",
      "推文\n",
      "盾能\n",
      "今求\n",
      "美卖\n",
      "三出\n",
      "京鲁战\n",
      "推人者\n",
      "四股\n",
      "摔昏\n",
      "推单\n",
      "收米\n",
      "佩莱疯\n",
      "健后\n",
      "绝平后\n",
      "很愁\n",
      "竟人\n",
      "再恶\n",
      "这草\n",
      "天就会\n",
      "乌如墨\n",
      "如黑\n",
      "永难\n",
      "似彦墨\n",
      "固发\n",
      "配他\n",
      "时加个\n",
      "多得\n",
      "似如\n",
      "人不愿信\n",
      "领世\n",
      "安兔\n",
      "分超\n",
      "1000w\n",
      "d800\n",
      "d610\n",
      "d4\n",
      "10nm\n",
      "骗补\n",
      "20000mah\n",
      "电一电\n",
      "省电保\n",
      "m5\n",
      "smrt\n",
      "劲量\n",
      "二十周年\n",
      "55w\n",
      "八强\n",
      "ios11\n",
      "分中\n",
      "谁言膏方\n",
      "病治\n",
      "调脾\n",
      "最给力\n",
      "卫衣码\n",
      "现极\n",
      "液用\n",
      "马云价\n",
      "五十多\n",
      "试完\n",
      "多角恋\n",
      "顺好\n",
      "剖好\n",
      "猫妈来\n",
      "比谢贤\n",
      "黄渤现\n",
      "要查\n",
      "种三高\n",
      "不口\n",
      "不升糖\n",
      "德堂\n",
      "清肝毒\n",
      "特期\n",
      "重拟\n",
      "必十连板\n",
      "仓进\n",
      "获秒\n",
      "全仓必\n",
      "超金隅\n",
      "烯股\n",
      "爆十连板\n",
      "多备\n",
      "之情\n",
      "新审\n",
      "在售\n",
      "一店\n",
      "ix35\n",
      "向志玲\n",
      "情缠\n",
      "和志玲\n",
      "语带\n",
      "壁咚\n",
      "更虐\n",
      "一伴\n",
      "韩媒闹\n",
      "标途观\n",
      "g536\n",
      "山大店\n",
      "市交委\n",
      "可年\n",
      "i6573519737785942531\n",
      "utm\n",
      "1530519470\n",
      "知一孕\n",
      "哭伤\n",
      "东隔空\n",
      "榕未\n",
      "不骑\n",
      "会破\n",
      "深足\n",
      "诺借\n",
      "拆楼\n",
      "卖酒\n",
      "临淇\n",
      "快大一\n",
      "网传红\n",
      "川足\n",
      "个板\n",
      "迎主升浪\n",
      "月首\n",
      "用五至\n",
      "六周\n",
      "现多起\n",
      "闻一闻\n",
      "或现\n",
      "某新盘\n",
      "前滩\n",
      "认筹数\n",
      "需配\n",
      "中车\n",
      "口隆湖\n",
      "栗鹏来\n",
      "川内\n",
      "亿来厦\n",
      "领高达\n",
      "景甜方\n",
      "早资道\n",
      "日才\n",
      "辟清\n",
      "去洛社\n",
      "一万块\n",
      "今过\n",
      "后扮\n",
      "其隔空\n",
      "刀郎会\n",
      "狂赞\n",
      "刀郎称\n",
      "刀郎能\n",
      "刀郎以\n",
      "封歌\n",
      "朱之文拉着\n",
      "刀郎醉\n",
      "终浮\n",
      "那英该\n",
      "十几条\n",
      "欠刀郎\n",
      "第三张\n",
      "点刀郎歌\n",
      "那英刀\n",
      "那英力\n",
      "获过\n",
      "过刀郎\n",
      "其圈\n",
      "马云宋\n",
      "不欠\n",
      "那英称\n",
      "微博仅关\n",
      "歌用\n",
      "那英输\n",
      "群传\n",
      "十路\n",
      "死系\n",
      "真能作\n",
      "该起\n",
      "抛河\n",
      "坠河致\n",
      "取光后\n",
      "要记\n",
      "进岛\n",
      "听烦\n",
      "称武黄\n",
      "外讯\n",
      "讀讀\n",
      "語無倫次\n",
      "楊瀾\n",
      "脫語\n",
      "花點\n",
      "時間\n",
      "從此\n",
      "認真\n",
      "饒舌\n",
      "認真讀\n",
      "本好\n",
      "補貼\n",
      "金額\n",
      "對象\n",
      "發生\n",
      "變化\n",
      "爆降\n",
      "粮补到\n",
      "别坑\n",
      "端上来\n",
      "德制\n",
      "拖成\n",
      "肝区\n",
      "启停\n",
      "撕景甜\n",
      "太多锅\n",
      "七倍\n",
      "泰迪犬\n",
      "达人秀\n",
      "病能\n",
      "宝现\n",
      "样丑\n",
      "提汉兰达\n",
      "车太轻\n",
      "445km\n",
      "小途锐\n",
      "想不火\n",
      "嘴治\n",
      "晚天排\n",
      "渴是\n",
      "六百年\n",
      "一活\n",
      "竟大有\n",
      "f35b\n",
      "现己\n",
      "这下林\n",
      "狂妃\n",
      "光吃\n",
      "瘦越\n",
      "五十斤\n",
      "以瘦\n",
      "奢姿\n",
      "自做\n",
      "胸大胸\n",
      "奶多\n",
      "奶少\n",
      "食药署\n",
      "易消化\n",
      "而备\n",
      "多任\n",
      "曝唐\n",
      "同能\n",
      "真得会\n",
      "一瘦\n",
      "6000w\n",
      "令权健\n",
      "真想用\n",
      "迪奥拉\n",
      "老白为\n",
      "阿媒\n",
      "比鸡强\n",
      "二十元\n",
      "看值\n",
      "已办\n",
      "f1\n",
      "二队\n",
      "我图\n",
      "放超\n",
      "因给\n",
      "aos\n",
      "当吃瓜\n",
      "十几分\n",
      "缺笑\n",
      "嫂以\n",
      "朱之文想\n",
      "喝高\n",
      "绿大一\n",
      "博要\n",
      "朱之文称\n",
      "打报\n",
      "几百万倍\n",
      "后付\n",
      "抢瓜\n",
      "内禁\n",
      "人管\n",
      "一喷锅\n",
      "得卓伟\n",
      "拉群\n",
      "二分之一\n",
      "证再\n",
      "证请\n",
      "匹林\n",
      "外洗\n",
      "加梨煮\n",
      "烧到\n",
      "汗出\n",
      "速退\n",
      "一用立\n",
      "买台\n",
      "开年量\n",
      "版顶\n",
      "配高达\n",
      "十组\n",
      "天以\n",
      "发恼\n",
      "排净宿\n",
      "别水\n",
      "q10\n",
      "比生\n",
      "吸净\n",
      "禁外\n",
      "二脉\n",
      "越薄越\n",
      "cp3\n",
      "湖人组\n",
      "皇椒\n",
      "因球\n",
      "詹皇下家\n",
      "天第\n",
      "差不爱\n",
      "购俄\n",
      "t90sm\n",
      "货用\n",
      "人齐\n",
      "锅具\n",
      "脏难\n",
      "化眼妆\n",
      "360n\n",
      "成小妈\n",
      "爆三字\n",
      "现李晨\n",
      "韩红发\n",
      "送服\n",
      "多易\n",
      "皱市\n",
      "二俩\n",
      "出长\n",
      "邓紫\n",
      "收云字\n",
      "照才\n",
      "拆不散\n",
      "而炸\n",
      "锋力\n",
      "误捐\n",
      "万不给\n",
      "粉美白\n",
      "堪比帝\n",
      "墓主带\n",
      "面帛\n",
      "人尊\n",
      "效如\n",
      "遮三丑\n",
      "这五白\n",
      "喝养\n",
      "毒养\n",
      "臭粑\n",
      "眼别\n",
      "九镇\n",
      "跳增\n",
      "九月底\n",
      "第一艘\n",
      "b型\n",
      "别想生\n",
      "想怀\n",
      "明宝庆\n",
      "成蒙宁\n",
      "甘陕\n",
      "沙蒿\n",
      "网传权\n",
      "媒官\n",
      "博在\n",
      "推特上\n",
      "一阳\n",
      "金蜘蛛\n",
      "虽属\n",
      "郫筒区\n",
      "似人似\n",
      "昨办\n",
      "未修图\n",
      "诗传\n",
      "诗大\n",
      "诗图\n",
      "合开\n",
      "称当\n",
      "演吻\n",
      "诗疑\n",
      "拍太有\n",
      "诗终\n",
      "舒过\n",
      "惊住\n",
      "诗近\n",
      "遮孕肚\n",
      "小隆包\n",
      "诗当\n",
      "两人素\n",
      "诗孕\n",
      "诗面露\n",
      "诗回\n",
      "诗素颜\n",
      "披大\n",
      "赵丽颖后\n",
      "奇隆\n",
      "诗用\n",
      "诗得\n",
      "黑国足\n",
      "多亩\n",
      "最淡\n",
      "巨猫\n",
      "种油加\n",
      "油加\n",
      "腰细体\n",
      "得偿\n",
      "头不大\n",
      "而强\n",
      "胶济\n",
      "還記\n",
      "兩歲\n",
      "再假\n",
      "狗活\n",
      "石咀子\n",
      "同框录\n",
      "萌自\n",
      "因真爱\n",
      "缺爱\n",
      "爆将\n",
      "张杰助\n",
      "博表\n",
      "冯柯气\n",
      "冯珂气\n",
      "这受\n",
      "两人越\n",
      "美手照\n",
      "不肉\n",
      "狂销\n",
      "賽人\n",
      "西亞\n",
      "偏遠\n",
      "小島\n",
      "爆因\n",
      "咱有\n",
      "鲁能泰山\n",
      "之口\n",
      "掠地\n",
      "天看\n",
      "天是\n",
      "没往\n",
      "这想\n",
      "已写\n",
      "内马尔球\n",
      "十秒\n",
      "前内斗\n",
      "广佛要\n",
      "大跳桥\n",
      "金玩出\n",
      "七级\n",
      "摊手\n",
      "有山\n",
      "返中超\n",
      "夸雷\n",
      "买斯\n",
      "战中超\n",
      "冬窗\n",
      "报要\n",
      "传么\n",
      "点能\n",
      "首創\n",
      "車問\n",
      "車將\n",
      "喝个\n",
      "不烧\n",
      "第十三\n",
      "切信\n",
      "人游\n",
      "传婚\n",
      "郑祺吐槽\n",
      "老罗停\n",
      "handshaker\n",
      "出低\n",
      "最蠢\n",
      "三波\n",
      "版雷军\n",
      "出骁龙版\n",
      "称陆奇\n",
      "s1\n",
      "无降\n",
      "6c\n",
      "六耳\n",
      "老铁卖\n",
      "可真难\n",
      "夹碎\n",
      "要娜\n",
      "改吃\n",
      "萌兽\n",
      "埋雪中\n",
      "奇香楼\n",
      "东体\n",
      "遭三停\n",
      "规土委对\n",
      "经信局\n",
      "仍会\n",
      "三体\n",
      "不实别\n",
      "太酸\n",
      "必肥\n",
      "招月\n",
      "蚁侠\n",
      "喝大\n",
      "或仅\n",
      "周新批\n",
      "两暖心\n",
      "换乐福加\n",
      "天香\n",
      "vit17\n",
      "极悍\n",
      "不输路\n",
      "比路\n",
      "堪比悍\n",
      "不凉\n",
      "兑着\n",
      "夜能\n",
      "贩偷\n",
      "绕颈要\n",
      "禁入\n",
      "隐离\n",
      "品消\n",
      "泡脚土\n",
      "扒门\n",
      "达头\n",
      "爱播\n",
      "真源市\n",
      "网传女\n",
      "停气\n",
      "当辅警\n",
      "no49\n",
      "沈辽路\n",
      "乐偷\n",
      "名偷\n",
      "托关系\n",
      "帝景\n",
      "网传俩\n",
      "一个三岁\n",
      "曲业东\n",
      "h3n8\n",
      "五驴\n",
      "我画\n",
      "966669\n",
      "因网购\n",
      "g7\n",
      "缺战\n",
      "和维金\n",
      "问过\n",
      "飞防\n",
      "市林\n",
      "检局\n",
      "册系\n",
      "办新\n",
      "版白大\n",
      "不硬\n",
      "疯传后\n",
      "国乒退赛\n",
      "获佳女\n",
      "一伙\n",
      "防指\n",
      "电排\n",
      "称镇\n",
      "挖致\n",
      "腹疼\n",
      "三死\n",
      "四伤\n",
      "第十七期\n",
      "携武内\n",
      "急归力\n",
      "gta5\n",
      "整座\n",
      "人蠢\n",
      "穿髓\n",
      "肥事\n",
      "十份\n",
      "2016beyond\n",
      "线似\n",
      "个局\n",
      "还交\n",
      "称个\n",
      "抛家\n",
      "力挺破\n",
      "60fps\n",
      "xiao8\n",
      "ti7\n",
      "切假\n",
      "曝中甲\n",
      "推售\n",
      "几百名\n",
      "520li\n",
      "爆罗志祥豪\n",
      "我爱得\n",
      "叫妈\n",
      "几十艘\n",
      "未停\n",
      "传徕\n",
      "养颜美白\n",
      "石国鹏\n",
      "热毒型\n",
      "人肉治\n",
      "席炎麟\n",
      "糖生\n",
      "戒燥\n",
      "戒怒\n",
      "燃脂水\n",
      "能藏\n",
      "百搭大码\n",
      "小作动\n",
      "黑臭宿\n",
      "忍声\n",
      "吞气\n",
      "房菊尼\n",
      "实胖\n",
      "没天\n",
      "瘦肚腹\n",
      "這四種\n",
      "醒來\n",
      "jama\n",
      "毒源\n",
      "老药\n",
      "新用疗\n",
      "四管\n",
      "油清\n",
      "称炸\n",
      "快拿瓣\n",
      "卖油\n",
      "带点\n",
      "纹淡\n",
      "解油\n",
      "不遭\n",
      "难戒\n",
      "五运六气\n",
      "路虎塔塔\n",
      "evision\n",
      "比饿\n",
      "支妙\n",
      "合费\n",
      "要会用\n",
      "湿减\n",
      "皂苷能\n",
      "蒜片\n",
      "一爆\n",
      "口干苦\n",
      "没犯\n",
      "魔衣\n",
      "十余年\n",
      "补阳強\n",
      "成男神\n",
      "袁篇\n",
      "发版别\n",
      "卅二\n",
      "精发版别\n",
      "入旗\n",
      "写过\n",
      "湘字\n",
      "十族\n",
      "马云问\n",
      "外体\n",
      "赫欲\n",
      "驻美前\n",
      "难装\n",
      "开毫车\n",
      "队全\n",
      "皇贝\n",
      "中國七大壽星\n",
      "還有\n",
      "聞名\n",
      "真成国\n",
      "昭熙\n",
      "比张\n",
      "这汤\n",
      "我传\n",
      "人颜值\n",
      "区到\n",
      "亿枚\n",
      "附币商\n",
      "不持\n",
      "七百年\n",
      "3glasses\n",
      "造不\n",
      "舰则\n",
      "养颜不显\n",
      "更养颜\n",
      "补满\n",
      "常吃安\n",
      "好显\n",
      "养颜排\n",
      "既养颜\n",
      "养颜助\n",
      "三女\n",
      "一食\n",
      "常吃助眠\n",
      "看长\n",
      "越美有\n",
      "美家\n",
      "人微博\n",
      "恐不敌\n",
      "吴京必\n",
      "铝价\n",
      "抵不上\n",
      "癌痛\n",
      "这型\n",
      "十几艘\n",
      "若敢\n",
      "几艘\n",
      "几车\n",
      "标着\n",
      "霸要\n",
      "多亿美元\n",
      "十一座\n",
      "射针\n",
      "为国点\n",
      "领全\n",
      "可白\n",
      "种不出\n",
      "咖开\n",
      "游梅城\n",
      "为荣\n",
      "人不嫁\n",
      "能别\n",
      "萌呆\n",
      "漂拳\n",
      "未捐\n",
      "送油\n",
      "赵蕊蕊终\n",
      "川皇\n",
      "有胆\n",
      "污染环境\n",
      "君给\n",
      "表都\n",
      "全中超\n",
      "外媒争\n",
      "停搏\n",
      "维中超\n",
      "阿媒爆\n",
      "亿追\n",
      "汇回\n",
      "3c\n",
      "某媒称\n",
      "越真\n",
      "赫要\n",
      "退队\n",
      "传多\n",
      "四强\n",
      "好盘\n",
      "再划\n",
      "生科\n",
      "背大\n",
      "sofm\n",
      "摔晕\n",
      "爆怒\n",
      "大背\n",
      "摔加\n",
      "被系\n",
      "另一家\n",
      "俄制\n",
      "30sm\n",
      "折天记\n",
      "背钱\n",
      "红嫩\n",
      "杨炳莲\n",
      "没干过\n",
      "百朋\n",
      "流山\n",
      "名松\n",
      "假树\n",
      "这棵\n",
      "数千公里\n",
      "vt4\n",
      "性强\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "遭开\n",
      "雷军排\n",
      "最尾\n",
      "难一见\n",
      "上极\n",
      "鬼村\n",
      "未炸\n",
      "造歼\n",
      "逼美\n",
      "微博太\n",
      "搜是\n",
      "加身\n",
      "吴雨珏\n",
      "将播\n",
      "阿乌巴\n",
      "后谈\n",
      "成吐槽\n",
      "涨粉\n",
      "发快\n",
      "名印\n",
      "常林回\n",
      "半年前\n",
      "人散\n",
      "现售\n",
      "掌厅\n",
      "f117\n",
      "烟渍\n",
      "越中\n",
      "种人领\n",
      "终遇\n",
      "沈万三\n",
      "遭泼油\n",
      "李秋平外\n",
      "电地\n",
      "和晶\n",
      "豪斥\n",
      "稳抓\n",
      "信反信\n",
      "亿小散\n",
      "城洞\n",
      "大暴击\n",
      "无数个\n",
      "马云放\n",
      "俞凌雄点\n",
      "人年入\n",
      "超坚瑞沃\n",
      "超赣锋\n",
      "诚迈\n",
      "士兰\n",
      "微封\n",
      "博聞社\n",
      "離境\n",
      "萬達\n",
      "崩盤\n",
      "求大\n",
      "库鸟\n",
      "读品\n",
      "游一游\n",
      "小师弟\n",
      "被免\n",
      "一逆天\n",
      "巨坑\n",
      "子之父\n",
      "恰尔汗\n",
      "代差\n",
      "航发\n",
      "无梦到\n",
      "莱口\n",
      "觉太\n",
      "觉浅\n",
      "睡不著\n",
      "不夜\n",
      "无梦\n",
      "巨魔成\n",
      "出蓝贴\n",
      "极寒来\n",
      "起转\n",
      "startfragment\n",
      "有雨\n",
      "迎特\n",
      "中抱\n",
      "旧图\n",
      "今明\n",
      "虽多\n",
      "天气晴好\n",
      "天别\n",
      "2018121\n",
      "十座\n",
      "狂整\n",
      "几腿\n",
      "惊掉\n",
      "而现\n",
      "示软求\n",
      "过胎\n",
      "亮哥心\n",
      "第三步\n",
      "第一盏\n",
      "王思聪卓伟\n",
      "爱嘻哈\n",
      "七张\n",
      "新瓜\n",
      "清力\n",
      "探班求\n",
      "发正\n",
      "涉入\n",
      "长小\n",
      "马蓉微\n",
      "卓尔写\n",
      "整幢\n",
      "满帮\n",
      "医三人\n",
      "靠种\n",
      "有钱赚\n",
      "一百多亩\n",
      "稻蟹\n",
      "人不告\n",
      "糙发\n",
      "膏来\n",
      "艾尚彩\n",
      "出一\n",
      "食必思\n",
      "黄焖\n",
      "陷商票\n",
      "说学\n",
      "多梦太熬\n",
      "假觉\n",
      "韩美军\n",
      "乘热\n",
      "放太多\n",
      "购内少\n",
      "蜜友\n",
      "苏索辟\n",
      "权健亚冠\n",
      "恒大真\n",
      "核闹\n",
      "扎哈维转\n",
      "权健换帅\n",
      "权健要\n",
      "抢人换\n",
      "成索萨\n",
      "两支\n",
      "李霄鹏任\n",
      "刀别\n",
      "而动\n",
      "一土帅\n",
      "中超队\n",
      "阿隆来\n",
      "有鲁能\n",
      "谈换帅\n",
      "中超近\n",
      "李总任\n",
      "换帅系\n",
      "还应\n",
      "托大\n",
      "学恒大\n",
      "奖真\n",
      "只升\n",
      "上港成\n",
      "贺惯\n",
      "赢上\n",
      "纳英戈兰\n",
      "成中超\n",
      "恒大要\n",
      "当枪\n",
      "杜煜征\n",
      "津媒欲\n",
      "被鲁能\n",
      "遭截\n",
      "卖药\n",
      "一擦灵\n",
      "赶离\n",
      "口人\n",
      "宝斗石\n",
      "终取\n",
      "赵蕊蕊\n",
      "scoal\n",
      "星人怕\n",
      "临冠路\n",
      "宋集坞\n",
      "estarpro\n",
      "四连号\n",
      "防拐\n",
      "会吸\n",
      "板放\n",
      "御锦湾\n",
      "等校\n",
      "指不收\n",
      "害娃\n",
      "相不中\n",
      "遭喷\n",
      "小三假\n",
      "终出\n",
      "出道史\n",
      "赵楚纶\n",
      "小三后\n",
      "如一人\n",
      "这小三当\n",
      "超美腻\n",
      "小三史\n",
      "官博已\n",
      "热聊引\n",
      "发羊癫\n",
      "前先\n",
      "接甜馨\n",
      "十二岁\n",
      "生咬蛇\n",
      "宝妈别\n",
      "喜茶\n",
      "人假\n",
      "论耍\n",
      "带人到\n",
      "竟送\n",
      "引骂战\n",
      "剩油\n",
      "染绿\n",
      "甩马蓉\n",
      "几十条\n",
      "虾肠\n",
      "卡补审\n",
      "胖疑\n",
      "马云送\n",
      "恒大欲\n",
      "孙莉生\n",
      "三朵\n",
      "排期\n",
      "粉粹\n",
      "机来\n",
      "黄磊首\n",
      "铁卫吉尔\n",
      "jdg\n",
      "用纳尔\n",
      "骚男道\n",
      "往鲁能\n",
      "针多针\n",
      "遭洪爷\n",
      "日停\n",
      "我大\n",
      "鱼籽\n",
      "非小\n",
      "用曲\n",
      "美替\n",
      "非尼\n",
      "恒大刚\n",
      "恒大真核\n",
      "人常去\n",
      "为北飞\n",
      "曝向\n",
      "减购\n",
      "为成\n",
      "惨触\n",
      "音当\n",
      "网红竟\n",
      "录抖音\n",
      "身疾\n",
      "男说\n",
      "身残\n",
      "亿全\n",
      "摸象\n",
      "肃毒局\n",
      "没人教\n",
      "终盼来\n",
      "简安桀\n",
      "十余\n",
      "信错\n",
      "竟害\n",
      "却赖\n",
      "辽足求\n",
      "多人持\n",
      "屍體\n",
      "嘗到\n",
      "自動\n",
      "久升\n",
      "一东\n",
      "几单\n",
      "飙泪答\n",
      "殷桃要\n",
      "厅市\n",
      "泡会\n",
      "tinashe\n",
      "伤过\n",
      "书心\n",
      "巧破\n",
      "雪姨豪\n",
      "嘴型\n",
      "腾程\n",
      "千百年\n",
      "赚出\n",
      "补错\n",
      "桥头绿化\n",
      "带旁\n",
      "推遭\n",
      "链家\n",
      "150825\n",
      "好丽友\n",
      "抗华\n",
      "退华\n",
      "盒马\n",
      "鲜生\n",
      "绿心\n",
      "其遭\n",
      "洪臣\n",
      "天无\n",
      "文钱渡\n",
      "六车\n",
      "胆码助\n",
      "破残\n",
      "说乐视\n",
      "伊思诺\n",
      "网传亚冠及\n",
      "微评\n",
      "142625\n",
      "爆乐视\n",
      "传卖\n",
      "微博致\n",
      "乐视酷\n",
      "救乐视\n",
      "向乐视\n",
      "买乐视\n",
      "视要\n",
      "致百人\n",
      "一达\n",
      "那卖\n",
      "郎咸平\n",
      "每台\n",
      "飞凡\n",
      "传乐视\n",
      "顾颖琼发\n",
      "曝贾跃亭\n",
      "乐视员\n",
      "张继科生\n",
      "无球\n",
      "王丽坤恋\n",
      "比娜\n",
      "爱宝强\n",
      "蒋欣自\n",
      "脸用\n",
      "这四宝\n",
      "显老像\n",
      "变年经\n",
      "要分\n",
      "位大\n",
      "咖级视\n",
      "袁立互\n",
      "曝火\n",
      "器是\n",
      "复播成\n",
      "宋章\n",
      "微博均\n",
      "袁立勇\n",
      "真闹\n",
      "长水\n",
      "骗得\n",
      "关育兵\n",
      "佳乐家\n",
      "信办\n",
      "深晚\n",
      "天不腐\n",
      "霍林河\n",
      "退改\n",
      "需强\n",
      "种错\n",
      "对富\n",
      "过此\n",
      "黑入\n",
      "万必火\n",
      "多真\n",
      "大迈\n",
      "比途\n",
      "昂大\n",
      "gl8\n",
      "乱选\n",
      "雄安人\n",
      "两层\n",
      "时飘窗\n",
      "完飘窗\n",
      "买母\n",
      "皮薄肉\n",
      "招辨\n",
      "薄肉\n",
      "熟母\n",
      "母梨比\n",
      "公梨\n",
      "母梨\n",
      "比母\n",
      "保熟\n",
      "娃教\n",
      "一个包\n",
      "微博手\n",
      "遭痛\n",
      "来产奶\n",
      "高钙\n",
      "第一期\n",
      "授破谣\n",
      "狂发\n",
      "喃们\n",
      "喃再\n",
      "曝付\n",
      "成红人\n",
      "尼美舒\n",
      "系是\n",
      "美团涉\n",
      "毒如\n",
      "相刻\n",
      "油是\n",
      "度仅\n",
      "死舅\n",
      "人油\n",
      "一个团\n",
      "钟极\n",
      "餐员竟\n",
      "遇黑\n",
      "租到\n",
      "房太难\n",
      "线全\n",
      "汪小菲护妻\n",
      "破腹\n",
      "时宝妈\n",
      "接必\n",
      "驾时\n",
      "转顺\n",
      "信酸儿\n",
      "卢神帅\n",
      "詹皇累\n",
      "养颜是\n",
      "我非\n",
      "屡陷\n",
      "多丑\n",
      "因取\n",
      "伊相杰\n",
      "朱之文该\n",
      "哭边\n",
      "唱绝\n",
      "为于\n",
      "泪干肠断\n",
      "衣哥\n",
      "朱之文付\n",
      "雨下\n",
      "教朱\n",
      "之文于\n",
      "最亲\n",
      "遭辅警\n",
      "龙舌坡\n",
      "登镇\n",
      "东峡克麻\n",
      "烟店\n",
      "河超警\n",
      "漫堤\n",
      "阻后\n",
      "微为\n",
      "网帖\n",
      "网传东\n",
      "中良\n",
      "人案\n",
      "省医\n",
      "神碰瓷\n",
      "仍不信\n",
      "浓溪\n",
      "赊烟\n",
      "融冻泥\n",
      "微博微\n",
      "驾致\n",
      "称系毒\n",
      "抢车\n",
      "不扎\n",
      "夺底\n",
      "经鉴\n",
      "莫信谣\n",
      "谢弃\n",
      "演之恩\n",
      "主弃\n",
      "大获\n",
      "杨紫竟\n",
      "接之恩\n",
      "唱火\n",
      "以表\n",
      "王丹婷\n",
      "马曼玲\n",
      "处加\n",
      "三高管\n",
      "高管涉\n",
      "潘绫莹\n",
      "摄屏\n",
      "摄手\n",
      "石猪\n",
      "某牙\n",
      "台主播\n",
      "鸡主播\n",
      "抽个\n",
      "超管\n",
      "德云色家\n",
      "七是\n",
      "挺哥\n",
      "小洲\n",
      "鸡用\n",
      "主播界\n",
      "妹晒\n",
      "临查\n",
      "必普\n",
      "汤爹\n",
      "狼堡\n",
      "市后\n",
      "脸马蓉\n",
      "传新\n",
      "瓜可防\n",
      "阿信力\n",
      "仍蒸\n",
      "dota2\n",
      "很逆天\n",
      "专吃生\n",
      "快替\n",
      "连面\n",
      "几捆\n",
      "仍点\n",
      "赞井柏然\n",
      "恐要\n",
      "天好\n",
      "法加尼\n",
      "gcmfx\n",
      "险致\n",
      "肯巴\n",
      "类加分\n",
      "湖天\n",
      "车内放\n",
      "十多辆\n",
      "可避\n",
      "狗尿伤\n",
      "摘些\n",
      "加二物\n",
      "发尾\n",
      "日蓝牌\n",
      "市城\n",
      "许鄢\n",
      "七家\n",
      "短够\n",
      "遭贴\n",
      "后编\n",
      "马蓉来\n",
      "拿卡会\n",
      "会算酒\n",
      "地查\n",
      "使油\n",
      "分将成\n",
      "卖分\n",
      "已至\n",
      "主们\n",
      "还会查\n",
      "此属\n",
      "师站\n",
      "说脏\n",
      "前奶\n",
      "太稀\n",
      "虎牌\n",
      "突持\n",
      "指马云\n",
      "共抗\n",
      "七点\n",
      "远输天\n",
      "缺芯\n",
      "再斥\n",
      "减担\n",
      "内拿钱\n",
      "魂恐\n",
      "天受\n",
      "排肠治\n",
      "付永来\n",
      "指创\n",
      "元降\n",
      "城报\n",
      "拍科\n",
      "窗溪村\n",
      "封杀令\n",
      "多番\n",
      "振文\n",
      "系以\n",
      "被取\n",
      "猪脸\n",
      "来蓉放\n",
      "无所依\n",
      "拉姑带\n",
      "纪凌尘会\n",
      "用回\n",
      "笑炸\n",
      "问想\n",
      "减脂养\n",
      "颜治\n",
      "射着\n",
      "音上\n",
      "系有\n",
      "一微信\n",
      "致车\n",
      "鼾穴\n",
      "毒积滞\n",
      "膏能\n",
      "十羊九不全\n",
      "某自\n",
      "破虏\n",
      "将会重\n",
      "做系\n",
      "昆们\n",
      "别刷\n",
      "养发液\n",
      "清晒照\n",
      "假海\n",
      "手有\n",
      "有财\n",
      "上存\n",
      "无迎机\n",
      "连号值\n",
      "有见\n",
      "段友们\n",
      "拟发\n",
      "69189\n",
      "现报\n",
      "66616\n",
      "66108\n",
      "稳于\n",
      "差约\n",
      "限汇\n",
      "欧购\n",
      "人名币\n",
      "要往\n",
      "老演\n",
      "赵丽颖生\n",
      "太萌\n",
      "要顺\n",
      "破腹产\n",
      "点赞点\n",
      "段生\n",
      "萧敬明\n",
      "抓原\n",
      "两人飙\n",
      "不冻\n",
      "食在\n",
      "无冰\n",
      "徐梦洁\n",
      "没虐\n",
      "爱猫\n",
      "700bike\n",
      "吴亦凡录\n",
      "逼封\n",
      "瑞圣尔\n",
      "原森态\n",
      "拍楚\n",
      "数都数\n",
      "外油\n",
      "健言\n",
      "注糖\n",
      "有胶\n",
      "体脂\n",
      "吴京靠\n",
      "戏为\n",
      "以爱之名\n",
      "喝茵\n",
      "栀黄\n",
      "招补\n",
      "破其\n",
      "没钱花\n",
      "福之人\n",
      "常吃些\n",
      "脸疼\n",
      "用刀郎\n",
      "再累\n",
      "喊要\n",
      "多疼\n",
      "但萌\n",
      "一美人\n",
      "祛烦\n",
      "血药\n",
      "眼销\n",
      "这靠\n",
      "思创\n",
      "沏杯\n",
      "业需\n",
      "大乔新\n",
      "乳协\n",
      "系属\n",
      "儿慈会\n",
      "大脸\n",
      "赵丽颖帅\n",
      "非因\n",
      "宋喆开\n",
      "走车\n",
      "非酒\n",
      "团上\n",
      "壹号\n",
      "美帝\n",
      "乱编\n",
      "卢本伟系\n",
      "变人\n",
      "合推\n",
      "快开\n",
      "嗅网\n",
      "老铁教\n",
      "邱茂庭\n",
      "戏是\n",
      "点满\n",
      "仍待解\n",
      "冼钱\n",
      "野鱼\n",
      "多鱼\n",
      "提竿\n",
      "人全\n",
      "数十亿美元\n",
      "网传兰\n",
      "传洪秀柱\n",
      "交棒\n",
      "竟越\n",
      "涨越\n",
      "澳交所\n",
      "涨多高\n",
      "祥明\n",
      "开州\n",
      "新糖\n",
      "开榨\n",
      "君为\n",
      "立炖\n",
      "即炖\n",
      "现炖\n",
      "不发此\n",
      "甲状\n",
      "劳腺\n",
      "球爹\n",
      "拒湖\n",
      "天里\n",
      "连喊\n",
      "三句\n",
      "地好\n",
      "能存\n",
      "马云替\n",
      "拆系\n",
      "仅店\n",
      "美漫\n",
      "帝葛军\n",
      "脚烂\n",
      "巧得\n",
      "越痒\n",
      "还治好\n",
      "不审\n",
      "前塌\n",
      "改后\n",
      "婶来\n",
      "纷至\n",
      "晨讯\n",
      "职技\n",
      "鲁尼为\n",
      "航获\n",
      "争纳\n",
      "曝权健\n",
      "松和纳\n",
      "齐耶赫\n",
      "世体\n",
      "签布\n",
      "苏媒\n",
      "稳留\n",
      "编们\n",
      "孔卡埃\n",
      "神必\n",
      "留权健\n",
      "空欢喜\n",
      "因登贝莱\n",
      "170510\n",
      "凯源\n",
      "库蒂\n",
      "其戏\n",
      "案要\n",
      "车连撞\n",
      "上发\n",
      "今创\n",
      "引热传\n",
      "脸大脸\n",
      "万不敌\n",
      "起交强\n",
      "竟惊现\n",
      "贬刀郎\n",
      "日首\n",
      "无酒\n",
      "李晨受\n",
      "曝自降\n",
      "吴亦凡娜\n",
      "特送\n",
      "咋们\n",
      "这一闹\n",
      "宝妈手\n",
      "专宰\n",
      "造点\n",
      "马兹不离\n",
      "这待\n",
      "基黄\n",
      "最假\n",
      "天高\n",
      "幂尬\n",
      "比伯愿\n",
      "为赛\n",
      "村往\n",
      "大乔梅\n",
      "岁系\n",
      "睡成\n",
      "诗自\n",
      "拍力\n",
      "美妆\n",
      "种不贵\n",
      "紫塞网\n",
      "蒙域\n",
      "发变\n",
      "人未到\n",
      "个加\n",
      "另人\n",
      "姜农教\n",
      "可别染\n",
      "只须\n",
      "随鲜\n",
      "刚下映\n",
      "底现\n",
      "百平方米\n",
      "害长\n",
      "别害\n",
      "那英为\n",
      "看尽\n",
      "金鸿鸣家\n",
      "集油盒\n",
      "因恨\n",
      "小河边\n",
      "寻祖\n",
      "照破\n",
      "扣致\n",
      "曝周琦前\n",
      "枪下\n",
      "恩闪婚\n",
      "祝你们\n",
      "180308\n",
      "谦友\n",
      "七八次\n",
      "胡快\n",
      "拜仁苦\n",
      "吴威子\n",
      "8s\n",
      "互斯\n",
      "猎车\n",
      "第二十九\n",
      "毒赛\n",
      "闫来\n",
      "比金贵\n",
      "新诺\n",
      "基立福\n",
      "今靠\n",
      "族名\n",
      "掌族\n",
      "海明路\n",
      "版黛玉\n",
      "后岁\n",
      "黑块\n",
      "真惨\n",
      "几百几千\n",
      "六块钱\n",
      "批小\n",
      "第一刀\n",
      "造库\n",
      "官翻\n",
      "哪出\n",
      "美可卓\n",
      "看众\n",
      "揭任静\n",
      "阪依\n",
      "传陆奇\n",
      "自媒\n",
      "cmo\n",
      "金特会\n",
      "竟引\n",
      "元跌\n",
      "称均\n",
      "微博门\n",
      "朱日\n",
      "马蓉道\n",
      "马蓉见\n",
      "博竟\n",
      "马蓉住\n",
      "赞王\n",
      "导快\n",
      "毁房\n",
      "naati\n",
      "萌犬\n",
      "成精会\n",
      "还会用\n",
      "这狗成\n",
      "这狗要\n",
      "蜗人皮\n",
      "巨肚\n",
      "纽卡\n",
      "脸众\n",
      "准新援\n",
      "铁腰\n",
      "澳超\n",
      "外媒劲\n",
      "诈伤\n",
      "官宣沙\n",
      "奇里\n",
      "万英镑\n",
      "皇社\n",
      "西媒称\n",
      "内少\n",
      "建队\n",
      "看西\n",
      "微联\n",
      "拟起\n",
      "yoox\n",
      "曝贝利\n",
      "小聋\n",
      "出素\n",
      "颜照力\n",
      "扮嫩\n",
      "自破\n",
      "陈晓晒\n",
      "甜照\n",
      "论唱\n",
      "衰美团\n",
      "果小美以\n",
      "王兴称\n",
      "木鸟\n",
      "不遠\n",
      "學家\n",
      "滅亡\n",
      "照陷\n",
      "180506\n",
      "川影\n",
      "指小三\n",
      "韬蕴\n",
      "懒财网\n",
      "第三发\n",
      "带嫩妹\n",
      "没凉\n",
      "房弃\n",
      "选率\n",
      "说少\n",
      "聂欢\n",
      "迟讯\n",
      "赵明微\n",
      "买歌\n",
      "美信\n",
      "来涉\n",
      "但币安离\n",
      "已入币安\n",
      "球哥\n",
      "网用\n",
      "币币\n",
      "从林丹\n",
      "超极丹\n",
      "胸嫩模\n",
      "再证\n",
      "4tb\n",
      "两票\n",
      "堆如山\n",
      "破闺蜜\n",
      "删博因\n",
      "下吉\n",
      "七年级\n",
      "送父\n",
      "太豪\n",
      "一小半\n",
      "人拉黑\n",
      "七十几岁\n",
      "180508\n",
      "张天柏\n",
      "康贝清\n",
      "不婚性\n",
      "小三有子\n",
      "许多年\n",
      "管彤用\n",
      "立破\n",
      "多人传\n",
      "曝中超\n",
      "亿邀\n",
      "低帮\n",
      "重夺\n",
      "三旬\n",
      "仍能\n",
      "翻全\n",
      "科怀\n",
      "kawhi\n",
      "leonard\n",
      "刺迷\n",
      "波帅\n",
      "疑传\n",
      "采参人\n",
      "山挖\n",
      "大财\n",
      "江叔藏\n",
      "互攀\n",
      "两人配\n",
      "亿表\n",
      "甚平\n",
      "一找\n",
      "再任\n",
      "戏不接\n",
      "胡霍\n",
      "晓晨刚\n",
      "尿王\n",
      "薛之谦旧\n",
      "三巨\n",
      "胜已\n",
      "之钥\n",
      "不浊变\n",
      "变浊\n",
      "粮酒\n",
      "浓是\n",
      "这红\n",
      "赫子铭手\n",
      "抢孩\n",
      "赫子铭恐\n",
      "要养\n",
      "其上\n",
      "假渣\n",
      "相逼要\n",
      "手举\n",
      "价牌\n",
      "老夫老妻\n",
      "被何\n",
      "完谢娜\n",
      "一男娶\n",
      "及现\n",
      "互晒\n",
      "拉孟美岐\n",
      "加群\n",
      "第十四天\n",
      "好文荐\n",
      "青读\n",
      "温晓萍\n",
      "一读\n",
      "余承东微\n",
      "wahway\n",
      "大嘴别\n",
      "撤镇\n",
      "别请\n",
      "晏来\n",
      "比太\n",
      "小凯凯\n",
      "从弹\n",
      "弹舱\n",
      "10cm\n",
      "好无语\n",
      "陈思诚怀\n",
      "没和大雄\n",
      "韩安旭\n",
      "假点\n",
      "酱话\n",
      "携岳云鹏\n",
      "手引\n",
      "就生\n",
      "万人次\n",
      "之日怀\n",
      "寻新欢\n",
      "佟丽娅长\n",
      "悦儿姐\n",
      "极简\n",
      "地问\n",
      "陈思诚方\n",
      "草娥\n",
      "热拍\n",
      "姜东昊方\n",
      "战狼粉\n",
      "3p\n",
      "他头\n",
      "酒能\n",
      "酒中\n",
      "招嫖案\n",
      "160629\n",
      "可假\n",
      "喝骨\n",
      "患用\n",
      "口仅\n",
      "揭刘涛\n",
      "个经\n",
      "黑标\n",
      "穿错\n",
      "九寒\n",
      "类备\n",
      "制谣\n",
      "前不洗\n",
      "损脾\n",
      "绕晕\n",
      "病发学\n",
      "新皮\n",
      "别活\n",
      "种燃脂\n",
      "出油长\n",
      "长斑长\n",
      "各表\n",
      "太脏别\n",
      "名是\n",
      "奶节\n",
      "光后\n",
      "哲利佑\n",
      "增胖\n",
      "外链\n",
      "凯路\n",
      "小鸣\n",
      "称小鸣\n",
      "黄车疑\n",
      "郑爽骚\n",
      "薛之谦吐槽\n",
      "因人设\n",
      "薛之谦怒\n",
      "薛之谦成\n",
      "薛之谦要\n",
      "荷兹\n",
      "吃辣生\n",
      "七匹\n",
      "咖都\n",
      "总刷\n",
      "无制\n",
      "幻忆\n",
      "郑爽领\n",
      "食安周\n",
      "请华哥\n",
      "亿男主\n",
      "卢靖姗成\n",
      "被诊\n",
      "血招\n",
      "血甜\n",
      "黑称\n",
      "太狂\n",
      "王思聪敢\n",
      "除味\n",
      "吃根\n",
      "似粥\n",
      "太多怕\n",
      "摆托\n",
      "beaba\n",
      "小猿\n",
      "搜题\n",
      "手能\n",
      "服拿着\n",
      "一两分钟\n",
      "七大美白\n",
      "zuzu\n",
      "重卡\n",
      "大井拐\n",
      "为徒\n",
      "圈真乱\n",
      "老不尊\n",
      "郭侯\n",
      "郭德纲率\n",
      "为分\n",
      "蒋欣想\n",
      "采莲令\n",
      "蒋欣大谈\n",
      "韩红自\n",
      "用眼\n",
      "不换易\n",
      "选和用\n",
      "东西长\n",
      "终得\n",
      "淡斑治\n",
      "酒叔教\n",
      "小茶\n",
      "s400\n",
      "主弹\n",
      "印忙\n",
      "俄已\n",
      "印俄\n",
      "没遭\n",
      "供卵\n",
      "一奖\n",
      "这太\n",
      "骑熊照\n",
      "天上飞\n",
      "系外\n",
      "第四代\n",
      "想拿苏\n",
      "驻墨\n",
      "喝变\n",
      "十快\n",
      "回恒大\n",
      "小讯\n",
      "一延\n",
      "十多名\n",
      "j68815\n",
      "180529\n",
      "网传昌菱\n",
      "请以\n",
      "案为\n",
      "限行系\n",
      "泸山\n",
      "迈得斯客\n",
      "迈乐士\n",
      "证不实\n",
      "锄沟\n",
      "宁信院\n",
      "骤停\n",
      "翔案\n",
      "肉会变\n",
      "舰比\n",
      "涵哥\n",
      "年费要\n",
      "即入\n",
      "一挡\n",
      "涉假\n",
      "有伙人\n",
      "加小黄\n",
      "边捕\n",
      "事微博\n",
      "百尾\n",
      "黄渤去\n",
      "达少\n",
      "李明霖\n",
      "高秋梓方\n",
      "药能\n",
      "别疯传\n",
      "亿和马云\n",
      "这仅\n",
      "极思细恐\n",
      "曝爱\n",
      "上迪丽\n",
      "骗贷\n",
      "凡白\n",
      "后颜值\n",
      "lushamg333\n",
      "产检时\n",
      "化得\n",
      "成倍增加\n",
      "不练\n",
      "由酸\n",
      "因恐\n",
      "一列\n",
      "假枪\n",
      "钢镚可换\n",
      "只种\n",
      "令马云大呼\n",
      "档会\n",
      "肾有\n",
      "喝促\n",
      "痛要\n",
      "期长\n",
      "服尼美\n",
      "跳财\n",
      "跳灾\n",
      "捂月子\n",
      "吃坏\n",
      "刘熙阳\n",
      "陆添\n",
      "传带\n",
      "假滴\n",
      "灯厂\n",
      "省大\n",
      "微商为\n",
      "炒票\n",
      "疑揭\n",
      "有念\n",
      "一哭\n",
      "拉姑\n",
      "总晒\n",
      "完太\n",
      "艳门照\n",
      "地唱\n",
      "共进\n",
      "疑锋锋\n",
      "爆两人\n",
      "耗不起\n",
      "别晒娃\n",
      "谢母证\n",
      "锋芝要\n",
      "今李\n",
      "被误\n",
      "之七\n",
      "watch2\n",
      "疑对\n",
      "反让\n",
      "条是\n",
      "频秀\n",
      "edwin\n",
      "鸭血能\n",
      "没充\n",
      "没电别\n",
      "必开\n",
      "遭窃后\n",
      "互飙\n",
      "13662738785\n",
      "藏珍\n",
      "该要\n",
      "竟相\n",
      "造当十\n",
      "样币\n",
      "堆中\n",
      "个版\n",
      "三钱\n",
      "六分\n",
      "横据\n",
      "达百\n",
      "袁像币\n",
      "人送\n",
      "平三钱\n",
      "法测\n",
      "便够\n",
      "十多家\n",
      "亿时\n",
      "度迎\n",
      "起多地\n",
      "迎大到\n",
      "董璇力\n",
      "物能\n",
      "遭霸\n",
      "凌入\n",
      "凌倒\n",
      "因霸\n",
      "凌转\n",
      "比肉贵\n",
      "思聪该\n",
      "李舒克\n",
      "二岁\n",
      "挖镇\n",
      "兽致\n",
      "三翅鸡\n",
      "自灭\n",
      "50g\n",
      "因网\n",
      "办卡\n",
      "制狼\n",
      "厅系\n",
      "建市\n",
      "sviper\n",
      "多城\n",
      "分题\n",
      "哪所\n",
      "有射墨\n",
      "谢娜助\n",
      "g55\n",
      "虐爆\n",
      "五通\n",
      "溺亡车\n",
      "比途观\n",
      "价为\n",
      "最常点\n",
      "款车品\n",
      "机鬼\n",
      "gogoing\n",
      "多人会\n",
      "之日系\n",
      "四批\n",
      "增募\n",
      "资约\n",
      "李亲\n",
      "比雪先\n",
      "传麻吉宝\n",
      "插根\n",
      "同屏线\n",
      "万勿\n",
      "样是\n",
      "可港\n",
      "媒放\n",
      "指炫富\n",
      "林狗哥\n",
      "看林\n",
      "王丽坤离\n",
      "曝重\n",
      "女轻\n",
      "支十神\n",
      "多婚\n",
      "看虎\n",
      "熏出\n",
      "能常\n",
      "趣彩网\n",
      "系自\n",
      "这几注\n",
      "筱杉\n",
      "胆王\n",
      "扎人系\n",
      "地引\n",
      "沱一桥\n",
      "某厂\n",
      "网传旺\n",
      "城有\n",
      "网传西\n",
      "我现\n",
      "内未\n",
      "车内久开\n",
      "网传联\n",
      "杀软\n",
      "因玩\n",
      "人失联\n",
      "前不面\n",
      "荔景\n",
      "这所\n",
      "鲁寨\n",
      "一门\n",
      "网传秀洲\n",
      "尊邸\n",
      "杆上\n",
      "十多岁\n",
      "银泉路\n",
      "总第\n",
      "没实\n",
      "技教\n",
      "破骗\n",
      "两黄\n",
      "种含\n",
      "反降\n",
      "稳布\n",
      "一黄\n",
      "保肾\n",
      "降降\n",
      "二白\n",
      "虽甜\n",
      "需录\n",
      "继小岳岳\n",
      "日去\n",
      "美醉\n",
      "难见\n",
      "这音\n",
      "称离\n",
      "亲承里\n",
      "印一命\n",
      "盾安\n",
      "继熊乃瑾\n",
      "廖志宇\n",
      "黄渤早\n",
      "几十米\n",
      "多患\n",
      "陶肽\n",
      "车连撞且\n",
      "做后\n",
      "限售系\n",
      "说渝贵\n",
      "此点\n",
      "微成\n",
      "搬侠\n",
      "新商\n",
      "一顆\n",
      "剝皮\n",
      "携甘比\n",
      "过好\n",
      "有多美\n",
      "华仔会\n",
      "长痣\n",
      "群现\n",
      "大蛇袭\n",
      "注了\n",
      "师德有\n",
      "第一项\n",
      "革碎\n",
      "吐点\n",
      "德赫亚换\n",
      "冯坤当\n",
      "绿萝是\n",
      "放绿萝\n",
      "绿萝能\n",
      "挤点\n",
      "头能\n",
      "有云\n",
      "家备\n",
      "益气生\n",
      "称遇\n",
      "继关晓彤\n",
      "没鹿晗\n",
      "李恋\n",
      "迷美\n",
      "男自\n",
      "贺哥\n",
      "早心\n",
      "敢否\n",
      "服应\n",
      "薛之谦后\n",
      "个遍\n",
      "杨洋到\n",
      "男一\n",
      "杨洋成\n",
      "脸晓彤\n",
      "连迪丽\n",
      "早是\n",
      "韩雪谈\n",
      "失联女\n",
      "灾后\n",
      "方吁\n",
      "看易\n",
      "现只\n",
      "秋冻\n",
      "鹿饭\n",
      "非尼可\n",
      "最闪\n",
      "只来\n",
      "验验\n",
      "屡破\n",
      "三石哥\n",
      "不养\n",
      "唱来\n",
      "进无出\n",
      "线纹\n",
      "美妞们\n",
      "全猜\n",
      "别到\n",
      "友要\n",
      "查个\n",
      "去查\n",
      "对对看\n",
      "可游\n",
      "调煮\n",
      "别车\n",
      "东鸟旗\n",
      "夏雨为\n",
      "张凯丽大闹\n",
      "粘东\n",
      "马蓉发\n",
      "撕宝强\n",
      "马蓉手\n",
      "将六登\n",
      "下华神\n",
      "生娃后\n",
      "用蛇\n",
      "不提\n",
      "欠迪丽\n",
      "期到\n",
      "表思意\n",
      "因鹿晗\n",
      "p60\n",
      "魅族醒\n",
      "cx70t\n",
      "万人会\n",
      "捐卵\n",
      "召忠\n",
      "张召忠谈\n",
      "人忙\n",
      "因不懂\n",
      "钱太多\n",
      "人笑\n",
      "英该\n",
      "遭小\n",
      "那英神\n",
      "王思聪炮\n",
      "主财\n",
      "沉水香\n",
      "自研\n",
      "两千多万\n",
      "五瓣\n",
      "之水\n",
      "大目\n",
      "纯甜\n",
      "穿个\n",
      "地票\n",
      "多套\n",
      "他乐\n",
      "开奶\n",
      "花个\n",
      "糯酸爽\n",
      "憨货\n",
      "笑痛\n",
      "处扣\n",
      "小三小四\n",
      "赵丽媚\n",
      "龙珠超\n",
      "码来\n",
      "专码\n",
      "不付\n",
      "码小\n",
      "之树\n",
      "godv\n",
      "选迪丽\n",
      "甚冷\n",
      "四元\n",
      "马华斥\n",
      "求王\n",
      "写得\n",
      "土培房\n",
      "深马\n",
      "最乱\n",
      "大升\n",
      "几本书\n",
      "黑哥\n",
      "马云怕\n",
      "打向\n",
      "根叶能\n",
      "会省\n",
      "无地\n",
      "法将\n",
      "将解\n",
      "白鬓\n",
      "后半辈子\n",
      "拿皂角\n",
      "黑密\n",
      "如沾墨\n",
      "碳墨\n",
      "匹林加\n",
      "太凶\n",
      "不抹\n",
      "用妙\n",
      "片加\n",
      "乌墨似\n",
      "手胀\n",
      "人当\n",
      "可治牙\n",
      "挖眼\n",
      "带字\n",
      "万给\n",
      "知值\n",
      "错币\n",
      "好几百\n",
      "毛学\n",
      "一杆\n",
      "年销\n",
      "操手\n",
      "以房\n",
      "十二种\n",
      "别骗\n",
      "进图\n",
      "驴家班\n",
      "朝迪牌\n",
      "破步\n",
      "自产自\n",
      "湿毒排\n",
      "张松英\n",
      "死得光\n",
      "用出\n",
      "搞野\n",
      "片地\n",
      "娃当\n",
      "必在\n",
      "证值\n",
      "万退\n",
      "如吸\n",
      "爆锋菲\n",
      "卓伟博\n",
      "能糊\n",
      "曝俩\n",
      "常吃难\n",
      "比吃肉\n",
      "吃得巧\n",
      "种低\n",
      "干帮\n",
      "前称\n",
      "哪能\n",
      "乖萌萌\n",
      "现办\n",
      "程野三人\n",
      "度电\n",
      "传换\n",
      "价下\n",
      "对马云\n",
      "为友\n",
      "马云夺\n",
      "必带\n",
      "超马云\n",
      "有书\n",
      "十二亩\n",
      "半地\n",
      "小到\n",
      "上富\n",
      "王凯疑\n",
      "良剂\n",
      "突人\n",
      "刘愈\n",
      "治痛\n",
      "缴起\n",
      "达旗\n",
      "地要\n",
      "根是\n",
      "人照\n",
      "谈莉娜\n",
      "杨洋受\n",
      "面变\n",
      "宠趣\n",
      "张翰真\n",
      "真爱过\n",
      "张爱天\n",
      "太辣\n",
      "宋欧尼\n",
      "大一岁\n",
      "弟恋\n",
      "杨洋为\n",
      "戏内戏\n",
      "外超\n",
      "被颖儿\n",
      "女主遭\n",
      "曝择\n",
      "未火时\n",
      "险错\n",
      "因爱得\n",
      "影中\n",
      "有佳\n",
      "感超\n",
      "两人领\n",
      "忘拉\n",
      "甜筑\n",
      "张翰好\n",
      "男主颜值\n",
      "遭卓伟\n",
      "大虐\n",
      "伤太深\n",
      "颜质\n",
      "遭爽\n",
      "张翰亏\n",
      "早见\n",
      "洋爽\n",
      "陈学冬旧\n",
      "杨洋该\n",
      "深惹\n",
      "微博替\n",
      "鸡拔\n",
      "测完\n",
      "一砖\n",
      "该用\n",
      "蒋欣吵\n",
      "杜杜拿起\n",
      "洗鼻治\n",
      "滴通\n",
      "a0001\n",
      "乌密\n",
      "阿匹\n",
      "能治腰\n",
      "突别\n",
      "霍家添\n",
      "桌游里\n",
      "卓伟自\n",
      "想学白\n",
      "七药\n",
      "如桃\n",
      "无颈\n",
      "纹众\n",
      "企客\n",
      "难分舍\n",
      "超杨\n",
      "別人\n",
      "可抹平\n",
      "健腰\n",
      "生精\n",
      "补髓\n",
      "石决明\n",
      "肥健\n",
      "主腰\n",
      "脚疾\n",
      "连三高\n",
      "强腰\n",
      "常吃包\n",
      "再教\n",
      "说输\n",
      "舌草能\n",
      "用众\n",
      "字令\n",
      "咖互\n",
      "拍新戏\n",
      "凡手\n",
      "一进\n",
      "已毁\n",
      "完冻\n",
      "内里费\n",
      "柴崎岳\n",
      "朱亚文来\n",
      "赵丽颖景\n",
      "酷宝\n",
      "雷宝\n",
      "二缺\n",
      "未失\n",
      "称疑\n",
      "棺内\n",
      "竟请\n",
      "这果\n",
      "节是\n",
      "店系\n",
      "老利\n",
      "秘诱\n",
      "越热越\n",
      "有口\n",
      "离大\n",
      "深排\n",
      "替田震\n",
      "晏爆\n",
      "种椒\n",
      "卖椒\n",
      "用奇招\n",
      "养竹鼠\n",
      "水里养\n",
      "优死\n",
      "蒙媒爆\n",
      "人会领\n",
      "想领\n",
      "三地\n",
      "g60\n",
      "吃够\n",
      "永禁\n",
      "外展\n",
      "人一到\n",
      "人算\n",
      "养再\n",
      "八零后\n",
      "李晨同\n",
      "已谈出\n",
      "一嫁\n",
      "微博零\n",
      "阿哲新\n",
      "共治\n",
      "二种\n",
      "卖粮\n",
      "却乐\n",
      "想备\n",
      "谱生\n",
      "孩是\n",
      "桑们\n",
      "会交\n",
      "交啦\n",
      "慌掉\n",
      "剩和曼\n",
      "无活\n",
      "可干\n",
      "十人用\n",
      "何建峰\n",
      "多放点\n",
      "捂汗\n",
      "加毒\n",
      "润志\n",
      "既暖宫\n",
      "先胖肚\n",
      "太大像\n",
      "梦中救\n",
      "脸去\n",
      "本京\n",
      "放证\n",
      "马佬\n",
      "更苦\n",
      "鸡条\n",
      "过港\n",
      "多后\n",
      "王思聪恋\n",
      "蒙停\n",
      "天称\n",
      "亿遭\n",
      "有次\n",
      "吴京力\n",
      "因酒\n",
      "反赔\n",
      "精门\n",
      "钱小佳\n",
      "问以\n",
      "这像\n",
      "拜个\n",
      "配文称\n",
      "太松\n",
      "我头\n",
      "遭主播\n",
      "该主播\n",
      "冯莫提\n",
      "庭萱\n",
      "霞姐\n",
      "mbk\n",
      "潇邦\n",
      "会滴\n",
      "后后\n",
      "脸见\n",
      "强太爱\n",
      "快换\n",
      "无漆\n",
      "无蜡\n",
      "除霉除\n",
      "用筷\n",
      "用久会\n",
      "平嘻王\n",
      "好几页\n",
      "小甜馨会\n",
      "太逆天\n",
      "王思聪来\n",
      "值个\n",
      "慎转\n",
      "禁发\n",
      "起涉\n",
      "虎踪\n",
      "人车\n",
      "飘花\n",
      "十几件\n",
      "开从\n",
      "俄料\n",
      "糯无裂\n",
      "雕出\n",
      "万买块\n",
      "新上\n",
      "爆七大\n",
      "看备\n",
      "图上\n",
      "准妈们\n",
      "服发\n",
      "对孕妈\n",
      "点会\n",
      "做怀\n",
      "看生\n",
      "遭狼\n",
      "口一\n",
      "压断\n",
      "率来\n",
      "变直\n",
      "人向\n",
      "出多\n",
      "天瘦出\n",
      "遮肉\n",
      "排完\n",
      "网传张\n",
      "轨谢娜\n",
      "卖特贵\n",
      "虽高\n",
      "用三物\n",
      "中洗\n",
      "出胶\n",
      "已传\n",
      "88816218\n",
      "无迪胖\n",
      "周狂\n",
      "遮去\n",
      "巨显\n",
      "网纱\n",
      "遮掉\n",
      "v13525430110\n",
      "迈不开\n",
      "谢娜家\n",
      "反减\n",
      "上能\n",
      "坐实疑\n",
      "宿世来\n",
      "无官\n",
      "无官星\n",
      "早中晚\n",
      "找罪\n",
      "這样\n",
      "好菜\n",
      "缩胃\n",
      "几碗\n",
      "腹法\n",
      "暗搓\n",
      "更胜\n",
      "变美小\n",
      "贱康\n",
      "草报\n",
      "马蓉成\n",
      "台媒惊\n",
      "䠷\n",
      "招水\n",
      "柚是\n",
      "皮吸\n",
      "三圈\n",
      "泳圈\n",
      "秒法\n",
      "腰变\n",
      "老得慢\n",
      "佳物\n",
      "雪燕\n",
      "超好次\n",
      "新新\n",
      "比任\n",
      "敷久\n",
      "疼小\n",
      "酒识\n",
      "酒侠\n",
      "赌石界\n",
      "淡斑变\n",
      "gsd\n",
      "印小妙\n",
      "天疯\n",
      "符回\n",
      "进家\n",
      "岿如\n",
      "甜爆\n",
      "近疑\n",
      "团要\n",
      "牛唐\n",
      "刚求\n",
      "李晨肯\n",
      "凤囚凰\n",
      "天如镜\n",
      "听下\n",
      "未见玲花\n",
      "比于\n",
      "谦多\n",
      "刀郎大\n",
      "全唱\n",
      "太美太\n",
      "时唱出\n",
      "网红大\n",
      "元到\n",
      "z6\n",
      "kp5gt\n",
      "骚白\n",
      "随妈\n",
      "各唱\n",
      "比玲花\n",
      "姜赛\n",
      "依澜雅居\n",
      "号头费\n",
      "遭疯传\n",
      "偷系\n",
      "马雪云传\n",
      "霍璇\n",
      "卡魔刹\n",
      "反伤\n",
      "2000w\n",
      "700w\n",
      "点脑\n",
      "拍车\n",
      "美如仙\n",
      "害鹿晗\n",
      "改拼\n",
      "吴昕解\n",
      "6d\n",
      "订婚戒指\n",
      "越玩越\n",
      "刀粉\n",
      "看万人\n",
      "成刀郎\n",
      "携美妻\n",
      "比淫\n",
      "魏翊东\n",
      "帮刀郎\n",
      "英写\n",
      "缘定\n",
      "当刀郎\n",
      "郭津彤\n",
      "六十年\n",
      "总戒\n",
      "亿万元\n",
      "年脂\n",
      "清肠少\n",
      "秦晓四\n",
      "养脚暖身\n",
      "黑照\n",
      "港媒传\n",
      "娱姬\n",
      "附三大\n",
      "这帅\n",
      "炒鸡\n",
      "照美哭\n",
      "照美到\n",
      "持剑\n",
      "好苦\n",
      "这一比\n",
      "唐诗咏\n",
      "高园园\n",
      "微隆似\n",
      "曝疑\n",
      "人爱死\n",
      "韩媒爆\n",
      "脸残\n",
      "侧颜\n",
      "看小\n",
      "抓秋菊\n",
      "两人蜜\n",
      "度往\n",
      "拍破\n",
      "逃不开\n",
      "另一名\n",
      "禁日令\n",
      "轩澜大波\n",
      "养有\n",
      "拍同\n",
      "百分之一\n",
      "越闹\n",
      "但称\n",
      "180216\n",
      "g2\n",
      "唐尼是\n",
      "donatella\n",
      "马云怒\n",
      "不吐不晕\n",
      "八千多\n",
      "中通\n",
      "有魏\n",
      "东言\n",
      "目染\n",
      "试爱\n",
      "师学艺\n",
      "年欲裁\n",
      "竟传\n",
      "拼娘\n",
      "马云言\n",
      "不太\n",
      "上少\n",
      "拍疑\n",
      "向華強\n",
      "唯獨\n",
      "人連\n",
      "学张翰\n",
      "吴京盛\n",
      "峰菲似\n",
      "穿卫衣\n",
      "四句\n",
      "尤伤\n",
      "多女\n",
      "曝确\n",
      "舒曾\n",
      "舒拦\n",
      "这真\n",
      "佟丽娅心\n",
      "姚晨带\n",
      "夜华脸\n",
      "任嘉伦方\n",
      "男小三\n",
      "真骗\n",
      "摔娃\n",
      "刘涛方\n",
      "药企\n",
      "几篇\n",
      "karrigan\n",
      "olof\n",
      "elige\n",
      "原以为\n",
      "下衣\n",
      "再美\n",
      "发下衣\n",
      "白滑吸\n",
      "葛斯林妻\n",
      "图秀\n",
      "照力\n",
      "遭泼\n",
      "己怀\n",
      "赵丽颖签\n",
      "竖置\n",
      "再无白\n",
      "删不掉\n",
      "离定\n",
      "太差入\n",
      "不验\n",
      "反说\n",
      "真比安迪\n",
      "王珂后\n",
      "姐快\n",
      "个字令\n",
      "绝逼\n",
      "最爱座\n",
      "递卡时\n",
      "克夫命\n",
      "成隐\n",
      "引众愤\n",
      "继靳东\n",
      "大谈床\n",
      "天闪婚\n",
      "造刘涛\n",
      "家去\n",
      "剧演\n",
      "阚清子系\n",
      "不离手\n",
      "怒道\n",
      "那沓\n",
      "保剑锋\n",
      "后星\n",
      "看狗仔\n",
      "因葛天\n",
      "周减\n",
      "会告\n",
      "孕状\n",
      "终怀\n",
      "该生\n",
      "曝杨颖\n",
      "陈赫有\n",
      "头自\n",
      "袁立用\n",
      "护夫\n",
      "圈三大\n",
      "黄轩方\n",
      "诗怒\n",
      "汪美麟\n",
      "疑造\n",
      "舒闪婚\n",
      "娶富\n",
      "冤不冤\n",
      "曝赵薇\n",
      "删博装\n",
      "铁着\n",
      "何振东\n",
      "叫江母\n",
      "别总坑\n",
      "妈常\n",
      "收为\n",
      "圆尖\n",
      "咸男甜\n",
      "吃酸生\n",
      "因生\n",
      "抱个\n",
      "柠橘\n",
      "圆女\n",
      "吃化\n",
      "梅怀\n",
      "圆准\n",
      "别当真\n",
      "概股\n",
      "助马蓉\n",
      "有小柳岩\n",
      "案有\n",
      "裸死于\n",
      "会想\n",
      "住建\n",
      "弹洞\n",
      "亿韩元\n",
      "次脸\n",
      "吃醉鹅嚼\n",
      "能致\n",
      "博似\n",
      "竟盗\n",
      "长得慢\n",
      "亿債\n",
      "斯特大\n",
      "马云心\n",
      "超万兴\n",
      "男宝妈\n",
      "男三大\n",
      "投会\n",
      "有市\n",
      "赵丽颖患\n",
      "涉药\n",
      "小药\n",
      "点档\n",
      "指王冕\n",
      "舞帝\n",
      "邹玉萍\n",
      "实锤开\n",
      "清晒出\n",
      "顶栏\n",
      "专将\n",
      "加费\n",
      "四十度\n",
      "韩综\n",
      "下架限\n",
      "亿够\n",
      "认对\n",
      "养骨\n",
      "偷请\n",
      "好扎心\n",
      "不脏\n",
      "太对\n",
      "哆弗\n",
      "脚有\n",
      "伤发\n",
      "它准\n",
      "烦翻\n",
      "老喝\n",
      "党们\n",
      "两排\n",
      "最年\n",
      "款哈弗\n",
      "h4\n",
      "r7\n",
      "a50\n",
      "爆卖\n",
      "x6\n",
      "称开\n",
      "a8\n",
      "比轩\n",
      "比埃尔法\n",
      "比五菱\n",
      "原卖\n",
      "ds6\n",
      "才销\n",
      "台法系\n",
      "现降\n",
      "油跑\n",
      "现低\n",
      "开不坏\n",
      "买宝骏\n",
      "越造\n",
      "款劳\n",
      "万冲\n",
      "接钱\n",
      "拔凉拔\n",
      "标只\n",
      "最豪\n",
      "配才\n",
      "rx8\n",
      "甩名\n",
      "一条街\n",
      "配无框\n",
      "无大修\n",
      "总伤\n",
      "7l\n",
      "品控\n",
      "急售\n",
      "万盆\n",
      "年大苗\n",
      "租来\n",
      "智跑\n",
      "万不卖\n",
      "tlx\n",
      "rdx\n",
      "路虎造\n",
      "这逼格\n",
      "比汉兰达\n",
      "还耐造\n",
      "万多起\n",
      "途乐\n",
      "途达\n",
      "全铝\n",
      "这货配\n",
      "销才\n",
      "skdj\n",
      "万缤智急\n",
      "别总看\n",
      "升白针\n",
      "净脾不虚\n",
      "四盒\n",
      "比吸\n",
      "利胎\n",
      "点肝要\n",
      "哄娃\n",
      "会犯\n",
      "一宿消\n",
      "超显\n",
      "显瘦盖\n",
      "还得学\n",
      "按月发\n",
      "伤薪\n",
      "忧酬\n",
      "新一波\n",
      "全吃进\n",
      "溶进\n",
      "一人哥\n",
      "条有\n",
      "趣贴\n",
      "超罗牛山\n",
      "跟治\n",
      "国乒两大\n",
      "绝未\n",
      "球输\n",
      "170606\n",
      "托谈\n",
      "诗家\n",
      "陈伟霆疑\n",
      "别太傲\n",
      "十枚\n",
      "快闻\n",
      "亿烂\n",
      "摊待夫\n",
      "酸生\n",
      "你会接\n",
      "会生个\n",
      "个条\n",
      "接咯\n",
      "马蓉分\n",
      "强怒\n",
      "主靠\n",
      "担演\n",
      "临拍\n",
      "傻白甜\n",
      "土算\n",
      "菜易\n",
      "店用\n",
      "变钝\n",
      "具马\n",
      "曾豪车\n",
      "美众\n",
      "速学\n",
      "行卡\n",
      "红董\n",
      "承旭\n",
      "我歌\n",
      "低入\n",
      "看舞\n",
      "功作\n",
      "称爱\n",
      "因常\n",
      "前防长\n",
      "独此\n",
      "半分钟\n",
      "出洞\n",
      "补能\n",
      "脆败\n",
      "车案\n",
      "以孕肚\n",
      "很麻痛\n",
      "帕楚\n",
      "咸粥\n",
      "某浪\n",
      "哈娜\n",
      "周琦前\n",
      "詹皇获\n",
      "超毒\n",
      "wannacry20\n",
      "网传受\n",
      "停至\n",
      "陆前\n",
      "限缩\n",
      "五泉\n",
      "还放话\n",
      "再告\n",
      "企业录\n",
      "陛桥成\n",
      "园方诉\n",
      "二幼\n",
      "第六个\n",
      "斯内德系\n",
      "账返\n",
      "超回\n",
      "街采\n",
      "中赫有\n",
      "猪养\n",
      "爱猪\n",
      "车摇号\n",
      "好方\n",
      "醋配\n",
      "鱼大获\n",
      "开饵\n",
      "没人用\n",
      "已早\n",
      "老钓人\n",
      "总不上\n",
      "飞竿\n",
      "盆钵体\n",
      "钓法\n",
      "钓人\n",
      "老钓者\n",
      "船避\n",
      "扎发\n",
      "鼻峰\n",
      "扎素\n",
      "现连\n",
      "亿拿地\n",
      "當十有\n",
      "传办\n",
      "一峰\n",
      "人社\n",
      "取会降\n",
      "或能\n",
      "40cm\n",
      "还降\n",
      "抗三高\n",
      "可降\n",
      "降餐\n",
      "糖人要\n",
      "两麦\n",
      "四豆\n",
      "太老\n",
      "终陷\n",
      "年半后\n",
      "疑显\n",
      "只涂\n",
      "过仅拔\n",
      "四颗\n",
      "杨颖素\n",
      "竟比本\n",
      "韩漂\n",
      "晏力\n",
      "晏怕\n",
      "史堪\n",
      "继杨颖\n",
      "没处\n",
      "杨颖晓明\n",
      "杨颖去\n",
      "颜自\n",
      "网红们\n",
      "暴差\n",
      "青小秀\n",
      "连凤姐\n",
      "好土\n",
      "本可\n",
      "男里\n",
      "郑爽颜\n",
      "只画\n",
      "整错\n",
      "立讽\n",
      "小三女\n",
      "半后\n",
      "提鲜\n",
      "常吃会\n",
      "滋肝\n",
      "太咸\n",
      "今携\n",
      "剪破\n",
      "超兆日\n",
      "制义\n",
      "十肝九病\n",
      "用酒\n",
      "e5n6\n",
      "明夏欲\n",
      "乌过\n",
      "乱治\n",
      "晏面\n",
      "济广\n",
      "拉货出\n",
      "玩时\n",
      "没得治\n",
      "腰好\n",
      "欧豪盛\n",
      "亲怼\n",
      "携王凯\n",
      "曝连聚\n",
      "因剧生\n",
      "情疑\n",
      "老糖友\n",
      "超于\n",
      "剧么\n",
      "新皂\n",
      "上印\n",
      "三不喝\n",
      "野蒜\n",
      "再愁\n",
      "里装\n",
      "太烫\n",
      "上以\n",
      "腰龙\n",
      "1200w\n",
      "处涂涂\n",
      "大未解\n",
      "会发\n",
      "尸库\n",
      "怪风\n",
      "活龟\n",
      "这具\n",
      "现女\n",
      "变美白\n",
      "娘妻\n",
      "二新规\n",
      "宝新轮\n",
      "附多张\n",
      "iphone7plus\n",
      "对彪\n",
      "威马纯\n",
      "荣威后\n",
      "长寿命\n",
      "造完\n",
      "5gwifi\n",
      "慢咯\n",
      "多差\n",
      "会断\n",
      "插线\n",
      "更省\n",
      "包系\n",
      "未息\n",
      "7nm\n",
      "拉要\n",
      "王欣要\n",
      "微博是\n",
      "胸污\n",
      "不污\n",
      "云蝉\n",
      "女命论\n",
      "男能\n",
      "正缘\n",
      "美满幸福\n",
      "掌趣\n",
      "亿跑\n",
      "从马云\n",
      "侵致\n",
      "继性\n",
      "亲指\n",
      "谭咏麟力\n",
      "清告\n",
      "卓伟发\n",
      "卓伟以\n",
      "藏尾\n",
      "清拉帮\n",
      "没发照\n",
      "信杰哥\n",
      "信娜姐\n",
      "曝卓伟\n",
      "曝隐\n",
      "爆隐\n",
      "哈噶\n",
      "引热\n",
      "邓超闹\n",
      "探班马\n",
      "卓伟死\n",
      "魏千雅\n",
      "声卓伟\n",
      "舒就会\n",
      "消风\n",
      "某高管\n",
      "岳云鹏疑\n",
      "别胜新\n",
      "急嫁\n",
      "扔河\n",
      "曝力\n",
      "毒坏\n",
      "卓伟竟\n",
      "中艳海\n",
      "撞者\n",
      "镇罗\n",
      "守岛\n",
      "逼装\n",
      "认爹\n",
      "重多\n",
      "南大跑\n",
      "大可\n",
      "延北\n",
      "日限行系\n",
      "网传潮\n",
      "田日亮\n",
      "网传大乔\n",
      "网传榕山\n",
      "系网\n",
      "传北现\n",
      "千美元\n",
      "对夏\n",
      "网传小卡\n",
      "网传带\n",
      "前向\n",
      "抢系\n",
      "那梭\n",
      "班程\n",
      "樊赵车\n",
      "七江\n",
      "双桂村\n",
      "院要\n",
      "近会\n",
      "头朝下\n",
      "有现\n",
      "轧人\n",
      "成血人系\n",
      "出把力\n",
      "斯威刚\n",
      "夏奇拉\n",
      "杉德诺\n",
      "漫斯\n",
      "花臂\n",
      "限号系\n",
      "寒官博\n",
      "传偷\n",
      "瞻榆偷\n",
      "吃粉\n",
      "烧净\n",
      "补连塔\n",
      "矿南\n",
      "炸倒\n",
      "抢娃\n",
      "航洋\n",
      "川师\n",
      "长麦路\n",
      "患脑\n",
      "癌花\n",
      "致一死\n",
      "之差\n",
      "断塌系\n",
      "人今\n",
      "甜馨会判\n",
      "事刚\n",
      "读网\n",
      "电销\n",
      "遭蛇\n",
      "好水\n",
      "波场币\n",
      "卷款\n",
      "系遭\n",
      "香锅店\n",
      "长太快\n",
      "一妙物\n",
      "选帅\n",
      "权健帕托\n",
      "恐回\n",
      "尤文去\n",
      "某音\n",
      "劲肩\n",
      "小鑫教\n",
      "累成\n",
      "仅活\n",
      "房新规\n",
      "亿当\n",
      "國家國\n",
      "旗國徽\n",
      "軍隊\n",
      "軍同樣\n",
      "中華龍\n",
      "就加\n",
      "最不愿\n",
      "脸要\n",
      "梗卓伟\n",
      "市一\n",
      "促排\n",
      "虐遍\n",
      "蛮准\n",
      "撒棒\n",
      "封肚\n",
      "越多怀\n",
      "减平\n",
      "做下\n",
      "最牛鸡\n",
      "竟活\n",
      "神鸡\n",
      "如父\n",
      "二年\n",
      "头越\n",
      "险入\n",
      "还订\n",
      "乱养\n",
      "拍来\n",
      "多米\n",
      "赵又廷家\n",
      "汪藏\n",
      "刮肠\n",
      "颜瘦\n",
      "燃脂消\n",
      "免死\n",
      "一清二\n",
      "中入\n",
      "这饭\n",
      "没吃够\n",
      "孙安佐\n",
      "没网\n",
      "人连\n",
      "何炅赠\n",
      "陈赫送\n",
      "好傲\n",
      "吃宿\n",
      "內湿外\n",
      "王凯会\n",
      "懂华哥\n",
      "看霍\n",
      "戏侃\n",
      "人骨脆\n",
      "重竟\n",
      "男骗\n",
      "脸往\n",
      "中颜值\n",
      "买安卓\n",
      "吴雨乐\n",
      "含龙根\n",
      "用会\n",
      "爱堵\n",
      "再厚\n",
      "音想\n",
      "中自\n",
      "幂别\n",
      "洋一\n",
      "因进\n",
      "款绿植\n",
      "几盘\n",
      "不和疑\n",
      "第一课\n",
      "nba4\n",
      "湖人于\n",
      "美肌道\n",
      "辱警\n",
      "再单\n",
      "栽柳\n",
      "添新丁\n",
      "自服\n",
      "心车\n",
      "混太惨\n",
      "金大谈\n",
      "一个巴掌拍不响\n",
      "q7suv\n",
      "刘宇宁\n",
      "跟国米\n",
      "佐菲\n",
      "光之国\n",
      "内近\n",
      "三批\n",
      "二模\n",
      "操碎\n",
      "心当\n",
      "迅颜值\n",
      "老去\n",
      "六七个\n",
      "谁造\n",
      "文晒\n",
      "爆夜会\n",
      "对娜\n",
      "长舒\n",
      "窦骁红\n",
      "味甜色\n",
      "甜靠\n",
      "主图\n",
      "款野\n",
      "钓大\n",
      "荒食\n",
      "空杆\n",
      "过狂\n",
      "大毛河\n",
      "磕碜\n",
      "聚鱼\n",
      "满篓\n",
      "黑坑\n",
      "野钓达\n",
      "学了\n",
      "狂钓\n",
      "枪天\n",
      "截指\n",
      "造双旗\n",
      "其属\n",
      "top8\n",
      "将助\n",
      "豪中\n",
      "控号\n",
      "擒下\n",
      "码到\n",
      "确成\n",
      "七乐彩\n",
      "期用\n",
      "亿奖池\n",
      "实单\n",
      "r2\n",
      "寿字币库\n",
      "号秀换\n",
      "造七钱\n",
      "一寿\n",
      "戏珠\n",
      "微博高仿\n",
      "给生\n",
      "手缺\n",
      "付辛\n",
      "婚中\n",
      "抢卓伟\n",
      "虽不劲\n",
      "困在\n",
      "克翔\n",
      "机后\n",
      "仁里场\n",
      "射个\n",
      "周铭孙\n",
      "胃火太大\n",
      "张瀚娜\n",
      "张瀚力\n",
      "挺娜\n",
      "某大\n",
      "喝刚\n",
      "说进\n",
      "公的母\n",
      "骁密会\n",
      "李沁爱得\n",
      "恋上娜\n",
      "荣置\n",
      "丝蛋\n",
      "吴昕疑\n",
      "更美配\n",
      "上塘主\n",
      "削骨\n",
      "脸会变\n",
      "钱治好\n",
      "招治好\n",
      "人鱼膏\n",
      "笑卿\n",
      "黄锦燊腻\n",
      "更红\n",
      "汪峰发\n",
      "脸露\n",
      "希版\n",
      "点上\n",
      "拒学\n",
      "望演\n",
      "毒王杰\n",
      "谈王杰\n",
      "害王杰\n",
      "卓伟别\n",
      "王杰毒\n",
      "因势\n",
      "卓伟认\n",
      "事明\n",
      "王杰别\n",
      "帮王杰\n",
      "谦迷\n",
      "为杰哥\n",
      "服卓伟\n",
      "破铁钱\n",
      "会高些\n",
      "给玲花\n",
      "疼竟\n",
      "会产\n",
      "淡印\n",
      "陈坤苦\n",
      "终得偿\n",
      "抖音款\n",
      "姐教\n",
      "想不白\n",
      "邹纹\n",
      "思加\n",
      "r1l77zv\n",
      "全不找\n",
      "大空\n",
      "將至\n",
      "結婚\n",
      "豪房\n",
      "团有\n",
      "传里\n",
      "博人传\n",
      "之槌\n",
      "不开森\n",
      "要辟\n",
      "跳个\n",
      "低时\n",
      "小三是\n",
      "計算\n",
      "機族\n",
      "殺手\n",
      "谢贤用\n",
      "价比\n",
      "直斥\n",
      "裤配\n",
      "誓为\n",
      "何震亚\n",
      "台媒成\n",
      "绿媒耍\n",
      "咬身\n",
      "每况\n",
      "日下\n",
      "24k\n",
      "驻美\n",
      "冯世宽\n",
      "语出\n",
      "厦金\n",
      "游看\n",
      "大担\n",
      "心战墙\n",
      "i8\n",
      "遭史\n",
      "拍碎\n",
      "四片\n",
      "😄\n",
      "采耳\n",
      "已无爱\n",
      "网传史\n",
      "译站\n",
      "读张\n",
      "食材常\n",
      "不省\n",
      "系老\n",
      "茶能解\n",
      "活羊\n",
      "种常\n",
      "会死星\n",
      "过水焯\n",
      "烹調\n",
      "中像\n",
      "同吃住\n",
      "同溜娃\n",
      "三十分钟\n",
      "立夏后\n",
      "种负\n",
      "第七篇\n",
      "一多二少\n",
      "越养越\n",
      "中晚\n",
      "五连县\n",
      "郝爱军\n",
      "圈传\n",
      "会染\n",
      "大驻\n",
      "莫沟\n",
      "村付\n",
      "活禽\n",
      "群热传\n",
      "辟得心\n",
      "已派\n",
      "吴小艳\n",
      "因吃扎旗\n",
      "三例\n",
      "彭兰妹\n",
      "什兰\n",
      "种会\n",
      "靓化\n",
      "补才\n",
      "豪吃\n",
      "微毒\n",
      "个杯面\n",
      "超辣\n",
      "种才\n",
      "果贩\n",
      "红大胃\n",
      "血变\n",
      "小柳岩\n",
      "网传用\n",
      "曝王丽坤林\n",
      "股现\n",
      "经粪口\n",
      "瓜能\n",
      "减盐防\n",
      "三高易\n",
      "jiekou\n",
      "社被\n",
      "十六元\n",
      "长竿\n",
      "疾控家\n",
      "食安办\n",
      "越酸\n",
      "华驼\n",
      "曼洛顿\n",
      "湖系\n",
      "张母案\n",
      "爆微信\n",
      "第五篇\n",
      "柚红\n",
      "柚为\n",
      "因戚\n",
      "胖丑\n",
      "n7n9\n",
      "人吃瓜\n",
      "生血\n",
      "之四\n",
      "辣会\n",
      "求长\n",
      "仨次\n",
      "晒得够\n",
      "存久\n",
      "闻味色\n",
      "飞单\n",
      "降一降\n",
      "瘦个\n",
      "听小益\n",
      "夫争\n",
      "约个\n",
      "事妈\n",
      "酸真会\n",
      "很肉\n",
      "太伤\n",
      "已顺\n",
      "期可\n",
      "看晚\n",
      "盗图\n",
      "卫楼\n",
      "深巴\n",
      "皮克破\n",
      "传宝能\n",
      "被证\n",
      "渔湖\n",
      "强拉上\n",
      "天喜\n",
      "药真\n",
      "中吸\n",
      "七周\n",
      "字吐槽\n",
      "五十年代\n",
      "一版\n",
      "零差评\n",
      "晒素颜\n",
      "弃孙俪\n",
      "范丞丞首\n",
      "得超\n",
      "拍凰\n",
      "已来\n",
      "云字辈\n",
      "改捧岳云鹏\n",
      "行里\n",
      "抢孙\n",
      "来涂\n",
      "开塞漉\n",
      "杜杜给\n",
      "次为\n",
      "走前\n",
      "杨柘怒\n",
      "血图\n",
      "太伏\n",
      "湖往\n",
      "真胖\n",
      "吸低\n",
      "开海\n",
      "爽爆\n",
      "腹产\n",
      "好快\n",
      "素颜甜\n",
      "补捐\n",
      "完月子\n",
      "脑越\n",
      "无爱\n",
      "脖会\n",
      "有川\n",
      "内变\n",
      "挖富\n",
      "开干\n",
      "不暴漏\n",
      "找张\n",
      "魏嬿婉\n",
      "徐坤开\n",
      "非官\n",
      "宣不认\n",
      "没降\n",
      "网传铁\n",
      "饼用\n",
      "赵丽颖来\n",
      "炮王\n",
      "170302\n",
      "热依扎\n",
      "亿秒领\n",
      "这事能\n",
      "假谢娜\n",
      "破娜昕\n",
      "崔敏静\n",
      "邓超能\n",
      "吴京首\n",
      "top100\n",
      "细八\n",
      "四根\n",
      "吴京淡\n",
      "难消\n",
      "微博后\n",
      "宜解\n",
      "女大\n",
      "气出\n",
      "教得\n",
      "某夜店\n",
      "同爸\n",
      "超遭\n",
      "当对\n",
      "恺乐\n",
      "有强\n",
      "四任\n",
      "两人座\n",
      "陈翔版\n",
      "掐点\n",
      "吴昕录\n",
      "日系风\n",
      "论颜值\n",
      "吴昕成\n",
      "爆到\n",
      "人咯\n",
      "问要\n",
      "脸强\n",
      "鑫娱\n",
      "何炅娜姐\n",
      "中隔空\n",
      "两不移\n",
      "赞张杰\n",
      "吴昕微\n",
      "男主脸\n",
      "我娜姐\n",
      "快本会\n",
      "没音\n",
      "却动\n",
      "美不输\n",
      "二十日\n",
      "更爱招\n",
      "点要\n",
      "几股\n",
      "黄不补\n",
      "之害\n",
      "指呆萌\n",
      "出柜恋\n",
      "疑出\n",
      "放马思纯\n",
      "第一眼\n",
      "两小口\n",
      "马思纯周\n",
      "某雅\n",
      "藏累\n",
      "对巴神\n",
      "林允狂\n",
      "微影\n",
      "梅威瑟\n",
      "笼打\n",
      "美队\n",
      "曝方\n",
      "同框秀\n",
      "形恋\n",
      "怒声\n",
      "tnf100\n",
      "反斥\n",
      "其手柱\n",
      "那英近\n",
      "周琦未\n",
      "有难\n",
      "坏习\n",
      "太多显\n",
      "三湾\n",
      "邢昭林方\n",
      "幽姬\n",
      "添品\n",
      "新劲刚\n",
      "牵迪丽\n",
      "比屎\n",
      "黑治黑\n",
      "鸡冻\n",
      "请君\n",
      "兰区\n",
      "江星村\n",
      "屠川后\n",
      "远昭\n",
      "旧米\n",
      "数杯\n",
      "艾神家\n",
      "必转\n",
      "样煮\n",
      "泡到\n",
      "一洒\n",
      "算个\n",
      "诉微\n",
      "特书\n",
      "请马云\n",
      "重瑞有\n",
      "重瑞比\n",
      "拥右护\n",
      "听迟\n",
      "重瑞说\n",
      "警为\n",
      "日为\n",
      "96766\n",
      "日微博\n",
      "看星爷\n",
      "屯镇\n",
      "阿娇恋\n",
      "挥肘\n",
      "东茛\n",
      "忌用\n",
      "财纹\n",
      "坐洋币\n",
      "骑记\n",
      "小蓝车\n",
      "奶会变\n",
      "坑妈\n",
      "非她莫属\n",
      "宗罪\n",
      "过迪丽\n",
      "传唐\n",
      "风超美\n",
      "四美同\n",
      "晋嫣恋\n",
      "类微博\n",
      "爆罗晋\n",
      "幂糖\n",
      "180114\n",
      "跟罗晋\n",
      "刘空清\n",
      "黑文\n",
      "自出\n",
      "遭深\n",
      "后仅用\n",
      "以特币\n",
      "哈弗高\n",
      "塔神\n",
      "好赛\n",
      "涉独\n",
      "第一句\n",
      "博破\n",
      "波狗\n",
      "带罗\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成罗晋\n",
      "网传罗\n",
      "中奥\n",
      "共著\n",
      "几页\n",
      "翔疑\n",
      "争足\n",
      "整死\n",
      "几座\n",
      "某天团\n",
      "有悲\n",
      "太初\n",
      "冲电\n",
      "赵丽颖张\n",
      "粉捞\n",
      "许华升\n",
      "宝想\n",
      "可颜值\n",
      "差太多\n",
      "满盆满\n",
      "赵丽颖开\n",
      "赚足\n",
      "水酿\n",
      "鸡鸟\n",
      "当糖\n",
      "卡喉\n",
      "请范伟\n",
      "恐只\n",
      "互骂\n",
      "吴亦凡用\n",
      "科粉\n",
      "清怒\n",
      "薛之谦买\n",
      "臀九女\n",
      "扎为助\n",
      "女宠\n",
      "签詹皇\n",
      "无香\n",
      "小迷弟\n",
      "杨洋刚\n",
      "话现\n",
      "杨洋正\n",
      "茉上\n",
      "一缸\n",
      "杨洋竟\n",
      "亲小爽\n",
      "井柏然史\n",
      "郑爽表\n",
      "杨洋狂\n",
      "后醉驾\n",
      "李慧林\n",
      "致钙\n",
      "湿仓\n",
      "天给\n",
      "药流\n",
      "夏热特\n",
      "网红科迪\n",
      "显瘦变\n",
      "出牙晚\n",
      "对会\n",
      "中脂\n",
      "起反\n",
      "过多时\n",
      "越苦\n",
      "大茶\n",
      "超贊\n",
      "超強\n",
      "酒风\n",
      "别多\n",
      "精元\n",
      "脑里\n",
      "追弗神\n",
      "化骨龙\n",
      "叫食\n",
      "绿瘦\n",
      "磨膝\n",
      "吞饭\n",
      "素会致\n",
      "咳不治\n",
      "种好物\n",
      "如石\n",
      "天硬\n",
      "一碰酒\n",
      "脸不红\n",
      "头不晕\n",
      "而应\n",
      "怒提\n",
      "之辱\n",
      "一游\n",
      "生三女\n",
      "中因\n",
      "杨紫为\n",
      "设要\n",
      "拍战\n",
      "迷妹们\n",
      "关爸\n",
      "宝沃要\n",
      "头长\n",
      "16607346286\n",
      "真矿\n",
      "拘一人\n",
      "对越\n",
      "需厚植\n",
      "血溅\n",
      "刀围\n",
      "币算力\n",
      "脸中\n",
      "最蠢萌\n",
      "大未\n",
      "变尖\n",
      "胸比\n",
      "赵丽颖大\n",
      "力捧连\n",
      "如孙俪\n",
      "脸获\n",
      "雷哭\n",
      "赵丽颖大脸\n",
      "穿乳环\n",
      "脸大眼\n",
      "赵丽颖旧\n",
      "赵丽颖火\n",
      "赵丽颖素\n",
      "王嘉尔要\n",
      "胖回\n",
      "脸现\n",
      "图惊现\n",
      "赵丽颖逆袭\n",
      "整美\n",
      "停戏\n",
      "课上\n",
      "电揽\n",
      "邵家桥\n",
      "日站\n",
      "正办\n",
      "内不受\n",
      "换特雷\n",
      "文旅部\n",
      "骚男\n",
      "日众\n",
      "日举国\n",
      "道准\n",
      "说华仔\n",
      "护犊\n",
      "施一公因\n",
      "起贷\n",
      "曝施\n",
      "一公因\n",
      "牵绳\n",
      "器来\n",
      "出会\n",
      "可离\n",
      "比蔚\n",
      "领帅\n",
      "urus\n",
      "这台家\n",
      "纸糊车\n",
      "开不烂\n",
      "翻增\n",
      "89413\n",
      "万想\n",
      "传祺给\n",
      "入内\n",
      "变豪车\n",
      "变双\n",
      "太挺\n",
      "团内互\n",
      "整没整\n",
      "替千玺\n",
      "妖猫\n",
      "研可\n",
      "朗动\n",
      "仨孩\n",
      "胆肥\n",
      "撩汉大\n",
      "桦褐孔菌\n",
      "竟神\n",
      "内惊现\n",
      "快种\n",
      "戒忧\n",
      "s500\n",
      "印找\n",
      "平趟\n",
      "荒信\n",
      "称池\n",
      "忠国\n",
      "董翰麟\n",
      "需经\n",
      "新帅雅\n",
      "继恒大\n",
      "巴坎布\n",
      "权健恒大才\n",
      "恒大狂\n",
      "购纳\n",
      "因格兰\n",
      "恒大过\n",
      "若纳斯\n",
      "继黄子\n",
      "三回\n",
      "多厚\n",
      "风百碟\n",
      "骑过\n",
      "谢娜整\n",
      "剪肉\n",
      "张瘦\n",
      "碱肥\n",
      "类不含\n",
      "很乖\n",
      "界竟\n",
      "皮淡定\n",
      "因凡\n",
      "忙点\n",
      "寄诚\n",
      "签后\n",
      "唐璧华\n",
      "前真龙\n",
      "真龙终\n",
      "擒龙\n",
      "男圆肚\n",
      "還淡斑\n",
      "同喝\n",
      "如夜\n",
      "乌如润墨\n",
      "黑得加\n",
      "亿三大\n",
      "签预\n",
      "微博靠\n",
      "黑钻要\n",
      "不淫\n",
      "可种\n",
      "两批\n",
      "一建四改\n",
      "被施\n",
      "打大呼\n",
      "黑牛\n",
      "小浩宇\n",
      "飞近\n",
      "脸像\n",
      "微信常\n",
      "外治\n",
      "死十人\n",
      "鉴江\n",
      "某权\n",
      "书恒\n",
      "如萍\n",
      "雪姨成\n",
      "因谢贤\n",
      "两人下\n",
      "曝欲\n",
      "几代\n",
      "未发\n",
      "闺蜜应\n",
      "卢靖姗要\n",
      "太多竟\n",
      "错床\n",
      "清忙\n",
      "几十亿美元\n",
      "201804\n",
      "互关\n",
      "不后\n",
      "五连板\n",
      "超柘中\n",
      "亿筑底\n",
      "真多得\n",
      "侵虐\n",
      "男主带\n",
      "提兰城\n",
      "异人族\n",
      "多该\n",
      "这擦\n",
      "该进\n",
      "來時\n",
      "機會\n",
      "詹皇明\n",
      "逃不脱\n",
      "中大有\n",
      "后代子孙\n",
      "主贵且\n",
      "隋国扬\n",
      "将分\n",
      "涨不涨\n",
      "梁全\n",
      "两三口\n",
      "力三高\n",
      "做车\n",
      "款豪车\n",
      "谎记\n",
      "发苦应\n",
      "个宝\n",
      "反香\n",
      "净肠肤\n",
      "加太满油\n",
      "领动\n",
      "子餐\n",
      "如过\n",
      "天淡\n",
      "斑妙\n",
      "cellcure\n",
      "用能\n",
      "其理\n",
      "当十极\n",
      "福義\n",
      "胃全\n",
      "坐久\n",
      "粗腿麻\n",
      "十辈子\n",
      "串个\n",
      "已亮\n",
      "炒得\n",
      "有广東\n",
      "水叫\n",
      "17817938090\n",
      "价各是\n",
      "伤肤\n",
      "有多烦\n",
      "男云\n",
      "没爆\n",
      "咬过\n",
      "以热\n",
      "吃店\n",
      "袪暑\n",
      "护心防\n",
      "一苦\n",
      "一甜\n",
      "利胃\n",
      "小满要\n",
      "解喉\n",
      "祛湿要\n",
      "养颜汤\n",
      "叙军\n",
      "勇减\n",
      "科丽客\n",
      "补维\n",
      "胃涤肠\n",
      "而定\n",
      "菜堪\n",
      "多一点\n",
      "如真\n",
      "鹿晗们\n",
      "角中\n",
      "有藏友\n",
      "愿花\n",
      "分其\n",
      "赵薇会\n",
      "立夫\n",
      "亿赵薇\n",
      "亲哥\n",
      "费高达\n",
      "陈蓉分\n",
      "论有\n",
      "费引人\n",
      "赵嫂\n",
      "费引\n",
      "小卡妹\n",
      "费值\n",
      "只为争\n",
      "辣鸡\n",
      "狂收\n",
      "清暴\n",
      "假料\n",
      "遭三人\n",
      "正会\n",
      "天送\n",
      "晚到\n",
      "两句\n",
      "必配\n",
      "当误\n",
      "单遭\n",
      "天不干\n",
      "这差\n",
      "评太\n",
      "多一份\n",
      "哥雨\n",
      "音摆\n",
      "doinb\n",
      "或进\n",
      "可夺\n",
      "几百公斤\n",
      "咬死条\n",
      "进青系\n",
      "外媒爆\n",
      "太大遭\n",
      "中俄有\n",
      "前真\n",
      "蠢到\n",
      "小诺要\n",
      "黑超特警\n",
      "或藏\n",
      "所救\n",
      "逗比\n",
      "塔电死\n",
      "百块\n",
      "肝会\n",
      "抛肉\n",
      "又助\n",
      "染对\n",
      "先别染\n",
      "助糖友\n",
      "听坑\n",
      "转胎\n",
      "真晕\n",
      "加一菜\n",
      "喝牛\n",
      "叁次\n",
      "意媒称\n",
      "陈晓帽\n",
      "李志玲\n",
      "配美照\n",
      "疼存\n",
      "姜允儿\n",
      "满色\n",
      "翡料\n",
      "黑乌沙\n",
      "蜡皮\n",
      "高冰阳\n",
      "糯冰\n",
      "高冰飘花\n",
      "抽六包\n",
      "区禾\n",
      "瞎染\n",
      "限古令\n",
      "造限\n",
      "前大骂\n",
      "首签\n",
      "韩颖华神\n",
      "锐界\n",
      "座仅\n",
      "锋菲恋终\n",
      "车卖\n",
      "有小三且\n",
      "媒记\n",
      "均系\n",
      "亿向\n",
      "如刀\n",
      "戏红到\n",
      "冯叔换\n",
      "疑见\n",
      "产检及\n",
      "孕妈会\n",
      "前得\n",
      "停刷\n",
      "三层楼\n",
      "挖回\n",
      "有记\n",
      "别有\n",
      "肌密\n",
      "pvdc\n",
      "标哥\n",
      "富氢水\n",
      "后酷\n",
      "刚连上\n",
      "药钱省\n",
      "补肝益\n",
      "太亏\n",
      "可通\n",
      "用头\n",
      "碰瓷界\n",
      "用维\n",
      "天清肠治\n",
      "瞬发\n",
      "列全\n",
      "听川普\n",
      "遭限犬办\n",
      "发已\n",
      "升油\n",
      "挖人\n",
      "这得省\n",
      "超牛\n",
      "马云年\n",
      "需回\n",
      "有纸\n",
      "吸纸\n",
      "模小\n",
      "放钱\n",
      "很满\n",
      "新配\n",
      "另均\n",
      "一百多斤\n",
      "腥版\n",
      "狂道\n",
      "下杆\n",
      "一护\n",
      "作钓\n",
      "钓草\n",
      "一射\n",
      "诱鱼\n",
      "然是\n",
      "美品\n",
      "郫都区\n",
      "护妻护\n",
      "首谈要\n",
      "惊言\n",
      "六位数\n",
      "实经\n",
      "挣快\n",
      "伤系\n",
      "致两死\n",
      "赵丽颖学江\n",
      "玩下衣\n",
      "油治\n",
      "扭一扭\n",
      "美白消\n",
      "神瓜\n",
      "越显\n",
      "有养颜\n",
      "肤抗\n",
      "养颜有\n",
      "可美\n",
      "不水润\n",
      "款养颜\n",
      "养颜越\n",
      "香到\n",
      "最宠\n",
      "种藏\n",
      "掰点\n",
      "太高降\n",
      "老靠\n",
      "有三高\n",
      "时泡\n",
      "别光\n",
      "甜饮\n",
      "吃二口\n",
      "治肾\n",
      "太渣\n",
      "亿债\n",
      "素颜未\n",
      "不清\n",
      "三头\n",
      "走顶\n",
      "一红\n",
      "那英遇\n",
      "字淡定\n",
      "他险\n",
      "因火\n",
      "哥是\n",
      "嫩照\n",
      "齐三磊\n",
      "当回\n",
      "发飚\n",
      "说太累\n",
      "没微博\n",
      "小耳朵\n",
      "要票\n",
      "抓疑\n",
      "出王\n",
      "小飛象\n",
      "吓孕妈\n",
      "王俊奇\n",
      "秦奋狂\n",
      "秦奋称\n",
      "力挺思聪\n",
      "再受\n",
      "滥玩\n",
      "真能防\n",
      "七段\n",
      "这下松\n",
      "150331\n",
      "区火\n",
      "只爱天\n",
      "掉品\n",
      "会当\n",
      "逼退\n",
      "另一边\n",
      "总于\n",
      "我事\n",
      "显大似\n",
      "第七期\n",
      "人赞\n",
      "变臭\n",
      "从洪到\n",
      "连傻子\n",
      "四晚\n",
      "好时\n",
      "qjy\n",
      "傻到\n",
      "同看\n",
      "共筑\n",
      "校霸\n",
      "谋朝\n",
      "马辣\n",
      "有娃\n",
      "有肥\n",
      "十多亿\n",
      "茶语\n",
      "娃上\n",
      "脚是\n",
      "难瘦\n",
      "阿讯\n",
      "军级\n",
      "数周\n",
      "男主遇\n",
      "北赵\n",
      "胡歌苦\n",
      "视后\n",
      "五倍\n",
      "帕卡致\n",
      "比挂\n",
      "熟茶\n",
      "挑人\n",
      "养肝同\n",
      "肝性\n",
      "全部排\n",
      "身死\n",
      "这口\n",
      "切咧\n",
      "仔想演\n",
      "围头湾\n",
      "多生\n",
      "首起涉\n",
      "郝永刚\n",
      "交规新\n",
      "蛆状\n",
      "下证\n",
      "搜买\n",
      "事半功\n",
      "171114\n",
      "胖兰\n",
      "交季\n",
      "此菜\n",
      "稳不\n",
      "料能\n",
      "要糊\n",
      "张翰素\n",
      "因帮\n",
      "因帮人\n",
      "问鹿晗\n",
      "海淘族\n",
      "迅近\n",
      "名姐\n",
      "阿迅\n",
      "千百万年\n",
      "之心\n",
      "白宇辰\n",
      "臭手\n",
      "几亿年\n",
      "中买\n",
      "一兆兆吨\n",
      "亿多年\n",
      "再升\n",
      "度会\n",
      "出能\n",
      "驾案\n",
      "做局\n",
      "被代驾\n",
      "骗系\n",
      "现碰瓷\n",
      "下阵\n",
      "精方\n",
      "源起\n",
      "我震\n",
      "四倍\n",
      "网传假\n",
      "黑分\n",
      "能润发\n",
      "染用\n",
      "老掉\n",
      "用神香\n",
      "翻女\n",
      "女宝来\n",
      "富区\n",
      "红岸\n",
      "波隆\n",
      "石梁子\n",
      "看洪\n",
      "盐鸿卖\n",
      "数到\n",
      "菅韧\n",
      "姿进\n",
      "瑞要\n",
      "万比速腾\n",
      "加四驱\n",
      "万比轩\n",
      "比朗逸\n",
      "惊坏\n",
      "产检获\n",
      "白鞋\n",
      "谢依\n",
      "拒中超\n",
      "过夏窗\n",
      "购马斯切\n",
      "帕托受\n",
      "没夺牌\n",
      "美规版\n",
      "现仅售\n",
      "720s\n",
      "这下值\n",
      "乳能\n",
      "岁常\n",
      "立春后\n",
      "講究\n",
      "茶葉\n",
      "款養\n",
      "飲大\n",
      "推薦\n",
      "餐间\n",
      "不老米\n",
      "处别\n",
      "这粉\n",
      "炫方\n",
      "做次\n",
      "车晓只\n",
      "化积\n",
      "很水\n",
      "需抹点\n",
      "既显\n",
      "天收\n",
      "掺来\n",
      "最痛\n",
      "重易\n",
      "越贵\n",
      "炮水\n",
      "配假\n",
      "生错\n",
      "即贵\n",
      "最克夫\n",
      "最讨\n",
      "越会\n",
      "值越\n",
      "心澄子\n",
      "重成\n",
      "扑身\n",
      "刚偷\n",
      "因维嘉\n",
      "超甜超\n",
      "音痴\n",
      "似阔\n",
      "疗情\n",
      "补天\n",
      "奇不奇\n",
      "福兆\n",
      "土到\n",
      "打隐翅虫会\n",
      "十多个\n",
      "参有\n",
      "中飘着\n",
      "数只\n",
      "立新功\n",
      "这超\n",
      "曝罗志祥豪\n",
      "万购\n",
      "亿置\n",
      "罗志祥购\n",
      "那英竟\n",
      "宏路\n",
      "两团\n",
      "火团\n",
      "十遍\n",
      "用拔\n",
      "大量排\n",
      "病要\n",
      "越好车\n",
      "咖对戏\n",
      "前谈\n",
      "不生个\n",
      "删旧\n",
      "肚儿\n",
      "咱老\n",
      "孕装\n",
      "甜馨秀\n",
      "pgtwo\n",
      "遮肚\n",
      "手比\n",
      "愿要\n",
      "称生\n",
      "刘艳芬\n",
      "搭过\n",
      "阙清子\n",
      "备孕禁\n",
      "丢狗后\n",
      "元终\n",
      "妈来\n",
      "影艺圈\n",
      "以手护\n",
      "肚似\n",
      "改微\n",
      "没逃过\n",
      "標示\n",
      "方為\n",
      "马云道\n",
      "丑穷\n",
      "伴过\n",
      "地玩过\n",
      "尴聊\n",
      "无攻\n",
      "隔一人\n",
      "频谈\n",
      "挺忙\n",
      "结离须\n",
      "疑其为\n",
      "更爱\n",
      "招撇\n",
      "幂首\n",
      "几线\n",
      "朱茵用\n",
      "男来\n",
      "幂式\n",
      "脸美\n",
      "急问\n",
      "宇春父\n",
      "因拒\n",
      "撕刀郎\n",
      "骗心\n",
      "骗身\n",
      "火而\n",
      "发张\n",
      "英交\n",
      "这水\n",
      "清肠法\n",
      "肉大招\n",
      "最块\n",
      "开超\n",
      "f5\n",
      "带四驱\n",
      "不输汉兰达\n",
      "颜值帅\n",
      "一万公里\n",
      "伪豪\n",
      "就塞到\n",
      "看朗逸\n",
      "310w\n",
      "v8\n",
      "涂乐\n",
      "再令\n",
      "比锐界\n",
      "感不输\n",
      "评车\n",
      "还拉风\n",
      "感有\n",
      "全触\n",
      "车颜值\n",
      "系要\n",
      "活都\n",
      "讽丽颖\n",
      "欺志玲\n",
      "最清\n",
      "带美瞳\n",
      "湿分\n",
      "冰桶\n",
      "广裕街\n",
      "缓嫁\n",
      "渤哥\n",
      "超甜志玲\n",
      "疑锋菲\n",
      "迅疑\n",
      "迅受\n",
      "迅要\n",
      "喜夜\n",
      "无子成\n",
      "断过\n",
      "这事定\n",
      "爱而活\n",
      "关难\n",
      "无子山\n",
      "剩豪车\n",
      "高圣远常\n",
      "同高\n",
      "疑陷\n",
      "终造\n",
      "禁聊\n",
      "爆周\n",
      "四旦\n",
      "迅方\n",
      "迅会\n",
      "脸真厚\n",
      "迅吗\n",
      "生娃娃\n",
      "亿肥\n",
      "婚补\n",
      "份力\n",
      "福剑\n",
      "太想\n",
      "喜领\n",
      "妈用\n",
      "跟云\n",
      "马廷江\n",
      "验胎\n",
      "人怀\n",
      "斐讯要\n",
      "马云梁\n",
      "橘猫\n",
      "愿下\n",
      "富纹\n",
      "206041718\n",
      "男是\n",
      "一灾\n",
      "有福人\n",
      "多命\n",
      "这六字\n",
      "反舰\n",
      "圈炸\n",
      "某微\n",
      "仔撑\n",
      "欠花\n",
      "雪炫\n",
      "要染\n",
      "用针\n",
      "挑掉\n",
      "u2\n",
      "疯传微\n",
      "中致\n",
      "巨阴\n",
      "单针\n",
      "证系\n",
      "一无牌\n",
      "曼朱\n",
      "男遭\n",
      "有小编\n",
      "佩为\n",
      "多组\n",
      "欧豪为\n",
      "巨门\n",
      "亿签\n",
      "利徒\n",
      "脸林允\n",
      "消身\n",
      "情订\n",
      "办个\n",
      "炖奶\n",
      "博变身\n",
      "还愁\n",
      "变裸替\n",
      "宠猫\n",
      "如能\n",
      "可防脫\n",
      "闻味识\n",
      "立大功\n",
      "风苓\n",
      "求娜\n",
      "因娜\n",
      "房凝似\n",
      "张钧蜜\n",
      "这一吻\n",
      "傍上\n",
      "因情\n",
      "别想进\n",
      "网爆纪\n",
      "下家来\n",
      "太特\n",
      "一陪\n",
      "李晨分\n",
      "戏博\n",
      "团隔\n",
      "空力\n",
      "熊乃瑾购\n",
      "两三层\n",
      "祛湿消\n",
      "招排\n",
      "立夏有\n",
      "纺衫\n",
      "太大减\n",
      "滞住\n",
      "腰侧\n",
      "减油\n",
      "小一姐\n",
      "因爱起\n",
      "黑近\n",
      "破哭\n",
      "我颜值\n",
      "杨颖自\n",
      "家出\n",
      "小璐家\n",
      "因唱\n",
      "新食局\n",
      "进雄安\n",
      "之贵\n",
      "马云辟\n",
      "经信委\n",
      "亿在\n",
      "小蚁\n",
      "靠接\n",
      "首嫁\n",
      "丽对\n",
      "地像\n",
      "已秘\n",
      "爆后\n",
      "两人见\n",
      "niel\n",
      "劝婚\n",
      "圣扮\n",
      "只生\n",
      "性寒易\n",
      "爆早\n",
      "服对\n",
      "多翅多\n",
      "尿得\n",
      "吹多会\n",
      "三海\n",
      "网传颍东\n",
      "树偷\n",
      "谢旗营\n",
      "麦明\n",
      "侵遭\n",
      "第三度\n",
      "肾功\n",
      "张艳家\n",
      "证全\n",
      "品蟹\n",
      "办张\n",
      "玩一玩\n",
      "孕检时\n",
      "那孕妈\n",
      "需营\n",
      "肉生\n",
      "会滑胎\n",
      "买豪车\n",
      "再引\n",
      "争破头\n",
      "太大意\n",
      "第三件\n",
      "种孕妈\n",
      "骨瘦如材\n",
      "最养胎\n",
      "孙像\n",
      "上六下\n",
      "团中\n",
      "邓超怒\n",
      "闫学晶谈\n",
      "强林丹\n",
      "盼夕\n",
      "信痛\n",
      "圆版\n",
      "洞主\n",
      "克拜峰\n",
      "位面\n",
      "脸胖\n",
      "张翰强\n",
      "时倒点\n",
      "13596783427\n",
      "成实外\n",
      "再学\n",
      "卡及\n",
      "梁伟瑜\n",
      "梅内塞\n",
      "一大截\n",
      "称清\n",
      "房何\n",
      "發燒\n",
      "降溫\n",
      "五種\n",
      "爆王鸥\n",
      "小脏\n",
      "神床\n",
      "何炅于\n",
      "眼痛\n",
      "用口\n",
      "趴睡\n",
      "裤会\n",
      "种点\n",
      "扔颗\n",
      "二十五年\n",
      "怪树\n",
      "三郎\n",
      "树高仅\n",
      "芦丁有\n",
      "火菜\n",
      "跟队\n",
      "韩餐\n",
      "瑞思迈\n",
      "别向\n",
      "刁然\n",
      "开借\n",
      "三高降\n",
      "可白过\n",
      "不侵\n",
      "一波儿\n",
      "一绿萝花\n",
      "完一查\n",
      "藏石\n",
      "万多块\n",
      "欲放\n",
      "马大哥\n",
      "缅币\n",
      "一补\n",
      "五遍\n",
      "\n",
      "茶威\n",
      "chx19820524\n",
      "中太\n",
      "说收\n",
      "交吧\n",
      "溫度\n",
      "萬億度\n",
      "立馬產黃金\n",
      "吞恆星\n",
      "请关\n",
      "神将\n",
      "令莫雷\n",
      "拒送\n",
      "前六已\n",
      "怀德桥吾悦\n",
      "粉粹机\n",
      "仙要\n",
      "共设\n",
      "受马蓉\n",
      "撕马蓉\n",
      "听张\n",
      "胜多\n",
      "负少\n",
      "枣片\n",
      "天吃出\n",
      "头用\n",
      "天如\n",
      "太多要\n",
      "匹林同\n",
      "配阿司\n",
      "水里系\n",
      "锁桩\n",
      "咱不背\n",
      "淹会\n",
      "蒋坑\n",
      "二楼\n",
      "变票\n",
      "两人恐\n",
      "接马蓉\n",
      "太污\n",
      "证清\n",
      "现遭\n",
      "宋喆后\n",
      "景甜用\n",
      "微博艾特\n",
      "真连\n",
      "非王\n",
      "病中\n",
      "宋喆怒\n",
      "强终\n",
      "敌马蓉\n",
      "第一把\n",
      "等言伦\n",
      "谈马蓉\n",
      "半口\n",
      "九辰\n",
      "除防\n",
      "程野宋\n",
      "争峰\n",
      "军会\n",
      "黄圣衣\n",
      "曝星爷\n",
      "葛素珍\n",
      "人父\n",
      "妈比\n",
      "孙俪来\n",
      "轨才\n",
      "桌伟要\n",
      "爆邓\n",
      "轨江\n",
      "一燕\n",
      "同剧\n",
      "好虐\n",
      "捧作\n",
      "那篇\n",
      "将行\n",
      "赌上\n",
      "眼伤\n",
      "分能\n",
      "深脑\n",
      "宁继春\n",
      "两草\n",
      "一果\n",
      "fm1076\n",
      "复传\n",
      "别以\n",
      "撒钱\n",
      "打不死\n",
      "药治\n",
      "阿左旗\n",
      "六翅鸡\n",
      "已因\n",
      "正对\n",
      "石硫\n",
      "翻价\n",
      "后越\n",
      "此数\n",
      "因孕妈\n",
      "总穿\n",
      "肿成\n",
      "长不胖\n",
      "一滚\n",
      "防刺\n",
      "六件\n",
      "柚柚妹\n",
      "会坑\n",
      "宝妈图\n",
      "点不输\n",
      "出牙期\n",
      "双待版\n",
      "超窄\n",
      "黄橙褐\n",
      "强讨\n",
      "所忧\n",
      "所扰\n",
      "肉知\n",
      "肉肉长\n",
      "总饿\n",
      "研特膳\n",
      "美白治\n",
      "事竟\n",
      "种暴\n",
      "腹婆变\n",
      "四分钟\n",
      "帅哥美女\n",
      "周暴\n",
      "招就够\n",
      "很痛\n",
      "版币\n",
      "五六米\n",
      "撞断\n",
      "数个\n",
      "上实\n",
      "奈飞\n",
      "分许\n",
      "几间\n",
      "拍剧\n",
      "早火\n",
      "不抱\n",
      "好于\n",
      "共破\n",
      "核裂\n",
      "新核\n",
      "中天微\n",
      "商乐鑫\n",
      "博主刚\n",
      "马云超\n",
      "直咒\n",
      "两百多\n",
      "粒药\n",
      "误开\n",
      "之敌\n",
      "拼酒\n",
      "急征\n",
      "水里配\n",
      "如脂\n",
      "乔欣撞\n",
      "补肽\n",
      "上值\n",
      "猛翻\n",
      "卖套\n",
      "五千块\n",
      "胖哥教\n",
      "睡易\n",
      "钱制\n",
      "造因\n",
      "我领\n",
      "说领\n",
      "拆太早\n",
      "需一土\n",
      "门引\n",
      "一长\n",
      "黏锅\n",
      "愁教\n",
      "总粘锅\n",
      "爱簪\n",
      "放闪\n",
      "真狠\n",
      "王思聪独\n",
      "十一点\n",
      "极酸\n",
      "男卑\n",
      "王一博刚\n",
      "爆与富\n",
      "网传富\n",
      "常搓\n",
      "能能\n",
      "往死里\n",
      "富氧\n",
      "带货王\n",
      "第一轮\n",
      "弊利\n",
      "眼用\n",
      "胆够\n",
      "劝颖宝\n",
      "驱豪车\n",
      "董洁素\n",
      "颜逛\n",
      "票债\n",
      "刚判\n",
      "疑谢娜\n",
      "提告\n",
      "辣眼照\n",
      "你学\n",
      "抢座\n",
      "版路\n",
      "十几万元\n",
      "关晓彤会\n",
      "买彩\n",
      "立翻\n",
      "价翻\n",
      "两三倍\n",
      "马云哥\n",
      "t600\n",
      "陈学冬靠\n",
      "洪币\n",
      "十都\n",
      "kfc200\n",
      "亲别\n",
      "茶治\n",
      "太愁\n",
      "猛虫\n",
      "谢他\n",
      "比小\n",
      "杀抖音\n",
      "抖音成\n",
      "装逼犯\n",
      "网红前\n",
      "不玩抖音\n",
      "何展\n",
      "咬会学\n",
      "9g\n",
      "竟不腐\n",
      "称不实\n",
      "出队\n",
      "屏坏\n",
      "换屏\n",
      "拍张\n",
      "欲意\n",
      "照显\n",
      "岁志玲\n",
      "志玲姐\n",
      "狼真来\n",
      "志林\n",
      "会和志玲\n",
      "求江\n",
      "韩媒错\n",
      "补刀键\n",
      "论雷军\n",
      "检单\n",
      "赵丽颖过\n",
      "赵丽颖选\n",
      "片配\n",
      "润亮\n",
      "前加\n",
      "送人\n",
      "竟翻\n",
      "翻长\n",
      "天在\n",
      "别染来\n",
      "染去\n",
      "切抹\n",
      "酷奴\n",
      "只染\n",
      "抹发\n",
      "乌似\n",
      "五十文\n",
      "亿高\n",
      "指带\n",
      "吴绮莉近\n",
      "其丑\n",
      "陈晓已\n",
      "竟干\n",
      "哥欠\n",
      "最易招\n",
      "宁惹\n",
      "必垮\n",
      "疑谈\n",
      "何炅大呼\n",
      "仍不敌\n",
      "越排\n",
      "牛货\n",
      "非布司\n",
      "曝前\n",
      "胜富力\n",
      "要常来\n",
      "生两\n",
      "未以\n",
      "裸亡\n",
      "人懵圈\n",
      "长贵\n",
      "新交规类\n",
      "男主拟\n",
      "期侍\n",
      "替下\n",
      "成女主\n",
      "竟以\n",
      "演不看\n",
      "但颖\n",
      "临京\n",
      "微博消\n",
      "dade\n",
      "pyl\n",
      "悟州\n",
      "旺城\n",
      "破谣\n",
      "迷昏药\n",
      "可直联\n",
      "桂康\n",
      "孟庆君\n",
      "滁新\n",
      "贴系\n",
      "虾里\n",
      "龙屯桥\n",
      "街有\n",
      "几伙\n",
      "懂别\n",
      "网遭\n",
      "疯传六景\n",
      "一粤\n",
      "遭本尊\n",
      "已多地\n",
      "三卷\n",
      "王云慧\n",
      "肖家洞\n",
      "唐山限行\n",
      "网传黎溪\n",
      "鸢飞路\n",
      "香岸\n",
      "传苟家井\n",
      "爆金句\n",
      "岳云鹏方\n",
      "输个\n",
      "岳张\n",
      "成楚\n",
      "认下\n",
      "继大\n",
      "三荷\n",
      "岳幕\n",
      "输在\n",
      "睡遍\n",
      "看正解\n",
      "炮高\n",
      "歪果\n",
      "发推特\n",
      "系扰序\n",
      "没疤\n",
      "已晒出\n",
      "小憨哥\n",
      "为华哥\n",
      "配醋\n",
      "斗及\n",
      "怀备\n",
      "后大谈生\n",
      "森碟\n",
      "王诗龄录\n",
      "完壮\n",
      "张继科领\n",
      "个换\n",
      "组讯\n",
      "小警\n",
      "菜水\n",
      "完米\n",
      "变柔\n",
      "七十三岁\n",
      "草水加\n",
      "老大夫\n",
      "已悄\n",
      "北控队\n",
      "签格列\n",
      "内马尔该\n",
      "因梅西\n",
      "内马尔要\n",
      "scbox\n",
      "血虐\n",
      "魏建伟\n",
      "日呼\n",
      "虾膏\n",
      "已下\n",
      "必疯传\n",
      "gsx\n",
      "妖机\n",
      "莫传\n",
      "种汤\n",
      "烧不熟\n",
      "胶和水\n",
      "种蕉\n",
      "用立\n",
      "总上\n",
      "2o18\n",
      "将刻\n",
      "添上\n",
      "前不焯\n",
      "常吃易\n",
      "大隐婚\n",
      "门竟\n",
      "台补刀\n",
      "王思聪千等\n",
      "吃泰迪\n",
      "期应禁\n",
      "整惨\n",
      "m4\n",
      "m16\n",
      "老多人\n",
      "b12\n",
      "重都\n",
      "茶解\n",
      "站本\n",
      "当钱花\n",
      "不愿取\n",
      "真脏\n",
      "遭其怒\n",
      "那码\n",
      "壕发\n",
      "官微博\n",
      "妖性\n",
      "亿吸\n",
      "筹锁\n",
      "李湘自\n",
      "差看\n",
      "指渣\n",
      "株树\n",
      "案系\n",
      "正安一\n",
      "惹人泪\n",
      "胃菌\n",
      "处会\n",
      "万寻子\n",
      "遭行\n",
      "逃费\n",
      "名高\n",
      "可住\n",
      "进新家\n",
      "土妙\n",
      "帮新家\n",
      "同城化\n",
      "出妙\n",
      "信嘛\n",
      "后同\n",
      "炸口\n",
      "想迁\n",
      "幂家似\n",
      "杰伦志颖家\n",
      "已逼平\n",
      "拥四坐\n",
      "李莹盈\n",
      "b2b\n",
      "未得\n",
      "詹皇狂\n",
      "将享\n",
      "要限贷\n",
      "万于\n",
      "八位\n",
      "郭德纲成\n",
      "服张\n",
      "十九代\n",
      "人恐\n",
      "郭净\n",
      "安纳达\n",
      "微博系\n",
      "t700\n",
      "太悬\n",
      "神谭\n",
      "醉泥\n",
      "备上\n",
      "曝备\n",
      "伪卡多\n",
      "新交规来\n",
      "袭州城\n",
      "暗生\n",
      "微博表\n",
      "比马\n",
      "郑爽边\n",
      "微博突\n",
      "李雪静\n",
      "连款\n",
      "冲蛋会\n",
      "彩巢\n",
      "南仙城\n",
      "分扣证\n",
      "嘲张翰\n",
      "湿性\n",
      "陈晓欲退\n",
      "张一山引\n",
      "好圈\n",
      "爆张\n",
      "柒个\n",
      "超多\n",
      "发实\n",
      "多料\n",
      "撩到\n",
      "登快\n",
      "疑患癌\n",
      "继他\n",
      "连患\n",
      "男张\n",
      "实锤张\n",
      "添锤\n",
      "杨紫语\n",
      "文疑\n",
      "传张\n",
      "一山患\n",
      "博求\n",
      "亡种\n",
      "几百万年\n",
      "两怕\n",
      "一怕\n",
      "二怕\n",
      "必因\n",
      "太怕\n",
      "养不教\n",
      "赵丽颖娜\n",
      "王源组\n",
      "相证\n",
      "最多判\n",
      "微博爆\n",
      "落尽\n",
      "下石\n",
      "第九次\n",
      "猛爆\n",
      "要判\n",
      "获判\n",
      "断均\n",
      "节晒\n",
      "谢贤放话\n",
      "购上\n",
      "亲弟\n",
      "杰吹\n",
      "脱饭\n",
      "挺孕\n",
      "肚晨\n",
      "闪着\n",
      "掩孕肚\n",
      "人站\n",
      "张杰会\n",
      "六周年\n",
      "破谢娜\n",
      "外陷\n",
      "怒破\n",
      "屡广\n",
      "喊魂\n",
      "祭桥\n",
      "快本斥\n",
      "170424\n",
      "邓紫棋来\n",
      "天惹\n",
      "要散\n",
      "局拍\n",
      "张吉记\n",
      "瘦时\n",
      "女系\n",
      "田沅\n",
      "jmj\n",
      "娱闻星\n",
      "后情\n",
      "手离\n",
      "网叹\n",
      "之戒\n",
      "改不改\n",
      "谢老爷子\n",
      "谢贤真\n",
      "恋时\n",
      "说霆锋\n",
      "亲发\n",
      "自宣\n",
      "好暖心\n",
      "站方\n",
      "这不怪\n",
      "小迪丽\n",
      "发图秀\n",
      "空等\n",
      "怒吵\n",
      "锋柏\n",
      "谢母力\n",
      "携女游\n",
      "高颜质\n",
      "晒泳\n",
      "狄波\n",
      "因新\n",
      "遭人破\n",
      "知后\n",
      "过霆锋\n",
      "似老\n",
      "与霆锋\n",
      "书能\n",
      "为子\n",
      "错望\n",
      "潼谈\n",
      "谢露峰\n",
      "只以\n",
      "请过\n",
      "终和好\n",
      "要和霆锋\n",
      "两儿\n",
      "富察容音\n",
      "富察\n",
      "秦岚新\n",
      "转勿传\n",
      "张继科发\n",
      "曝景甜\n",
      "这德系车\n",
      "黑景甜\n",
      "甜要\n",
      "爆于\n",
      "疯传景\n",
      "清指\n",
      "晒本\n",
      "头铁\n",
      "毁人\n",
      "毁己\n",
      "拒删\n",
      "泼向国\n",
      "清认\n",
      "删文\n",
      "那床\n",
      "小三够\n",
      "微博主\n",
      "郝小爷\n",
      "大玩下\n",
      "各生\n",
      "然道\n",
      "快本维嘉\n",
      "爱愿\n",
      "秀起\n",
      "郑爽粉\n",
      "塘主新\n",
      "连定\n",
      "谢宛辰\n",
      "婚迅\n",
      "素颜显\n",
      "宋茜露\n",
      "游两人\n",
      "段尬\n",
      "手别\n",
      "爱藏\n",
      "前神\n",
      "蒂易\n",
      "催恋\n",
      "吴昕亲\n",
      "吴昕点\n",
      "戏少\n",
      "扎里\n",
      "要离\n",
      "张翰爱娜\n",
      "彭梓城\n",
      "沅县\n",
      "系假\n",
      "一两岁\n",
      "败方\n",
      "卢本伟凉\n",
      "蓝黑色\n",
      "而战\n",
      "网传红米\n",
      "note4x\n",
      "但论\n",
      "凯仔\n",
      "晒侧\n",
      "脸引\n",
      "晏秀\n",
      "肥四\n",
      "殷金宝\n",
      "小渣\n",
      "薛之谦陷\n",
      "那股\n",
      "李奕霏\n",
      "冯珂成\n",
      "敷会\n",
      "后强\n",
      "不蹭\n",
      "生婴儿\n",
      "讽马云\n",
      "一亿人\n",
      "富月\n",
      "劈腿江\n",
      "凶如虎\n",
      "冷开水\n",
      "姚笛要\n",
      "比唐\n",
      "欧巴要\n",
      "邀访\n",
      "胖出\n",
      "韩媒大\n",
      "十碗\n",
      "没钱付\n",
      "带人夜\n",
      "还教\n",
      "爱何\n",
      "曾训\n",
      "养眠\n",
      "赵丽颖发\n",
      "九位数\n",
      "微博喊\n",
      "罢录\n",
      "敢播\n",
      "晏谈\n",
      "nyscps\n",
      "愿留阵\n",
      "众筹破\n",
      "伊要\n",
      "传含\n",
      "高庄桥\n",
      "蒋劲\n",
      "夫力\n",
      "171014\n",
      "希澈\n",
      "刚爆\n",
      "污婆\n",
      "晏互粉\n",
      "片饰\n",
      "人保过\n",
      "可生\n",
      "上鱼\n",
      "皮真能\n",
      "四瓜\n",
      "四菜\n",
      "黑青玉\n",
      "戏想\n",
      "超萌\n",
      "真嫁\n",
      "鲜吃遍\n",
      "称欲\n",
      "再导\n",
      "服宝强\n",
      "徐峥能\n",
      "徐峥力\n",
      "泰签\n",
      "黄渤携\n",
      "黄渤飙\n",
      "由星\n",
      "因说\n",
      "有奶\n",
      "错队\n",
      "会升糖\n",
      "不针\n",
      "还同\n",
      "需微信\n",
      "小平小妙\n",
      "qh0971tc\n",
      "养犬要\n",
      "新盟\n",
      "二死\n",
      "13567698281\n",
      "养颜补\n",
      "狂哭\n",
      "网监局\n",
      "微信查\n",
      "删才\n",
      "爆微博\n",
      "群控\n",
      "抢位\n",
      "看线\n",
      "不卡顿\n",
      "并亲\n",
      "大峰\n",
      "备孕妙\n",
      "背红\n",
      "走系\n",
      "二二厂\n",
      "太浮\n",
      "药吃成\n",
      "快设\n",
      "看以\n",
      "烧脑\n",
      "很久前\n",
      "推特近\n",
      "能买靓\n",
      "彭浦情\n",
      "范丞丞怒\n",
      "纯碎\n",
      "微信加\n",
      "杨洋下\n",
      "批食\n",
      "下微\n",
      "有学霸\n",
      "驻德\n",
      "网传华庭\n",
      "七期\n",
      "赵丽颖带\n",
      "可针\n",
      "占有欲\n",
      "称吊\n",
      "曝称\n",
      "赶绝\n",
      "发赴\n",
      "陈晓比\n",
      "真逆天\n",
      "立秋过\n",
      "疑由\n",
      "喜提\n",
      "陈伟霆握\n",
      "维嘉能\n",
      "传快播\n",
      "kuaibo\n",
      "如食\n",
      "胎芽\n",
      "属纯\n",
      "苟芸慧要\n",
      "薛之谦招\n",
      "胜鹿\n",
      "速收\n",
      "完存\n",
      "空净\n",
      "水油\n",
      "银容\n",
      "软嫩\n",
      "好始\n",
      "新锅\n",
      "freepure\n",
      "菲朴\n",
      "可美白\n",
      "如镜\n",
      "死太早\n",
      "辞剧\n",
      "群骂\n",
      "三十多\n",
      "愿小卡\n",
      "年扎心\n",
      "为迫\n",
      "很皮\n",
      "服真\n",
      "烟锁\n",
      "服晚\n",
      "生对\n",
      "两周年\n",
      "服有\n",
      "斤大胖\n",
      "多半会\n",
      "喜酸\n",
      "密方\n",
      "吃立\n",
      "天清\n",
      "之多\n",
      "四部\n",
      "球教\n",
      "甩光\n",
      "阻氧\n",
      "比药强\n",
      "大怀\n",
      "干过些\n",
      "证是\n",
      "桃同\n",
      "桃喷\n",
      "卖往\n",
      "佟丽娅雷\n",
      "爽糖\n",
      "厉母\n",
      "发斌\n",
      "还点\n",
      "重口\n",
      "食人場\n",
      "專吃\n",
      "至極\n",
      "但马\n",
      "总自\n",
      "爆中超\n",
      "西媒帮\n",
      "希生\n",
      "昆凌嫂\n",
      "互爆\n",
      "孙俪秀\n",
      "哲派\n",
      "哲哥\n",
      "神豪扎\n",
      "心佑粉\n",
      "曝阿哲\n",
      "自霍\n",
      "惨亏\n",
      "线选\n",
      "他别\n",
      "康报\n",
      "君带\n",
      "泡下\n",
      "三章\n",
      "网军\n",
      "毛倒\n",
      "罗极\n",
      "被斥\n",
      "第一号\n",
      "人之肉\n",
      "挂错\n",
      "不转\n",
      "两子\n",
      "针扎样\n",
      "微博下\n",
      "正拟\n",
      "女同\n",
      "出限行\n",
      "遭千人\n",
      "王珂上\n",
      "酸会\n",
      "腰象\n",
      "改完\n",
      "一窜\n",
      "美白超\n",
      "闺蜜要\n",
      "扎动\n",
      "越画\n",
      "血中\n",
      "一做\n",
      "壕哥\n",
      "曾讽\n",
      "获华鼎奖\n",
      "小璐要\n",
      "排残奶\n",
      "别信别\n",
      "昨在\n",
      "拆坝\n",
      "脸黄\n",
      "金新色\n",
      "妈大\n",
      "天见\n",
      "真凉心\n",
      "错能\n",
      "将诺菲\n",
      "博尔告\n",
      "菲玛称\n",
      "笔照\n",
      "爆爆\n",
      "胎吸\n",
      "孕传\n",
      "男得\n",
      "祝宝\n",
      "男神江\n",
      "签黄斌\n",
      "一个盆\n",
      "跟石\n",
      "梨埠\n",
      "发却文\n",
      "阿娇大\n",
      "阿娇忙\n",
      "胎真\n",
      "图为\n",
      "北多车\n",
      "陈晓过\n",
      "似眷\n",
      "三拒\n",
      "李晨大\n",
      "再管\n",
      "拒认\n",
      "时真美\n",
      "女近\n",
      "吴绮莉藏毒\n",
      "虐女\n",
      "吃会生\n",
      "硬菜\n",
      "生吃大\n",
      "郑爽成\n",
      "鹿关\n",
      "邀高伟\n",
      "说愿\n",
      "区檀营\n",
      "悦欣汇\n",
      "男借\n",
      "清渣\n",
      "提标\n",
      "现灵\n",
      "种胎\n",
      "张一山称\n",
      "继宋\n",
      "大劲顺\n",
      "确喜\n",
      "生且\n",
      "难到\n",
      "这泰迪\n",
      "头痒\n",
      "ryhpdlr\n",
      "缺纸\n",
      "遭狱\n",
      "需小编\n",
      "隔空互\n",
      "张嘎谢\n",
      "很靓\n",
      "着颖宝\n",
      "赵丽颖罗晋\n",
      "地替\n",
      "朴敏\n",
      "英长\n",
      "需族乐\n",
      "党媒批\n",
      "竟收\n",
      "人太\n",
      "可暴\n",
      "四十个\n",
      "腰暴\n",
      "三十下\n",
      "甘薇疑\n",
      "指顾颖琼\n",
      "包好别\n",
      "黄渤一语\n",
      "的關\n",
      "炫到\n",
      "千套\n",
      "送店\n",
      "做太伤\n",
      "会毁\n",
      "越薄\n",
      "会逆袭\n",
      "充算\n",
      "谷歌用\n",
      "p7\n",
      "忘教\n",
      "数千倍\n",
      "女朗\n",
      "早学早\n",
      "只配\n",
      "3050mah\n",
      "m1l\n",
      "电用\n",
      "照一照\n",
      "知真\n",
      "狼教\n",
      "upbit\n",
      "拉戴\n",
      "邊充\n",
      "電邊\n",
      "上大杀\n",
      "可月\n",
      "成闺蜜\n",
      "弱到\n",
      "总醒\n",
      "赵丽颖楚\n",
      "情定林\n",
      "演淳儿\n",
      "恐因\n",
      "遭杨颖\n",
      "赵丽颖出\n",
      "这则查\n",
      "车震照\n",
      "喝什麼\n",
      "適宜\n",
      "養生\n",
      "后巧\n",
      "看爽\n",
      "哪任\n",
      "寻获\n",
      "e330\n",
      "最潮\n",
      "看竖纹\n",
      "只割\n",
      "当主播\n",
      "人须\n",
      "丢不起\n",
      "装大湿\n",
      "已离\n",
      "砖家病\n",
      "妈滴\n",
      "条男宝\n",
      "自殺\n",
      "药火\n",
      "试测\n",
      "100d\n",
      "800d\n",
      "哑及\n",
      "美白堪\n",
      "参层\n",
      "岁算\n",
      "恋才\n",
      "演床\n",
      "疑带\n",
      "欲出\n",
      "太给\n",
      "疼不疼\n",
      "名草\n",
      "坏牙\n",
      "两大未解\n",
      "之迷\n",
      "厂花\n",
      "看其\n",
      "陈坤终\n",
      "陈坤性\n",
      "森哥\n",
      "打多办\n",
      "打星\n",
      "周比利\n",
      "再难\n",
      "之人终\n",
      "撬车\n",
      "放法\n",
      "丐版\n",
      "车亏\n",
      "辉腾味\n",
      "gl6\n",
      "5at\n",
      "拓低\n",
      "四驱非\n",
      "座四缸\n",
      "这车帅\n",
      "比宏光\n",
      "半级\n",
      "毒驾系\n",
      "男已\n",
      "ak4550\n",
      "网传京\n",
      "爆纪\n",
      "血比\n",
      "小兔兔\n",
      "这全\n",
      "哇特\n",
      "有傷\n",
      "上輩子\n",
      "印記\n",
      "宝妈备\n",
      "助生\n",
      "掏越\n",
      "有烟\n",
      "吸一晚\n",
      "一百支\n",
      "太熏\n",
      "点须\n",
      "家七人\n",
      "只下\n",
      "孰输\n",
      "陈庆聪\n",
      "新纹\n",
      "艺元\n",
      "涉雄安\n",
      "并教\n",
      "仔因\n",
      "别干\n",
      "坎山\n",
      "一法\n",
      "关翟\n",
      "天临\n",
      "高杏欣\n",
      "孙怡产女\n",
      "陈晓不\n",
      "陈晓是\n",
      "中首\n",
      "希而\n",
      "陈晓首\n",
      "希而非\n",
      "反追\n",
      "选瓜\n",
      "包熟\n",
      "赵欲\n",
      "四十斤\n",
      "肥鹅\n",
      "崔家桥\n",
      "sensortower\n",
      "top10live\n",
      "上舰\n",
      "排癌\n",
      "竟爆\n",
      "需擦\n",
      "矮女\n",
      "替刀郎\n",
      "喷刀郎\n",
      "收一女\n",
      "听十哭\n",
      "那英唱出\n",
      "唱碎\n",
      "能接\n",
      "降央卓玛\n",
      "听九人\n",
      "韩红想\n",
      "女刀粉\n",
      "听十人会\n",
      "英刀郎\n",
      "刀郎编\n",
      "师而战\n",
      "说刀郎\n",
      "刀郎边\n",
      "我爱刀\n",
      "不多花\n",
      "贷能\n",
      "善林\n",
      "款会\n",
      "分只\n",
      "降不涨\n",
      "出高\n",
      "马云出\n",
      "收药事\n",
      "增票\n",
      "附避费\n",
      "分高\n",
      "额过\n",
      "nnjianz\n",
      "够付\n",
      "本托\n",
      "翔补\n",
      "超逼格\n",
      "大驱\n",
      "马云用\n",
      "三十多种\n",
      "有微\n",
      "步痘\n",
      "蜂农\n",
      "哈中软\n",
      "患同\n",
      "粘力\n",
      "癌史\n",
      "根处\n",
      "竟低\n",
      "急开\n",
      "分项\n",
      "百股\n",
      "赵莉颖\n",
      "剥虾\n",
      "选陈妍\n",
      "希不选\n",
      "过儿\n",
      "客出\n",
      "绕前\n",
      "玉膏\n",
      "十二名\n",
      "晃仁\n",
      "李大美\n",
      "潮上\n",
      "游项\n",
      "他得癌\n",
      "抢周\n",
      "俊生\n",
      "遇史\n",
      "脸马伊\n",
      "签试恋\n",
      "对马伊\n",
      "竟动\n",
      "家接\n",
      "潮加\n",
      "达海诉\n",
      "路论\n",
      "扣波\n",
      "惠传\n",
      "伟神\n",
      "狂选\n",
      "太菜\n",
      "头法\n",
      "被拔\n",
      "中换\n",
      "系独大\n",
      "宝陷\n",
      "再展\n",
      "医美\n",
      "曝微整\n",
      "杀系\n",
      "狂浇甜馨\n",
      "就帅\n",
      "有会\n",
      "正作\n",
      "券改\n",
      "无根剂\n",
      "获窦骁\n",
      "配爱信\n",
      "gs4\n",
      "时大爆\n",
      "演雪姨\n",
      "今晒出\n",
      "卓伟为\n",
      "晨冰恋\n",
      "酷像\n",
      "喜送\n",
      "媒问\n",
      "得拉得\n",
      "血所造\n",
      "怒爆\n",
      "需拉\n",
      "不拉\n",
      "康辉神\n",
      "70w\n",
      "老梗给\n",
      "不老菜\n",
      "称资管\n",
      "引高\n",
      "推都\n",
      "毒圈\n",
      "趣笑果\n",
      "网传谷\n",
      "噩讯\n",
      "从变\n",
      "蚊于\n",
      "又制\n",
      "武天皇\n",
      "崖山\n",
      "累要\n",
      "种抗\n",
      "衰养颜\n",
      "孔伯华之孙\n",
      "吃太寒\n",
      "更水嫩\n",
      "却少\n",
      "毒显\n",
      "秀外\n",
      "必先养\n",
      "素颜美人\n",
      "汤汤水水\n",
      "六样\n",
      "养颜好\n",
      "更水润\n",
      "养颜且\n",
      "养颜清宿\n",
      "后常\n",
      "少易\n",
      "养颜要\n",
      "史末\n",
      "推助\n",
      "如神\n",
      "看遍\n",
      "一非\n",
      "因泼\n",
      "东奥会\n",
      "爬桥\n",
      "想用导\n",
      "一敌\n",
      "对美日\n",
      "显孕态\n",
      "未修\n",
      "有靓\n",
      "市管局\n",
      "被围\n",
      "人留灯\n",
      "孟爷\n",
      "分小叉\n",
      "分大叉\n",
      "润恒\n",
      "人神\n",
      "类水\n",
      "点内\n",
      "变凸\n",
      "线有\n",
      "蜜鸡\n",
      "线太深\n",
      "神掌\n",
      "爆关\n",
      "误陷\n",
      "雷劫\n",
      "昆凌速怀\n",
      "加朵\n",
      "杰微博\n",
      "真之棒\n",
      "审车\n",
      "网传夕佳\n",
      "谭镇\n",
      "骤响\n",
      "钱多事少\n",
      "我锤\n",
      "萌上\n",
      "合坐\n",
      "加视\n",
      "萌不萌\n",
      "热剧\n",
      "爱秀\n",
      "买瓜\n",
      "吃母\n",
      "识瓜\n",
      "说母\n",
      "一拍知\n",
      "笔钱\n",
      "赵薇辟\n",
      "围燕\n",
      "救璐\n",
      "男们\n",
      "男成\n",
      "邓超排\n",
      "因涉\n",
      "范伟有\n",
      "深扒林\n",
      "允小\n",
      "讀透\n",
      "社會少\n",
      "沉厚寡言\n",
      "跟易\n",
      "王建林成\n",
      "陈翔家\n",
      "秋乏\n",
      "退黄\n",
      "躲远点\n",
      "泼机\n",
      "信勿转\n",
      "王官集\n",
      "现唱\n",
      "称属\n",
      "平竖直\n",
      "王菁隐\n",
      "关碾房\n",
      "可高\n",
      "八架\n",
      "家姐\n",
      "精魄\n",
      "性寒\n",
      "可疏\n",
      "经缓\n",
      "痛养\n",
      "颜美白\n",
      "凉性\n",
      "多吃温\n",
      "姜如\n",
      "满聚\n",
      "咬核\n",
      "核吃\n",
      "耳骚\n",
      "堵教\n",
      "处接\n",
      "强接\n",
      "已接\n",
      "往好\n",
      "越细\n",
      "对景甜\n",
      "同张\n",
      "还出\n",
      "曝李玉刚\n",
      "隐婚生\n",
      "歌要\n",
      "还亮\n",
      "有天\n",
      "带景甜\n",
      "遭小三\n",
      "说称\n",
      "传某\n",
      "告到\n",
      "贷成\n",
      "竟无一人\n",
      "看老梁\n",
      "暴瘦照\n",
      "人组\n",
      "见底\n",
      "爆陈羽\n",
      "爱犯\n",
      "凡称\n",
      "辽媒\n",
      "七十九期\n",
      "三大点力\n",
      "杜淳家\n",
      "对海沃德\n",
      "好几分钟\n",
      "曾狠\n",
      "当狗\n",
      "曹云金回\n",
      "收六到\n",
      "不实系\n",
      "留胡渣\n",
      "失尽\n",
      "为娘\n",
      "杨紫是\n",
      "杨紫怒\n",
      "亿转\n",
      "对刀郎\n",
      "某车\n",
      "和玲花\n",
      "与玲花\n",
      "哭花\n",
      "歌未\n",
      "刘丹自\n",
      "教小\n",
      "七根\n",
      "多块\n",
      "制御\n",
      "百鬼\n",
      "两百块\n",
      "百来\n",
      "无框\n",
      "真得瑟\n",
      "曾害\n",
      "剧不红\n",
      "戏中\n",
      "演小三演\n",
      "拋弃\n",
      "某条\n",
      "方斥\n",
      "枪里\n",
      "一物降\n",
      "不功\n",
      "佟丽娅成\n",
      "难姐\n",
      "难妹\n",
      "斑要\n",
      "联沃家\n",
      "五颗\n",
      "终遭\n",
      "99a\n",
      "加勺\n",
      "脚治\n",
      "私闯\n",
      "吸门\n",
      "燃脂舞\n",
      "九组\n",
      "跳蝇\n",
      "排尽肠毒\n",
      "刮胆经\n",
      "舞瘦\n",
      "爆汗服\n",
      "变身易\n",
      "瘦伤\n",
      "rgmofwt\n",
      "微博刚\n",
      "货泉\n",
      "及花\n",
      "带皮\n",
      "华兄\n",
      "带辣模\n",
      "粉配\n",
      "粉加\n",
      "加白\n",
      "般水嫩\n",
      "水里点\n",
      "会白\n",
      "中滴\n",
      "好白快\n",
      "美白品\n",
      "百分之七十\n",
      "美白达\n",
      "粉拌\n",
      "这好\n",
      "萌妃\n",
      "组扎心\n",
      "没改\n",
      "不睹\n",
      "还学\n",
      "一测\n",
      "养国\n",
      "旁养\n",
      "轻食\n",
      "三不卖\n",
      "和慈禧\n",
      "曝闻\n",
      "身在\n",
      "票圈\n",
      "艰要\n",
      "鸟样\n",
      "仲得\n",
      "先乱\n",
      "贝妈\n",
      "云闪付\n",
      "余个\n",
      "压难\n",
      "传和雷\n",
      "这小妙\n",
      "刷量\n",
      "剧狂\n",
      "更辣\n",
      "佩莱绝\n",
      "再重\n",
      "四块\n",
      "神隐近\n",
      "两旺\n",
      "第一回\n",
      "多高\n",
      "数有\n",
      "组说\n",
      "停供\n",
      "八毛\n",
      "致墙\n",
      "称其想\n",
      "张召忠评\n",
      "递卡\n",
      "侯舍予\n",
      "撞奶\n",
      "太亮\n",
      "互侃\n",
      "强塞狗\n",
      "证其\n",
      "本台\n",
      "送财\n",
      "传联\n",
      "潘厚任\n",
      "点半整\n",
      "干十连板\n",
      "洗着\n",
      "蜕换\n",
      "哈弗方\n",
      "万比卡宴\n",
      "大而\n",
      "cs75\n",
      "最超\n",
      "今变\n",
      "大零\n",
      "个娘\n",
      "变挺\n",
      "因朱\n",
      "文之事\n",
      "节朱\n",
      "之文带\n",
      "获古\n",
      "买必\n",
      "聚隆\n",
      "300644\n",
      "股逆市\n",
      "股正\n",
      "下轨\n",
      "一妖股\n",
      "继吉\n",
      "继英\n",
      "暴冲\n",
      "同力\n",
      "而泣\n",
      "按此\n",
      "本要\n",
      "更博发\n",
      "爆堪\n",
      "曝车\n",
      "胡井马\n",
      "天人设\n",
      "难回\n",
      "rplxzqk\n",
      "rgvkip0\n",
      "天胶\n",
      "根老长\n",
      "背寿字\n",
      "不限号\n",
      "儒人\n",
      "照称\n",
      "被整\n",
      "李晟生\n",
      "陈晓陪\n",
      "只守\n",
      "男病\n",
      "香锅\n",
      "喜生\n",
      "已产\n",
      "未患\n",
      "发不实\n",
      "小男生\n",
      "窦唯过\n",
      "字怒\n",
      "结不\n",
      "四十六岁\n",
      "发六字\n",
      "葛宏向\n",
      "拍个\n",
      "录个\n",
      "莧加\n",
      "痔瘡\n",
      "路邊\n",
      "沒人\n",
      "男主李\n",
      "挂林兰协\n",
      "挂林兰展\n",
      "人砸展\n",
      "春爸\n",
      "春春笑\n",
      "马曼玲系\n",
      "dua\n",
      "lipa\n",
      "偷图\n",
      "肥妞变\n",
      "美妞\n",
      "某璐\n",
      "问甜馨\n",
      "誓无二心\n",
      "洗白后\n",
      "成猪\n",
      "对皮\n",
      "送甜馨\n",
      "喜当姐\n",
      "怀个\n",
      "pdone\n",
      "官博早\n",
      "清聊\n",
      "触则\n",
      "还怪\n",
      "腹儿\n",
      "小三找\n",
      "轻意\n",
      "七号\n",
      "陈学冬帮\n",
      "曝应\n",
      "比颜值\n",
      "这下馨爷\n",
      "早露\n",
      "却秀\n",
      "现自\n",
      "引人伶\n",
      "争娃\n",
      "众豪车\n",
      "演女配\n",
      "甜馨会\n",
      "白拉上\n",
      "我亮\n",
      "可苦\n",
      "瘦爆\n",
      "方终\n",
      "甜虐\n",
      "微博似\n",
      "宅圈\n",
      "大毁\n",
      "萌不受\n",
      "黄渤发\n",
      "不秀\n",
      "七位数\n",
      "之恩该\n",
      "遭范爷\n",
      "后住\n",
      "曝不交\n",
      "深发\n",
      "李沁要\n",
      "王岳伦认\n",
      "家豪到\n",
      "孕象\n",
      "条街\n",
      "学啥\n",
      "十四条\n",
      "辨不出\n",
      "维嘉有\n",
      "人前\n",
      "痛病\n",
      "咖自\n",
      "仅判\n",
      "比其大\n",
      "人高\n",
      "另算\n",
      "指爱\n",
      "总用\n",
      "不记\n",
      "用宝妈\n",
      "微博露\n",
      "选已定\n",
      "新爆\n",
      "胆儿\n",
      "太肥\n",
      "时不愿\n",
      "160504\n",
      "秤坏\n",
      "仍不卖\n",
      "董永来\n",
      "耳替\n",
      "手替\n",
      "称点\n",
      "赞是\n",
      "晋嫣\n",
      "小罗晋\n",
      "成热议\n",
      "咋长\n",
      "粉反\n",
      "处见\n",
      "一球定\n",
      "拆破\n",
      "旧鞋\n",
      "渐远\n",
      "超壕\n",
      "重属\n",
      "日狂\n",
      "假闺蜜\n",
      "颗星\n",
      "护家\n",
      "比衣品\n",
      "病疾\n",
      "蒋欣竟\n",
      "求霍\n",
      "出见\n",
      "疑因怀\n",
      "刘丹为\n",
      "幂成\n",
      "藏何\n",
      "搞些\n",
      "丫蛋儿\n",
      "镇办\n",
      "微博疑求\n",
      "比母桃\n",
      "替宝强\n",
      "清讽\n",
      "前撒狗\n",
      "粉儿们\n",
      "郑爽管\n",
      "严了\n",
      "井柏然求\n",
      "抱求\n",
      "上贝\n",
      "得够\n",
      "朱亚贤\n",
      "杨紫成\n",
      "以见\n",
      "埃神入\n",
      "这帮\n",
      "基齐\n",
      "聊骚\n",
      "头前\n",
      "杨紫上\n",
      "身潮\n",
      "脸回\n",
      "美出\n",
      "别学\n",
      "张檬整\n",
      "肌得\n",
      "毛宁唱\n",
      "不老女\n",
      "草上\n",
      "这拉风\n",
      "杨颖要\n",
      "卖萌照\n",
      "发杨\n",
      "一个天\n",
      "成白富\n",
      "看网\n",
      "将弃\n",
      "杨颖欲\n",
      "杨颖弃\n",
      "新名\n",
      "杨颖称\n",
      "aangelababy\n",
      "于林丹\n",
      "疑马蓉\n",
      "暴瘦似\n",
      "杨颖因\n",
      "先虐\n",
      "霍如\n",
      "陈阿伯\n",
      "我累\n",
      "当霍\n",
      "抢霍\n",
      "南宵\n",
      "粮天\n",
      "霍氏家族\n",
      "婊用\n",
      "虽传\n",
      "ait\n",
      "因打\n",
      "微肿\n",
      "同屏器\n",
      "沈腾神\n",
      "嫂方媛\n",
      "早说\n",
      "照美胸\n",
      "家应\n",
      "撩裙\n",
      "洪明伟\n",
      "因肉\n",
      "手遮肚\n",
      "阔衣\n",
      "丁霞斥\n",
      "王柳雯\n",
      "继赵\n",
      "曝林\n",
      "但林\n",
      "服能\n",
      "自让\n",
      "用珍仪\n",
      "头椿会\n",
      "张老师\n",
      "孩溺\n",
      "四十五岁\n",
      "能染\n",
      "桔果\n",
      "商遭\n",
      "角已\n",
      "加枣\n",
      "这片\n",
      "赵丽颖认\n",
      "朱丹为\n",
      "三两个\n",
      "体壮\n",
      "快散\n",
      "率极\n",
      "禁建\n",
      "三沙同\n",
      "13xxxx\n",
      "他同\n",
      "商看\n",
      "多枚\n",
      "卖饭\n",
      "神工意匠\n",
      "psg\n",
      "天消\n",
      "别老去\n",
      "既不伤\n",
      "能除\n",
      "比颖宝\n",
      "喊告\n",
      "宁吉喆\n",
      "将力\n",
      "两大准\n",
      "虐太惨\n",
      "男神级\n",
      "邀余\n",
      "原帮\n",
      "勉扣\n",
      "萬萬\n",
      "當天\n",
      "親生\n",
      "他发\n",
      "微博护\n",
      "生大眼\n",
      "后狂\n",
      "胖妻\n",
      "股望\n",
      "护刀\n",
      "有姓\n",
      "四斤\n",
      "村家\n",
      "食多\n",
      "多飞\n",
      "王大骂\n",
      "地求\n",
      "百秒\n",
      "猜作\n",
      "低扫\n",
      "弃赛\n",
      "提猜\n",
      "mbro\n",
      "超多炸\n",
      "改宋\n",
      "然在\n",
      "妈成\n",
      "玩车\n",
      "这狗会\n",
      "狗语\n",
      "phev\n",
      "三大珍肴\n",
      "我帅\n",
      "缺戏\n",
      "两到\n",
      "吃蕉\n",
      "亿怒\n",
      "盆友\n",
      "天刮脂\n",
      "臭宿\n",
      "静走\n",
      "生爱新\n",
      "西虹市\n",
      "递来\n",
      "天祛痘\n",
      "放久会\n",
      "萨普爱思\n",
      "博爆\n",
      "曝锋菲\n",
      "宽姐\n",
      "谢敢\n",
      "曾不输\n",
      "射尿\n",
      "叁天\n",
      "治膝\n",
      "是治好\n",
      "它治好\n",
      "七块\n",
      "需花\n",
      "早诊\n",
      "早治\n",
      "除菌全\n",
      "一場\n",
      "爆發\n",
      "寻女\n",
      "有千人\n",
      "密透\n",
      "倔起\n",
      "好几亿\n",
      "懒理江\n",
      "江小三\n",
      "曝当\n",
      "一币\n",
      "盛轩\n",
      "卅三\n",
      "giorgi\n",
      "比王凯\n",
      "好准\n",
      "那古仔\n",
      "撩发\n",
      "鱼机\n",
      "招住\n",
      "月线\n",
      "股法\n",
      "全傻\n",
      "比白\n",
      "鸡无鸡\n",
      "挺大\n",
      "一高二\n",
      "鹿粉\n",
      "揭鹿晗\n",
      "孕检单\n",
      "卓伟带\n",
      "必分\n",
      "立降\n",
      "马黛双\n",
      "调茶\n",
      "成新进\n",
      "迎开\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对张\n",
      "致晕\n",
      "已俩\n",
      "宋喆大\n",
      "女炫富\n",
      "太贱\n",
      "随江\n",
      "陪江\n",
      "葛军出\n",
      "株潭来\n",
      "龙画虎\n",
      "自护\n",
      "持斧\n",
      "多箱\n",
      "扎演\n",
      "有多酷\n",
      "爽妹\n",
      "没火当\n",
      "郑爽江\n",
      "翟天\n",
      "临则\n",
      "对柏芝\n",
      "皮切成\n",
      "天变润\n",
      "马航失\n",
      "联三大\n",
      "找代驾\n",
      "克雪菊\n",
      "一个通\n",
      "准降\n",
      "叶吃\n",
      "根都\n",
      "天杞\n",
      "降掉\n",
      "清肠利\n",
      "太高人\n",
      "药钱\n",
      "个降\n",
      "又护\n",
      "别老靠\n",
      "三常\n",
      "没高过\n",
      "十吃十降\n",
      "能通\n",
      "总降\n",
      "样小\n",
      "种人会\n",
      "捉蛇\n",
      "被拉进\n",
      "夺视\n",
      "图疑\n",
      "需放个\n",
      "娱记\n",
      "韬拉着\n",
      "何炅为\n",
      "种同食\n",
      "吃超\n",
      "如网\n",
      "器系\n",
      "利智会\n",
      "弄活\n",
      "画成\n",
      "六架\n",
      "橘光\n",
      "多架\n",
      "凯凯王\n",
      "胡可沙溢\n",
      "梁泳仪\n",
      "不买包\n",
      "陈思城\n",
      "刘恩乔\n",
      "一點\n",
      "不浮\n",
      "一寶\n",
      "輕十歲\n",
      "值会\n",
      "张免\n",
      "扬要\n",
      "假快播\n",
      "会补\n",
      "长得壮\n",
      "还护心\n",
      "毒上\n",
      "降三高护\n",
      "不体\n",
      "好几碗\n",
      "鲜滑\n",
      "味美有\n",
      "老香\n",
      "真需\n",
      "改搬\n",
      "华尔道\n",
      "夫要\n",
      "余人系\n",
      "乡来\n",
      "人偷\n",
      "累晕\n",
      "红雷哥\n",
      "银隆系\n",
      "壮长\n",
      "打多\n",
      "亲案\n",
      "180109\n",
      "一人敌\n",
      "店女\n",
      "饮巧\n",
      "茶酱\n",
      "ꈊ\n",
      "迁房\n",
      "读晨记\n",
      "171211\n",
      "排名第\n",
      "四地\n",
      "信马云\n",
      "我州\n",
      "叠溪\n",
      "吴大真教\n",
      "突有\n",
      "李老师\n",
      "三豆\n",
      "六十米\n",
      "群多\n",
      "速转求\n",
      "遮十丑\n",
      "狂揽\n",
      "需泡\n",
      "脚水里\n",
      "肚平\n",
      "哥玩\n",
      "不向\n",
      "受此\n",
      "币价\n",
      "没黑够\n",
      "抵台\n",
      "丽颖有\n",
      "因王俊凯\n",
      "唯粉\n",
      "频接\n",
      "年凯家\n",
      "王俊凯毒\n",
      "患小头\n",
      "美白误\n",
      "水润底\n",
      "瓷肌\n",
      "蓝水会\n",
      "伤不伤\n",
      "密疑\n",
      "希间\n",
      "赵丽颖颖宝\n",
      "赵丽颖起\n",
      "秀自\n",
      "被布\n",
      "无皱\n",
      "配一物\n",
      "紫越\n",
      "肾能\n",
      "皮茶\n",
      "天比\n",
      "似炭\n",
      "透黑\n",
      "灿友们\n",
      "了颖宝\n",
      "瑜许\n",
      "力挺颖宝\n",
      "郑爽暴\n",
      "灵招\n",
      "想染\n",
      "黑如绸\n",
      "越松\n",
      "洗牙易\n",
      "洗牙后\n",
      "新专\n",
      "玩会\n",
      "脸能\n",
      "蓝月亮\n",
      "陈皮配\n",
      "连洪欣\n",
      "过范\n",
      "看洪金\n",
      "范丞丞用\n",
      "问范丞丞\n",
      "五十多岁\n",
      "赵丽颖剧\n",
      "乔让\n",
      "真扎心\n",
      "此警情\n",
      "限油\n",
      "被车\n",
      "脸属\n",
      "你配\n",
      "入岛\n",
      "等涉\n",
      "井系\n",
      "酒比\n",
      "涂磊会\n",
      "抵套\n",
      "买公\n",
      "某小编\n",
      "无龄\n",
      "仔人\n",
      "刚卓伟\n",
      "绿着\n",
      "有超\n",
      "首认\n",
      "发都\n",
      "前洁面\n",
      "洗能\n",
      "无赤\n",
      "卖个\n",
      "至雄安\n",
      "摇号系\n",
      "出醜\n",
      "极少数\n",
      "变飞\n",
      "号生\n",
      "卖吉鲁\n",
      "晚旗报\n",
      "厄齐尔去\n",
      "驱火\n",
      "冲杯\n",
      "谣速\n",
      "徐峥会\n",
      "171210\n",
      "五线\n",
      "翔患\n",
      "mdd\n",
      "千寒易\n",
      "一湿\n",
      "难除\n",
      "老湿毒\n",
      "祛得\n",
      "角老\n",
      "想信\n",
      "采熙\n",
      "偷领\n",
      "捞车\n",
      "没派\n",
      "中盛\n",
      "入碗\n",
      "不融\n",
      "城坠亡\n",
      "坠亡终\n",
      "再辟\n",
      "城江\n",
      "勒伤\n",
      "必推\n",
      "杨馥瑜\n",
      "以歌\n",
      "搭逆袭\n",
      "万同款\n",
      "我昕姐\n",
      "亲辟\n",
      "额旗\n",
      "十几名\n",
      "地系\n",
      "一个千年\n",
      "穷常\n",
      "精虚\n",
      "补虚温\n",
      "男要\n",
      "排前\n",
      "肾为\n",
      "佐饭\n",
      "健力\n",
      "之品\n",
      "大且\n",
      "之圣品\n",
      "美白片\n",
      "美要\n",
      "疑打\n",
      "荆监\n",
      "谣称\n",
      "我进\n",
      "两将\n",
      "抢戈登\n",
      "超六\n",
      "五场\n",
      "一宝妈\n",
      "灿星\n",
      "完真\n",
      "后盖谍\n",
      "机背\n",
      "养颜养\n",
      "有苦\n",
      "过塞到\n",
      "超给力\n",
      "靈芝\n",
      "照吃\n",
      "黑垢\n",
      "防粘锅\n",
      "满空飞\n",
      "洗白成\n",
      "送史\n",
      "平桂区\n",
      "闹崩后\n",
      "频临\n",
      "杨紫因\n",
      "辣个\n",
      "处竟\n",
      "奇用\n",
      "因跑\n",
      "疑人设\n",
      "博一人\n",
      "爸是\n",
      "陈国邦\n",
      "多少倍\n",
      "官博忙\n",
      "三大实\n",
      "张翰合\n",
      "车企大\n",
      "活久\n",
      "陈嘉微博\n",
      "冰晨\n",
      "旧爱有\n",
      "得果\n",
      "得妙\n",
      "强燃\n",
      "难减\n",
      "有招\n",
      "女变\n",
      "人扎心\n",
      "二块钱\n",
      "因谢\n",
      "维嘉何炅疑\n",
      "马栏\n",
      "山一姐\n",
      "快本散\n",
      "出孕\n",
      "婚房练\n",
      "確實\n",
      "證據\n",
      "看會\n",
      "一輩子\n",
      "報導\n",
      "牛熊\n",
      "散友\n",
      "完不笑\n",
      "开看\n",
      "乐翻\n",
      "民熏\n",
      "结吗\n",
      "鹏华\n",
      "十不\n",
      "三后\n",
      "白装露\n",
      "玩快\n",
      "疯犬病\n",
      "还会出\n",
      "重女\n",
      "很补\n",
      "手像\n",
      "脚像\n",
      "hathaway\n",
      "粮吃定\n",
      "正月初一\n",
      "这画\n",
      "嘴要\n",
      "热骂\n",
      "堆積\n",
      "以後別\n",
      "岁路\n",
      "ninepercent\n",
      "农做\n",
      "韩雪爆\n",
      "邬童\n",
      "别蹭\n",
      "大鹿晗\n",
      "戏床\n",
      "马云输\n",
      "王凯选\n",
      "王凯秀\n",
      "帮王凯\n",
      "凯将\n",
      "争视帝\n",
      "抓放\n",
      "另一头\n",
      "乔恩姐\n",
      "这动\n",
      "图太暖心\n",
      "结新欢\n",
      "以孕\n",
      "相挟\n",
      "肩女\n",
      "搭肩\n",
      "强逆袭\n",
      "港记\n",
      "部待播\n",
      "保宋喆\n",
      "爆马蓉\n",
      "轻锤\n",
      "强疑\n",
      "判其\n",
      "后力\n",
      "打力\n",
      "撕马蓉力\n",
      "领金\n",
      "成双入\n",
      "对秀\n",
      "由马蓉\n",
      "这出\n",
      "劝马蓉\n",
      "丫想\n",
      "阔太变\n",
      "宝泰隆\n",
      "老罗微博\n",
      "称颜值\n",
      "强继\n",
      "看宝强\n",
      "强见\n",
      "需马蓉\n",
      "几集\n",
      "首见\n",
      "讽博\n",
      "后马蓉\n",
      "进新\n",
      "宝强终\n",
      "疑宝强\n",
      "马蓉逆袭\n",
      "爆光用\n",
      "洗白真\n",
      "没靠\n",
      "然卓伟\n",
      "停攻\n",
      "王思聪夺\n",
      "别吃瓜\n",
      "那英继\n",
      "桃妈\n",
      "王思聪替\n",
      "抱上\n",
      "王思聪遇\n",
      "雷军身\n",
      "哪传\n",
      "引王\n",
      "思聪狂\n",
      "急称\n",
      "预追马\n",
      "亿系\n",
      "王冰萌\n",
      "马云狂\n",
      "真蠢\n",
      "英蠢\n",
      "那英摊\n",
      "当个富\n",
      "奋全火\n",
      "开八\n",
      "只干\n",
      "山不容\n",
      "二虎\n",
      "发对\n",
      "鲁豫方\n",
      "已输\n",
      "空撞\n",
      "人富\n",
      "有迪丽\n",
      "挺美\n",
      "上分\n",
      "未重\n",
      "为梦奇\n",
      "喷为\n",
      "大弯区\n",
      "两离\n",
      "锋哥\n",
      "对鲁豫\n",
      "窦家媛\n",
      "窦唯童\n",
      "方替\n",
      "谢贤赞\n",
      "谁养\n",
      "相唱\n",
      "谢贤留\n",
      "王公公\n",
      "朱之文子\n",
      "別嫁\n",
      "谢门\n",
      "和霆锋\n",
      "终找\n",
      "他终\n",
      "萌炸\n",
      "了暧昧\n",
      "哪噜\n",
      "仔惊\n",
      "痛伤\n",
      "火到\n",
      "真会拔\n",
      "头足\n",
      "王诗玲\n",
      "获大赞\n",
      "禁产\n",
      "称龙\n",
      "第五十章\n",
      "真龙该\n",
      "身而过\n",
      "亿豪车\n",
      "李湘素\n",
      "亿竟\n",
      "街委\n",
      "球球泪\n",
      "依萍江\n",
      "王凯演\n",
      "赵丽颖会\n",
      "礼景甜\n",
      "碰不起\n",
      "再赞\n",
      "竟事\n",
      "孕味重\n",
      "备孕接\n",
      "圆逆袭\n",
      "加块\n",
      "湿药\n",
      "祛湿平\n",
      "投发\n",
      "加配\n",
      "照大\n",
      "天抹出\n",
      "会毒\n",
      "立懂\n",
      "越吃病\n",
      "白嘴儿\n",
      "b365\n",
      "已验\n",
      "爆准\n",
      "姐高露\n",
      "女不生\n",
      "几十款\n",
      "肺脓疡\n",
      "小方治\n",
      "防不在治\n",
      "有得长\n",
      "种治\n",
      "树豆治\n",
      "天睡\n",
      "可固发\n",
      "用草治\n",
      "奇草\n",
      "正应\n",
      "治胆\n",
      "襄炎\n",
      "治掉\n",
      "六块\n",
      "遇猪\n",
      "草治猪\n",
      "又验\n",
      "virta\n",
      "二型\n",
      "多吃易\n",
      "单知\n",
      "塞钱\n",
      "吃维\n",
      "枝繁\n",
      "4cm\n",
      "天俊\n",
      "真钞\n",
      "全秃\n",
      "泡遍\n",
      "发剂\n",
      "血稠\n",
      "五小时\n",
      "用奶\n",
      "浓亮\n",
      "不落色\n",
      "二十载\n",
      "想淡斑\n",
      "难掉\n",
      "越久越\n",
      "放盆水\n",
      "皮往\n",
      "钓超\n",
      "招秘制\n",
      "赵丽颖显\n",
      "演他\n",
      "倪能\n",
      "剧都\n",
      "坏壶\n",
      "变新壶\n",
      "没坏\n",
      "女怀\n",
      "對著\n",
      "杨紫娜\n",
      "乐活家\n",
      "家明\n",
      "粮拉\n",
      "口爽\n",
      "吴昕泪\n",
      "两人疑\n",
      "多易致\n",
      "宁喝\n",
      "不昏\n",
      "對視\n",
      "超過\n",
      "兩人關\n",
      "灯下\n",
      "大起\n",
      "男拍\n",
      "底竟\n",
      "抓狗\n",
      "克林布\n",
      "玛悟饭\n",
      "系因\n",
      "焚车\n",
      "发博官\n",
      "灵湖\n",
      "用网\n",
      "面快\n",
      "网传星\n",
      "沙松雅\n",
      "二十多名\n",
      "怒喘\n",
      "恶灵锁\n",
      "万后\n",
      "越壮\n",
      "旺家运\n",
      "中夸\n",
      "女竟\n",
      "组为\n",
      "王鸥素\n",
      "颜显\n",
      "疑大\n",
      "季疑\n",
      "季开录\n",
      "遭跑\n",
      "鹿晗成\n",
      "男时\n",
      "磨坝村\n",
      "芮微\n",
      "博重\n",
      "狂晒\n",
      "赵丽颖恋\n",
      "苏麻喇\n",
      "打太多\n",
      "二篇\n",
      "微博吐槽\n",
      "终惹\n",
      "缠到\n",
      "切是\n",
      "净肠草\n",
      "腹汤\n",
      "总嫌\n",
      "瘦得慢\n",
      "大吸脂\n",
      "吸脂王\n",
      "还得加\n",
      "腰太难\n",
      "这一痛\n",
      "两三颗\n",
      "2o\n",
      "引三高\n",
      "靠染\n",
      "再长\n",
      "岁娜\n",
      "终修\n",
      "枕眠\n",
      "扎会\n",
      "小三要\n",
      "这婚结\n",
      "接娜\n",
      "柏然互\n",
      "于莎莎要\n",
      "于莎莎\n",
      "开微博\n",
      "茂别\n",
      "用加\n",
      "发多野\n",
      "挡水\n",
      "少头\n",
      "愁用\n",
      "分上色\n",
      "液加\n",
      "多显\n",
      "玉红用\n",
      "端窝\n",
      "宋晓峰入\n",
      "前气\n",
      "森蝶\n",
      "今说\n",
      "多麼\n",
      "趣看\n",
      "国空\n",
      "白百何协\n",
      "似马蓉\n",
      "凡疑\n",
      "下架系\n",
      "现携\n",
      "欲度\n",
      "人暖心\n",
      "玩够\n",
      "这绿能\n",
      "凡似\n",
      "两人秀\n",
      "探班秀\n",
      "凡苦\n",
      "降三高治\n",
      "能灯\n",
      "三救\n",
      "知救\n",
      "黄荷娜疑\n",
      "病比\n",
      "酒里\n",
      "俩口\n",
      "从造\n",
      "柔亮\n",
      "新脸\n",
      "周美白\n",
      "地活\n",
      "因币面\n",
      "协称\n",
      "刮净\n",
      "视其为\n",
      "我见\n",
      "有客\n",
      "拾记\n",
      "为保\n",
      "封陆贞为\n",
      "肝疼\n",
      "系虾\n",
      "十珍\n",
      "翻遍\n",
      "加字版\n",
      "多吃助\n",
      "微博竟\n",
      "人慎入\n",
      "它定\n",
      "后招\n",
      "遭夜华\n",
      "快减\n",
      "肉照\n",
      "瘦十\n",
      "补脾能\n",
      "补对\n",
      "补不对\n",
      "鲜酿\n",
      "爆宝\n",
      "该学\n",
      "疑购\n",
      "婚房首\n",
      "牛婚\n",
      "拒上\n",
      "并长\n",
      "疯康辉\n",
      "张翰点\n",
      "卓亨瑜\n",
      "美王\n",
      "昏后\n",
      "来拉上\n",
      "脸王\n",
      "高中毕业\n",
      "脸辣妈\n",
      "从招\n",
      "幂娜\n",
      "袁珊\n",
      "修素\n",
      "似路\n",
      "劝过\n",
      "比大\n",
      "希子\n",
      "扎个\n",
      "配过\n",
      "受个\n",
      "唐嫣动\n",
      "毯槽\n",
      "前照\n",
      "诗显\n",
      "背替\n",
      "说整\n",
      "称比\n",
      "整多\n",
      "现坑\n",
      "林允近\n",
      "陈恺威\n",
      "太出\n",
      "郑爽侧\n",
      "杨紫先\n",
      "瘦疑\n",
      "爱格\n",
      "模迪丽\n",
      "残成\n",
      "脸糊\n",
      "终撞\n",
      "磨骨\n",
      "打肉毒\n",
      "这贴\n",
      "那英用\n",
      "刀郎用\n",
      "刀郎道\n",
      "刀郎近\n",
      "赵丽颖谈\n",
      "问何\n",
      "超般\n",
      "完竟\n",
      "男神要\n",
      "素颜真\n",
      "升油能\n",
      "谈马云\n",
      "引一众\n",
      "房疑\n",
      "宫娘娘\n",
      "狂力\n",
      "算尽\n",
      "官泄\n",
      "主舰\n",
      "舱弹\n",
      "张继科易\n",
      "鲁能命\n",
      "董洁用\n",
      "基情秀\n",
      "祛火\n",
      "招睡\n",
      "前操\n",
      "四五块\n",
      "郭智超\n",
      "三十多斤\n",
      "数它\n",
      "可淡斑\n",
      "脸焕\n",
      "腹别\n",
      "記得\n",
      "關了\n",
      "2b\n",
      "曝陈羽\n",
      "亲蜜\n",
      "爆肥撑\n",
      "继与\n",
      "董铭逸\n",
      "张博路\n",
      "rolex\n",
      "r36\n",
      "裤来\n",
      "鞋脏\n",
      "十地\n",
      "女主选角\n",
      "纯手\n",
      "附男宝\n",
      "要接\n",
      "报个\n",
      "小女生\n",
      "想不接\n",
      "带财\n",
      "还旺\n",
      "父旺母\n",
      "接男宝准\n",
      "若成\n",
      "明夏二选\n",
      "万获\n",
      "亿顶\n",
      "薪稳\n",
      "休城开\n",
      "忧成\n",
      "终迎\n",
      "赌豪阵\n",
      "追一超\n",
      "可灭勇\n",
      "组五\n",
      "背记\n",
      "有马云\n",
      "偿试\n",
      "神洗\n",
      "过用\n",
      "多村\n",
      "栽土里\n",
      "不长叶\n",
      "警企\n",
      "并赞\n",
      "吴佳尼爱\n",
      "身态\n",
      "主有\n",
      "医草\n",
      "可食\n",
      "路央子\n",
      "拖久\n",
      "长吃肉会\n",
      "酿大错\n",
      "越蠢\n",
      "梦到\n",
      "除净\n",
      "胜万药\n",
      "一湿难\n",
      "天净\n",
      "几罐\n",
      "可劲\n",
      "茶来\n",
      "肺毒\n",
      "腰细脸\n",
      "排净毒\n",
      "肝净\n",
      "掩心\n",
      "熏疼\n",
      "郭采洁开\n",
      "赵倩儿\n",
      "博未\n",
      "却大减\n",
      "歌刚\n",
      "29149\n",
      "里实\n",
      "时疑现\n",
      "三十万元\n",
      "五脚\n",
      "欢子\n",
      "拍短\n",
      "曝范爷\n",
      "裙值\n",
      "一晒出\n",
      "牛不牛\n",
      "晨冰\n",
      "婚房照\n",
      "蜜回\n",
      "婚巢\n",
      "素颜看\n",
      "170120\n",
      "三千块\n",
      "美有\n",
      "驴蹄鞋\n",
      "千万级\n",
      "岁秀智\n",
      "家超\n",
      "我勒个\n",
      "同个\n",
      "比同\n",
      "饭中\n",
      "喝温\n",
      "喝凉\n",
      "肝检\n",
      "咳掉\n",
      "家成\n",
      "猛一\n",
      "似怀\n",
      "管汪峰\n",
      "已取\n",
      "笑成\n",
      "土掉\n",
      "无圈\n",
      "正给\n",
      "谷七郎\n",
      "中真龙\n",
      "雄安真龙\n",
      "雄安股\n",
      "特补\n",
      "女准\n",
      "你准\n",
      "咱来\n",
      "白面馒头\n",
      "錄下\n",
      "靈異\n",
      "上放个\n",
      "完孕妈\n",
      "先穷\n",
      "后富\n",
      "毛宁差\n",
      "车饰\n",
      "其和赖\n",
      "毛宁送\n",
      "混它\n",
      "郑爽建\n",
      "群收\n",
      "拿杯\n",
      "连湿毒\n",
      "连胃\n",
      "抓肉\n",
      "抖三抖\n",
      "层肉\n",
      "三四层\n",
      "多层\n",
      "不老药\n",
      "草可\n",
      "最极\n",
      "张杰互\n",
      "一痒\n",
      "曝张杰\n",
      "爆谢娜\n",
      "孙杨有\n",
      "炒出\n",
      "有多远\n",
      "男朋微信\n",
      "只会降\n",
      "书里\n",
      "材是\n",
      "洛江仙\n",
      "福建网\n",
      "万顿\n",
      "1cm\n",
      "多涂\n",
      "次淡斑\n",
      "淡皱\n",
      "斑小妙\n",
      "淡斑效\n",
      "竟淡斑\n",
      "女借\n",
      "可年销\n",
      "六七百\n",
      "万的业\n",
      "急时\n",
      "散寒防\n",
      "拉砖\n",
      "煮易\n",
      "枣及\n",
      "32gb\n",
      "天胖到\n",
      "三班\n",
      "qqzjc20120802\n",
      "带风\n",
      "大瘦\n",
      "玲子\n",
      "辣妈生\n",
      "语有\n",
      "前杠\n",
      "戏靠\n",
      "当窝\n",
      "全哭\n",
      "看美得\n",
      "款顶配\n",
      "粉可致\n",
      "草像\n",
      "易三高\n",
      "看唐\n",
      "罗晋同\n",
      "人提\n",
      "可罗晋\n",
      "超配\n",
      "而罗晋\n",
      "继唐\n",
      "爆美\n",
      "材睡\n",
      "黑醋\n",
      "如乌墨\n",
      "别总去\n",
      "陈红以\n",
      "pk10\n",
      "号国服\n",
      "网传国服\n",
      "审为\n",
      "端游国服\n",
      "最多人\n",
      "万属\n",
      "戏里戏\n",
      "外尔豪\n",
      "靠头\n",
      "两去\n",
      "出纯\n",
      "仔黑\n",
      "比柳岩\n",
      "腻害\n",
      "出看\n",
      "疑指\n",
      "充維\n",
      "他命\n",
      "反怼\n",
      "妖铃铃\n",
      "再吐槽\n",
      "话糙\n",
      "理不糙\n",
      "又何\n",
      "裂得\n",
      "具茨山\n",
      "系毒\n",
      "群所传\n",
      "撤区\n",
      "设县\n",
      "撤乡\n",
      "设镇\n",
      "烟有\n",
      "沉江\n",
      "芝堰\n",
      "人勿传\n",
      "环高\n",
      "杀星\n",
      "地揽\n",
      "连马云开\n",
      "带离\n",
      "网传汉军\n",
      "五旬\n",
      "某中\n",
      "銀币\n",
      "造壹圆\n",
      "有收\n",
      "九眼\n",
      "网传全\n",
      "陈太太\n",
      "桃同食\n",
      "丁家店\n",
      "一鸡店\n",
      "rg1dqz3\n",
      "vv5\n",
      "七中\n",
      "演楚乔\n",
      "新女\n",
      "主换\n",
      "听卓伟\n",
      "一在\n",
      "万人点\n",
      "结吧\n",
      "帮提\n",
      "字笑侃\n",
      "网红凤姐\n",
      "掀骂战\n",
      "李晨录\n",
      "车高达\n",
      "唐嫣气\n",
      "传正\n",
      "后首秀\n",
      "驾豪车\n",
      "三人该\n",
      "无爱真\n",
      "微信开\n",
      "离下\n",
      "这自\n",
      "王石田\n",
      "博主发\n",
      "微博说\n",
      "小三当\n",
      "纯素颜\n",
      "马蓉争\n",
      "阿哲连麦\n",
      "出亲\n",
      "豪置\n",
      "青久后\n",
      "青方媛\n",
      "罗志祥疑\n",
      "变罗太\n",
      "万置\n",
      "吵成\n",
      "出大视\n",
      "正试\n",
      "爸乐\n",
      "罗晋婚\n",
      "好弱\n",
      "57d\n",
      "配钻\n",
      "这国称\n",
      "油而\n",
      "特香\n",
      "香是\n",
      "发博骂\n",
      "140630\n",
      "总在\n",
      "遭杨\n",
      "可闹出\n",
      "之斗\n",
      "宠粉\n",
      "人耗\n",
      "谈币色\n",
      "李晨求\n",
      "说露\n",
      "选李晨\n",
      "吞俩\n",
      "嘴变\n",
      "星受\n",
      "斤生\n",
      "缺牙\n",
      "补易\n",
      "曝现\n",
      "美白得\n",
      "称无药\n",
      "抵十副药\n",
      "不告\n",
      "一室\n",
      "吊足\n",
      "马云下\n",
      "邀马云\n",
      "劝其生\n",
      "准一姐\n",
      "成小三\n",
      "女江\n",
      "小三闺蜜\n",
      "二上\n",
      "斑暗\n",
      "减斤\n",
      "肾伤\n",
      "减肚\n",
      "募招\n",
      "17076\n",
      "绿叁\n",
      "两版\n",
      "补号\n",
      "要常买\n",
      "土药\n",
      "壮似\n",
      "起过\n",
      "连挂\n",
      "第七个\n",
      "好怕\n",
      "他开\n",
      "挂者\n",
      "妻要\n",
      "老妻心\n",
      "很会\n",
      "做分\n",
      "看范伟\n",
      "问得\n",
      "合不上\n",
      "抓鸡\n",
      "带范伟\n",
      "驾无牌\n",
      "老炮\n",
      "称连\n",
      "因不愿\n",
      "锁近\n",
      "带云馨\n",
      "录新\n",
      "乐大码\n",
      "减脂期\n",
      "拿瓣\n",
      "大像\n",
      "需几瓣\n",
      "三瓜\n",
      "三茶\n",
      "种多\n",
      "偏高时\n",
      "老糖\n",
      "友用\n",
      "调药\n",
      "菜里\n",
      "人秀\n",
      "巧防\n",
      "一花\n",
      "燃掉\n",
      "肝掌\n",
      "非常明显\n",
      "补肝血\n",
      "绝会\n",
      "之根\n",
      "抗炎\n",
      "入菜\n",
      "学做\n",
      "春到\n",
      "这果赛\n",
      "接必应\n",
      "十人九胖\n",
      "狂吸\n",
      "旭彦堂\n",
      "冯柯闹\n",
      "胡可才\n",
      "女闺蜜\n",
      "蛮配\n",
      "骑去\n",
      "没断\n",
      "心让\n",
      "缺胡\n",
      "手点\n",
      "黄老邪\n",
      "胡歌身\n",
      "权志\n",
      "迷弟\n",
      "出假\n",
      "冯曼娜\n",
      "因胡歌\n",
      "变御姐\n",
      "只增\n",
      "样燃脂\n",
      "可强\n",
      "总洗\n",
      "黑洗\n",
      "物助\n",
      "拿块\n",
      "东互\n",
      "东收\n",
      "水妙\n",
      "用拉\n",
      "再无斑\n",
      "毯罗晋\n",
      "脾經\n",
      "大藥房\n",
      "请照\n",
      "健不\n",
      "胜十副药\n",
      "几克\n",
      "肩酸胀\n",
      "佳方\n",
      "盐治好\n",
      "个用\n",
      "不藤\n",
      "草治好\n",
      "还百试\n",
      "养情\n",
      "可播\n",
      "无台\n",
      "顶十副药\n",
      "疼有\n",
      "建微信\n",
      "希芸\n",
      "只羡\n",
      "不羡仙\n",
      "盆来\n",
      "阿骚\n",
      "二硕\n",
      "待播剧\n",
      "三茬\n",
      "种藕养\n",
      "一千只\n",
      "挣上\n",
      "人太牛\n",
      "占卜术\n",
      "签纸\n",
      "如应\n",
      "勤般\n",
      "爆疑\n",
      "条少\n",
      "愢\n",
      "这不刚\n",
      "一痛\n",
      "认他\n",
      "认小\n",
      "比娶\n",
      "赵又廷组\n",
      "削片\n",
      "八片\n",
      "六粒\n",
      "之方\n",
      "不泡\n",
      "治久\n",
      "两三片\n",
      "中泡\n",
      "招醋\n",
      "点低\n",
      "张翰高\n",
      "天清肠毒\n",
      "天吃次\n",
      "多像\n",
      "爆的料\n",
      "怀第\n",
      "秦岚掉\n",
      "积安堂\n",
      "别骂\n",
      "苟芸慧齐\n",
      "曝阿\n",
      "随鲁能\n",
      "默特\n",
      "k6\n",
      "要毒\n",
      "二千多\n",
      "十法\n",
      "证对\n",
      "地和房\n",
      "降酸有\n",
      "遭控\n",
      "传范丞丞跑\n",
      "占半\n",
      "传范丞丞微博\n",
      "太壕\n",
      "脸竟\n",
      "清为证\n",
      "无超\n",
      "牛带\n",
      "因范爷\n",
      "再撒糖\n",
      "先当\n",
      "离分\n",
      "捂肚\n",
      "连扯\n",
      "恋要\n",
      "演鬼\n",
      "女说\n",
      "杨颖整\n",
      "李晨方\n",
      "图慎入\n",
      "照疯转\n",
      "好大是\n",
      "消肥\n",
      "直泼\n",
      "很红\n",
      "之耐\n",
      "却恋\n",
      "这瓶\n",
      "次灭\n",
      "不输兰蔻\n",
      "说现\n",
      "却点\n",
      "太陽將\n",
      "针差\n",
      "般掉\n",
      "后次\n",
      "洗不净\n",
      "整木\n",
      "养颜为\n",
      "循坏\n",
      "病难\n",
      "扫码求\n",
      "康宝莱\n",
      "吃代餐\n",
      "宝妈发\n",
      "个字力\n",
      "曲委\n",
      "太野\n",
      "用三不作\n",
      "小三向\n",
      "沈腾病\n",
      "改增\n",
      "图一\n",
      "排油治\n",
      "后开\n",
      "投次\n",
      "我红\n",
      "疑晒\n",
      "陈坤要\n",
      "董洁见\n",
      "所爱成\n",
      "蒋欣为\n",
      "有商\n",
      "其性\n",
      "认遭\n",
      "台蔚来\n",
      "es8\n",
      "徐坤疑\n",
      "邵夏\n",
      "根粉\n",
      "转红\n",
      "送首\n",
      "人久\n",
      "骗情\n",
      "恐惹\n",
      "薛之谦摊\n",
      "最会装\n",
      "薛之谦自\n",
      "装逼立\n",
      "薛之谦演\n",
      "主球\n",
      "更爱甜\n",
      "杀个\n",
      "别琐\n",
      "蛋价\n",
      "掺点\n",
      "野原\n",
      "兰棵\n",
      "得脑\n",
      "排干\n",
      "因不戒\n",
      "怒降\n",
      "做小糖\n",
      "六年级\n",
      "鼻用\n",
      "袁弘爆\n",
      "改票\n",
      "器全\n",
      "袁立别\n",
      "撕战\n",
      "拖款\n",
      "赵丽颖系\n",
      "带牙套\n",
      "大帽\n",
      "十二句\n",
      "大伪\n",
      "潜成\n",
      "不给生\n",
      "真滑\n",
      "自扇\n",
      "指不雅\n",
      "伤家\n",
      "饭气\n",
      "宽贵\n",
      "梵资管\n",
      "肚大如球\n",
      "刀叔\n",
      "扎情\n",
      "负点责\n",
      "g6\n",
      "袁世杰\n",
      "摇中\n",
      "怒烧\n",
      "疑因查\n",
      "神是\n",
      "有筋\n",
      "传射\n",
      "竞升\n",
      "韩古村\n",
      "多降\n",
      "处肉\n",
      "后远超\n",
      "以正\n",
      "之风\n",
      "力撑\n",
      "强光照\n",
      "h20\n",
      "可伶\n",
      "选座\n",
      "认真思考\n",
      "之鬼门\n",
      "红块\n",
      "其咎\n",
      "正以\n",
      "家会\n",
      "关晓彤生\n",
      "看怒\n",
      "胡路区\n",
      "劳肥\n",
      "管办\n",
      "升哥\n",
      "许晴太作\n",
      "暗批\n",
      "和现\n",
      "爆恋童\n",
      "转自\n",
      "献爱王\n",
      "该出\n",
      "准不信\n",
      "可鱼\n",
      "想演\n",
      "分卖\n",
      "已使\n",
      "蓬出\n",
      "用非\n",
      "烯快\n",
      "争疯\n",
      "黑稿\n",
      "侧空\n",
      "只会涨\n",
      "台会神\n",
      "王思聪放话\n",
      "普制\n",
      "被性\n",
      "侵者\n",
      "做要\n",
      "维嘉停\n",
      "录何\n",
      "走定\n",
      "话暖心\n",
      "十几次\n",
      "坐娜姐\n",
      "杨迪送\n",
      "吴昕会\n",
      "诞子\n",
      "听林丹\n",
      "谢菲恋\n",
      "谢少\n",
      "提小\n",
      "谢贤慌\n",
      "谢贤死\n",
      "想替\n",
      "谢贤邀\n",
      "亿换\n",
      "形只\n",
      "影单\n",
      "亿难\n",
      "字霆锋\n",
      "五一回\n",
      "港办\n",
      "爸害\n",
      "出恐\n",
      "谢贤自\n",
      "失得\n",
      "柏芝家\n",
      "一念间\n",
      "传喜\n",
      "前似\n",
      "完无一\n",
      "十辆\n",
      "疑隔空\n",
      "没尽\n",
      "竟想花\n",
      "亿把\n",
      "酒口\n",
      "3xl\n",
      "钙王\n",
      "e79w32\n",
      "运死\n",
      "旧爱大\n",
      "高管互\n",
      "供其\n",
      "照杨\n",
      "帮甜馨\n",
      "愿得\n",
      "实李\n",
      "想秀\n",
      "卖人设\n",
      "带群\n",
      "迪玛希\n",
      "曝办\n",
      "脸亮\n",
      "太响\n",
      "给乐视\n",
      "乐视命\n",
      "劳福德\n",
      "君花\n",
      "赌石大牛\n",
      "高货\n",
      "奥拓换\n",
      "莫湾基\n",
      "帕克恐\n",
      "慈善赛\n",
      "赫子铭称\n",
      "涵力\n",
      "李沁女\n",
      "赵丽颖人\n",
      "赵丽颖仅\n",
      "撤有\n",
      "冯绍峰疑\n",
      "拍添\n",
      "赵丽颖冲\n",
      "你颖宝\n",
      "张翰俩\n",
      "赵丽颖长\n",
      "框演\n",
      "赵丽颖喜\n",
      "宣新\n",
      "高奢\n",
      "冯绍峰家\n",
      "装疼\n",
      "赵丽颖官\n",
      "宣完\n",
      "赵丽颖当\n",
      "何炅笑\n",
      "爆不雅照\n",
      "已均\n",
      "发盐\n",
      "惹人赞\n",
      "扣图\n",
      "前上\n",
      "有文替\n",
      "武替\n",
      "论卧\n",
      "接剧\n",
      "混剪\n",
      "棋帅\n",
      "赵丽颖现\n",
      "真恋\n",
      "修图师\n",
      "他秀\n",
      "冯绍峰帅\n",
      "他帅\n",
      "陈晓说\n",
      "谈场\n",
      "曝未\n",
      "曝楚\n",
      "爆楚\n",
      "乔传用\n",
      "抱替\n",
      "撒起\n",
      "连范爷\n",
      "系男神\n",
      "我美\n",
      "五家\n",
      "可及\n",
      "敲迪丽\n",
      "反笑\n",
      "一世英名\n",
      "毁光\n",
      "卖炸串\n",
      "已尽\n",
      "看球球\n",
      "炫迈\n",
      "向利哥\n",
      "小犟\n",
      "哲家军\n",
      "帮利哥\n",
      "小安九入\n",
      "九局\n",
      "首麦\n",
      "家似\n",
      "曾欲雪藏\n",
      "立遗\n",
      "争仪\n",
      "自比\n",
      "见利哥\n",
      "带带\n",
      "赵武儿\n",
      "密会迪丽\n",
      "好成\n",
      "认马云\n",
      "快气\n",
      "曝和马云\n",
      "七白膏\n",
      "要叠\n",
      "国了\n",
      "后似\n",
      "韩姨指\n",
      "乱战出\n",
      "愿取\n",
      "越毒\n",
      "对国足\n",
      "提力\n",
      "速干\n",
      "韬会\n",
      "鹿含\n",
      "缓震\n",
      "我怒\n",
      "闺蜜学\n",
      "随流\n",
      "速卖通\n",
      "开纯电\n",
      "灯是\n",
      "混差\n",
      "肝毒防\n",
      "疤膏\n",
      "亿主播\n",
      "旺己\n",
      "旺子\n",
      "铁元素\n",
      "取车\n",
      "未配\n",
      "不偷\n",
      "集满\n",
      "积赞\n",
      "b2c\n",
      "新大招\n",
      "碰维\n",
      "轻加\n",
      "艾炙来\n",
      "干满\n",
      "而里\n",
      "人取\n",
      "个月速\n",
      "殘疾人\n",
      "能夠\n",
      "返厂\n",
      "美人魚\n",
      "纸皮\n",
      "六千元\n",
      "近加\n",
      "近半年\n",
      "一春\n",
      "大耳雷子\n",
      "博主称\n",
      "迅播\n",
      "多少度\n",
      "繁事\n",
      "太毁\n",
      "价才\n",
      "没枪\n",
      "恐伤\n",
      "还记\n",
      "亿帮\n",
      "越富\n",
      "很受\n",
      "鱼别\n",
      "特伤\n",
      "种假\n",
      "虽大\n",
      "稳山\n",
      "娃恨\n",
      "伙起\n",
      "三瓶\n",
      "扶车尬\n",
      "用万人\n",
      "辣竟\n",
      "这乱\n",
      "再香\n",
      "越有\n",
      "吴京成\n",
      "男到\n",
      "太背\n",
      "事来\n",
      "点醋\n",
      "别常\n",
      "二哈成\n",
      "这字\n",
      "别想申\n",
      "萌到\n",
      "赵丽颖远\n",
      "吃似\n",
      "元币\n",
      "竟卖\n",
      "吃助\n",
      "咖酚\n",
      "赵丽颖遇\n",
      "黄西发\n",
      "陈自瑶同\n",
      "配双\n",
      "配速\n",
      "地笑\n",
      "易清洗\n",
      "极香\n",
      "卖上\n",
      "竟能治好\n",
      "这书\n",
      "梵希\n",
      "称断\n",
      "货王\n",
      "食材用\n",
      "剧是\n",
      "这门炮\n",
      "韦少利\n",
      "找人顶\n",
      "十场\n",
      "不输迪丽\n",
      "光不舍\n",
      "惹泪\n",
      "郑恺祖\n",
      "蓝未\n",
      "直掉\n",
      "因不红\n",
      "终首\n",
      "季跑\n",
      "二女\n",
      "累齐\n",
      "真会藏\n",
      "谢谢您\n",
      "寒要\n",
      "高聚能\n",
      "阿雀山\n",
      "斤大蛇\n",
      "速点\n",
      "鸡长\n",
      "湖下\n",
      "巾石\n",
      "百变身\n",
      "遭指性\n",
      "鼻好\n",
      "嘴凸\n",
      "鼻太\n",
      "邓莎用\n",
      "业富\n",
      "轨为\n",
      "超哥求\n",
      "男全\n",
      "邓超江\n",
      "妈气\n",
      "邓超苦\n",
      "那個\n",
      "難忍\n",
      "歲爺\n",
      "爺給\n",
      "有个富\n",
      "连老梁\n",
      "难报\n",
      "那英因\n",
      "抢田震\n",
      "微博关\n",
      "女骗\n",
      "之歌\n",
      "那英谈\n",
      "受太多\n",
      "邀刀郎\n",
      "邱泽曾\n",
      "某辅\n",
      "警开\n",
      "打小三\n",
      "马云连\n",
      "昆渣\n",
      "现紧\n",
      "十几辆\n",
      "致多\n",
      "卡补\n",
      "审期\n",
      "鹿晗力\n",
      "陈赫爆\n",
      "太能作\n",
      "曾大闹\n",
      "张翰七字\n",
      "演男主\n",
      "没娜\n",
      "郑爽发\n",
      "太多暖味\n",
      "身畔\n",
      "张恒吻\n",
      "张翰应\n",
      "特像\n",
      "最爱爽\n",
      "月定\n",
      "风燕\n",
      "扎秀\n",
      "爆热\n",
      "宋宁来\n",
      "没离成\n",
      "携嫩模\n",
      "欺师灭\n",
      "祖想\n",
      "姜昆能\n",
      "郭德纲息\n",
      "逼岳云鹏\n",
      "誓疑\n",
      "指上\n",
      "唱新歌\n",
      "两物同\n",
      "嫂说\n",
      "说酸生\n",
      "男辣生\n",
      "狂撒\n",
      "悄吃\n",
      "万杯\n",
      "第五种\n",
      "不吐\n",
      "酷宝儿\n",
      "加双摄\n",
      "男圆女\n",
      "盼带\n",
      "中潜\n",
      "三连板\n",
      "特仑苏\n",
      "缴会\n",
      "悦榕庄\n",
      "嫌路\n",
      "堵开\n",
      "领跌\n",
      "树倒\n",
      "例人\n",
      "狼真要\n",
      "第一笔\n",
      "五市\n",
      "两区\n",
      "九县\n",
      "设两\n",
      "西野朗\n",
      "助之小\n",
      "皇疑涉\n",
      "陈学冬有\n",
      "相食\n",
      "饮粒\n",
      "金投\n",
      "那英狂\n",
      "试吻\n",
      "酬表\n",
      "韩颖华爆\n",
      "名女模\n",
      "入酒\n",
      "金針菇\n",
      "變多\n",
      "逆生長\n",
      "相關\n",
      "鱼友们\n",
      "扬竿\n",
      "散炮\n",
      "大撒狗\n",
      "粮秀\n",
      "唐嫣定\n",
      "待捞\n",
      "但易\n",
      "先退\n",
      "发像\n",
      "乃乐视\n",
      "十几家\n",
      "补卡\n",
      "关不多\n",
      "痛下\n",
      "万定\n",
      "超七\n",
      "锋菲大婚\n",
      "谢贤站\n",
      "老罗微\n",
      "真机图\n",
      "姓周\n",
      "曲腿\n",
      "直臂\n",
      "孟岗镇\n",
      "首撞\n",
      "20180614\n",
      "建和街\n",
      "需急\n",
      "百户\n",
      "万收来\n",
      "晕沉\n",
      "扔点\n",
      "万交\n",
      "哪座\n",
      "ca1350\n",
      "珍草\n",
      "闪偷\n",
      "涉兰\n",
      "集赞够\n",
      "完该\n",
      "腹藏\n",
      "几宗\n",
      "爱琴\n",
      "速改\n",
      "进河\n",
      "某楚\n",
      "主醉\n",
      "杨公寻龙\n",
      "为考\n",
      "透黑似\n",
      "如绸\n",
      "空界\n",
      "阿娇赖\n",
      "弘国\n",
      "未买\n",
      "憾平\n",
      "幂姐\n",
      "天斑\n",
      "这涂\n",
      "imagina\n",
      "链圈\n",
      "助马云\n",
      "诛仙\n",
      "女女\n",
      "群称\n",
      "乘路\n",
      "之宜\n",
      "命换\n",
      "秦舒培要\n",
      "产有\n",
      "中牛\n",
      "三四个\n",
      "腰治\n",
      "拳迷为\n",
      "俄羅斯\n",
      "市場\n",
      "大伽\n",
      "惊炸\n",
      "人奔富\n",
      "达摩院\n",
      "爆利\n",
      "后电\n",
      "马云上\n",
      "马云不惧\n",
      "东无语\n",
      "i6\n",
      "8w\n",
      "20w\n",
      "马云乐\n",
      "亳言\n",
      "马云借\n",
      "分没到\n",
      "曝金句\n",
      "不达\n",
      "会下\n",
      "董都\n",
      "放新招\n",
      "马云受\n",
      "几辈子\n",
      "马云拜\n",
      "无房族\n",
      "马云数\n",
      "那三大\n",
      "卷潮\n",
      "马云欲\n",
      "打无商\n",
      "可务\n",
      "富起\n",
      "一神\n",
      "第三届\n",
      "亿位\n",
      "马云挡\n",
      "a5\n",
      "翻生\n",
      "东答\n",
      "雅灭\n",
      "人会富\n",
      "万存\n",
      "年二大\n",
      "马云脸\n",
      "马云豪车\n",
      "称送\n",
      "没人脉\n",
      "五到\n",
      "末来\n",
      "任正菲\n",
      "睡后\n",
      "馅入\n",
      "个大牛\n",
      "发啦\n",
      "1a\n",
      "换道\n",
      "终嫁\n",
      "背怕\n",
      "真不大\n",
      "退恐\n",
      "萝莉呆萌\n",
      "周秀波\n",
      "亿镑\n",
      "郑爽照\n",
      "节众\n",
      "泰国人\n",
      "周夏雪\n",
      "马思纯力\n",
      "之好\n",
      "吸开\n",
      "拍死\n",
      "交为\n",
      "擂人\n",
      "竟点\n",
      "宇给\n",
      "遭孟非\n",
      "男留\n",
      "灯到\n",
      "微博号\n",
      "先爆\n",
      "被国\n",
      "齐点\n",
      "需打\n",
      "多读\n",
      "点书\n",
      "撕上\n",
      "鹿晗求\n",
      "气骂\n",
      "夺王\n",
      "爸结\n",
      "爸卷\n",
      "我理\n",
      "遭四字\n",
      "加烂\n",
      "奖获\n",
      "赞正\n",
      "心真毒\n",
      "马蓉怕\n",
      "学凤姐\n",
      "马蓉戏\n",
      "亿马蓉\n",
      "还宝强\n",
      "万带\n",
      "马蓉斥\n",
      "连易\n",
      "强放话\n",
      "马蓉法\n",
      "院争儿\n",
      "清痛\n",
      "脸好\n",
      "马蓉用\n",
      "遭颖宝\n",
      "丽颖神\n",
      "财两失\n",
      "但素\n",
      "想求\n",
      "黄宝强\n",
      "马蓉花\n",
      "多大仇\n",
      "曝花\n",
      "被颖宝\n",
      "马蓉载\n",
      "太马蓉\n",
      "马蓉假\n",
      "怪响\n",
      "舒揭\n",
      "这方面\n",
      "千好\n",
      "口时\n",
      "科二科\n",
      "能加分\n",
      "拟扣\n",
      "驾着\n",
      "人想考\n",
      "学个\n",
      "考个\n",
      "科三将\n",
      "四新规\n",
      "秦舒培过\n",
      "郑嘉颖为\n",
      "表真爱\n",
      "郑嘉颖婚\n",
      "点透\n",
      "细思\n",
      "恐极\n",
      "称儿\n",
      "获赞强\n",
      "希才\n",
      "陈晓秀\n",
      "臭脸\n",
      "全崩\n",
      "陈晓成\n",
      "陈晓再\n",
      "倪妻\n",
      "传疑\n",
      "薛之谦受\n",
      "人写\n",
      "喷渣\n",
      "女主王\n",
      "天楚\n",
      "互叫\n",
      "从面\n",
      "仙是\n",
      "刘芷微发\n",
      "佟丽娅首\n",
      "佟丽娅用\n",
      "陈思诚发\n",
      "女主发\n",
      "原小三\n",
      "佟丽娅情\n",
      "曝携\n",
      "哑忍\n",
      "勾俩\n",
      "陈思诚陷\n",
      "爆入\n",
      "拒读\n",
      "希晒生\n",
      "陈晓谈\n",
      "贞湛恋\n",
      "希微\n",
      "希传\n",
      "希是\n",
      "实凿\n",
      "陈晓霍\n",
      "现晒\n",
      "陈猎\n",
      "太毒\n",
      "打狱\n",
      "大呼辣\n",
      "绿成\n",
      "还肯\n",
      "疑因江\n",
      "因江\n",
      "曝人设\n",
      "晒孕肚\n",
      "陈赫为\n",
      "讽借\n",
      "团会\n",
      "陈赫花\n",
      "陈赫谈\n",
      "邓超破\n",
      "陈金典\n",
      "陈锴杰\n",
      "好药\n",
      "降血高\n",
      "多趟\n",
      "推韩流\n",
      "爬藤花\n",
      "要种\n",
      "香飘\n",
      "曝黑\n",
      "黑过\n",
      "还性\n",
      "需喷点\n",
      "起市\n",
      "mp3\n",
      "菜伤\n",
      "春春带\n",
      "或京冀\n",
      "155cc\n",
      "修墓\n",
      "寻得托\n",
      "油米\n",
      "雞蛋\n",
      "鐘會\n",
      "之迪丽\n",
      "签进\n",
      "咖位\n",
      "签了\n",
      "继马云\n",
      "其下家\n",
      "雾下\n",
      "出高货\n",
      "锋管\n",
      "这币\n",
      "购率\n",
      "胜于蓝\n",
      "鲁豫大赞\n",
      "亿算\n",
      "已欲\n",
      "召妓\n",
      "揭霍\n",
      "杜江齐\n",
      "秦岚忙\n",
      "天灭\n",
      "人灭\n",
      "总借\n",
      "独立思考\n",
      "本世纪内\n",
      "椰苗\n",
      "毒唯粉\n",
      "敷得\n",
      "李佳后\n",
      "最帅星\n",
      "粘好\n",
      "出优\n",
      "花称\n",
      "一万亿美元\n",
      "发迪丽\n",
      "发迪力\n",
      "韩妞\n",
      "竟拿盆接\n",
      "当志颖\n",
      "插票\n",
      "昆凌摸\n",
      "献声\n",
      "竟无一\n",
      "韩红办\n",
      "钱不花\n",
      "脆口\n",
      "顶股\n",
      "套商\n",
      "为公\n",
      "附公\n",
      "几十分钟\n",
      "四分之一\n",
      "颐妍堂\n",
      "暴漏\n",
      "背盖\n",
      "纽途丽爱\n",
      "不飞\n",
      "五里\n",
      "之计\n",
      "手检\n",
      "打加\n",
      "gb18187\n",
      "六七十年代\n",
      "两毛\n",
      "店仅\n",
      "吃梨防\n",
      "豹性\n",
      "喷停\n",
      "睡范伟\n",
      "魅族乐视\n",
      "全疯\n",
      "机皇真机\n",
      "挑事\n",
      "莫雷笑\n",
      "必送\n",
      "先发个\n",
      "詹韦全\n",
      "董璇头\n",
      "翔能\n",
      "侵在\n",
      "翔恐\n",
      "翔换\n",
      "霸凌患\n",
      "求凤九\n",
      "活灌\n",
      "铜水\n",
      "卓伟道\n",
      "力未\n",
      "档上\n",
      "证未\n",
      "叶翠翠\n",
      "养个\n",
      "穿肥款\n",
      "竟干出\n",
      "战黑坑\n",
      "狂拔\n",
      "人收\n",
      "锅入\n",
      "分学霸\n",
      "抽开\n",
      "前忙\n",
      "五大类\n",
      "又治\n",
      "新规日\n",
      "高钾\n",
      "邪地\n",
      "无大变\n",
      "国乒出\n",
      "教国\n",
      "亿人里\n",
      "多夺\n",
      "硬咽\n",
      "腥毒\n",
      "刚换帅\n",
      "因换帅\n",
      "无鸡\n",
      "之谈\n",
      "鸡蛋里挑\n",
      "看喜\n",
      "鸭血里\n",
      "要怪\n",
      "继隐\n",
      "实比\n",
      "狂掉\n",
      "微博变\n",
      "粉发\n",
      "送鞋\n",
      "关晓丹\n",
      "一亿多\n",
      "接新戏\n",
      "向迪丽\n",
      "陈赫发\n",
      "倒求\n",
      "号会\n",
      "鹿晗学\n",
      "对迪丽\n",
      "欣都\n",
      "胖迪才\n",
      "拍择\n",
      "生有\n",
      "爱豆接\n",
      "演小昭\n",
      "鹿晗点\n",
      "赞迪丽\n",
      "爆黑料\n",
      "因太娘\n",
      "鹿晗生\n",
      "爆其隐\n",
      "档床\n",
      "出跑\n",
      "杨颖受\n",
      "问有\n",
      "卓伟戏\n",
      "上十赌\n",
      "陈晓去\n",
      "先灭\n",
      "工黄毅\n",
      "作室\n",
      "第二页\n",
      "不忘手\n",
      "惟爱\n",
      "马句\n",
      "没死现\n",
      "杨颖陷\n",
      "重料\n",
      "清狂\n",
      "正戏\n",
      "清用\n",
      "时爆\n",
      "可婚\n",
      "将致\n",
      "韩樱子\n",
      "后美过\n",
      "年朴\n",
      "疑新\n",
      "爆已\n",
      "选豪车\n",
      "惹人愁\n",
      "其能\n",
      "坐人拉货\n",
      "岁鲁豫近\n",
      "只鲁豫\n",
      "现传\n",
      "王杰同\n",
      "桥哥\n",
      "爆言\n",
      "微博神\n",
      "同晒\n",
      "董洁带\n",
      "董洁满\n",
      "指想\n",
      "另结\n",
      "纹满\n",
      "筱绡\n",
      "贱婢\n",
      "真华妃\n",
      "待儿\n",
      "小三引\n",
      "我想怀\n",
      "想坏\n",
      "变美想\n",
      "网传放洁\n",
      "宰得\n",
      "同演\n",
      "后传\n",
      "今一人\n",
      "甩包\n",
      "万平事\n",
      "爆一波\n",
      "删疑\n",
      "爆其花\n",
      "顶热\n",
      "发叫\n",
      "三娃\n",
      "白萝布\n",
      "30ml\n",
      "付花\n",
      "黄渤加\n",
      "第四部\n",
      "黄渤三\n",
      "路放\n",
      "挑着\n",
      "满获\n",
      "这微博\n",
      "和富\n",
      "三高输\n",
      "戒得\n",
      "产烟\n",
      "烂戏\n",
      "半内\n",
      "鞋会\n",
      "急个\n",
      "食蟹\n",
      "果吃\n",
      "动下\n",
      "top5\n",
      "脏到\n",
      "堵脑\n",
      "怒升\n",
      "看腿\n",
      "岚头\n",
      "镇岚\n",
      "借子\n",
      "愿护\n",
      "太直\n",
      "愿用\n",
      "爆嫁\n",
      "袁立姐\n",
      "博开\n",
      "最烂\n",
      "袁立友\n",
      "数条\n",
      "招反\n",
      "浙卫脸\n",
      "秦一铭\n",
      "乐嘉力\n",
      "人爆\n",
      "因太多\n",
      "张桐发\n",
      "袁立直\n",
      "这集\n",
      "太戏\n",
      "称讨薪\n",
      "20gb\n",
      "版迪丽\n",
      "音四子\n",
      "用渣\n",
      "胡歌教\n",
      "还火\n",
      "晏恋\n",
      "晏许\n",
      "两人暗\n",
      "八月份\n",
      "名吃瓜\n",
      "凡发\n",
      "萧敬腾力\n",
      "竟分\n",
      "越红越\n",
      "生吃熟\n",
      "西崖底\n",
      "服在\n",
      "散尽\n",
      "受怕\n",
      "准会降\n",
      "毁神星\n",
      "人比\n",
      "多回\n",
      "系拍微\n",
      "河路\n",
      "喜当爸\n",
      "与志玲\n",
      "到林\n",
      "微博透\n",
      "薛之谦同\n",
      "密游\n",
      "腰能\n",
      "揭用\n",
      "许晴当\n",
      "一胖识\n",
      "赵薇命\n",
      "这非\n",
      "收小\n",
      "大醉后\n",
      "帽甜\n",
      "变萌\n",
      "很铁\n",
      "马云认\n",
      "背定\n",
      "好娘\n",
      "贾装\n",
      "得服\n",
      "声临\n",
      "其境\n",
      "退戏\n",
      "先凉\n",
      "抢颖宝\n",
      "杨颖摊\n",
      "听鲁能\n",
      "等物\n",
      "马都拉\n",
      "万完\n",
      "爆路\n",
      "后频\n",
      "遭康辉\n",
      "演是\n",
      "巴城麻\n",
      "6395505654904652034\n",
      "曝传\n",
      "微凸孕\n",
      "轨闹\n",
      "删秀\n",
      "维嘉疯\n",
      "非黑\n",
      "岁疑\n",
      "谢贤喜\n",
      "驾豪\n",
      "谢贤豪车\n",
      "儿豪车\n",
      "获将\n",
      "归柏芝\n",
      "字狠\n",
      "曝谢贤\n",
      "锋疑\n",
      "情到\n",
      "而选\n",
      "亿拿回\n",
      "埋珠\n",
      "三两米\n",
      "痛过\n",
      "多过\n",
      "因借戏\n",
      "穷成\n",
      "lucus\n",
      "弃柏芝\n",
      "选近\n",
      "二子录\n",
      "养孩\n",
      "气怒\n",
      "各回\n",
      "买不亏\n",
      "當心\n",
      "傷腎\n",
      "損害\n",
      "障礙\n",
      "吃者\n",
      "不考\n",
      "李湘头\n",
      "艺恋\n",
      "后素颜\n",
      "赫子铭后\n",
      "爆赫子铭\n",
      "何洁别\n",
      "后赫子铭\n",
      "各分\n",
      "疑何洁现\n",
      "度极\n",
      "非渣\n",
      "我够\n",
      "教甜馨\n",
      "傻死\n",
      "这群神\n",
      "贾笑\n",
      "来美白\n",
      "有红彩\n",
      "对鲁能\n",
      "专方\n",
      "军医治\n",
      "疼秒法\n",
      "第一集\n",
      "宝多\n",
      "不己\n",
      "宝卖萌\n",
      "事让颖宝\n",
      "列队欢迎\n",
      "赵丽颖教\n",
      "宝太有\n",
      "戏时\n",
      "迪玛希新\n",
      "爆曾\n",
      "两厢\n",
      "希哭\n",
      "秀智\n",
      "赵丽颖井柏然\n",
      "泥萌造\n",
      "合狗\n",
      "尽现\n",
      "赵丽颖继\n",
      "何炅起\n",
      "陈伟霆会\n",
      "反指\n",
      "赵丽颖大虐\n",
      "上仙\n",
      "揭花\n",
      "开豪\n",
      "瘦多\n",
      "低成\n",
      "吴京道\n",
      "人鱼恋\n",
      "暖萌\n",
      "两大狗\n",
      "补刀疑\n",
      "刘丹怒\n",
      "与颖儿\n",
      "高多金\n",
      "已石锤\n",
      "仔爆\n",
      "王鸥现\n",
      "姐太\n",
      "科一\n",
      "科四\n",
      "男小\n",
      "人档\n",
      "头好\n",
      "说颖宝\n",
      "一个圈\n",
      "赵丽颖首\n",
      "还壮\n",
      "300ml\n",
      "共住\n",
      "这卫衣\n",
      "遭嘲\n",
      "无白\n",
      "爆作\n",
      "赵丽颖快\n",
      "萌死\n",
      "超暖\n",
      "赵又廷迪丽\n",
      "齐骂\n",
      "红大婚\n",
      "某主播\n",
      "球新\n",
      "胆挺大\n",
      "宣传照\n",
      "嘴肿\n",
      "不有\n",
      "妈宝\n",
      "嘻哈圈\n",
      "郭达近\n",
      "何炅藏\n",
      "维嘉暴\n",
      "晒妻\n",
      "八次\n",
      "尖笑\n",
      "做油\n",
      "泼面\n",
      "那层\n",
      "相胁\n",
      "因对\n",
      "师兄弟\n",
      "买前\n",
      "车不崩\n",
      "唐嫣装\n",
      "曝孙俪\n",
      "找卓伟\n",
      "林丹后\n",
      "遭孙俪\n",
      "轨花\n",
      "大住\n",
      "爆想用\n",
      "邓超居\n",
      "事有\n",
      "邓超游\n",
      "马云非\n",
      "男同\n",
      "剩载\n",
      "车库里\n",
      "真不浅\n",
      "恐已\n",
      "飞在\n",
      "冲十连板\n",
      "李佳悦\n",
      "播鹿晗\n",
      "邓超发\n",
      "学霸超\n",
      "第六集\n",
      "爆要\n",
      "我无语\n",
      "小肉球\n",
      "通是\n",
      "小肉粒\n",
      "邓超包\n",
      "g240\n",
      "快输\n",
      "此新规\n",
      "郑爽求\n",
      "爸疑\n",
      "故布\n",
      "用种\n",
      "书大赞\n",
      "张翰才\n",
      "博后\n",
      "而行\n",
      "屏版\n",
      "600w\n",
      "罐好\n",
      "有负\n",
      "多似\n",
      "求儿\n",
      "怎料\n",
      "金嘛\n",
      "配纯电\n",
      "万不火\n",
      "增驾\n",
      "亿农房\n",
      "越吵\n",
      "一属\n",
      "想不发\n",
      "家吵\n",
      "情打\n",
      "网红真\n",
      "卓伟神\n",
      "带孩及\n",
      "拍桌\n",
      "威爷\n",
      "诗渐\n",
      "脸手\n",
      "招称\n",
      "后美\n",
      "拼色\n",
      "如戏\n",
      "卓伟后\n",
      "韩澳\n",
      "常使\n",
      "虽长\n",
      "克加\n",
      "水煎服\n",
      "岁治好\n",
      "试不试\n",
      "三圣散\n",
      "速透皮\n",
      "症有\n",
      "奇药\n",
      "一个顶\n",
      "十付\n",
      "用土\n",
      "老中攻\n",
      "你治\n",
      "夜交藤\n",
      "皮配\n",
      "却百治\n",
      "我三哥\n",
      "看明间\n",
      "火灸\n",
      "消痛膏\n",
      "小飞燕\n",
      "痛起\n",
      "以疼\n",
      "攻疼\n",
      "耳加\n",
      "别求\n",
      "二十几天\n",
      "三五天\n",
      "成病\n",
      "l4l5\n",
      "刺血排\n",
      "想永\n",
      "彭突\n",
      "熬制\n",
      "苗药\n",
      "人腰\n",
      "招治\n",
      "突全\n",
      "韩老师\n",
      "一狗仔\n",
      "欲断\n",
      "如娶\n",
      "如伴\n",
      "你动\n",
      "红配\n",
      "招叫\n",
      "得易\n",
      "体适\n",
      "一盏\n",
      "三四斤\n",
      "减命\n",
      "把生\n",
      "300g\n",
      "周爆减\n",
      "非胖\n",
      "爽到\n",
      "用红米\n",
      "藏友长\n",
      "种以\n",
      "老说\n",
      "嘴脏\n",
      "薛之谦竟\n",
      "不脏手\n",
      "马云人\n",
      "马云金句\n",
      "可凉血\n",
      "改开\n",
      "刚擦\n",
      "全清光\n",
      "杨紫秒\n",
      "赛悍\n",
      "远远不够\n",
      "李易峰疑\n",
      "气爽\n",
      "吃豆\n",
      "少食\n",
      "几桶\n",
      "人花\n",
      "艺方\n",
      "它具\n",
      "胎宝\n",
      "斑太难\n",
      "还坏\n",
      "年三版\n",
      "可清肠\n",
      "懂花\n",
      "六同\n",
      "整株\n",
      "肝用\n",
      "杨颖换\n",
      "几波\n",
      "爆带\n",
      "暂不接剧\n",
      "陈伟霆光\n",
      "吴亦凡秀\n",
      "和霆霆\n",
      "箱油能\n",
      "看萌娃\n",
      "何洁用\n",
      "惨博\n",
      "显而易\n",
      "网惹\n",
      "气成\n",
      "歌里\n",
      "两期\n",
      "看鹿晗\n",
      "妹迪丽\n",
      "终现\n",
      "卫衣成\n",
      "还悄\n",
      "可帅\n",
      "可萝莉\n",
      "可排\n",
      "太走心\n",
      "说太会\n",
      "坐鹿晗\n",
      "变宅\n",
      "对罗晋\n",
      "曝大\n",
      "俩成\n",
      "疑讽\n",
      "人老先\n",
      "老腿\n",
      "上管\n",
      "赵丽颖范爷\n",
      "六条\n",
      "还禁\n",
      "揭它\n",
      "更火\n",
      "指其\n",
      "马蓉酒\n",
      "驾遇\n",
      "能迁\n",
      "邓紫棋称\n",
      "照送\n",
      "邓紫棋疑\n",
      "正旧\n",
      "三五个\n",
      "曝次\n",
      "车晓是\n",
      "爆霍\n",
      "今力\n",
      "开脑\n",
      "只开\n",
      "穷是\n",
      "并手\n",
      "那英大\n",
      "必常\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "养声\n",
      "露下\n",
      "种颜色\n",
      "医都\n",
      "没卵用\n",
      "几万人\n",
      "点事\n",
      "那英首\n",
      "小三开\n",
      "打星们\n",
      "红本\n",
      "镇因\n",
      "张恒新\n",
      "赵丽颖接\n",
      "入群\n",
      "张翰力\n",
      "继快\n",
      "称马\n",
      "这四字\n",
      "前开\n",
      "两人发\n",
      "何炅维嘉\n",
      "內地\n",
      "爽恋\n",
      "糖里\n",
      "两人似\n",
      "微博珠\n",
      "曝马\n",
      "微博写\n",
      "整蒙\n",
      "家场\n",
      "找力宏\n",
      "三人算\n",
      "息屏\n",
      "李湘爆\n",
      "云伟\n",
      "马云演\n",
      "接男宝进\n",
      "信则\n",
      "女像\n",
      "我独\n",
      "一食材\n",
      "头不疼\n",
      "一人战\n",
      "算才\n",
      "图比\n",
      "试目\n",
      "脸谈\n",
      "已存\n",
      "万人存\n",
      "网红为\n",
      "音惨\n",
      "漫展\n",
      "关晓彤团\n",
      "关晓彤索\n",
      "比蛇\n",
      "baofeng\n",
      "男贱\n",
      "假裙\n",
      "撕人\n",
      "小汉教\n",
      "爆汪峰\n",
      "不来学\n",
      "顶百副药\n",
      "一钓\n",
      "获多到\n",
      "手竿台\n",
      "可连\n",
      "低钠\n",
      "称地\n",
      "心人\n",
      "再条\n",
      "添未解\n",
      "侠竟\n",
      "四无\n",
      "面若\n",
      "同锅\n",
      "编可转\n",
      "兑到\n",
      "时撒\n",
      "发吃点\n",
      "前必\n",
      "一东后\n",
      "所转\n",
      "日岳阳\n",
      "不关会\n",
      "某芳\n",
      "诗张\n",
      "根硕\n",
      "个养\n",
      "肝菜\n",
      "天由\n",
      "体大如\n",
      "嘴大如盆\n",
      "快偷\n",
      "出尽\n",
      "邀戏\n",
      "闫妮认\n",
      "上纹\n",
      "只罚\n",
      "将记\n",
      "分狠\n",
      "大猪\n",
      "终未\n",
      "如润墨\n",
      "从生\n",
      "兑上\n",
      "墨亮\n",
      "司匹林\n",
      "多载\n",
      "不染头\n",
      "变乌密\n",
      "似润墨\n",
      "不抹染剂\n",
      "再密\n",
      "天来\n",
      "三吉\n",
      "不学太亏\n",
      "似墨别\n",
      "发再野\n",
      "五丸\n",
      "多根\n",
      "如雨落\n",
      "虽美白\n",
      "皱显\n",
      "需染\n",
      "如森\n",
      "凶白\n",
      "四粒\n",
      "三千丈\n",
      "斥小三\n",
      "疑指赖\n",
      "公媒\n",
      "李荣浩去\n",
      "劲销\n",
      "万多辆\n",
      "防蹭网\n",
      "恩凯\n",
      "我来养\n",
      "胖一\n",
      "遇收\n",
      "某非\n",
      "次婚\n",
      "杨紫问\n",
      "男神名\n",
      "草有主\n",
      "儿疑\n",
      "夜互\n",
      "发照秀\n",
      "后介\n",
      "现欲\n",
      "用六字\n",
      "当谢娜\n",
      "懂博越\n",
      "纵置\n",
      "减了\n",
      "清肠养\n",
      "时黃瓜別\n",
      "脂掉\n",
      "有奇方\n",
      "湿毒调\n",
      "亲看\n",
      "开掉\n",
      "千平\n",
      "人暴\n",
      "秘透\n",
      "决密\n",
      "套别\n",
      "还斗得\n",
      "预谈\n",
      "会降\n",
      "mp467\n",
      "马云爆\n",
      "一马\n",
      "中造\n",
      "马云透\n",
      "吴京触\n",
      "马云分\n",
      "一个千\n",
      "变富\n",
      "穷请\n",
      "富人榜\n",
      "马云排\n",
      "马云财\n",
      "之神\n",
      "觉察到\n",
      "20182019\n",
      "再夺\n",
      "东笑\n",
      "曝马伊\n",
      "遭黄\n",
      "缝生\n",
      "我火\n",
      "投马\n",
      "发棒\n",
      "增甜\n",
      "龙空\n",
      "探因\n",
      "乔恩遭\n",
      "这比\n",
      "微搏求\n",
      "微博带\n",
      "讽王\n",
      "仍住\n",
      "马蓉过\n",
      "大孕肚\n",
      "愁色\n",
      "鹿晗发\n",
      "榨成\n",
      "以谢\n",
      "打马蓉\n",
      "送宝强\n",
      "问约\n",
      "分王\n",
      "送马蓉\n",
      "马蓉扎\n",
      "书算\n",
      "忙分\n",
      "叫宝强\n",
      "马蓉刚\n",
      "驯熊\n",
      "微博初\n",
      "买靓房\n",
      "宋喆称\n",
      "搜之马蓉\n",
      "野夫\n",
      "卓伟狗\n",
      "万欲\n",
      "马蓉怒\n",
      "马蓉时\n",
      "需车\n",
      "过满\n",
      "一树\n",
      "子喜\n",
      "谢贤八\n",
      "要秀\n",
      "微博之言\n",
      "陈坤红\n",
      "迅怒\n",
      "那英迫\n",
      "希疑\n",
      "千骨\n",
      "希暗\n",
      "陈晓面\n",
      "陈晓臭\n",
      "遭瞎传\n",
      "希钓出\n",
      "瞪大眼\n",
      "怪到\n",
      "林丹们\n",
      "找小三\n",
      "先开\n",
      "人空\n",
      "耀文\n",
      "曹查理\n",
      "探班白\n",
      "baby16\n",
      "偏高别\n",
      "口全\n",
      "假文\n",
      "今恋\n",
      "牛俊峰\n",
      "有型\n",
      "继惠氏\n",
      "和护\n",
      "崔岷植\n",
      "何孟怀要\n",
      "没照\n",
      "已同\n",
      "港媒称\n",
      "门害\n",
      "秘游\n",
      "何孟怀于\n",
      "人型\n",
      "诵佛\n",
      "抄经\n",
      "对心\n",
      "吻界\n",
      "这盘\n",
      "棋下\n",
      "字服\n",
      "似龙\n",
      "太险\n",
      "不全\n",
      "古级\n",
      "智穹\n",
      "外球\n",
      "人瞬秒\n",
      "用新锅\n",
      "别换\n",
      "卖锅\n",
      "列三大\n",
      "怒言\n",
      "韩红邀\n",
      "其留\n",
      "韩红气\n",
      "八岁时\n",
      "餐坏\n",
      "抱错\n",
      "多吃生\n",
      "最可选\n",
      "成汁\n",
      "天菜\n",
      "为怀\n",
      "首晒孕\n",
      "味足\n",
      "批太作\n",
      "防動脈\n",
      "2mm\n",
      "禅武医\n",
      "一转\n",
      "手麻治好\n",
      "多场\n",
      "美璃\n",
      "重搭\n",
      "需内调\n",
      "周喝\n",
      "加橘\n",
      "天白\n",
      "层卖\n",
      "完可算\n",
      "喷太\n",
      "美欧\n",
      "必内\n",
      "壮到\n",
      "指鹿晗\n",
      "无真爱\n",
      "该分\n",
      "配骁龙\n",
      "两大癌\n",
      "说妈\n",
      "之宝\n",
      "能温\n",
      "知其\n",
      "完长\n",
      "款高\n",
      "脑吃个\n",
      "楼塌\n",
      "rgn0jgq\n",
      "想私\n",
      "夜华\n",
      "多大点\n",
      "晒妈\n",
      "更急\n",
      "猛捞\n",
      "夜华君\n",
      "网传该\n",
      "赵又廷疑\n",
      "专钓\n",
      "连竿到\n",
      "小白到\n",
      "建哥\n",
      "活擒\n",
      "版微\n",
      "信有\n",
      "a00001\n",
      "分考\n",
      "一茶\n",
      "药好\n",
      "可蹭\n",
      "开存\n",
      "保肝强\n",
      "平腰\n",
      "推个\n",
      "小肉\n",
      "由慢\n",
      "粗腰\n",
      "别穿\n",
      "字衫\n",
      "特显\n",
      "消脂王\n",
      "太大易\n",
      "umatin\n",
      "养森\n",
      "康美娜\n",
      "高鑫要\n",
      "g6602\n",
      "奥恰\n",
      "字亮\n",
      "传两人\n",
      "爆闹\n",
      "魚腥\n",
      "成背\n",
      "虽劲道\n",
      "加两宝\n",
      "之患\n",
      "第四招\n",
      "剝掉\n",
      "蛋殼\n",
      "細嫩\n",
      "調理\n",
      "营尚媒\n",
      "知識\n",
      "苦撑\n",
      "薛之谦当\n",
      "不爱何\n",
      "问张\n",
      "肩全\n",
      "同王\n",
      "张凯毅\n",
      "吃杏肉\n",
      "王思聪立\n",
      "立贴\n",
      "鹿晗确\n",
      "依小三\n",
      "依继小三\n",
      "爆黄圣\n",
      "依发\n",
      "两妻\n",
      "归家过\n",
      "避狗仔\n",
      "自言\n",
      "夺女\n",
      "还暴\n",
      "黄渤把\n",
      "黄渤一\n",
      "燕兰熹\n",
      "洗膏\n",
      "拖发\n",
      "太道\n",
      "一小片\n",
      "一烧\n",
      "张一山套\n",
      "六则\n",
      "市防指\n",
      "幼龙\n",
      "Null word embeddings: 27704\n",
      "这会灯\n",
      " \n",
      "《\n",
      "喻言吐槽\n",
      "上吐槽\n",
      "喻言狂\n",
      "ceodiss\n",
      "这五种\n",
      "有名气\n",
      "赌高冰\n",
      "1000vs10\n",
      "快回去\n",
      "霍金的\n",
      "包难消\n",
      "给治好\n",
      "好几个\n",
      "治一好\n",
      "速存\n",
      "日新规\n",
      "想不长\n",
      "开喷战\n",
      "审新规\n",
      "四驱带\n",
      "加分制\n",
      "一个月\n",
      "玩太多\n",
      "養顏茶\n",
      "这几物\n",
      "这四物\n",
      "而出名\n",
      "撒药治\n",
      "软肥肚\n",
      "达人教\n",
      "选股法\n",
      "甩腹\n",
      "171008\n",
      "171110\n",
      "煅荷\n",
      "物泡\n",
      "亿封板\n",
      "万买台\n",
      "这三类\n",
      "第二个\n",
      "驚現\n",
      "講手機\n",
      "快来领\n",
      "桥底下\n",
      "专克鸡\n",
      "勺油治\n",
      "能巧治\n",
      "就治好\n",
      "斩恒大创\n",
      "人太少\n",
      "還敢\n",
      "种食材\n",
      "有益于\n",
      "美白淡\n",
      "日交规\n",
      "驾不系\n",
      "双旗币\n",
      "这三项\n",
      "博瑞颜值\n",
      "可多涨\n",
      "六星版\n",
      "和央企\n",
      "轩逸竟\n",
      "证年\n",
      "马云会\n",
      "74318\n",
      "这两项\n",
      "第三个\n",
      "合三大\n",
      "日算起\n",
      "别忘领\n",
      "小多校\n",
      "乐坏了\n",
      "20180508\n",
      "丰仕洁\n",
      "有所提高\n",
      "还会涨\n",
      "项新规\n",
      "太好了\n",
      "用得着\n",
      "两大新\n",
      "万马云\n",
      "年小本\n",
      "对照表\n",
      "云不回\n",
      "这部分\n",
      "连马云\n",
      "种违\n",
      "新规来\n",
      "祝好孕\n",
      "可加分\n",
      "这三大\n",
      "考新规\n",
      "想学车\n",
      "三大假\n",
      "完不亏\n",
      "再白交\n",
      "那英要\n",
      "朱之文带\n",
      "个小本\n",
      "王西提\n",
      "疑提\n",
      "一金新\n",
      "权待\n",
      "关键所在\n",
      "将会省\n",
      "嫌太辣\n",
      "排不出\n",
      "马云称\n",
      "條飲食\n",
      "一人敢\n",
      "造不出\n",
      "莫雷神\n",
      "仿妆马云\n",
      "赵丽颖饰\n",
      "日陕\n",
      "戏太深\n",
      "要逆袭\n",
      "个小妙\n",
      "岁迪丽\n",
      "没颈纹\n",
      "看不上\n",
      "名埃\n",
      "周晒\n",
      "女宝下\n",
      "太暖心\n",
      "遭酸\n",
      "有所突破\n",
      "三人以\n",
      "甜素颜\n",
      "张继科会\n",
      "地将值\n",
      "有着落\n",
      "车晓曾\n",
      "这辈子\n",
      "天美白\n",
      "黄渤搭戏\n",
      "岁玲花\n",
      "亿险\n",
      "对林丹\n",
      "生下白\n",
      "岁罗晋\n",
      "出男宝\n",
      "亿刘涛\n",
      "岁秋瓷\n",
      "接女宝\n",
      "求摩拜\n",
      "看不下去\n",
      "排肝\n",
      "大食材\n",
      "出小蛮\n",
      "加一物\n",
      "王凤雅\n",
      "李晨要\n",
      "怀男宝\n",
      "款神\n",
      "系胡歌\n",
      "附男\n",
      "理不直\n",
      "各瘦\n",
      "鲍蕾素\n",
      "刘谦近\n",
      "陈坤忍\n",
      "翁帆近\n",
      "同一个\n",
      "比谢娜\n",
      "何炅首\n",
      "迅素颜\n",
      "每天晚上\n",
      "晒孕\n",
      "毛宁会\n",
      "鲁豫近\n",
      "岁鲁豫\n",
      "今傍上\n",
      "英田震\n",
      "疑追生\n",
      "张伦硕要\n",
      "遭吐槽\n",
      "张伦硕生\n",
      "做产检\n",
      "微隆嘟\n",
      "王俊凯易\n",
      "没人敢\n",
      "别不信\n",
      "好膚色\n",
      "传好孕\n",
      "秀逆\n",
      "万起售\n",
      "㊙\n",
      "加一宝\n",
      "引群愤\n",
      "败光霆锋\n",
      "三胞眙\n",
      "英遭\n",
      "曝靠\n",
      "朱之文大婚\n",
      "遇朱\n",
      "曝犯\n",
      "田震近\n",
      "美不回\n",
      "这三物\n",
      "华仔要\n",
      "开卢本伟\n",
      "开复播\n",
      "烟不离\n",
      "因撞场\n",
      "三大悔\n",
      "三大悔害\n",
      "经济实用\n",
      "一万个\n",
      "能买白\n",
      "我治好\n",
      "与会代表\n",
      "换新证\n",
      "载满了\n",
      "或大涨\n",
      "般美白\n",
      "瘦下去\n",
      "太多人\n",
      "有点像\n",
      "曝刷单\n",
      "撕逼战\n",
      "反刷单\n",
      "单争\n",
      "亲民价\n",
      "这一波\n",
      "多着呢\n",
      "方代扣\n",
      "哭死了\n",
      "加熱會\n",
      "黑如碳\n",
      "之事要\n",
      "宝妈愁\n",
      "让你在\n",
      "全限行\n",
      "亿宝粉\n",
      "天发质\n",
      "谢贤为\n",
      "谢贤令\n",
      "行逆驶\n",
      "已选好\n",
      "吸脂水\n",
      "天治根\n",
      "药不离口\n",
      "疯降\n",
      "别约考\n",
      "铁总下\n",
      "降下去\n",
      "曝恋童\n",
      "穿靓靓\n",
      "后辣妈\n",
      "后宝妈\n",
      "曝翁帆\n",
      "斤且\n",
      "韩红泪\n",
      "首同框\n",
      "车内别\n",
      "atfx\n",
      "以色列\n",
      "aiili\n",
      "大变盘\n",
      "这条线\n",
      "带七架\n",
      "斯盾舰\n",
      "脱猫\n",
      "脸迪丽\n",
      "杨颖假\n",
      "chiliz\n",
      "这三家\n",
      "新四字\n",
      "手游帅\n",
      "抽烈\n",
      "coinpark\n",
      "罗恼\n",
      "梅西夺\n",
      "欧皇别\n",
      "狗托\n",
      "买卓伟\n",
      "韬疑\n",
      "fanbeauty\n",
      "仪短\n",
      "android80\n",
      "锦山段\n",
      "宇补位\n",
      "gjsay\n",
      "宋智孝要\n",
      "刘明婷\n",
      "疑退赛\n",
      "卓伟渐\n",
      "首麦词\n",
      "retina15\n",
      "有用吗\n",
      "来源于\n",
      "厂敬鹏\n",
      "平镇厂\n",
      "pg1400\n",
      "薛之谦人设\n",
      "曝让\n",
      "曾艳芬力\n",
      "这么久\n",
      "疑王俊凯\n",
      "传王俊凯\n",
      "王俊凯交\n",
      "太雷人\n",
      "付不起\n",
      "没人要\n",
      "人臨\n",
      "2017ufo\n",
      "乐寿寺\n",
      "vol98\n",
      "wpa3\n",
      "淳恩\n",
      "莫雷欲\n",
      "陈赫车\n",
      "贴妈\n",
      "微博称\n",
      "素颜美到\n",
      "糖寿\n",
      "无副作用\n",
      "向安卓\n",
      "版谍\n",
      "真机照\n",
      "iphonexi\n",
      "屏国行\n",
      "变大到\n",
      "不刷机\n",
      "iphone218\n",
      "张巳丁谈\n",
      "qeemoo\n",
      "vivox21\n",
      "​\n",
      "個民間\n",
      "致国足\n",
      "一指弹\n",
      "七大邪\n",
      "落汤机\n",
      "乐视块\n",
      "视智家\n",
      "长祝剑\n",
      "微博晒\n",
      "瑞不爱\n",
      "重瑞首\n",
      "揭营收\n",
      "朱之文发\n",
      "朱之文疑\n",
      "终不敌\n",
      "蒋欣称\n",
      "获马云\n",
      "查微信\n",
      "方共出\n",
      "韩红唱\n",
      "吃蔗\n",
      "蔗毒\n",
      "万来治\n",
      "碱孕宝\n",
      "赵丽颖成\n",
      "收不付\n",
      "系不实\n",
      "三大救市\n",
      "爆错料\n",
      "炮首幕\n",
      "撒药治虫\n",
      "能治好\n",
      "脚放点\n",
      "路人遇\n",
      "‼\n",
      "►\n",
      "✅\n",
      "❤\n",
      "演紫儿\n",
      "赵丽颖演\n",
      "董永由\n",
      "双女主\n",
      "出剧版\n",
      "男夜华\n",
      "迪丽热\n",
      "赵又廷成\n",
      "有嘻哈\n",
      "由复联\n",
      "菜破\n",
      "男主大\n",
      "女主则\n",
      "女主迪丽\n",
      "男主比\n",
      "女主小\n",
      "男主似\n",
      "看颖宝\n",
      "靠蹭秀\n",
      "胡歌迪丽\n",
      "游无九景\n",
      "建官博\n",
      "后衣品\n",
      "主已定\n",
      "黄渤王\n",
      "徐峥弃\n",
      "黄渤组\n",
      "黄渤三贱\n",
      "黄渤宝强\n",
      "三角回归\n",
      "陈世妍疑\n",
      "男主是\n",
      "金恩淑爆\n",
      "官宣迪丽\n",
      "胖迪录\n",
      "鹿晗会\n",
      "变周播\n",
      "天连放\n",
      "集疯\n",
      "狂吐槽\n",
      "曝变\n",
      "人的尬\n",
      "fc54116\n",
      "杨洋别\n",
      "肖奈贝\n",
      "女主后\n",
      "女主换\n",
      "郑爽接\n",
      "演贝\n",
      "杨洋会\n",
      "何炅泪\n",
      "因谢娜\n",
      "拒台媒\n",
      "郑爽颖宝\n",
      "赵丽颖丁\n",
      "一宇组\n",
      "郑爽组\n",
      "携几对\n",
      "认马伊\n",
      "￼\n",
      "女主引\n",
      "演罗子\n",
      "关微博\n",
      "早不来\n",
      "亿登\n",
      "成不了\n",
      "吴京四字\n",
      "好会选\n",
      "用小新肉\n",
      "吴京放话\n",
      "吴京仅\n",
      "晏段\n",
      "宏唐\n",
      "愿零\n",
      "女主是\n",
      "吴京余\n",
      "马蓉力\n",
      "段宏毅\n",
      "卢靖姗任\n",
      "年開\n",
      "將開\n",
      "唐嫣將\n",
      "吴京早\n",
      "装不输\n",
      "凤九竟\n",
      "女二竟\n",
      "凄慘\n",
      "赵丽颖神\n",
      "赵丽颖林\n",
      "马蓉要\n",
      "男主林\n",
      "女主定\n",
      "和颖宝\n",
      "五美缺\n",
      "齐聚五美\n",
      "五美聚\n",
      "五美难\n",
      "王莎莎要\n",
      "袁立开\n",
      "袁立手\n",
      "曝单\n",
      "文千玺\n",
      "别去了\n",
      "靳东景\n",
      "全部都是\n",
      "赵丽颖为\n",
      "围有雷\n",
      "靠你了\n",
      "双男主\n",
      "要弃剧\n",
      "链热\n",
      "因不敌\n",
      "女主竟\n",
      "男主霍\n",
      "女主小骨\n",
      "演小骨\n",
      "版小骨\n",
      "非鹿晗\n",
      "当不了\n",
      "爱豆们\n",
      "后星爷\n",
      "陈赫终\n",
      "糟透了\n",
      "细思极\n",
      "打一星\n",
      "评一星\n",
      "唐嫣任\n",
      "暂定为\n",
      "想弃剧\n",
      "马小翠近\n",
      "添新规\n",
      "180509\n",
      "照谣\n",
      "养肝护\n",
      "穿涼鞋\n",
      "買點\n",
      "貨塗塗\n",
      "腳丫恢\n",
      "天检荐\n",
      "遭抖音\n",
      "辉凉\n",
      "履蛋收\n",
      "转发给\n",
      "瘦腿术\n",
      "沒幾天\n",
      "寿字币\n",
      "纤营\n",
      "撒药灭\n",
      "老鸣\n",
      "误以为\n",
      "越香越\n",
      "迅解\n",
      "图在动\n",
      "54169\n",
      "翔性\n",
      "指唐德\n",
      "李晨补\n",
      "\n",
      "赵丽颖称\n",
      "有助于\n",
      "完电不拔\n",
      "有何感想\n",
      "从根本上\n",
      "诚寻大\n",
      "就会变\n",
      "一两个\n",
      "可治好\n",
      "瘦到斤\n",
      "人真会\n",
      "看不过去\n",
      "曝买\n",
      "要人命\n",
      "纸氏\n",
      "教你用\n",
      "一切都是\n",
      "咖总\n",
      "十副药\n",
      "却治好\n",
      "美白小妙\n",
      "姜胜十副药\n",
      "快来学\n",
      "成一毒\n",
      "你治好\n",
      "不治而亡\n",
      "亿锁\n",
      "百副药\n",
      "八副药\n",
      "❗\n",
      "✨\n",
      "睡前用\n",
      "焕颜变\n",
      "十买九涨\n",
      "李湘家\n",
      "家比差\n",
      "听娇点\n",
      "水水嫩\n",
      "67871\n",
      "及月子\n",
      "血可测\n",
      "血测癌\n",
      "天无痘\n",
      "点千股\n",
      "燃脂治\n",
      "司匹\n",
      "竟治好\n",
      "果治好\n",
      "被誉为\n",
      "证惠若琪\n",
      "朱婷张\n",
      "潜藏在\n",
      "战播求\n",
      "遭西提\n",
      "三战播求\n",
      "七八个\n",
      "瘦斤\n",
      "放一物\n",
      "铠同\n",
      "乐视能\n",
      "王思聪会\n",
      "房企下\n",
      "天湿毒\n",
      "全无减\n",
      "可清署\n",
      "卖不出去\n",
      "刮肠油\n",
      "不瘦来\n",
      "闻泰龙旗\n",
      "因肿\n",
      "脸卡关\n",
      "看懵圈\n",
      "真能值\n",
      "13887546807\n",
      "亿婚\n",
      "上六星\n",
      "哈弗慌\n",
      "万敢\n",
      "买途观\n",
      "严限行\n",
      "在职人员\n",
      "摩拜称\n",
      "限不限\n",
      "解决不了\n",
      "查载\n",
      "種人\n",
      "能領\n",
      "检查一下\n",
      "谈灵体\n",
      "买回去\n",
      "图三请\n",
      "不作会\n",
      "有大用\n",
      "不单单是\n",
      "斤治\n",
      "有益健康\n",
      "年後產下\n",
      "活嬰\n",
      "曾美过\n",
      "尚雯婕力\n",
      "不拉黑\n",
      "菱宏光\n",
      "哈弗都\n",
      "帶寶寶出門\n",
      "马蓉妈\n",
      "宋喆爸\n",
      "张翰掌\n",
      "张忠谋急\n",
      "更美白\n",
      "不瞒你说\n",
      "速藏\n",
      "喷增\n",
      "谈白百\n",
      "v15951761774\n",
      "⃣\n",
      "天燃脂\n",
      "不全是\n",
      "不来扰\n",
      "种小痛\n",
      "等同于\n",
      "不论是\n",
      "小物配\n",
      "变新锅\n",
      "驾罚\n",
      "微博上\n",
      "地不种\n",
      "清肠宿\n",
      "减脂消\n",
      "顾得上\n",
      "脸美白\n",
      "天可瘦\n",
      "拉筋术\n",
      "快来查\n",
      "秒方\n",
      "岁划\n",
      "十女配\n",
      "我连见\n",
      "克就值\n",
      "这人竟\n",
      "有多缺\n",
      "最後一頭\n",
      "最难开\n",
      "阿波菲\n",
      "小新均\n",
      "鸣人路\n",
      "受毀\n",
      "附混改\n",
      "疯减\n",
      "旅恐\n",
      "两苦养\n",
      "是否是\n",
      "一个个\n",
      "半人半\n",
      "一个头\n",
      "个人所得税\n",
      "税大改\n",
      "皮令国足\n",
      "官媒刚\n",
      "美白妙\n",
      "易兴堂\n",
      "勺净\n",
      "有门道\n",
      "祛湿治\n",
      "率高达\n",
      "小茶方\n",
      "祛湿调\n",
      "这六物\n",
      "净肠毒\n",
      "别越治\n",
      "和平解决\n",
      "一选股\n",
      "成一买\n",
      "人不愿\n",
      "战亚冠\n",
      "帮国足\n",
      "非如灯\n",
      "排不上\n",
      "对美亮\n",
      "遗留下\n",
      "三十个\n",
      "马云求\n",
      "装嫌\n",
      "光卖水\n",
      "嫁过去\n",
      "陈俊活\n",
      "李清云活\n",
      "国足进\n",
      "头都造\n",
      "受得了\n",
      "仔卓伟\n",
      "坚瑞沃\n",
      "种大涨\n",
      "亿增仓\n",
      "成摇钱\n",
      "挖岛\n",
      "令美日\n",
      "赶得上\n",
      "撞人立\n",
      "因太过\n",
      "超歼\n",
      "也將\n",
      "古希伯來語\n",
      "有夠\n",
      "中美块\n",
      "外治贴\n",
      "掀换帅\n",
      "鲁能成\n",
      "首胜换帅\n",
      "鲁能险\n",
      "中超要\n",
      "恒大截\n",
      "天淡斑\n",
      "還不\n",
      "买君越\n",
      "推豪车\n",
      "不必要\n",
      "对人畜\n",
      "保仓村\n",
      "马蓉会\n",
      "一个男孩\n",
      "吴京张\n",
      "一山要\n",
      "硬如纸\n",
      "系跌\n",
      "孕圆肚\n",
      "为北回\n",
      "拍抖音\n",
      "为逆袭\n",
      "抢筹此\n",
      "传同片\n",
      "香猪妹\n",
      "十跖\n",
      "交不起\n",
      "人会否\n",
      "乐视离\n",
      "乒联官\n",
      "梁之死\n",
      "梁死\n",
      "结一瓜\n",
      "尚能育否\n",
      "成学霸\n",
      "壹天汇\n",
      "市江益\n",
      "斤逆袭\n",
      "往水里\n",
      "全仓进\n",
      "有钱人\n",
      "知坑\n",
      "时可别\n",
      "毛仅\n",
      "买朗逸\n",
      "不惹癌\n",
      "编转成\n",
      "亏不亏\n",
      "刻润\n",
      "各大房\n",
      "男宝来\n",
      "附怀\n",
      "宝妈来\n",
      "接好孕\n",
      "接男宝\n",
      "小男宝\n",
      "这么回事\n",
      "朱之文为\n",
      "朱之文唱\n",
      "朱之文真\n",
      "吃不下\n",
      "曼丽爱\n",
      "赵丽颖怒\n",
      "云飞火\n",
      "练大招\n",
      "斑美白\n",
      "实锤后\n",
      "小智小莫\n",
      "四驱配\n",
      "众尼师\n",
      "李小作\n",
      "变六美\n",
      "变六险\n",
      "法加尼恐\n",
      "进不了\n",
      "不交辅\n",
      "习费\n",
      "最多要\n",
      "詹皇望\n",
      "能逆天\n",
      "供扫码\n",
      "起新规\n",
      "望卡友\n",
      "有苦难言\n",
      "连老铁\n",
      "说到底\n",
      "无闪付\n",
      "日马云\n",
      "杨颖疑\n",
      "伪豪车\n",
      "长新发\n",
      "看少动\n",
      "惟日股\n",
      "67925\n",
      "69262\n",
      "多墨币\n",
      "币离\n",
      "到哪去\n",
      "现半人\n",
      "餐桌上\n",
      "刷安卓\n",
      "曝谢娜\n",
      "日常行为\n",
      "更扎心\n",
      "进不去\n",
      "地球日\n",
      "开博越\n",
      "✈\n",
      "试一下\n",
      "最多能\n",
      "价无粮\n",
      "瓜林存\n",
      "佩莱恐\n",
      "签乌神锋\n",
      "辱华高管\n",
      "这一物\n",
      "爆火后\n",
      "十测\n",
      "没人见\n",
      "pn6312\n",
      "备孕备\n",
      "就可以看\n",
      "新三花\n",
      "话疑\n",
      "何炅怒\n",
      "任静近\n",
      "用婧氏牙\n",
      "薛之谦该\n",
      "别乱用\n",
      "竟会致\n",
      "韦陀像\n",
      "双帆币\n",
      "半水石\n",
      "任丘苑\n",
      "竟隐婚\n",
      "曝隐婚\n",
      "爆隐婚\n",
      "这太坑\n",
      "力捧岳云鹏\n",
      "做美白\n",
      "传余承东\n",
      "传周迅\n",
      "两男宝\n",
      "传张杰\n",
      "传张翰\n",
      "和空姐\n",
      "不复存在\n",
      "传罗志祥\n",
      "传美团\n",
      "传谢娜\n",
      "传谢贤\n",
      "小卡必\n",
      "更多大\n",
      "这几人\n",
      "微凉天\n",
      "隔脏\n",
      "可高达\n",
      "洗肝菜\n",
      "何一怒\n",
      "币安割\n",
      "何洁带\n",
      "黑何洁\n",
      "何洁疑\n",
      "称何洁\n",
      "男赫子铭\n",
      "可赫子铭\n",
      "何洁谈\n",
      "曝何洁\n",
      "何炅上\n",
      "微博发\n",
      "上拉孟美岐\n",
      "谈隐婚\n",
      "何琳首\n",
      "卡三摄\n",
      "余承动\n",
      "却炸出\n",
      "小志明\n",
      "对孕妻\n",
      "宝摊\n",
      "宝新规\n",
      "王俊凯成\n",
      "蛮负\n",
      "上三大渣\n",
      "韩绿谭\n",
      "佟丽娅怀\n",
      "佟丽娅疑\n",
      "有多坏\n",
      "连马蓉\n",
      "微博中\n",
      "陈思诚首\n",
      "微博晒照\n",
      "15933068468\n",
      "薛之谦会\n",
      "你会用\n",
      "15270020984\n",
      "曝高管\n",
      "不换会\n",
      "骂迪丽\n",
      "就行了\n",
      "进书里\n",
      "能算出\n",
      "我白刷\n",
      "美國窮\n",
      "有多深\n",
      "不愧为\n",
      "中之王\n",
      "我虎躯\n",
      "放绿植\n",
      "补不上\n",
      "季雾\n",
      "修侯门\n",
      "云伟为\n",
      "斤宿\n",
      "年宿\n",
      "长高达\n",
      "压哈弗\n",
      "毫无作用\n",
      "疑熊为\n",
      "很立秋\n",
      "老不患\n",
      "三不装\n",
      "翔变\n",
      "翔顶\n",
      "郑爽会\n",
      "推扫码\n",
      "贷拒\n",
      "倩狐\n",
      "倪妮虐\n",
      "传虐\n",
      "母欲救\n",
      "假梗\n",
      "辣不长\n",
      "说月子\n",
      "健十教\n",
      "范丞丞微博\n",
      "抱娃疑\n",
      "人人得而\n",
      "傳中國\n",
      "上大骂\n",
      "种辅食\n",
      "台一姐\n",
      "爆何洁\n",
      "20180523\n",
      "肽助\n",
      "票游\n",
      "不老颜\n",
      "猜值\n",
      "要逆天\n",
      "附大照\n",
      "全男宝\n",
      "胖人易\n",
      "加拿当\n",
      "第四个\n",
      "因撞期\n",
      "招钓\n",
      "疑关\n",
      "地震局\n",
      "变王俊凯\n",
      "戴鹿晗\n",
      "嘟嘴索\n",
      "关晓彤终\n",
      "太不给\n",
      "太多违\n",
      "韦断\n",
      "曝马蓉妈\n",
      "兴秀洲\n",
      "扔出去\n",
      "手游开\n",
      "田飞鸡\n",
      "姜毒\n",
      "月治好\n",
      "錫盟东\n",
      "昆凌生\n",
      "半路上\n",
      "84405\n",
      "十连板\n",
      "超士兰微\n",
      "张召忠马\n",
      "市面上\n",
      "合涨\n",
      "元能领\n",
      "为十到\n",
      "胶毛球\n",
      "除肝毒\n",
      "圆样币\n",
      "挺必\n",
      "脚朝西\n",
      "漏领\n",
      "池值\n",
      "比粮补\n",
      "人能领\n",
      "法迎\n",
      "地底下\n",
      "需一晚\n",
      "摘桃浆\n",
      "停不下\n",
      "养香猪\n",
      "有良效\n",
      "有福享\n",
      "最爱用\n",
      "拆农房\n",
      "马云向\n",
      "人有福\n",
      "人白交\n",
      "迁回去\n",
      "低筹\n",
      "迁出去\n",
      "这三证\n",
      "全花光\n",
      "种货要\n",
      "改电有\n",
      "专克腰\n",
      "我泪目\n",
      "盼望着\n",
      "肝抗\n",
      "养肝滋肾\n",
      "大半个\n",
      "106095\n",
      "地能领\n",
      "还旺财\n",
      "再不去\n",
      "想入行\n",
      "种农房\n",
      "白不领\n",
      "全身上下\n",
      "壮全\n",
      "下可领\n",
      "证能值\n",
      "会烂手\n",
      "农残高\n",
      "提五统\n",
      "快产肉量\n",
      "能亩\n",
      "称之为\n",
      "没人养\n",
      "吉工家\n",
      "合新规\n",
      "这三大类\n",
      "没交够\n",
      "算药食\n",
      "这几大\n",
      "腹胖\n",
      "养颜少\n",
      "肚大瘦\n",
      "地暖会\n",
      "养颜圣品\n",
      "毁肝\n",
      "护心养\n",
      "告丫\n",
      "李晨神\n",
      "新戏用\n",
      "洪晃吐槽\n",
      "黄渤是\n",
      "洗不白\n",
      "莫床\n",
      "提莫床\n",
      "曝骗\n",
      "赵丽颖治\n",
      "冯渣\n",
      "越不化\n",
      "样种\n",
      "运狼\n",
      "减不掉\n",
      "变辣妈\n",
      "愁常\n",
      "肉肉全\n",
      "餐助\n",
      "久减\n",
      "补减\n",
      "瘦胃\n",
      "燃脂灭\n",
      "体轻降\n",
      "斤化\n",
      "13500939511\n",
      "肠毒抗\n",
      "天祛湿\n",
      "这两点\n",
      "排出去\n",
      "减脂汁\n",
      "盆骨操\n",
      "腰秀\n",
      "补脾是\n",
      "祛湿减\n",
      "达人用\n",
      "养颜瘦\n",
      "满满的\n",
      "健孙怡\n",
      "切下去\n",
      "天治好\n",
      "似煤\n",
      "嫩嫩的\n",
      "因玲花\n",
      "是玲花\n",
      "玲花要\n",
      "太扎心\n",
      "完玲花\n",
      "曾毅气\n",
      "遭谢娜\n",
      "高副帅\n",
      "机一照\n",
      "亿捧\n",
      "那英脸\n",
      "王思聪力\n",
      "唱悔\n",
      "唱刀郎歌\n",
      "刀郎震住\n",
      "刀郎火\n",
      "浓浓的\n",
      "马云点\n",
      "刀郎要\n",
      "上放此\n",
      "辣阴\n",
      "汪峰力\n",
      "风控花\n",
      "张鈞\n",
      "超华锋\n",
      "列瓦蒂奇\n",
      "刘丹要\n",
      "照美翻\n",
      "网红张\n",
      "母共侍\n",
      "赔十的料\n",
      "上唱首\n",
      "刘和岗\n",
      "人代生\n",
      "说不出\n",
      "收胡军\n",
      "仍不离\n",
      "东太宠\n",
      "东太爱\n",
      "贵马云\n",
      "东娶\n",
      "马云举\n",
      "年三大\n",
      "将献唱\n",
      "卖冰沙\n",
      "没有特权\n",
      "演不动\n",
      "后放话\n",
      "这事要\n",
      "幂家\n",
      "幂力\n",
      "已和丽虹成\n",
      "带秋菊\n",
      "卓伟放话\n",
      "揭杨\n",
      "看上去\n",
      "幂己\n",
      "没王鸥\n",
      "肩夜会\n",
      "曝强\n",
      "刚帮王\n",
      "李晨车\n",
      "卓伟冲\n",
      "胡军家\n",
      "算白演\n",
      "臀超\n",
      "王珂竟\n",
      "张翰五任\n",
      "刘涛终\n",
      "王珂疑\n",
      "演不下\n",
      "手接素\n",
      "情崩\n",
      "张翰竟\n",
      "王珂要\n",
      "杨紫只\n",
      "诗孕肚\n",
      "马舒雅竟\n",
      "诗挺孕\n",
      "肚现\n",
      "微博新\n",
      "诗生孩\n",
      "诗红毯\n",
      "狂撒狗\n",
      "诗造\n",
      "刘谦因\n",
      "刘谦给\n",
      "刘谦遭\n",
      "刘雯大\n",
      "这番话\n",
      "指暴击\n",
      "一声令下\n",
      "归马蓉\n",
      "薛之谦前\n",
      "酒桌上\n",
      "刘涛学\n",
      "马云愿\n",
      "sunnee\n",
      "爆肝点\n",
      "塘主险\n",
      "删前速\n",
      "白之路\n",
      "删张杰\n",
      "超顺丰\n",
      "强不强\n",
      "张冠号\n",
      "别信酸儿\n",
      "斑全\n",
      "皮薄汁\n",
      "喝分\n",
      "一窝灭\n",
      "看汉兰达\n",
      "先清肠\n",
      "那英毁\n",
      "爆实\n",
      "刷不白\n",
      "总爱用\n",
      "前中國\n",
      "用不着\n",
      "婚房秀\n",
      "胎梦真能\n",
      "吴京逆袭\n",
      "htycoin\n",
      "马云慌\n",
      "马云有\n",
      "孕接\n",
      "恋现\n",
      "頻頻\n",
      "担双\n",
      "男主为\n",
      "腰腿速\n",
      "1270222535\n",
      "领阿迪\n",
      "13841463650\n",
      "总舞\n",
      "癌终\n",
      "堪比雾\n",
      "地铁线\n",
      "俄大亮\n",
      "能防霾\n",
      "季城六区\n",
      "进耳竟\n",
      "股神仅\n",
      "义撞\n",
      "链电\n",
      "医微讯\n",
      "超药明\n",
      "十万个\n",
      "男有福\n",
      "先胖腹\n",
      "十人九湿\n",
      "次治好\n",
      "马蓉愿\n",
      "十几个\n",
      "十胃\n",
      "十胖\n",
      "十胖九湿\n",
      "九疼\n",
      "喝留\n",
      "令多地\n",
      "不关脑\n",
      "种人要\n",
      "emui90\n",
      "亿借壳\n",
      "配版要\n",
      "威马造\n",
      "总难止\n",
      "全仓干\n",
      "万火到\n",
      "宇携\n",
      "宇邓\n",
      "传鹿晗\n",
      "卓伟作\n",
      "揭白百何\n",
      "卓伟出\n",
      "幂确\n",
      "爆大料\n",
      "曝鹿晗\n",
      "卓伟因\n",
      "爆错\n",
      "卓伟报\n",
      "卓伟收\n",
      "蒋欣斥\n",
      "卓伟本\n",
      "卓伟爆\n",
      "姓人妻\n",
      "蒋欣力\n",
      "爆关晓彤\n",
      "蒋欣怒\n",
      "爆张杰\n",
      "卓伟猛\n",
      "卓伟疑\n",
      "卓伟继\n",
      "王思聪顶\n",
      "团揍\n",
      "炫富称\n",
      "南何楼\n",
      "彭拐\n",
      "航洋现\n",
      "多人梦中\n",
      "母森\n",
      "至水鸣\n",
      "卡佛尼白\n",
      "恒大欲签\n",
      "怂发\n",
      "暗示着\n",
      "疯传会\n",
      "帮其造\n",
      "美不卖\n",
      "新规会\n",
      "可防雾\n",
      "fcae\n",
      "曝任泉\n",
      "马蓉母\n",
      "還不晚\n",
      "背小三\n",
      "最多活\n",
      "力捧迪丽\n",
      "有据可依\n",
      "四少王\n",
      "玉思隐\n",
      "张翰和娜\n",
      "核竟\n",
      "马曼琳\n",
      "云美翻\n",
      "安卓锁\n",
      "这不死\n",
      "郭德纲气\n",
      "一豪车\n",
      "扑上去\n",
      "肥季\n",
      "没颜值\n",
      "镇无牌\n",
      "跑不了\n",
      "牛人带\n",
      "吸脂养\n",
      "曝郎永淳\n",
      "轻奢版成\n",
      "地产商\n",
      "需和面\n",
      "一个角\n",
      "投联\n",
      "看衣识\n",
      "积太多\n",
      "窦骁比\n",
      "张瀚渣\n",
      "扎首\n",
      "蕴含着\n",
      "采洁系\n",
      "曝蜜恋\n",
      "古斯大\n",
      "脱春\n",
      "一个点\n",
      "生没生\n",
      "思同食\n",
      "配曼\n",
      "可呼出\n",
      "壁清\n",
      "没电时\n",
      "岩遇\n",
      "曝罗志祥花\n",
      "爆罗志祥\n",
      "台媒赞\n",
      "牛假\n",
      "来得快\n",
      "陈皮能\n",
      "宮癌\n",
      "請轉\n",
      "含乙草胺\n",
      "太多会\n",
      "太少会\n",
      "胡就能\n",
      "留蜡\n",
      "形食\n",
      "吃桃全\n",
      "吃梨有\n",
      "熟吃易\n",
      "孕宝生\n",
      "错易成\n",
      "過生\n",
      "鸡国服\n",
      "房企大\n",
      "限地限贷\n",
      "128817\n",
      "王志今\n",
      "同冠号\n",
      "男鹿晗\n",
      "比范丞丞惨\n",
      "李晨疑\n",
      "赵丽颖点\n",
      "赞微\n",
      "博惹\n",
      "吸进去\n",
      "蒋欣去\n",
      "蒋欣扇\n",
      "杜杜太\n",
      "买汉兰达\n",
      "鱼生致\n",
      "这四人\n",
      "万佑家军\n",
      "亿演\n",
      "景甜首\n",
      "黄渤气\n",
      "ི\n",
      "有川字\n",
      "搞了个\n",
      "糖疤\n",
      "有川纹\n",
      "有川字会\n",
      "刘雯录\n",
      "比不上\n",
      "赵丽颖气\n",
      "微博遭\n",
      "赵丽颖言\n",
      "吴亦凡颖宝\n",
      "吴京为\n",
      "吴京怒\n",
      "张翰战\n",
      "爆鹿晗\n",
      "吴京摊\n",
      "吴京称\n",
      "微博炸\n",
      "男主由\n",
      "护肚疑\n",
      "整完容\n",
      "值逆天\n",
      "　\n",
      "探班护妻\n",
      "舒破\n",
      "探班护\n",
      "吴昕凉\n",
      "新一姐\n",
      "沈梦辰秀起\n",
      "杨紫隔空\n",
      "吴秀波疑\n",
      "吴雨约\n",
      "为馨爷\n",
      "操碎心\n",
      "☜\n",
      "♞\n",
      "时可领\n",
      "暴十连板\n",
      "两人要\n",
      "揭周\n",
      "周启元家\n",
      "思聪力\n",
      "双男一\n",
      "吴京用\n",
      "亿妥\n",
      "揭爱\n",
      "林允担\n",
      "汁断\n",
      "附金股\n",
      "昆凌晒\n",
      "微博互\n",
      "中闪婚\n",
      "周琦会\n",
      "高回播\n",
      "案迎\n",
      "说得准\n",
      "马云去\n",
      "黄独毒\n",
      "应狠\n",
      "幂整\n",
      "神林寺\n",
      "客紧\n",
      "牵霍\n",
      "迅素\n",
      "劈腿成\n",
      "控好量\n",
      "生什麼\n",
      "比换个\n",
      "屠川当\n",
      "幂现\n",
      "肺护\n",
      "緊轉\n",
      "不对会\n",
      "男主哭\n",
      "錢全\n",
      "笑噴\n",
      "這下\n",
      "跪算盤\n",
      "新登哥\n",
      "哪一城会\n",
      "孕相能\n",
      "备孕生\n",
      "哪几个\n",
      "残奶会致\n",
      "重瑞才\n",
      "继刘诗\n",
      "竟秀起\n",
      "懂罗晋\n",
      "孕肚难\n",
      "说一说\n",
      "罗晋定\n",
      "微凸疑\n",
      "幂渐\n",
      "邱泽刷\n",
      "赵丽颖互\n",
      "某大花\n",
      "罗晋疑\n",
      "怀罗晋\n",
      "郑爽恋\n",
      "王石疑\n",
      "菜涂\n",
      "加两物\n",
      "取之不出\n",
      "喊麦界\n",
      "博秒\n",
      "买教\n",
      "最不伤\n",
      "喝世\n",
      "不祛湿\n",
      "别喝了\n",
      "法媒教\n",
      "种水会\n",
      "种小妙\n",
      "不醉变\n",
      "喷杨\n",
      "一波起\n",
      "嘉诚评\n",
      "衣娃\n",
      "胡燕桃\n",
      "这得活\n",
      "姓康姓\n",
      "国一国\n",
      "国乒惨\n",
      "国三车\n",
      "国五才\n",
      "严国六来\n",
      "屏美得\n",
      "配全时\n",
      "驱仅售\n",
      "万必成\n",
      "路虎见\n",
      "已海试\n",
      "globeimposter\n",
      "区有活\n",
      "抢纳\n",
      "因戈兰\n",
      "说鲁能\n",
      "原国足\n",
      "推女鲁能\n",
      "截胡恒大\n",
      "朱之文后\n",
      "出大招\n",
      "村干要\n",
      "爆冯\n",
      "王思聪放\n",
      "朱婷建\n",
      "皮亲\n",
      "国足迎\n",
      "曝里\n",
      "规世乒赛\n",
      "展真功\n",
      "打一物\n",
      "圆肚生\n",
      "尖肚生\n",
      "发新歌\n",
      "地能值\n",
      "两大证\n",
      "叙若\n",
      "解释一下\n",
      "微博全\n",
      "微博王\n",
      "这七对\n",
      "嫁五旬\n",
      "想买个\n",
      "馆水\n",
      "展死\n",
      "小主看\n",
      "打不响\n",
      "曝睡\n",
      "能給\n",
      "地主家\n",
      "上七大\n",
      "有六星\n",
      "地痞流氓\n",
      "高人能\n",
      "不能自己\n",
      "传可引\n",
      "骨痛液\n",
      "矢野浩\n",
      "周星闻\n",
      "备孕常\n",
      "想不生\n",
      "推神车\n",
      "需一物\n",
      "速瘦法\n",
      "性大易致\n",
      "清肠排\n",
      "省电妙\n",
      "需涂点\n",
      "美白抗\n",
      "后白过\n",
      "黄无光\n",
      "液小妙\n",
      "越放越\n",
      "驾查\n",
      "两大派\n",
      "后美白\n",
      "种当季\n",
      "招美白\n",
      "夏钓大\n",
      "谈差评\n",
      "这样的话\n",
      "有多苦\n",
      "评竟\n",
      "没电用\n",
      "其厚唇\n",
      "曝霉霉\n",
      "外媒证\n",
      "中俄正\n",
      "干人血\n",
      "太大太想\n",
      "吃大雄\n",
      "胡可断\n",
      "遇不上\n",
      "罗普郡\n",
      "种助孕\n",
      "想了个\n",
      "炮不爆\n",
      "恐熬\n",
      "来恒大\n",
      "获韬蕴\n",
      "沒妈\n",
      "无汉兰达\n",
      "万比汉兰达\n",
      "神泉堡\n",
      "马思纯疑\n",
      "¥\n",
      "燃脂液\n",
      "揭闺蜜间\n",
      "晨尿测\n",
      "玩抖音\n",
      "1587997\n",
      "美判\n",
      "电不拔\n",
      "小寶寶較\n",
      "邓超外\n",
      "曝料疑\n",
      "佛须\n",
      "平七钱\n",
      "爆杨\n",
      "涨不动\n",
      "已久终\n",
      "这五物\n",
      "盒纯\n",
      "黑杯面\n",
      "王密子\n",
      "同食会\n",
      "强如牛\n",
      "只会生\n",
      "毒蒜\n",
      "泡醋治\n",
      "砍大蛇\n",
      "歌一唱\n",
      "好你个\n",
      "缘极满\n",
      "朱之文自\n",
      "朱之文闹\n",
      "嫂闹\n",
      "男滚出\n",
      "曝马蓉\n",
      "傳遭\n",
      "活腻了\n",
      "清微博\n",
      "孙俪泪\n",
      "狂排\n",
      "被治好\n",
      "曝摩拜\n",
      "说得好\n",
      "这一妙\n",
      "农哥教\n",
      "养肝王\n",
      "祛湿王\n",
      "常吃排\n",
      "24881\n",
      "帕卡来\n",
      "双凤有\n",
      "马蓉开\n",
      "多人染\n",
      "公积转\n",
      "蒸错\n",
      "平躺着\n",
      "一马云\n",
      "gdp22\n",
      "诈捐后\n",
      "这几对\n",
      "全仓此\n",
      "曝捆\n",
      "董卿争\n",
      "邀鹿晗\n",
      "多梦别\n",
      "多梦气\n",
      "多梦试\n",
      "生新发\n",
      "时放点\n",
      "别乱染\n",
      "礼疑\n",
      "瓜友\n",
      "土食材\n",
      "天不坏\n",
      "人宝能\n",
      "有多强\n",
      "原石切\n",
      "张继科景\n",
      "进何猷\n",
      "奚猷\n",
      "罗和梅西\n",
      "创三大\n",
      "差宁泽涛\n",
      "载不离\n",
      "迈腾君\n",
      "泰迪竟\n",
      "可养颜\n",
      "养颜显\n",
      "戴银饰\n",
      "养颜使\n",
      "吃酸能\n",
      "养颜变\n",
      "臀越\n",
      "养颜淡斑\n",
      "养颜永葆\n",
      "有美白\n",
      "祛湿后\n",
      "纷传要\n",
      "马蓉后\n",
      "不愿牌\n",
      "养颜常\n",
      "斤养\n",
      "看小三\n",
      "很爱丽颖\n",
      "猪难\n",
      "太浓致\n",
      "成杨颖\n",
      "装瞎陪\n",
      "杨颖未\n",
      "没人信\n",
      "抢本主\n",
      "邓莎未\n",
      "感受一下\n",
      "刚拉出\n",
      "千萬別\n",
      "男闺蜜教\n",
      "男丑母\n",
      "男宝时\n",
      "继孙俪\n",
      "天祛掉\n",
      "有害物\n",
      "传雅培正\n",
      "岁险\n",
      "赵丽颖同\n",
      "时美过\n",
      "戏富\n",
      "赵丽颖疑\n",
      "差远了\n",
      "分豪车\n",
      "大麟子\n",
      "韩红向\n",
      "遭群嘲\n",
      "曝斥\n",
      "仇元甲兄\n",
      "☕\n",
      "掉进去\n",
      "组亲肤\n",
      "微信放\n",
      "没钱治\n",
      "推一刷\n",
      "美妈们\n",
      "太清奇\n",
      "传怕\n",
      "窦骁娜\n",
      "泰森太\n",
      "含肉毒\n",
      "宝惊\n",
      "没拉住\n",
      "朱丹回\n",
      "李湘为\n",
      "永远都是\n",
      "称迪丽\n",
      "爆禁\n",
      "用脏手\n",
      "张翰要\n",
      "终没人\n",
      "窦骁新\n",
      "张翰罚\n",
      "张庭孕\n",
      "张翰因\n",
      "一人设\n",
      "继谢娜\n",
      "继张馨予\n",
      "谢娜疑\n",
      "求宝强\n",
      "赵丽颖要\n",
      "比马蓉强\n",
      "微速览\n",
      "鹏疑\n",
      "老铁们\n",
      "何炅见\n",
      "娱姐\n",
      "关晓彤糊\n",
      "王思聪米\n",
      "王俊凯迪丽\n",
      "说太辣\n",
      "招洗\n",
      "手台费\n",
      "获重判\n",
      "岁潮\n",
      "豪命\n",
      "怒怀\n",
      "孕妈常\n",
      "那可要\n",
      "孕妈生\n",
      "养颜去\n",
      "长高个\n",
      "需不需要\n",
      "男宝帅\n",
      "女宝美\n",
      "条怀\n",
      "女宝妈\n",
      "选不对\n",
      "孕妈别\n",
      "服就够\n",
      "邓超要\n",
      "赵丽颖竟\n",
      "陈晓任\n",
      "16620781034\n",
      "孙杨劳\n",
      "姚晨办\n",
      "专将成\n",
      "学渣成\n",
      "关晓彤疑\n",
      "学鲁能\n",
      "超换个\n",
      "用得上\n",
      "被拉到\n",
      "长不高该\n",
      "长高靠\n",
      "吴忠至\n",
      "拒游\n",
      "大大的\n",
      "曝微\n",
      "三高稳\n",
      "身壮似\n",
      "人不爱\n",
      "保肝护\n",
      "减脂王\n",
      "常吃固\n",
      "遭人割\n",
      "有多准\n",
      "凤祥银\n",
      "图可要\n",
      "博放狠话\n",
      "并放话\n",
      "宋喆放话\n",
      "马蓉称\n",
      "宋喆疑\n",
      "最多会判\n",
      "可宝强\n",
      "马蓉禁\n",
      "微博求\n",
      "宋喆要\n",
      "程野大\n",
      "太大要\n",
      "曝暂\n",
      "宋爆\n",
      "宋祖得\n",
      "算出去\n",
      "生不动\n",
      "揭施\n",
      "前国足\n",
      "乐遭\n",
      "街夏联\n",
      "一喝立\n",
      "似港\n",
      "放瓶水\n",
      "实拍用\n",
      "实拍超\n",
      "韩姨爆\n",
      "活多大\n",
      "半患\n",
      "一去不复返了\n",
      "杨紫林\n",
      "吸废排\n",
      "边放上\n",
      "厚厚的\n",
      "扔教\n",
      "牛人教\n",
      "见不着\n",
      "需放点\n",
      "积极参与\n",
      "injuv\n",
      "莹久\n",
      "招清宿\n",
      "众鑫活\n",
      "盛悦府\n",
      "补氧神水\n",
      "美中印\n",
      "王凯版\n",
      "雪姨有\n",
      "王思聪家\n",
      "赵丽颖何\n",
      "董洁王\n",
      "不愿用\n",
      "盛一伦小妾\n",
      "小七暴\n",
      "这颜值\n",
      "王俊凯学\n",
      "食人蜂\n",
      "问岳云鹏\n",
      "竟射出\n",
      "招太好\n",
      "驾扣\n",
      "变程野\n",
      "文松面\n",
      "照终\n",
      "音界里\n",
      "遭短\n",
      "真机谍\n",
      "做安卓\n",
      "单雷军\n",
      "乐视存\n",
      "拼红米\n",
      "买贵补\n",
      "直怼\n",
      "消不掉\n",
      "发多狠\n",
      "多小妙\n",
      "有效率\n",
      "其滚出\n",
      "或大降\n",
      "男不离\n",
      "驱蟹\n",
      "这八本\n",
      "豪高鑫\n",
      "周琦再\n",
      "天就治好\n",
      "昆凌为\n",
      "坂东永辉\n",
      "万在华\n",
      "比瞬秒\n",
      "传摩拜\n",
      "北沂堂\n",
      "评制\n",
      "三鲁能\n",
      "杨润达\n",
      "通血补\n",
      "湿毒治\n",
      "时可加\n",
      "山渣加\n",
      "编的民\n",
      "于谦忙\n",
      "认岳云鹏\n",
      "于谦成\n",
      "时冲过\n",
      "大鑫城\n",
      "峰菲恋\n",
      "崔天临\n",
      "csc8952\n",
      "3u8633\n",
      "谈三大\n",
      "部怒\n",
      "紧接着\n",
      "托孟婆\n",
      "左旗林\n",
      "显白显\n",
      "造壹仙\n",
      "還能\n",
      "卖员\n",
      "竟高达\n",
      "微博放话\n",
      "句话解\n",
      "币安买岛\n",
      "币安在\n",
      "美白显\n",
      "帅丕张\n",
      "翰面\n",
      "张翰大\n",
      "迎三大\n",
      "少一人\n",
      "愿鲁能\n",
      "菩洱\n",
      "配一宝\n",
      "肝护\n",
      "可有福\n",
      "不愿收\n",
      "里巧放\n",
      "干不了\n",
      "胃不痛\n",
      "从三楼\n",
      "现扫\n",
      "交违\n",
      "库平七钱\n",
      "恒大来\n",
      "罗韦世豪\n",
      "广東\n",
      "几十个\n",
      "多大恨\n",
      "没拉下\n",
      "吞物门\n",
      "称可供\n",
      "莫隐婚\n",
      "遭石锤\n",
      "稿齐\n",
      "应易璐\n",
      "康震为\n",
      "救蛇保\n",
      "几百个\n",
      "新用式\n",
      "别慌有\n",
      "杨紫周\n",
      "实锤图\n",
      "秀同款\n",
      "曝实\n",
      "杨紫微\n",
      "张一山恋\n",
      "杨紫要\n",
      "被抛弃了\n",
      "张伦硕带\n",
      "完候\n",
      "爸人脉\n",
      "蒋欣遇\n",
      "截胡小\n",
      "局狂\n",
      "陈晓退\n",
      "亨离\n",
      "张杰录\n",
      "叫炅炅\n",
      "杰粉\n",
      "中谢娜\n",
      "成为事实\n",
      "还合开\n",
      "二十个\n",
      "和好如初\n",
      "遭霆锋\n",
      "赶过去\n",
      "新戏定\n",
      "亿争\n",
      "子不当\n",
      "再多生\n",
      "别想用\n",
      "竟放话\n",
      "谢贤因\n",
      "要大婚\n",
      "疑反\n",
      "谢贤回\n",
      "张伦硕姓\n",
      "已无路\n",
      "李晨泪\n",
      "之家终\n",
      "张檬妆容\n",
      "曝不雅\n",
      "科甜\n",
      "位炮友\n",
      "科姗恋\n",
      "跟景甜\n",
      "成渣现\n",
      "张翰快\n",
      "在生活中\n",
      "张翰出\n",
      "博隔空\n",
      "郑爽疑\n",
      "塘主心\n",
      "张翰称\n",
      "扎配\n",
      "戏生情\n",
      "微博传\n",
      "张翰微\n",
      "博秀花\n",
      "张翰想\n",
      "接张翰\n",
      "张翰有\n",
      "张翰暗\n",
      "张翰用\n",
      "张翰怒\n",
      "曝与娜\n",
      "尽撒狗\n",
      "要塘\n",
      "张翰首\n",
      "王思聪怒\n",
      "疑求\n",
      "秀将播\n",
      "可鹿晗\n",
      "兴罗志祥\n",
      "兴罗志祥要\n",
      "而鲁豫\n",
      "唐艺昕发\n",
      "指蹭秀\n",
      "马思纯秀\n",
      "晏疑\n",
      "晏有何\n",
      "袁立会\n",
      "博疑\n",
      "业有成\n",
      "微博点\n",
      "比何洁\n",
      "冯柯未\n",
      "戏真多\n",
      "窦骁同\n",
      "予步\n",
      "暴瘦致\n",
      "张鹤伦当\n",
      "也治好\n",
      "巨友门\n",
      "眼妆太\n",
      "会得眼\n",
      "吃蒜法\n",
      "大吐槽\n",
      "有爱互\n",
      "何许人也\n",
      "晏惊\n",
      "哔柜\n",
      "来代餐\n",
      "除醛法\n",
      "用不完\n",
      "微博骂\n",
      "深八王\n",
      "途三\n",
      "女主太\n",
      "男主铁\n",
      "黄渤宝\n",
      "聚共演\n",
      "窃卖\n",
      "梁论\n",
      "真会学\n",
      "48111577\n",
      "跟不上\n",
      "安卓狗\n",
      "赞扣\n",
      "码可得\n",
      "微博热\n",
      "微博留\n",
      "微商们\n",
      "动真格的\n",
      "带德系\n",
      "法拿针\n",
      "王源粉\n",
      "赵丽颖想\n",
      "心知元\n",
      "心真大\n",
      "姐疑\n",
      "旭旭要\n",
      "题亮\n",
      "快生了\n",
      "这三人\n",
      "堂复牌\n",
      "不揽收\n",
      "有益无害\n",
      "天祛湿毒\n",
      "男宝后\n",
      "怀不上\n",
      "竟产活\n",
      "后孕妈\n",
      "第几个\n",
      "说会生\n",
      "孕妈晨\n",
      "多宝妈\n",
      "孕妈来\n",
      "阿碧假\n",
      "说酸儿\n",
      "说法不一\n",
      "胎宝会\n",
      "希素颜\n",
      "悦蕾\n",
      "養肌\n",
      "一人成\n",
      "18570268587\n",
      "侵靓绝\n",
      "恒大古\n",
      "前拜仁\n",
      "通吃安卓\n",
      "全靠演\n",
      "一个半月\n",
      "泰艾\n",
      "音酿\n",
      "周琦恐成\n",
      "张一山亲\n",
      "規模值\n",
      "宋喆同\n",
      "杨颖怒\n",
      "爆摩拜\n",
      "爆马云\n",
      "一个多\n",
      "粮撒多\n",
      "醋治好\n",
      "不养颜\n",
      "做迪丽\n",
      "网红惨\n",
      "想治好\n",
      "生不出\n",
      "不单是\n",
      "先祛湿\n",
      "铲肉\n",
      "大眼长\n",
      "长长的\n",
      "做速白\n",
      "看马云\n",
      "肠寿\n",
      "投美团\n",
      "曝马云\n",
      "队欲签\n",
      "外媒闹\n",
      "见识一下\n",
      "无一人敢\n",
      "夜不散\n",
      "yefine\n",
      "黑构\n",
      "精主播\n",
      "成德同\n",
      "掉下去\n",
      "改拉人\n",
      "开无牌\n",
      "疑张\n",
      "吴绮莉前\n",
      "算不上\n",
      "王凯王\n",
      "骑上去\n",
      "光迪丽\n",
      "带你去\n",
      "穿大码\n",
      "战狼二高\n",
      "战狼高\n",
      "戚玉婷\n",
      "四五个\n",
      "租不起\n",
      "川字会\n",
      "一格电\n",
      "上放根\n",
      "一千多个\n",
      "完惊出\n",
      "剩一格\n",
      "屏炸\n",
      "更大是\n",
      "比满格强\n",
      "比买个\n",
      "阿饱教\n",
      "進水裡\n",
      "手機入\n",
      "速乾法\n",
      "有长有短\n",
      "靳东怕\n",
      "吴佩慈要\n",
      "癖许\n",
      "遭何洁\n",
      "打卓伟\n",
      "赵又廷现\n",
      "放此宝\n",
      "將口\n",
      "扫交\n",
      "扬武坊\n",
      "批刀郎\n",
      "省电有\n",
      "现太惨\n",
      "成小迷弟\n",
      "股全览\n",
      "抖友们\n",
      "药奥司\n",
      "防衰促\n",
      "码提\n",
      "挖纳\n",
      "辅警致\n",
      "截金晨\n",
      "何炅尬\n",
      "恒大够\n",
      "以一敌\n",
      "一个三天\n",
      "拉羊车\n",
      "杨颖带\n",
      "拒拜\n",
      "大梦力\n",
      "转黑成\n",
      "选不出\n",
      "挤金晨\n",
      "战欲以\n",
      "自黑王\n",
      "取不取\n",
      "换新表后\n",
      "纪凌尘疑\n",
      "小谢贤\n",
      "名高管\n",
      "换安卓\n",
      "吴磊演\n",
      "翔演\n",
      "硬说是\n",
      "过万有\n",
      "排清宿\n",
      "涨请\n",
      "男主辞演\n",
      "✌\n",
      "张翰扇\n",
      "emcbet\n",
      "韩姨发\n",
      "迅怀\n",
      "小三姚\n",
      "阿宝和\n",
      "做鹅肝酱\n",
      "全国上下\n",
      "竟连人\n",
      "胖迪有\n",
      "摩拜史\n",
      "毒唯们\n",
      "快拿起\n",
      "大招教\n",
      "网怒\n",
      "没人领\n",
      "沒靈感\n",
      "备孕大招\n",
      "有话要说\n",
      "公瓜\n",
      "滑显\n",
      "斤小妙\n",
      "知锈\n",
      "用安卓\n",
      "粉篇\n",
      "深喊\n",
      "教瘦哥\n",
      "李湘大\n",
      "精鼻\n",
      "两小物\n",
      "姚笛时\n",
      "卢本伟见\n",
      "网红要\n",
      "韦神同\n",
      "演依萍\n",
      "范丞丞上\n",
      "停新规\n",
      "驾记\n",
      "狮岗路\n",
      "别多交\n",
      "交不交\n",
      "股之王\n",
      "这么晚\n",
      "演小七\n",
      "男主后\n",
      "演尔豪\n",
      "豪方瑜\n",
      "男主太\n",
      "关晓彤排\n",
      "两字疑\n",
      "18530797265\n",
      "零充\n",
      "一较高下\n",
      "不拉会\n",
      "过首保\n",
      "书无字\n",
      "喝真能\n",
      "曝含\n",
      "之人抖\n",
      "换不起\n",
      "我学过\n",
      "领投美团\n",
      "发不雅\n",
      "此国肯\n",
      "旧爱霍\n",
      "可大有\n",
      "学白富\n",
      "不僅養\n",
      "时下生\n",
      "杰伦是\n",
      "开黑组\n",
      "昆凌晒照\n",
      "昆凌说\n",
      "信备\n",
      "内大狗\n",
      "有大招\n",
      "证才行\n",
      "遭掌\n",
      "爆张馨予\n",
      "房拼\n",
      "轨霍\n",
      "赵丽颖家\n",
      "鹿晗择\n",
      "某电该\n",
      "天启大\n",
      "別語\n",
      "無倫次\n",
      "美空露\n",
      "跪亲\n",
      "赵丽颖冻\n",
      "带盆带\n",
      "快给我\n",
      "男主罗志祥\n",
      "肠净\n",
      "养颜季\n",
      "爱盐\n",
      "猛长个\n",
      "昨天晚上\n",
      "推新歌\n",
      "晒娃狂\n",
      "不晒娃\n",
      "博晒照\n",
      "泡脚往\n",
      "景甜带\n",
      "张继科见\n",
      "瓜众\n",
      "景甜微\n",
      "景甜怀\n",
      "张继科要\n",
      "张继科终\n",
      "继科见\n",
      "景甜要\n",
      "超鹿晗\n",
      "潘思宁\n",
      "转嫁给\n",
      "67374\n",
      "拔不拔\n",
      "暖炸\n",
      "薛之谦渣\n",
      "系旧谣\n",
      "跳真\n",
      "蔡家现\n",
      "若冲超\n",
      "新世俱杯\n",
      "皇萨仁\n",
      "曝京鲁\n",
      "ئ\n",
      "ا\n",
      "پ\n",
      "ت\n",
      "و\n",
      "م\n",
      "ب\n",
      "ى\n",
      "ل\n",
      "ش\n",
      "ق\n",
      "ۇ\n",
      "ر\n",
      "ن\n",
      "ڭ\n",
      "ج\n",
      "د\n",
      "ي\n",
      "曝关晓彤\n",
      "曝吴\n",
      "爆星爷\n",
      "曝周迅\n",
      "抢金晨\n",
      "曝杜\n",
      "沈梦辰疑\n",
      "曝李易峰\n",
      "曝杜淳\n",
      "曝杨子\n",
      "曝罗\n",
      "季黄子\n",
      "曝迪丽\n",
      "曝邓\n",
      "150618\n",
      "驾系\n",
      "曝韩红\n",
      "曝黄太吉\n",
      "曹三玲\n",
      "曹云金染\n",
      "微博撒狗\n",
      "必可死\n",
      "成胡静\n",
      "英师出\n",
      "韩姨写\n",
      "有多乱\n",
      "出柜成\n",
      "认不识\n",
      "晏苦\n",
      "现爆降\n",
      "恨透了\n",
      "那英会\n",
      "传小三\n",
      "微博早\n",
      "误认为\n",
      "人销分\n",
      "万级家\n",
      "众泰圆\n",
      "鹿晗首\n",
      "季何猷\n",
      "快本出\n",
      "要大涨\n",
      "归小璐\n",
      "丰十连板\n",
      "李晨大婚\n",
      "有车有房\n",
      "马蓉疑\n",
      "完鹿晗\n",
      "吴亦凡们\n",
      "烧多狠\n",
      "堪比换\n",
      "有点烦\n",
      "月安馨\n",
      "不爱坏\n",
      "韩红怒\n",
      "民可得\n",
      "有喜有忧\n",
      "开扒托奶\n",
      "微信分\n",
      "而北控\n",
      "测男宝\n",
      "要放上\n",
      "时水里\n",
      "有福之人\n",
      "护肝养\n",
      "还会降\n",
      "知多坑\n",
      "万黑稿\n",
      "传洁\n",
      "现神药\n",
      "桥惊现\n",
      "昆四任\n",
      "农佟\n",
      "易评\n",
      "不入行\n",
      "下一波\n",
      "本兮以\n",
      "本兮未\n",
      "跟汉兰\n",
      "哈弗和宝俊\n",
      "车太惨\n",
      "朱之文于\n",
      "朱之文竟\n",
      "办大席\n",
      "这段话\n",
      "嫂妇\n",
      "上拉于\n",
      "朱之文熊\n",
      "朱之文要\n",
      "歌坛上\n",
      "小尼小撒\n",
      "步罗京\n",
      "朴信惠为\n",
      "朴智宪晒\n",
      "r4obqbp\n",
      "rbqxu80\n",
      "退不起\n",
      "权健恒大\n",
      "二丫终\n",
      "李书沸\n",
      "李书福要\n",
      "四驱仅\n",
      "男不愿\n",
      "致王祖\n",
      "蓝真要\n",
      "小三微博\n",
      "许晴约\n",
      "李咏携\n",
      "這八本\n",
      "這幾本\n",
      "李大毛教\n",
      "漂钓法\n",
      "获超快\n",
      "pgone1400\n",
      "王思聪暗\n",
      "万拉王\n",
      "有多贵\n",
      "秦奋怒\n",
      "学白百何\n",
      "桌伟\n",
      "王思聪大\n",
      "戏太多\n",
      "做辣妈\n",
      "看甜馨\n",
      "甜馨锁\n",
      "李湘备\n",
      "整怪\n",
      "微博用\n",
      "疑陪\n",
      "锅侠\n",
      "观舌象\n",
      "卓伟点\n",
      "继鹿晗\n",
      "陈伟霆发\n",
      "有多豪\n",
      "吻下去\n",
      "jiyunhudong\n",
      "6395653190230278401\n",
      "李易峰斥\n",
      "李易峰方\n",
      "继科景\n",
      "敏俊演\n",
      "人太甜\n",
      "好太多\n",
      "微博要\n",
      "白新招\n",
      "比景甜\n",
      "韬鲁豫\n",
      "做不了\n",
      "吻帅\n",
      "问景甜\n",
      "催婚团\n",
      "而范爷\n",
      "杀甜\n",
      "可卓伟\n",
      "婚址\n",
      "李晨头\n",
      "吴亦凡林\n",
      "万婚\n",
      "战西提\n",
      "今微博\n",
      "李沁新\n",
      "晒多图\n",
      "李易峰录\n",
      "李沁口\n",
      "李浩菲疑\n",
      "李湘富养\n",
      "某三字\n",
      "韩红刀\n",
      "年疑\n",
      "薛之谦是\n",
      "曝命\n",
      "现腿病\n",
      "马云视\n",
      "赔判\n",
      "遭利智\n",
      "微博狂\n",
      "薛之谦想\n",
      "王思聪神\n",
      "孕照首\n",
      "保三争\n",
      "棺内现\n",
      "拉人后\n",
      "买吨\n",
      "加陈醋\n",
      "湖人前\n",
      "沈梦辰结\n",
      "壕出\n",
      "时撒狗\n",
      "不输给\n",
      "差天别\n",
      "斥叛\n",
      "掩孕\n",
      "汪曼春成\n",
      "坐实怀\n",
      "亲口说\n",
      "自泄瘾\n",
      "刘空青\n",
      "王思聪该\n",
      "赵丽颖夺\n",
      "引迷弟\n",
      "幂斥\n",
      "获乐嘉力\n",
      "揭靠\n",
      "幂生\n",
      "宋茜钟\n",
      "太有福\n",
      "李易峰家\n",
      "杨洋带\n",
      "杨洋恋\n",
      "杨洋用\n",
      "女主颜值\n",
      "杨洋要\n",
      "求小爽\n",
      "杨紫吃\n",
      "杨紫张\n",
      "杨紫断\n",
      "杨紫晒\n",
      "应勤生\n",
      "杨紫晒验\n",
      "王丽坤全\n",
      "杨蓉步\n",
      "走秀旧\n",
      "没一看\n",
      "杨颖为\n",
      "吃瓜纷\n",
      "杨颖戏\n",
      "遭胡歌\n",
      "杨颖接\n",
      "杨颖旧\n",
      "万周迅\n",
      "洗牙有\n",
      "比马云\n",
      "史大起\n",
      "林丹带\n",
      "整牙换\n",
      "淤青向\n",
      "林允大秀\n",
      "狂撒糖\n",
      "相戏里\n",
      "头七在\n",
      "已哭成\n",
      "素颜晒\n",
      "因太宅\n",
      "证怀\n",
      "比伯和赛\n",
      "凸肚疑\n",
      "刘畊宏发\n",
      "换八女\n",
      "咖旁\n",
      "打马云\n",
      "六副药\n",
      "保肝养\n",
      "网红上\n",
      "sbitch5\n",
      "消腹\n",
      "祛湿养\n",
      "几大美白\n",
      "地太早\n",
      "浓美白\n",
      "李天翰要\n",
      "思梅桥\n",
      "唱刀郎\n",
      "望十连板\n",
      "称莫因\n",
      "喷威少\n",
      "吃杏时\n",
      "公桃\n",
      "母桃\n",
      "13945671177\n",
      "嘉玲生\n",
      "梅婷前\n",
      "梅婷暖心\n",
      "镇雁\n",
      "大光边\n",
      "梅西率\n",
      "长高菜\n",
      "比绿萝\n",
      "斑美\n",
      "爆小三\n",
      "曝赫子铭\n",
      "蛋惊现\n",
      "付辛博颖儿\n",
      "欧冠队\n",
      "范辰辰\n",
      "继迪丽\n",
      "阿娇飞\n",
      "13137037109\n",
      "为护刀\n",
      "此国女\n",
      "遭高人\n",
      "武旭霞\n",
      "残武僧\n",
      "猜播求\n",
      "十五个\n",
      "前十有\n",
      "扎恋\n",
      "没花过\n",
      "每一顆\n",
      "天清肠\n",
      "泡错\n",
      "天暖胃\n",
      "毒促\n",
      "巧喝\n",
      "不當恐\n",
      "个小物\n",
      "越养颜\n",
      "150120\n",
      "ev360\n",
      "阴养颜\n",
      "比播求\n",
      "比一龙输\n",
      "韩红见\n",
      "美妆达\n",
      "同献唱\n",
      "毛晓彤疑\n",
      "巧治腰\n",
      "获竟\n",
      "徐元晦\n",
      "国足来\n",
      "马云急\n",
      "拉人来\n",
      "坂东店\n",
      "求不来\n",
      "兴迪丽\n",
      "能破窗\n",
      "150719\n",
      "撒药治白\n",
      "汪秀萍案\n",
      "开炫富\n",
      "太会装\n",
      "睡颜王\n",
      "卷不分\n",
      "地质局\n",
      "骁神\n",
      "陷小三\n",
      "败光路\n",
      "我太想\n",
      "车傲\n",
      "占雾\n",
      "车企对\n",
      "沂案\n",
      "沈腾录\n",
      "沈腾气\n",
      "连微博\n",
      "相比之下\n",
      "胡可孕\n",
      "沙溢竟\n",
      "版埃尔法\n",
      "esp12\n",
      "条新规\n",
      "考不上\n",
      "没红时\n",
      "一没过\n",
      "人真要\n",
      "野钓年\n",
      "街艳泉\n",
      "连加分\n",
      "晋升为\n",
      "保不实\n",
      "天中市\n",
      "孔慌\n",
      "醫絕\n",
      "怎麼治\n",
      "法澜秀\n",
      "众谈\n",
      "马蓉难\n",
      "可逼出\n",
      "洋蔥千萬\n",
      "會導致\n",
      "闺蜜赛\n",
      "堪比磨\n",
      "风首秀\n",
      "造不起\n",
      "603289\n",
      "水逆年\n",
      "全溶光\n",
      "堪比荣整\n",
      "这食材\n",
      "比钙快\n",
      "配一宝堪\n",
      "雖好\n",
      "时先用\n",
      "变乌润\n",
      "时放上\n",
      "乌润似\n",
      "太长易\n",
      "美白三大\n",
      "洗牙加\n",
      "加牙套\n",
      "洗牙要\n",
      "后小白片\n",
      "这几宝\n",
      "治頭\n",
      "津一骑\n",
      "吓呆了\n",
      "不尿多\n",
      "款伪\n",
      "周硬\n",
      "限行令\n",
      "新交规速\n",
      "亿加仓\n",
      "陕造\n",
      "治阳事\n",
      "称乐视\n",
      "睿灿\n",
      "深国改\n",
      "限外车\n",
      "在经济上\n",
      "微博开\n",
      "李晨差\n",
      "深穗排\n",
      "亿吸筹\n",
      "看才准\n",
      "大婚夜\n",
      "这一注\n",
      "变火人\n",
      "连有角\n",
      "男之首\n",
      "赚疯了\n",
      "瓯通\n",
      "遭王祖\n",
      "吴婉华夫\n",
      "港媒爆\n",
      "阿朱卖\n",
      "港珠港\n",
      "孙杨战\n",
      "开不起\n",
      "锁颈后\n",
      "因烟炎\n",
      "遭爱狗\n",
      "湿猴\n",
      "榆四脉\n",
      "疑交新\n",
      "有多差\n",
      "曝黑料\n",
      "斤堪\n",
      "侠美队\n",
      "全在力\n",
      "央子港\n",
      "潘傻\n",
      "嘻哈妹\n",
      "毯甜\n",
      "吴昕称\n",
      "吴昕求\n",
      "只租楼\n",
      "董洁要\n",
      "曝凤姐\n",
      "良心何在\n",
      "过多会\n",
      "28f4\n",
      "助莫雷\n",
      "戈登难\n",
      "莫雷苦\n",
      "已不惧\n",
      "莫雷有\n",
      "莫雷点\n",
      "神塔要\n",
      "和保罗\n",
      "親測\n",
      "增晰酷\n",
      "放太多油\n",
      "股神大\n",
      "买新锅\n",
      "还大涨\n",
      "雅瑪人\n",
      "有三種\n",
      "郭德纲面\n",
      "继林丹\n",
      "一个班\n",
      "焰楠\n",
      "对马蓉\n",
      "强太多\n",
      "熏醋防\n",
      "不长个\n",
      "吸六包\n",
      "有多累\n",
      "爆李\n",
      "爆马蓉妈\n",
      "帮马蓉\n",
      "爱吃西\n",
      "爱吃鹅肝者\n",
      "爱尚轻\n",
      "吃狗娘\n",
      "水与身\n",
      "根本就是\n",
      "父皇要\n",
      "点想长\n",
      "吴京包\n",
      "遭知乎\n",
      "撕娜\n",
      "与此有关\n",
      "牙太黄\n",
      "宝妈变\n",
      "挤太多会\n",
      "洗牙强\n",
      "买美白\n",
      "牛人用\n",
      "有害无益\n",
      "美白变\n",
      "暗黄变\n",
      "机没造\n",
      "有美人\n",
      "男宝要\n",
      "曝汪峰\n",
      "仔列沙\n",
      "胡可要\n",
      "狗尿会\n",
      "而刀郎\n",
      "附超\n",
      "证可领\n",
      "超优德\n",
      "天不烂\n",
      "首安茶\n",
      "肉堪\n",
      "红沙皮\n",
      "需一剪\n",
      "追美合\n",
      "王一博美合\n",
      "王丽坤林\n",
      "逆袭成\n",
      "护易\n",
      "问马云\n",
      "微博甜\n",
      "网传王\n",
      "宋喆该\n",
      "强交新\n",
      "宋喆养\n",
      "网传宝强\n",
      "中泪点\n",
      "强泪\n",
      "熊乃瑾秀\n",
      "总费用\n",
      "比马蓉靓\n",
      "宋喆恐\n",
      "微博疑\n",
      "强宝强\n",
      "宋喆会\n",
      "宋喆终\n",
      "宋喆进\n",
      "超马蓉\n",
      "胜马蓉\n",
      "熊乃瑾疑\n",
      "称马蓉\n",
      "爆宝强\n",
      "赵薇版\n",
      "引马蓉\n",
      "发博表\n",
      "赞宝强\n",
      "有宝强\n",
      "归宝强\n",
      "微博向\n",
      "马蓉案\n",
      "王思聪为\n",
      "马云思聪\n",
      "王思聪出\n",
      "雪莉富\n",
      "发冯\n",
      "病治好\n",
      "王思聪友\n",
      "王思聪发\n",
      "称鹿晗\n",
      "脸景甜\n",
      "英放狠话\n",
      "王思聪带\n",
      "马云要\n",
      "微博怒\n",
      "喷马云\n",
      "王思聪手\n",
      "李晨白\n",
      "章泽天口\n",
      "东怒\n",
      "王思聪欲出\n",
      "王思聪欲花\n",
      "讽冯\n",
      "王思聪狂\n",
      "王思聪疑\n",
      "讽鹿晗\n",
      "王思聪称\n",
      "字扎心\n",
      "王思聪竟\n",
      "王思聪约\n",
      "王思聪维密秀\n",
      "王思聪要\n",
      "我愿用\n",
      "英滚出\n",
      "王思聪讽\n",
      "王思聪道\n",
      "真唱过\n",
      "王珂靠\n",
      "买太多\n",
      "送出去\n",
      "天美请\n",
      "窦唯在\n",
      "窦唯哭\n",
      "谢贤要\n",
      "用四字\n",
      "爆孽缘\n",
      "导锁\n",
      "柏芝选\n",
      "肚大如筐\n",
      "有三爹\n",
      "谢贤怒\n",
      "窦唯之女\n",
      "爆签\n",
      "克屎\n",
      "王岳伦为\n",
      "一个八岁\n",
      "娃招\n",
      "字气坏\n",
      "李湘竟\n",
      "李湘上\n",
      "还艳压\n",
      "曝借\n",
      "却大爱\n",
      "后能值\n",
      "任总说\n",
      "爆岳云鹏\n",
      "韩星长\n",
      "玲琅满\n",
      "混进去\n",
      "致一人\n",
      "地下商场\n",
      "高迪榜\n",
      "替佑家军\n",
      "磕太多\n",
      "前不敬\n",
      "吴京后\n",
      "真应学\n",
      "甘姿\n",
      "甘敬闹\n",
      "格桑加\n",
      "甜馨成\n",
      "曝沈梦辰\n",
      "没湿毒\n",
      "脂治\n",
      "水加个\n",
      "一晚治\n",
      "毒调\n",
      "轮似\n",
      "前内腺\n",
      "看肚型\n",
      "生男先\n",
      "看孕妈\n",
      "‍\n",
      "天不掉\n",
      "再染头\n",
      "用蒜加\n",
      "搭配着\n",
      "人不信\n",
      "裡都\n",
      "用運動\n",
      "用雪碧做\n",
      "籽熏出\n",
      "李湘怒\n",
      "甄微博\n",
      "周可住\n",
      "天多地\n",
      "违规行为\n",
      "传马云\n",
      "电塔上\n",
      "头靠头\n",
      "女主会\n",
      "竞马蓉\n",
      "女主由\n",
      "越吃会\n",
      "失戀次數\n",
      "这七大\n",
      "卵洒\n",
      "以上者\n",
      "偶得开\n",
      "曾毅齐\n",
      "卖雄安\n",
      "拍不雅\n",
      "画换个\n",
      "桌大怒\n",
      "赔坏\n",
      "堆如墙\n",
      "孩抓\n",
      "成鹿晗\n",
      "可防霾\n",
      "男尖\n",
      "李沁送\n",
      "读检时\n",
      "胎梦准\n",
      "附女宝\n",
      "网红地\n",
      "卓伟要\n",
      "马蓉点\n",
      "赞王宝\n",
      "疑宋喆\n",
      "曝杨洋\n",
      "疑某\n",
      "群内收\n",
      "数十个\n",
      "崖冈芝\n",
      "湿引\n",
      "瘦不掉\n",
      "瘦不去\n",
      "這才\n",
      "小招教\n",
      "缠不上\n",
      "凳登\n",
      "不学亏\n",
      "猖绝\n",
      "变不黑\n",
      "黑如炭\n",
      "多别染\n",
      "天乌润\n",
      "几大百\n",
      "比新刷\n",
      "弄脏了\n",
      "白太多\n",
      "更易长\n",
      "太多能\n",
      "不学真\n",
      "甭染\n",
      "面大骂\n",
      "探班送\n",
      "怀陈羽\n",
      "喝下去\n",
      "降三高特\n",
      "天祛皱\n",
      "美白除\n",
      "穿不下\n",
      "如雨下\n",
      "宝妈似\n",
      "速美白\n",
      "青秀有\n",
      "结竹米\n",
      "百白何\n",
      "皂角加\n",
      "黄又糙\n",
      "掺小\n",
      "前加个\n",
      "皱兆龙\n",
      "盐配\n",
      "恶灵袭\n",
      "毛骨悚人\n",
      "巨震大\n",
      "博主孙\n",
      "有恋足\n",
      "盛刷\n",
      "最能生\n",
      "比马云挡\n",
      "暗怼\n",
      "直击限行\n",
      "直到现在\n",
      "侯耀文葬\n",
      "万淘回\n",
      "脸祁同伟\n",
      "这小腰\n",
      "前不愿\n",
      "看刀郎\n",
      "谢贤点\n",
      "张宇教\n",
      "d170727\n",
      "一个多月\n",
      "重不重\n",
      "看耳知\n",
      "德牧獨\n",
      "自開車\n",
      "嚇壞\n",
      "图会动\n",
      "看马伊\n",
      "2116w\n",
      "王思聪点\n",
      "有酸儿\n",
      "刘丹笑\n",
      "孕妈怀\n",
      "认识一下\n",
      "袁立变\n",
      "眼妆画\n",
      "有多脏\n",
      "消不去\n",
      "吴磊妈\n",
      "美白平\n",
      "能拉出\n",
      "黑宿\n",
      "時別\n",
      "機放\n",
      "前放点\n",
      "曝刘诗\n",
      "爆白百何\n",
      "知行易\n",
      "某豫\n",
      "尚城名\n",
      "六连板\n",
      "較聰明\n",
      "愈颜圣品\n",
      "停止使用\n",
      "磨桂梅\n",
      "抢走了\n",
      "一个四岁\n",
      "三死二伤\n",
      "还会伤\n",
      "祝傻根\n",
      "鸡镇\n",
      "豪型\n",
      "元药事\n",
      "福羲\n",
      "以藏养\n",
      "曝龙珠\n",
      "填新证\n",
      "白百对\n",
      "黄渤带\n",
      "女爱豆\n",
      "看何洁\n",
      "种药同\n",
      "重不除\n",
      "有何意义\n",
      "更為\n",
      "请网\n",
      "湖人当\n",
      "项驾\n",
      "天刮肉\n",
      "既能治\n",
      "没练成\n",
      "墓乐坏\n",
      "李静谈\n",
      "劲咽\n",
      "無束\n",
      "刚过去\n",
      "克金有\n",
      "接娃时\n",
      "神卫伤\n",
      "山大主\n",
      "窦唯两\n",
      "窦家媛长\n",
      "袁立信\n",
      "宗萨上\n",
      "骁远\n",
      "亿陪\n",
      "爆患\n",
      "王思聪成\n",
      "看抖音\n",
      "赵丽颖化\n",
      "好妆换\n",
      "有多神\n",
      "第一章\n",
      "角十连\n",
      "角版别\n",
      "谈压色\n",
      "第六十四章\n",
      "元冠号\n",
      "当折白\n",
      "区之迷\n",
      "重复使用\n",
      "籽陷\n",
      "吴昕面\n",
      "吴昕献\n",
      "欲迪丽\n",
      "万颜值\n",
      "糖友常\n",
      "没得说\n",
      "菜助\n",
      "一吃顿\n",
      "列汀能\n",
      "尿不甜\n",
      "肌膚會\n",
      "紅糖加\n",
      "吃得下\n",
      "反闹出\n",
      "李嫣接\n",
      "比得上\n",
      "会尿出\n",
      "斑减\n",
      "沒过\n",
      "水真能\n",
      "天紧肤\n",
      "小白片\n",
      "戈兰为\n",
      "袁立设\n",
      "中不受\n",
      "三高绕\n",
      "完林丹\n",
      "109388230\n",
      "亲承博卡\n",
      "喝仟佰宠\n",
      "☝\n",
      "✔\n",
      "菜而手\n",
      "有三人\n",
      "小福加\n",
      "疼一病\n",
      "晕系\n",
      "三大高管\n",
      "继卓伟\n",
      "继刘涛\n",
      "继双宋\n",
      "携子录\n",
      "继方静\n",
      "继景甜\n",
      "继港\n",
      "继王俊凯\n",
      "继白百何\n",
      "继胡歌\n",
      "继袁立\n",
      "继裹\n",
      "增瘦\n",
      "继郑恺\n",
      "继郑爽\n",
      "亲鹿晗\n",
      "继阿娇\n",
      "继韩庚\n",
      "继马蓉\n",
      "续林丹\n",
      "续白百何\n",
      "续鹿晗\n",
      "维嘉隐婚\n",
      "维小保\n",
      "对美白\n",
      "绿专\n",
      "看绿凯\n",
      "绿凯会\n",
      "贝江到\n",
      "请迪丽\n",
      "高伟光组\n",
      "网传余承东\n",
      "棠樂\n",
      "网传卓伟\n",
      "码酿\n",
      "豪不雅\n",
      "网传望\n",
      "撕八组\n",
      "网传棚\n",
      "网传泉港\n",
      "网传海湖\n",
      "网传现\n",
      "网传玲花\n",
      "坠落在\n",
      "已中枪\n",
      "网传葛军\n",
      "写新歌\n",
      "临天八弄\n",
      "邓超花\n",
      "网传雷\n",
      "恐赔\n",
      "微凸似\n",
      "获马蓉点\n",
      "曝窦\n",
      "曝胡歌\n",
      "问卓伟\n",
      "张翰马\n",
      "真能生\n",
      "河田飞\n",
      "赠送给\n",
      "为小爽\n",
      "欧签\n",
      "艺考照\n",
      "曝沙\n",
      "思聪称\n",
      "曝白百何\n",
      "曝罗志祥\n",
      "曝罗晋\n",
      "微博晒动\n",
      "疑携新\n",
      "曝雷\n",
      "曝马蓉现\n",
      "认爱则\n",
      "为栓住\n",
      "王思聪谈\n",
      "马蓉带\n",
      "孙志立\n",
      "网红黑\n",
      "购婚\n",
      "包炫富\n",
      "罗志祥斥\n",
      "罗志祥花\n",
      "爆斥\n",
      "购正\n",
      "罗志祥要\n",
      "罗志祥豪\n",
      "罗胖坑\n",
      "唐嫣信\n",
      "嫣疑\n",
      "夸惨\n",
      "罗玉凤发\n",
      "紧悟\n",
      "罪之美\n",
      "中俄能\n",
      "两国杠\n",
      "季不看\n",
      "日惊现\n",
      "两异象\n",
      "没人能\n",
      "不佳易\n",
      "曝见\n",
      "上射出\n",
      "竟十女配\n",
      "大醋方\n",
      "美女用\n",
      "股神放话\n",
      "美妆博主长\n",
      "曝詹皇\n",
      "湖人要\n",
      "草可治乳\n",
      "師洩密\n",
      "年秋起\n",
      "齒將\n",
      "這物\n",
      "翁帆用\n",
      "实小三\n",
      "亿堪\n",
      "养颜治\n",
      "密茶\n",
      "内治好\n",
      "說准\n",
      "说十胖九湿\n",
      "这一宝\n",
      "如雨般\n",
      "人不爱登\n",
      "大开疑\n",
      "爱红歌\n",
      "老杜在\n",
      "可范伟\n",
      "老梁观\n",
      "真得值\n",
      "枪锈管\n",
      "生苍\n",
      "百挑百准\n",
      "老罗说\n",
      "老钓友\n",
      "孕妈防\n",
      "澄不清\n",
      "联糖\n",
      "即锁机\n",
      "男宝及\n",
      "五六个\n",
      "太大别\n",
      "太大愁\n",
      "提不上\n",
      "吃二片\n",
      "鼓鼓的\n",
      "肚尖生\n",
      "男肚\n",
      "肝毒排\n",
      "根可排\n",
      "毒益\n",
      "天肝毒\n",
      "病不扰\n",
      "迎限售\n",
      "低拉响\n",
      "捂谷必\n",
      "超顶量\n",
      "精蓄锐\n",
      "虚除\n",
      "有治好\n",
      "讨薪博\n",
      "晨尿变\n",
      "胎寶寶和\n",
      "億萬父\n",
      "親母親\n",
      "胎梦能\n",
      "胎梦真\n",
      "胖人先\n",
      "胖腹\n",
      "扣不上\n",
      "胡可说\n",
      "爱沙溢\n",
      "王莫涵\n",
      "土创\n",
      "必有用\n",
      "赵丽颖迪丽\n",
      "胡歌江\n",
      "恋上富\n",
      "胡歌版\n",
      "胡歌疑\n",
      "真不愧是\n",
      "曝与江\n",
      "却大呼\n",
      "男主云\n",
      "变迷妹\n",
      "胡歌领\n",
      "同食易\n",
      "胡蘿\n",
      "白蘿\n",
      "转下去\n",
      "悄悄的\n",
      "成王俊凯\n",
      "谈鹿晗\n",
      "庞博吐槽\n",
      "黄多斑\n",
      "亮白显\n",
      "神蒜子\n",
      "根一壶\n",
      "天跳起\n",
      "直不起\n",
      "一些丝\n",
      "蹄配\n",
      "草教\n",
      "腰凸\n",
      "条明路\n",
      "芯系\n",
      "一员大将\n",
      "疼选\n",
      "上罗晋\n",
      "燃脂宿\n",
      "⭐\n",
      "醫教\n",
      "幾招\n",
      "帮不了\n",
      "假哏\n",
      "发博要\n",
      "微博倡\n",
      "鸡准\n",
      "车晓要\n",
      "邓超会\n",
      "都治好\n",
      "禅洗\n",
      "这条经\n",
      "劲椎痛\n",
      "13730400322\n",
      "最易复\n",
      "潇起\n",
      "夸买\n",
      "高衣品\n",
      "购公\n",
      "诗鹿晗\n",
      "肠毒治\n",
      "天可治\n",
      "天抹平\n",
      "lll555\n",
      "爆含\n",
      "比中美\n",
      "之约成\n",
      "苏牙身\n",
      "中吐饼\n",
      "要求归还\n",
      "苟芸慧捞\n",
      "若孕妈\n",
      "大秀新\n",
      "最多反\n",
      "三连助\n",
      "比安卓\n",
      "变满格\n",
      "充爱奇艺\n",
      "比安卓贵\n",
      "范丞丞出\n",
      "范丞丞初\n",
      "范丞丞唱\n",
      "范丞丞开\n",
      "范丞丞微\n",
      "博设\n",
      "范丞丞是\n",
      "范丞丞疑\n",
      "范大美人\n",
      "范丞丞赢\n",
      "范丞丞跑\n",
      "一入题\n",
      "这逼装\n",
      "遭退剧\n",
      "人可住\n",
      "李晨婚\n",
      "亿备\n",
      "婚房疑\n",
      "不输范\n",
      "微博晒素\n",
      "红本秀\n",
      "予酸气\n",
      "⋯\n",
      "曝李晨\n",
      "粉装捞\n",
      "装不下\n",
      "其真烂\n",
      "一沉斥\n",
      "李晨换\n",
      "撕白\n",
      "梗加\n",
      "王二妮现\n",
      "区昌元\n",
      "揭胡歌\n",
      "净白逆龄\n",
      "将军肚\n",
      "莫雷慌\n",
      "雪藏恐\n",
      "切不动\n",
      "老粘锅\n",
      "萌宠成\n",
      "快没了\n",
      "萨德后\n",
      "出爱自\n",
      "泰莱托\n",
      "窗擦出\n",
      "亮银版\n",
      "甩功\n",
      "这一说\n",
      "元骗\n",
      "跨济青\n",
      "用狗求\n",
      "涉汛\n",
      "亲宝来\n",
      "六不喝\n",
      "谣记\n",
      "传夺\n",
      "留秒\n",
      "男主而\n",
      "谢娜孕\n",
      "买扬\n",
      "传学车\n",
      "原男主非\n",
      "邓伦成\n",
      "销分者\n",
      "ufoufo\n",
      "被常来\n",
      "爽呆了\n",
      "马云败\n",
      "长高必\n",
      "耻可雪\n",
      "称宜信\n",
      "配四驱\n",
      "配小版汉兰达\n",
      "井柏然方\n",
      "郭冠樱\n",
      "需交药\n",
      "分可达\n",
      "骗嫩\n",
      "孙宁后\n",
      "斥收\n",
      "卓伟怒\n",
      "甩斤\n",
      "撒药系\n",
      "网传市\n",
      "pivm\n",
      "hqp88jszlmfz7kgvw\n",
      "袁立敢\n",
      "袁立输\n",
      "浙卫玩大\n",
      "袁立斥\n",
      "喻言太狂\n",
      "发耳沙\n",
      "溺亡系\n",
      "扮瘦\n",
      "不学车\n",
      "清血凉\n",
      "没得癌\n",
      "被忽略了\n",
      "会大放\n",
      "离月供\n",
      "殊灭\n",
      "版樊胜美\n",
      "mp412\n",
      "王嘉俩\n",
      "请宝妈\n",
      "剪肥\n",
      "编门\n",
      "邓超带\n",
      "毕滢\n",
      "洪欣成\n",
      "曝戚\n",
      "先热车\n",
      "美白大长\n",
      "就会少\n",
      "赵伟健\n",
      "植森式\n",
      "缩肚法\n",
      "暗黄靠\n",
      "钱小白片\n",
      "調理治\n",
      "招辈传\n",
      "奖中超\n",
      "场暂\n",
      "签新帅\n",
      "埃神博\n",
      "亚冠上\n",
      "美链\n",
      "理综第\n",
      "显瘦特\n",
      "小仁村\n",
      "194027\n",
      "加全满\n",
      "乳包\n",
      "丘卡堡\n",
      "天审车\n",
      "纸糊房\n",
      "养颜能\n",
      "畜博\n",
      "工救\n",
      "镇堤\n",
      "马云摊\n",
      "马云过\n",
      "该吐槽\n",
      "房企散\n",
      "不在染\n",
      "传男宝\n",
      "遭迷烟\n",
      "网传分\n",
      "分新规\n",
      "热帖系\n",
      "没本数\n",
      "薛之谦疑\n",
      "薛之谦能\n",
      "薛之谦遭\n",
      "严新交规\n",
      "条新交规\n",
      "日新交规\n",
      "改区市\n",
      "打户工\n",
      "图一查\n",
      "图帮算\n",
      "立补立\n",
      "想吐槽\n",
      "张修维醉\n",
      "納宝力\n",
      "满蒙非\n",
      "花口贝\n",
      "进国网\n",
      "物熬\n",
      "链反\n",
      "链币\n",
      "非美图\n",
      "新规要\n",
      "需交缴\n",
      "走会收\n",
      "﻿\n",
      "造人论\n",
      "有三大\n",
      "获塔塔\n",
      "阎焱购\n",
      "审扣\n",
      "永防\n",
      "杨凌限行\n",
      "将限行\n",
      "酸酸的\n",
      "不装罚\n",
      "三高显\n",
      "退不退\n",
      "蒋欣骗\n",
      "蒋欣假\n",
      "没人会\n",
      "类违\n",
      "媳难\n",
      "去不去\n",
      "这三大假\n",
      "你会生\n",
      "人不交\n",
      "万高二\n",
      "土地出让\n",
      "最多省\n",
      "二建要\n",
      "无新规\n",
      "交规大\n",
      "内算酒\n",
      "高科城\n",
      "厕宝易\n",
      "跑员称\n",
      "地税局\n",
      "天白过\n",
      "后抹点\n",
      "美白太难\n",
      "素颜要\n",
      "黄美白\n",
      "越白滑\n",
      "中放点\n",
      "水乳霜加\n",
      "美白逆龄\n",
      "越白过\n",
      "越雪嫩\n",
      "可真大\n",
      "只会用\n",
      "七子粉\n",
      "亮白细\n",
      "水嫩亮\n",
      "暗黄有\n",
      "车不装\n",
      "最马云\n",
      "东喘\n",
      "年宝妈\n",
      "马云谈\n",
      "换新卡\n",
      "脑补求\n",
      "要摇号\n",
      "赵又廷演\n",
      "相给力\n",
      "沃展\n",
      "致沪上\n",
      "驾不查\n",
      "一虎要\n",
      "拉不开\n",
      "欧风麦\n",
      "贾跃亭力\n",
      "超百人\n",
      "合返\n",
      "交费用\n",
      "备孕要\n",
      "提至语\n",
      "青训生\n",
      "年安在\n",
      "eiracube\n",
      "领克用\n",
      "墨拒\n",
      "关晓彤发\n",
      "亿嫁\n",
      "扎迪丽\n",
      "剧旧\n",
      "胖迪暴\n",
      "全治好\n",
      "官宣引\n",
      "投权健\n",
      "上港发\n",
      "遭大梦\n",
      "演小三\n",
      "频蹭\n",
      "网传洁\n",
      "季四人\n",
      "最暖心\n",
      "关晓彤成\n",
      "录迪丽\n",
      "宣迪丽\n",
      "比玉好\n",
      "大余来\n",
      "杨紫和周\n",
      "国乒让\n",
      "董洁大婚\n",
      "这国仅\n",
      "李沁为\n",
      "杨紫撞\n",
      "怪怪的\n",
      "疑晒出\n",
      "它治尿\n",
      "加骁龙\n",
      "活可產生\n",
      "屍傳\n",
      "传埃\n",
      "案烧\n",
      "限酬\n",
      "斤虫\n",
      "寒开测\n",
      "马崴\n",
      "出高冰阳\n",
      "罗晋陷\n",
      "网传罗晋\n",
      "老嚼\n",
      "变大脸\n",
      "抢景甜\n",
      "携发\n",
      "还助眠\n",
      "基满色\n",
      "沙匀\n",
      "原石过\n",
      "起鸡油\n",
      "级籽料\n",
      "赌石大\n",
      "喝無糖\n",
      "年娜\n",
      "没和娜\n",
      "蒋欣疑\n",
      "向郎导\n",
      "周鸿祎发\n",
      "李晨大怒\n",
      "微博心\n",
      "罗玉凤凤姐\n",
      "突删\n",
      "亿因\n",
      "肺唱\n",
      "生女宝\n",
      "允晒照\n",
      "晒素\n",
      "十三个\n",
      "六物膏\n",
      "网红圈\n",
      "一人妻\n",
      "曾放话\n",
      "后华哥\n",
      "很委\n",
      "一个二十岁\n",
      "币安一姐\n",
      "网传币\n",
      "币安何\n",
      "币安下\n",
      "虾帝\n",
      "建不起\n",
      "停贷系\n",
      "再貴\n",
      "德云色协\n",
      "微博热传\n",
      "仅仅只是\n",
      "不大呼\n",
      "人老孟\n",
      "当十有\n",
      "实锤蛇哥\n",
      "何炅大\n",
      "疑何\n",
      "高圣运\n",
      "继谢娜生\n",
      "黑周杰\n",
      "因美过\n",
      "之陆判\n",
      "剩胡歌\n",
      "晏单\n",
      "之所以\n",
      "还拉上\n",
      "半爷\n",
      "传嫁\n",
      "邹市\n",
      "张伦硕早\n",
      "张伦硕为\n",
      "张伦硕怀\n",
      "引谢贤\n",
      "柏芝乐\n",
      "挺大孕肚\n",
      "峰菲芝\n",
      "张伦硕揽\n",
      "大媽教\n",
      "破不老\n",
      "打帕奎\n",
      "表女宝\n",
      "网传驾\n",
      "一和四需\n",
      "一和四\n",
      "考大变\n",
      "考更难\n",
      "附驾考\n",
      "练车会\n",
      "晚排\n",
      "肚臍上\n",
      "雪蛤炖\n",
      "协站\n",
      "冻多效\n",
      "官宣将\n",
      "链引\n",
      "因良率\n",
      "一语表\n",
      "万字文\n",
      "ios113\n",
      "木桃式\n",
      "王思聪告\n",
      "完刀郎\n",
      "素颜近\n",
      "180101\n",
      "气颖姐\n",
      "20171118132212\n",
      "退贵圈\n",
      "牛莉为\n",
      "洛瑞怒\n",
      "赔朱\n",
      "之文练\n",
      "杨子姗连\n",
      "听鹿晗\n",
      "阿杜患\n",
      "吴京非\n",
      "美媒惊\n",
      "曝泰伦卢\n",
      "朝伟嘉玲\n",
      "素颜上\n",
      "曝不生\n",
      "称太大\n",
      "发博晒\n",
      "微博已\n",
      "目驚心\n",
      "为蛇哥\n",
      "卢本伟骗\n",
      "微博一\n",
      "龙弃\n",
      "马云闹\n",
      "挽不回\n",
      "称壹佰\n",
      "燃脂法\n",
      "养颜防\n",
      "颈期\n",
      "宝妈用\n",
      "暴汗服\n",
      "嘴致\n",
      "阅球\n",
      "莫雷为\n",
      "认芯\n",
      "认磁\n",
      "卡不认\n",
      "时卡险\n",
      "装逼新\n",
      "放心使用\n",
      "㕛\n",
      "柯南七大\n",
      "屡热传\n",
      "惠安崇\n",
      "武惊传\n",
      "法斗步\n",
      "希晒\n",
      "有太多\n",
      "俄懷孕\n",
      "年後竟\n",
      "產活\n",
      "控糖用\n",
      "榜刷单\n",
      "万起定\n",
      "万不费\n",
      "仔乱\n",
      "年夏普\n",
      "王石陷\n",
      "比翁帆\n",
      "很扎心\n",
      "两人用\n",
      "专瘦\n",
      "黄恒泰\n",
      "飞防真\n",
      "打谢娜\n",
      "谢娜讽\n",
      "现张杰\n",
      "愿宝\n",
      "附肚型\n",
      "能养颜\n",
      "陈醋加\n",
      "某微博\n",
      "给霆锋\n",
      "谢贤立\n",
      "吹霉\n",
      "为大婚\n",
      "市驾考\n",
      "化限行\n",
      "行新规\n",
      "卡友圈\n",
      "宝兰客\n",
      "可防脱\n",
      "现又陷\n",
      "谢贤疑\n",
      "谢贤刚\n",
      "谢贤谈\n",
      "财產归\n",
      "谢贤想分\n",
      "吃味传\n",
      "谢贤称\n",
      "曝加\n",
      "拟运向\n",
      "过高要\n",
      "无降配\n",
      "很乱系\n",
      "周超快\n",
      "附超全\n",
      "已诞下\n",
      "好孕气\n",
      "生宝状\n",
      "看恋童\n",
      "有恋童\n",
      "指恋童\n",
      "踏俩\n",
      "辣妈用\n",
      "练鬼步\n",
      "那学来\n",
      "猛瘦\n",
      "甩肚\n",
      "莫暴\n",
      "极塑\n",
      "中圣品\n",
      "知爽\n",
      "含屎\n",
      "无三高\n",
      "晴批\n",
      "宋雨洪\n",
      "无论是\n",
      "以微博\n",
      "薛之谦个\n",
      "周杰互\n",
      "谦谦爱\n",
      "鼓不起\n",
      "网剧令\n",
      "返本型\n",
      "曝卖\n",
      "王一博自\n",
      "消保委约\n",
      "老铁要\n",
      "李湘笑\n",
      "球场上\n",
      "青微博\n",
      "无墅\n",
      "喝多会\n",
      "痴汉脸\n",
      "查飞单\n",
      "投入使用\n",
      "矿圈\n",
      "吴评鑫\n",
      "删路\n",
      "被尬\n",
      "其言尽\n",
      "撒内宁\n",
      "凭颜值\n",
      "况丽任\n",
      "中酒协\n",
      "附选股\n",
      "嘉楠耘\n",
      "杨颖太像\n",
      "一人带\n",
      "这大招\n",
      "安迪竟\n",
      "upit\n",
      "币安将\n",
      "称中美\n",
      "比安迪豪\n",
      "看孕囊\n",
      "商飞用\n",
      "媒脸\n",
      "队不换\n",
      "根可治癌\n",
      "涉癌\n",
      "qklw\n",
      "罗又陷\n",
      "鲁尼梅格\n",
      "20180705\n",
      "亿追内\n",
      "欧冠要\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "曝齐祖\n",
      "西媒报\n",
      "梅西发\n",
      "内马尔回\n",
      "▹\n",
      "被旭旭\n",
      "未锁抗\n",
      "店卷款\n",
      "1440cc\n",
      "姐退赛\n",
      "偏慨全\n",
      "姐赴\n",
      "帮白娅婧\n",
      "网传高\n",
      "越聰明\n",
      "當夜\n",
      "貓族\n",
      "小智称\n",
      "啪姐\n",
      "连麦散\n",
      "变人全\n",
      "完牙要\n",
      "10gt\n",
      "马蓉终\n",
      "周琦发\n",
      "条微博\n",
      "180320\n",
      "抬高自己\n",
      "微博热文\n",
      "明升车\n",
      "发推称\n",
      "qq144\n",
      "karasa\n",
      "推特谈\n",
      "爆招\n",
      "保健作用\n",
      "现与九好\n",
      "tfrboys\n",
      "后易祥千玺\n",
      "天合光\n",
      "战悬\n",
      "王源陷\n",
      "王蒙芳\n",
      "disspg\n",
      "绿休团\n",
      "真不看\n",
      "陕甲\n",
      "逆领\n",
      "戏暴\n",
      "毒通\n",
      "净瘦\n",
      "天刮肠治\n",
      "回小蛮\n",
      "通督法\n",
      "颜值帝\n",
      "28576\n",
      "买哈弗\n",
      "談靈體\n",
      "码截屏\n",
      "戊仁\n",
      "杨颖大\n",
      "欠裸贷\n",
      "刚发糖\n",
      "晒孕照\n",
      "曝送\n",
      "吴秀波方\n",
      "曝带\n",
      "懷男寶最\n",
      "大特徵\n",
      "一居卖\n",
      "曹德旺成\n",
      "ios80\n",
      "ufs21\n",
      "iphonex1\n",
      "ufo37\n",
      "称摩拜\n",
      "成转商\n",
      "有细针\n",
      "王兴靠\n",
      "只捧林\n",
      "王智产女\n",
      "破虚红\n",
      "看球系\n",
      "曾哥悟悟\n",
      "霉霉和赛\n",
      "小虎铁\n",
      "大东翔\n",
      "竞有料\n",
      "致万人\n",
      "网传皂\n",
      "称马航\n",
      "轻松自在\n",
      "打其脸\n",
      "雪中放\n",
      "健今\n",
      "房算白\n",
      "慌教\n",
      "乐视要\n",
      "妥滴\n",
      "传梦老\n",
      "网传酒\n",
      "网传龙\n",
      "桂风起\n",
      "心热时\n",
      "想不美\n",
      "箱偷\n",
      "照火遍\n",
      "百人团\n",
      "说春白\n",
      "中春尾寿眉\n",
      "西牛岭\n",
      "侯继刚\n",
      "暂不收\n",
      "水贝买\n",
      "前将现\n",
      "香颜值\n",
      "发微斥\n",
      "危物種\n",
      "万疑\n",
      "能防雾\n",
      "喝鼠\n",
      "乃不实\n",
      "暖文有\n",
      "删长\n",
      "双滦事\n",
      "通过观察\n",
      "171013\n",
      "特破此\n",
      "传烧\n",
      "双榜来\n",
      "中吃出\n",
      "lucas1\n",
      "发给你\n",
      "在京举行\n",
      "挖莱万\n",
      "曝蒂\n",
      "莱万亲\n",
      "众筹刷单\n",
      "何一称\n",
      "网传豪\n",
      "币之父\n",
      "jgg88885\n",
      "曝偷\n",
      "删孕\n",
      "深得于\n",
      "很多遍\n",
      "王丽坤苦\n",
      "网红莉哥\n",
      "就会松\n",
      "蛭富\n",
      "麝取\n",
      "养鹅有\n",
      "王凯称\n",
      "删不实\n",
      "群传雪\n",
      "若风为\n",
      "四连辟\n",
      "放洁\n",
      "国通星\n",
      "不雅未\n",
      "高鑫情\n",
      "早吃金\n",
      "晚吃毒\n",
      "称微博\n",
      "桃梨橙柿\n",
      "金宇车\n",
      "微博为\n",
      "辛芷蕾陷\n",
      "乘网\n",
      "剂致\n",
      "唐艺昕互\n",
      "路肉串\n",
      "瑞世佳典\n",
      "网传湖\n",
      "体脂会\n",
      "途虎卖\n",
      "筹旧\n",
      "圈七大\n",
      "造财库\n",
      "半女宝\n",
      "这不王\n",
      "剧招\n",
      "注胶门\n",
      "李书沸徐\n",
      "要拉黑\n",
      "暗黄长\n",
      "那血病\n",
      "肾越\n",
      "满暖心\n",
      "恒大有\n",
      "赵丽颖方\n",
      "赵丽颖用\n",
      "治蛾\n",
      "纪台桥\n",
      "马斯切\n",
      "孙安佐案\n",
      "马云当\n",
      "但会致\n",
      "吃产\n",
      "国燕委\n",
      "发防骗\n",
      "锋霸亲\n",
      "全仓该\n",
      "对乐视\n",
      "传辉山\n",
      "放黑血\n",
      "战帕奎\n",
      "无根粉\n",
      "最扎心\n",
      "传市\n",
      "治蛾别\n",
      "疯传明\n",
      "撒药治蛾\n",
      "浙土梅\n",
      "微博送\n",
      "白鸠川\n",
      "赵丽颖变\n",
      "两作媒\n",
      "151023\n",
      "推常旅\n",
      "李昂发\n",
      "演侯亮\n",
      "演候\n",
      "男主陆毅\n",
      "靳东换\n",
      "陆毅版\n",
      "旗币\n",
      "女主选\n",
      "王俊凯担\n",
      "凯靳东\n",
      "剧荒期\n",
      "剧透下\n",
      "昆凌请\n",
      "姿疑怀\n",
      "演女主\n",
      "女主比\n",
      "张翰开\n",
      "倪秋云家\n",
      "同食变\n",
      "男一罗志祥\n",
      "加蓝条\n",
      "马云组\n",
      "徐峥怒\n",
      "黄渤王宝\n",
      "徐峥强\n",
      "黄渤铁\n",
      "称其为\n",
      "万救\n",
      "姚译\n",
      "胖迪遭\n",
      "驾仅\n",
      "哪七大\n",
      "称好剧\n",
      "180102\n",
      "赔巴清传\n",
      "肖奈是\n",
      "微博道\n",
      "入水后\n",
      "肝钓\n",
      "章奔\n",
      "溃泪\n",
      "发博破\n",
      "超暖心\n",
      "传吸粉\n",
      "赵丽颖能\n",
      "赵丽颖版\n",
      "微商教\n",
      "佟丽娅会\n",
      "对耳窃语\n",
      "阚清子面\n",
      "网传纪\n",
      "系维密\n",
      "纪尘凌\n",
      "赞纪\n",
      "霍汶希为\n",
      "霍汶希生\n",
      "是霆锋\n",
      "郑爽配\n",
      "熊梓淇组\n",
      "郑爽力\n",
      "这三对\n",
      "靳东弃\n",
      "娘式\n",
      "王思聪表\n",
      "吴京要\n",
      "吴京终\n",
      "晏任\n",
      "能不传\n",
      "财新及\n",
      "迅称\n",
      "那英怒\n",
      "会死系\n",
      "真裕子\n",
      "蛙妈们\n",
      "爸蛙\n",
      "妈莫慌\n",
      "演若白\n",
      "麗穎迎\n",
      "之劇\n",
      "郑爽首\n",
      "演元淳\n",
      "我颖宝\n",
      "男二让\n",
      "五美来\n",
      "宇微博\n",
      "宇秒\n",
      "吴亦凡告\n",
      "浙卫输\n",
      "批戏\n",
      "吴总说\n",
      "咋治才\n",
      "登爸\n",
      "致敌命\n",
      "鹿晗疑\n",
      "马思纯用\n",
      "果凝多\n",
      "邓超装\n",
      "邓超接\n",
      "大口赞\n",
      "邓超用\n",
      "男主换\n",
      "男主变\n",
      "苏变身\n",
      "赵丽颖组\n",
      "胡歌组\n",
      "而迪丽\n",
      "巴铁歼\n",
      "醋同\n",
      "他逆袭\n",
      "李晨称\n",
      "没算到\n",
      "人人平等\n",
      "女主唐\n",
      "网红高仿\n",
      "演聂风\n",
      "段浪成\n",
      "无一人\n",
      "反萨德\n",
      "天不换\n",
      "昆滇早\n",
      "网传卖\n",
      "大孩带\n",
      "在吾悦\n",
      "款裸车\n",
      "这一撞\n",
      "吸合门\n",
      "比卡宴\n",
      "扯不上\n",
      "穷送\n",
      "餐速\n",
      "养颜小\n",
      "天法润\n",
      "人东迁\n",
      "真退赛\n",
      "成币安\n",
      "注胶系\n",
      "日限牌\n",
      "不相谣\n",
      "信遥\n",
      "撞公\n",
      "缠玉烧\n",
      "骗下去\n",
      "传勿信\n",
      "网传台\n",
      "煤苑\n",
      "淘影\n",
      "佛系养\n",
      "蛙爸\n",
      "审只\n",
      "验癌\n",
      "液真能\n",
      "予中交\n",
      "谣之花\n",
      "油表亮\n",
      "汁治癌\n",
      "矿震系\n",
      "张翰斥\n",
      "网传临\n",
      "网传坤\n",
      "剩晴\n",
      "张艺兴方\n",
      "中所传\n",
      "烦伊思\n",
      "阿祖苗药\n",
      "青荐\n",
      "多会变\n",
      "迷晕路\n",
      "imeos\n",
      "常旅\n",
      "南和史\n",
      "路之机\n",
      "城疑\n",
      "拐系\n",
      "请友商\n",
      "附警情\n",
      "塔溪镇\n",
      "到湾井\n",
      "楠市子\n",
      "e8l446\n",
      "铁北圈\n",
      "市功\n",
      "互斗为\n",
      "网传学车\n",
      "河面上\n",
      "人死系\n",
      "网传洛江\n",
      "电死系\n",
      "一伤系\n",
      "网传雪\n",
      "姚村北\n",
      "一人狂\n",
      "魅族官\n",
      "蔡甸人\n",
      "癌源\n",
      "微博可\n",
      "新饰代\n",
      "小迪当\n",
      "邓超称\n",
      "撩迪丽\n",
      "借卓伟名\n",
      "某鱼府\n",
      "峡垮方\n",
      "唯恐天下\n",
      "区庆远\n",
      "死十伤\n",
      "网红拿刀\n",
      "菌六人\n",
      "有六人\n",
      "微博疯\n",
      "胎真能\n",
      "传多地\n",
      "群老转\n",
      "锋菲恋现\n",
      "遭谢贤\n",
      "要慎服\n",
      "陈晓要\n",
      "陈晓唱\n",
      "陈晓在\n",
      "咳热\n",
      "小三越\n",
      "不信来\n",
      "法新规\n",
      "论肥宅\n",
      "見影\n",
      "昊然俊凯\n",
      "刀郎歌\n",
      "万闹\n",
      "实锤来\n",
      "回欧冠\n",
      "名太硬\n",
      "这三只\n",
      "变净白\n",
      "奖变\n",
      "pd5208\n",
      "杨紫自\n",
      "赵丽颖手\n",
      "搭颖\n",
      "微博暖\n",
      "需一個\n",
      "間盤\n",
      "試用過\n",
      "挺大孕\n",
      "假剧\n",
      "真希逛\n",
      "黄渤用\n",
      "快来加\n",
      "xy520897\n",
      "ttunes\n",
      "石锤碎\n",
      "加钱换\n",
      "quirion\n",
      "雷军微\n",
      "除美白\n",
      "堪比去\n",
      "过万不去\n",
      "已急召\n",
      "索萨当\n",
      "支小白\n",
      "王志称\n",
      "嘟拉舞\n",
      "肉真得\n",
      "吃瓜要\n",
      "谴圈\n",
      "豪车试\n",
      "借眼伤\n",
      "生男神药\n",
      "继鸡\n",
      "广汽等\n",
      "依美多\n",
      "还会变\n",
      "疯传集\n",
      "赞赠\n",
      "先讽\n",
      "刀郎后\n",
      "听刀郎\n",
      "那英放\n",
      "继刀郎\n",
      "頂過\n",
      "十副藥\n",
      "記得存\n",
      "籽治\n",
      "15336438788\n",
      "暴瘦妙\n",
      "bei0220147\n",
      "若美朝\n",
      "水检法\n",
      "因吃鸡\n",
      "必逆市\n",
      "致小七\n",
      "似沾墨\n",
      "条术\n",
      "破康\n",
      "鄂字版\n",
      "卖出去\n",
      "因颜值\n",
      "用意何在\n",
      "枭龙要\n",
      "两央\n",
      "三大央企\n",
      "三央企\n",
      "包敷治\n",
      "地摊货\n",
      "淘游\n",
      "医破\n",
      "杨紫霍\n",
      "切末加\n",
      "还会致\n",
      "比二宝\n",
      "生二宝\n",
      "这棵树\n",
      "粉睡\n",
      "送五杀\n",
      "遇血后\n",
      "要拉人\n",
      "能拉人入\n",
      "tr3b\n",
      "太多毁\n",
      "三厢家\n",
      "网传领\n",
      "镀晶液\n",
      "一龙疑\n",
      "康二番\n",
      "猜太过\n",
      "腹高扫\n",
      "電腦族\n",
      "應常\n",
      "那英真\n",
      "两三个\n",
      "时呼出\n",
      "曝一常\n",
      "韩红竟\n",
      "iveryone\n",
      "起复牌\n",
      "吴京战\n",
      "告战\n",
      "蒋欣当\n",
      "不轻传\n",
      "会得癌\n",
      "玩雪会\n",
      "包过费\n",
      "天補血\n",
      "重瑞开\n",
      "会爱上\n",
      "使人患\n",
      "堂饼\n",
      "三大主播\n",
      "回顾过去\n",
      "京鲁战\n",
      "推人者\n",
      "佩莱疯\n",
      "绝平后\n",
      "似彦墨\n",
      "时加个\n",
      "人不愿信\n",
      "电一电\n",
      "省电保\n",
      "谁言膏方\n",
      "卫衣码\n",
      "马云价\n",
      "猫妈来\n",
      "比谢贤\n",
      "黄渤现\n",
      "种三高\n",
      "不升糖\n",
      "必十连板\n",
      "获秒\n",
      "全仓必\n",
      "超金隅\n",
      "烯股\n",
      "爆十连板\n",
      "和志玲\n",
      "韩媒闹\n",
      "标途观\n",
      "山大店\n",
      "i6573519737785942531\n",
      "1530519470\n",
      "知一孕\n",
      "东隔空\n",
      "榕未\n",
      "诺借\n",
      "快大一\n",
      "网传红\n",
      "迎主升浪\n",
      "用五至\n",
      "现多起\n",
      "晕过去\n",
      "口隆湖\n",
      "栗鹏来\n",
      "亿来厦\n",
      "领高达\n",
      "景甜方\n",
      "早资道\n",
      "去洛社\n",
      "刀郎会\n",
      "刀郎称\n",
      "刀郎能\n",
      "刀郎以\n",
      "朱之文拉着\n",
      "刀郎醉\n",
      "那英该\n",
      "欠刀郎\n",
      "点刀郎歌\n",
      "那英刀\n",
      "那英力\n",
      "过刀郎\n",
      "马云宋\n",
      "那英称\n",
      "微博仅关\n",
      "那英输\n",
      "真能作\n",
      "取光后\n",
      "称武黄\n",
      "楊瀾\n",
      "脫語\n",
      "認真讀\n",
      "粮补到\n",
      "撕景甜\n",
      "太多锅\n",
      "提汉兰达\n",
      "车太轻\n",
      "小途锐\n",
      "嘴治\n",
      "晚天排\n",
      "竟大有\n",
      "这下林\n",
      "瘦越\n",
      "胸大胸\n",
      "有分寸\n",
      "曝唐\n",
      "真得会\n",
      "令权健\n",
      "真想用\n",
      "老白为\n",
      "当吃瓜\n",
      "容不下\n",
      "朱之文想\n",
      "绿大一\n",
      "朱之文称\n",
      "一喷锅\n",
      "得卓伟\n",
      "加梨煮\n",
      "一用立\n",
      "开年量\n",
      "配高达\n",
      "排净宿\n",
      "湖人组\n",
      "皇椒\n",
      "詹皇下家\n",
      "差不爱\n",
      "t90sm\n",
      "成小妈\n",
      "爆三字\n",
      "现李晨\n",
      "收云字\n",
      "拆不散\n",
      "万不给\n",
      "粉美白\n",
      "墓主带\n",
      "面帛\n",
      "这五白\n",
      "臭粑\n",
      "明宝庆\n",
      "成蒙宁\n",
      "网传权\n",
      "推特上\n",
      "郫筒区\n",
      "未修图\n",
      "演吻\n",
      "不能不要\n",
      "拍太有\n",
      "诗孕\n",
      "诗面露\n",
      "诗素颜\n",
      "赵丽颖后\n",
      "黑国足\n",
      "种油加\n",
      "腰细体\n",
      "头不大\n",
      "還記\n",
      "同框录\n",
      "因真爱\n",
      "张杰助\n",
      "博表\n",
      "冯柯气\n",
      "冯珂气\n",
      "美手照\n",
      "賽人\n",
      "内马尔球\n",
      "前内斗\n",
      "广佛要\n",
      "大跳桥\n",
      "金玩出\n",
      "車問\n",
      "車將\n",
      "郑祺吐槽\n",
      "老罗停\n",
      "版雷军\n",
      "出骁龙版\n",
      "称陆奇\n",
      "老铁卖\n",
      "可真难\n",
      "奇香楼\n",
      "遭三停\n",
      "规土委对\n",
      "不实别\n",
      "账户就\n",
      "周新批\n",
      "两暖心\n",
      "换乐福加\n",
      "vit17\n",
      "不输路\n",
      "堪比悍\n",
      "贩偷\n",
      "绕颈要\n",
      "品消\n",
      "泡脚土\n",
      "真源市\n",
      "乐偷\n",
      "网传俩\n",
      "一个三岁\n",
      "曲业东\n",
      "因网购\n",
      "和维金\n",
      "册系\n",
      "版白大\n",
      "国乒退赛\n",
      "获佳女\n",
      "挖致\n",
      "携武内\n",
      "急归力\n",
      "2016beyond\n",
      "力挺破\n",
      "曝中甲\n",
      "爆罗志祥豪\n",
      "我爱得\n",
      "阻止不了\n",
      "传徕\n",
      "吻上了\n",
      "人肉治\n",
      "席炎麟\n",
      "燃脂水\n",
      "百搭大码\n",
      "小作动\n",
      "黑臭宿\n",
      "房菊尼\n",
      "瘦肚腹\n",
      "這四種\n",
      "新用疗\n",
      "快拿瓣\n",
      "路虎塔塔\n",
      "要会用\n",
      "湿减\n",
      "皂苷能\n",
      "补阳強\n",
      "袁篇\n",
      "发版别\n",
      "精发版别\n",
      "马云问\n",
      "赫欲\n",
      "活不了\n",
      "驻美前\n",
      "开毫车\n",
      "中國七大壽星\n",
      "真成国\n",
      "人颜值\n",
      "附币商\n",
      "养颜不显\n",
      "更养颜\n",
      "常吃安\n",
      "养颜排\n",
      "既养颜\n",
      "养颜助\n",
      "常吃助眠\n",
      "越美有\n",
      "人微博\n",
      "恐不敌\n",
      "吴京必\n",
      "抵不上\n",
      "为国点\n",
      "种不出\n",
      "咖开\n",
      "游梅城\n",
      "人不嫁\n",
      "漂拳\n",
      "赵蕊蕊终\n",
      "川皇\n",
      "外媒争\n",
      "维中超\n",
      "阿媒爆\n",
      "某媒称\n",
      "没干过\n",
      "雷军排\n",
      "微博太\n",
      "阿乌巴\n",
      "成吐槽\n",
      "常林回\n",
      "种人领\n",
      "遭泼油\n",
      "李秋平外\n",
      "信反信\n",
      "亿小散\n",
      "大暴击\n",
      "无数个\n",
      "俞凌雄点\n",
      "超坚瑞沃\n",
      "超赣锋\n",
      "微封\n",
      "博聞社\n",
      "一逆天\n",
      "子之父\n",
      "莱口\n",
      "巨魔成\n",
      "出蓝贴\n",
      "极寒来\n",
      "startfragment\n",
      "迎特\n",
      "2018121\n",
      "示软求\n",
      "亮亮的\n",
      "亮哥心\n",
      "王思聪卓伟\n",
      "爱嘻哈\n",
      "探班求\n",
      "马蓉微\n",
      "卓尔写\n",
      "医三人\n",
      "有钱赚\n",
      "人不告\n",
      "糙发\n",
      "艾尚彩\n",
      "陷商票\n",
      "多梦太熬\n",
      "放太多\n",
      "购内少\n",
      "苏索辟\n",
      "权健亚冠\n",
      "恒大真\n",
      "核闹\n",
      "扎哈维转\n",
      "权健换帅\n",
      "权健要\n",
      "抢人换\n",
      "成索萨\n",
      "李霄鹏任\n",
      "一土帅\n",
      "阿隆来\n",
      "有鲁能\n",
      "李总任\n",
      "换帅系\n",
      "上港成\n",
      "恒大要\n",
      "杜煜征\n",
      "津媒欲\n",
      "宝斗石\n",
      "scoal\n",
      "星人怕\n",
      "临冠路\n",
      "宋集坞\n",
      "指不收\n",
      "害娃\n",
      "小三假\n",
      "出道史\n",
      "小三后\n",
      "如一人\n",
      "这小三当\n",
      "小三史\n",
      "官博已\n",
      "热聊引\n",
      "接甜馨\n",
      "生咬蛇\n",
      "宝妈别\n",
      "引骂战\n",
      "甩马蓉\n",
      "卡补审\n",
      "胖疑\n",
      "马云送\n",
      "恒大欲\n",
      "黄磊首\n",
      "铁卫吉尔\n",
      "用纳尔\n",
      "骚男道\n",
      "往鲁能\n",
      "针多针\n",
      "遭洪爷\n",
      "恒大真核\n",
      "人常去\n",
      "为北飞\n",
      "曝向\n",
      "惨触\n",
      "网红竟\n",
      "录抖音\n",
      "没人教\n",
      "辽足求\n",
      "飙泪答\n",
      "殷桃要\n",
      "雪姨豪\n",
      "对不上\n",
      "推遭\n",
      "很难说\n",
      "150825\n",
      "文钱渡\n",
      "胆码助\n",
      "说乐视\n",
      "网传亚冠及\n",
      "爆乐视\n",
      "微博致\n",
      "乐视酷\n",
      "救乐视\n",
      "致百人\n",
      "顾颖琼发\n",
      "曝贾跃亭\n",
      "乐视员\n",
      "张继科生\n",
      "王丽坤恋\n",
      "爱宝强\n",
      "蒋欣自\n",
      "这四宝\n",
      "显老像\n",
      "变年经\n",
      "咖级视\n",
      "袁立互\n",
      "复播成\n",
      "微博均\n",
      "袁立勇\n",
      "天不腐\n",
      "在此之前\n",
      "雄安人\n",
      "时飘窗\n",
      "完飘窗\n",
      "皮薄肉\n",
      "招辨\n",
      "母梨比\n",
      "一个包\n",
      "微博手\n",
      "来产奶\n",
      "授破谣\n",
      "喃再\n",
      "曝付\n",
      "成红人\n",
      "尼美舒\n",
      "美团涉\n",
      "一个团\n",
      "餐员竟\n",
      "房太难\n",
      "汪小菲护妻\n",
      "时宝妈\n",
      "信酸儿\n",
      "养颜是\n",
      "朱之文该\n",
      "朱之文付\n",
      "之文于\n",
      "遭辅警\n",
      "东峡克麻\n",
      "河超警\n",
      "网传东\n",
      "神碰瓷\n",
      "仍不信\n",
      "融冻泥\n",
      "微博微\n",
      "称系毒\n",
      "莫信谣\n",
      "谢弃\n",
      "演之恩\n",
      "杨紫竟\n",
      "接之恩\n",
      "马曼玲\n",
      "潘绫莹\n",
      "正忙着\n",
      "鸡主播\n",
      "德云色家\n",
      "妹晒\n",
      "汤爹\n",
      "脸马蓉\n",
      "瓜可防\n",
      "阿信力\n",
      "仍蒸\n",
      "很逆天\n",
      "专吃生\n",
      "赞井柏然\n",
      "类加分\n",
      "车内放\n",
      "有车族\n",
      "狗尿伤\n",
      "加二物\n",
      "日蓝牌\n",
      "许鄢\n",
      "拿卡会\n",
      "会算酒\n",
      "分将成\n",
      "还会查\n",
      "突持\n",
      "指马云\n",
      "远输天\n",
      "魂恐\n",
      "排肠治\n",
      "付永来\n",
      "来蓉放\n",
      "纪凌尘会\n",
      "减脂养\n",
      "鼾穴\n",
      "毒积滞\n",
      "将会重\n",
      "昆们\n",
      "养发液\n",
      "清晒照\n",
      "无迎机\n",
      "连号值\n",
      "段友们\n",
      "66616\n",
      "66108\n",
      "限汇\n",
      "赵丽颖生\n",
      "抓原\n",
      "吴亦凡录\n",
      "数都数\n",
      "吴京靠\n",
      "喝茵\n",
      "没钱花\n",
      "福之人\n",
      "用刀郎\n",
      "眼销\n",
      "大乔新\n",
      "赵丽颖帅\n",
      "宋喆开\n",
      "卢本伟系\n",
      "老铁教\n",
      "邱茂庭\n",
      "网传兰\n",
      "传洪秀柱\n",
      "涨多高\n",
      "立炖\n",
      "不发此\n",
      "劳腺\n",
      "拒湖\n",
      "马云替\n",
      "拆系\n",
      "帝葛军\n",
      "还治好\n",
      "鲁尼为\n",
      "航获\n",
      "争纳\n",
      "松和纳\n",
      "稳留\n",
      "孔卡埃\n",
      "留权健\n",
      "因登贝莱\n",
      "引热传\n",
      "脸大脸\n",
      "万不敌\n",
      "起交强\n",
      "贬刀郎\n",
      "李晨受\n",
      "曝自降\n",
      "吴亦凡娜\n",
      "这一闹\n",
      "宝妈手\n",
      "马兹不离\n",
      "基黄\n",
      "幂尬\n",
      "比伯愿\n",
      "大乔梅\n",
      "进行谈判\n",
      "种不贵\n",
      "紫塞网\n",
      "姜农教\n",
      "可别染\n",
      "刚下映\n",
      "那英为\n",
      "金鸿鸣家\n",
      "扣致\n",
      "曝周琦前\n",
      "恩闪婚\n",
      "180308\n",
      "胡快\n",
      "拜仁苦\n",
      "吴威子\n",
      "毒赛\n",
      "比金贵\n",
      "版黛玉\n",
      "揭任静\n",
      "传陆奇\n",
      "金特会\n",
      "马蓉道\n",
      "马蓉见\n",
      "博竟\n",
      "马蓉住\n",
      "导快\n",
      "成精会\n",
      "还会用\n",
      "这狗成\n",
      "这狗要\n",
      "蜗人皮\n",
      "脸众\n",
      "外媒劲\n",
      "官宣沙\n",
      "曝贝利\n",
      "颜照力\n",
      "衰美团\n",
      "果小美以\n",
      "王兴称\n",
      "照陷\n",
      "180506\n",
      "指小三\n",
      "带嫩妹\n",
      "房弃\n",
      "以至于\n",
      "迟讯\n",
      "赵明微\n",
      "但币安离\n",
      "已入币安\n",
      "\b\n",
      "从林丹\n",
      "超极丹\n",
      "胸嫩模\n",
      "堆如山\n",
      "破闺蜜\n",
      "删博因\n",
      "180508\n",
      "康贝清\n",
      "不婚性\n",
      "小三有子\n",
      "管彤用\n",
      "亿邀\n",
      "采参人\n",
      "江叔藏\n",
      "亿表\n",
      "薛之谦旧\n",
      "不浊变\n",
      "赫子铭手\n",
      "赫子铭恐\n",
      "假渣\n",
      "相逼要\n",
      "完谢娜\n",
      "拉孟美岐\n",
      "好文荐\n",
      "余承东微\n",
      "wahway\n",
      "大嘴别\n",
      "小凯凯\n",
      "陈思诚怀\n",
      "没和大雄\n",
      "携岳云鹏\n",
      "之日怀\n",
      "佟丽娅长\n",
      "悦儿姐\n",
      "陈思诚方\n",
      "姜东昊方\n",
      "战狼粉\n",
      "招嫖案\n",
      "揭刘涛\n",
      "类备\n",
      "病发学\n",
      "种燃脂\n",
      "出油长\n",
      "太脏别\n",
      "哲利佑\n",
      "称小鸣\n",
      "黄车疑\n",
      "郑爽骚\n",
      "薛之谦吐槽\n",
      "因人设\n",
      "薛之谦怒\n",
      "薛之谦成\n",
      "薛之谦要\n",
      "吃辣生\n",
      "郑爽领\n",
      "食安周\n",
      "请华哥\n",
      "亿男主\n",
      "卢靖姗成\n",
      "王思聪敢\n",
      "«\n",
      "太多怕\n",
      "服拿着\n",
      "七大美白\n",
      "大井拐\n",
      "郭德纲率\n",
      "蒋欣想\n",
      "蒋欣大谈\n",
      "韩红自\n",
      "不换易\n",
      "选和用\n",
      "淡斑治\n",
      "酒叔教\n",
      "印忙\n",
      "骑熊照\n",
      "想拿苏\n",
      "180529\n",
      "网传昌菱\n",
      "限行系\n",
      "迈得斯客\n",
      "迈乐士\n",
      "证不实\n",
      "宁信院\n",
      "翔案\n",
      "年费要\n",
      "有伙人\n",
      "加小黄\n",
      "事微博\n",
      "黄渤去\n",
      "高秋梓方\n",
      "用心险恶\n",
      "别疯传\n",
      "亿和马云\n",
      "极思细恐\n",
      "上迪丽\n",
      "后颜值\n",
      "lushamg333\n",
      "钢镚可换\n",
      "令马云大呼\n",
      "混不下去\n",
      "服尼美\n",
      "陆添\n",
      "微商为\n",
      "记挂着\n",
      "疑揭\n",
      "疑锋锋\n",
      "耗不起\n",
      "别晒娃\n",
      "谢母证\n",
      "锋芝要\n",
      "鸭血能\n",
      "过不下去\n",
      "没电别\n",
      "13662738785\n",
      "造当十\n",
      "袁像币\n",
      "平三钱\n",
      "迎大到\n",
      "董璇力\n",
      "凌入\n",
      "思聪该\n",
      "挖镇\n",
      "兽致\n",
      "三翅鸡\n",
      "交智\n",
      "有射墨\n",
      "谢娜助\n",
      "溺亡车\n",
      "比途观\n",
      "最常点\n",
      "款车品\n",
      "之日系\n",
      "比雪先\n",
      "传麻吉宝\n",
      "同屏线\n",
      "可港\n",
      "媒放\n",
      "指炫富\n",
      "林狗哥\n",
      "王丽坤离\n",
      "支十神\n",
      "趣彩网\n",
      "这几注\n",
      "筱杉\n",
      "胆王\n",
      "扎人系\n",
      "网传旺\n",
      "网传西\n",
      "车内久开\n",
      "网传联\n",
      "前不面\n",
      "网传秀洲\n",
      "破骗\n",
      "稳布\n",
      "需录\n",
      "继小岳岳\n",
      "说好听\n",
      "亲承里\n",
      "印一命\n",
      "继熊乃瑾\n",
      "黄渤早\n",
      "陶肽\n",
      "车连撞且\n",
      "限售系\n",
      "说渝贵\n",
      "搬侠\n",
      "携甘比\n",
      "有多美\n",
      "大蛇袭\n",
      "师德有\n",
      "革碎\n",
      "德赫亚换\n",
      "冯坤当\n",
      "绿萝是\n",
      "放绿萝\n",
      "绿萝能\n",
      "继关晓彤\n",
      "没鹿晗\n",
      "冲上去\n",
      "薛之谦后\n",
      "杨洋到\n",
      "脸晓彤\n",
      "连迪丽\n",
      "韩雪谈\n",
      "方吁\n",
      "进无出\n",
      "浑身上下\n",
      "东鸟旗\n",
      "夏雨为\n",
      "张凯丽大闹\n",
      "粘东\n",
      "马蓉发\n",
      "撕宝强\n",
      "马蓉手\n",
      "将六登\n",
      "下华神\n",
      "欠迪丽\n",
      "表思意\n",
      "因鹿晗\n",
      "魅族醒\n",
      "张召忠谈\n",
      "因不懂\n",
      "那英神\n",
      "王思聪炮\n",
      "糯酸爽\n",
      "选迪丽\n",
      "马华斥\n",
      "马云怕\n",
      "根叶能\n",
      "拿皂角\n",
      "如沾墨\n",
      "匹林加\n",
      "乌墨似\n",
      "可治牙\n",
      "驴家班\n",
      "朝迪牌\n",
      "自产自\n",
      "湿毒排\n",
      "死得光\n",
      "证值\n",
      "爆锋菲\n",
      "卓伟博\n",
      "曝俩\n",
      "常吃难\n",
      "乖萌萌\n",
      "程野三人\n",
      "对马云\n",
      "马云夺\n",
      "超马云\n",
      "王凯疑\n",
      "放下去\n",
      "杨洋受\n",
      "真爱过\n",
      "张爱天\n",
      "杨洋为\n",
      "戏内戏\n",
      "被颖儿\n",
      "女主遭\n",
      "曝择\n",
      "未火时\n",
      "甜筑\n",
      "男主颜值\n",
      "遭卓伟\n",
      "遭爽\n",
      "张翰亏\n",
      "陈学冬旧\n",
      "杨洋该\n",
      "微博替\n",
      "蒋欣吵\n",
      "杜杜拿起\n",
      "洗鼻治\n",
      "滴通\n",
      "卓伟自\n",
      "想学白\n",
      "纹众\n",
      "难分舍\n",
      "连三高\n",
      "常吃包\n",
      "可食用\n",
      "舌草能\n",
      "开了个\n",
      "内里费\n",
      "朱亚文来\n",
      "赵丽颖景\n",
      "树底下\n",
      "越热越\n",
      "➕\n",
      "替田震\n",
      "晏爆\n",
      "卖椒\n",
      "用奇招\n",
      "水里养\n",
      "蒙媒爆\n",
      "人一到\n",
      "李晨同\n",
      "已谈出\n",
      "微博零\n",
      "阿哲新\n",
      "这时候\n",
      "谱生\n",
      "剩和曼\n",
      "十人用\n",
      "多放点\n",
      "既暖宫\n",
      "先胖肚\n",
      "太大像\n",
      "梦中救\n",
      "马佬\n",
      "王思聪恋\n",
      "蒙停\n",
      "亿遭\n",
      "吴京力\n",
      "遭主播\n",
      "强太爱\n",
      "除霉除\n",
      "用久会\n",
      "小甜馨会\n",
      "太逆天\n",
      "王思聪来\n",
      "慎转\n",
      "糯无裂\n",
      "万买块\n",
      "爆七大\n",
      "对孕妈\n",
      "天瘦出\n",
      "网传张\n",
      "轨谢娜\n",
      "卖特贵\n",
      "用三物\n",
      "88816218\n",
      "无迪胖\n",
      "v13525430110\n",
      "迈不开\n",
      "谢娜家\n",
      "坐实疑\n",
      "无官星\n",
      "這样\n",
      "变美小\n",
      "贱康\n",
      "台媒惊\n",
      "䠷\n",
      "❓\n",
      "超好次\n",
      "酒识\n",
      "赌石界\n",
      "淡斑变\n",
      "印小妙\n",
      "岿如\n",
      "近疑\n",
      "牛唐\n",
      "李晨肯\n",
      "未见玲花\n",
      "刀郎大\n",
      "太美太\n",
      "时唱出\n",
      "kp5gt\n",
      "比玲花\n",
      "偷系\n",
      "马雪云传\n",
      "卡魔刹\n",
      "美如仙\n",
      "害鹿晗\n",
      "吴昕解\n",
      "成刀郎\n",
      "帮刀郎\n",
      "当刀郎\n",
      "年脂\n",
      "清肠少\n",
      "养脚暖身\n",
      "港媒传\n",
      "附三大\n",
      "照美哭\n",
      "照美到\n",
      "这一比\n",
      "微隆似\n",
      "曝疑\n",
      "人爱死\n",
      "有志气\n",
      "抓秋菊\n",
      "禁日令\n",
      "轩澜大波\n",
      "180216\n",
      "唐尼是\n",
      "马云怒\n",
      "不吐不晕\n",
      "年欲裁\n",
      "马云言\n",
      "拍疑\n",
      "唯獨\n",
      "人連\n",
      "学张翰\n",
      "吴京盛\n",
      "峰菲似\n",
      "穿卫衣\n",
      "放着不用\n",
      "吹出去\n",
      "师达能\n",
      "曝确\n",
      "舒曾\n",
      "舒拦\n",
      "佟丽娅心\n",
      "夜华脸\n",
      "任嘉伦方\n",
      "摔娃\n",
      "刘涛方\n",
      "发下衣\n",
      "白滑吸\n",
      "葛斯林妻\n",
      "赵丽颖签\n",
      "太差入\n",
      "真比安迪\n",
      "王珂后\n",
      "个字令\n",
      "最爱座\n",
      "递卡时\n",
      "引众愤\n",
      "继靳东\n",
      "大谈床\n",
      "天闪婚\n",
      "造刘涛\n",
      "阚清子系\n",
      "不离手\n",
      "因葛天\n",
      "曝杨颖\n",
      "陈赫有\n",
      "袁立用\n",
      "圈三大\n",
      "黄轩方\n",
      "诗怒\n",
      "舒闪婚\n",
      "曝赵薇\n",
      "删博装\n",
      "叫江母\n",
      "别总坑\n",
      "咸男甜\n",
      "吃酸生\n",
      "柠橘\n",
      "圆准\n",
      "助马蓉\n",
      "有小柳岩\n",
      "裸死于\n",
      "吃醉鹅嚼\n",
      "博似\n",
      "亿債\n",
      "搭进去\n",
      "马云心\n",
      "超万兴\n",
      "男宝妈\n",
      "别老是\n",
      "男三大\n",
      "赵丽颖患\n",
      "指王冕\n",
      "实锤开\n",
      "清晒出\n",
      "西成客\n",
      "下架限\n",
      "好扎心\n",
      "哆弗\n",
      "烦翻\n",
      "款哈弗\n",
      "比埃尔法\n",
      "比五菱\n",
      "台法系\n",
      "开不坏\n",
      "买宝骏\n",
      "款劳\n",
      "甩名\n",
      "年大苗\n",
      "万不卖\n",
      "路虎造\n",
      "这逼格\n",
      "比汉兰达\n",
      "还耐造\n",
      "这货配\n",
      "万缤智急\n",
      "升白针\n",
      "净脾不虚\n",
      "利胎\n",
      "点肝要\n",
      "一宿消\n",
      "显瘦盖\n",
      "还得学\n",
      "伤薪\n",
      "忧酬\n",
      "全吃进\n",
      "一人哥\n",
      "趣贴\n",
      "超罗牛山\n",
      "国乒两大\n",
      "托谈\n",
      "陈伟霆疑\n",
      "人类史上\n",
      "亿烂\n",
      "摊待夫\n",
      "会生个\n",
      "马蓉分\n",
      "曾豪车\n",
      "红董\n",
      "以孕肚\n",
      "很麻痛\n",
      "周琦前\n",
      "詹皇获\n",
      "wannacry20\n",
      "网传受\n",
      "快死了\n",
      "还放话\n",
      "陛桥成\n",
      "园方诉\n",
      "斯内德系\n",
      "账返\n",
      "中赫有\n",
      "醋配\n",
      "鱼大获\n",
      "没人用\n",
      "老钓人\n",
      "总不上\n",
      "盆钵体\n",
      "老钓者\n",
      "亿拿地\n",
      "當十有\n",
      "取会降\n",
      "降餐\n",
      "糖人要\n",
      "年半后\n",
      "疑显\n",
      "过仅拔\n",
      "杨颖素\n",
      "竟比本\n",
      "晏力\n",
      "晏怕\n",
      "继杨颖\n",
      "杨颖晓明\n",
      "杨颖去\n",
      "青小秀\n",
      "郑爽颜\n",
      "立讽\n",
      "小三女\n",
      "超兆日\n",
      "十肝九病\n",
      "明夏欲\n",
      "晏面\n",
      "没得治\n",
      "欧豪盛\n",
      "亲怼\n",
      "携王凯\n",
      "曝连聚\n",
      "因剧生\n",
      "三不喝\n",
      "处涂涂\n",
      "变美白\n",
      "二新规\n",
      "宝新轮\n",
      "附多张\n",
      "威马纯\n",
      "荣威后\n",
      "王欣要\n",
      "微博是\n",
      "胸污\n",
      "女命论\n",
      "侵致\n",
      "谭咏麟力\n",
      "清告\n",
      "卓伟发\n",
      "卓伟以\n",
      "清拉帮\n",
      "没发照\n",
      "信杰哥\n",
      "信娜姐\n",
      "曝卓伟\n",
      "曝隐\n",
      "爆隐\n",
      "自认是\n",
      "邓超闹\n",
      "卓伟死\n",
      "声卓伟\n",
      "舒就会\n",
      "岳云鹏疑\n",
      "别胜新\n",
      "曝力\n",
      "卓伟竟\n",
      "中艳海\n",
      "南大跑\n",
      "日限行系\n",
      "网传潮\n",
      "田日亮\n",
      "网传大乔\n",
      "网传榕山\n",
      "传北现\n",
      "网传小卡\n",
      "网传带\n",
      "樊赵车\n",
      "成血人系\n",
      "斯威刚\n",
      "杉德诺\n",
      "限号系\n",
      "寒官博\n",
      "传偷\n",
      "瞻榆偷\n",
      "岳林继\n",
      "癌花\n",
      "致一死\n",
      "断塌系\n",
      "甜馨会判\n",
      "波场币\n",
      "一妙物\n",
      "权健帕托\n",
      "尤文去\n",
      "劲肩\n",
      "小鑫教\n",
      "房新规\n",
      "國家國\n",
      "旗國徽\n",
      "軍同樣\n",
      "中華龍\n",
      "最不愿\n",
      "梗卓伟\n",
      "撒棒\n",
      "越多怀\n",
      "最牛鸡\n",
      "赵又廷家\n",
      "燃脂消\n",
      "孙安佐\n",
      "何炅赠\n",
      "內湿外\n",
      "王凯会\n",
      "懂华哥\n",
      "人骨脆\n",
      "中颜值\n",
      "买安卓\n",
      "吴雨乐\n",
      "含龙根\n",
      "幂别\n",
      "款绿植\n",
      "๐\n",
      "̆\n",
      "̭\n",
      "不和疑\n",
      "湖人于\n",
      "美肌道\n",
      "混太惨\n",
      "金大谈\n",
      "在短期内\n",
      "迅颜值\n",
      "六七个\n",
      "爆夜会\n",
      "味甜色\n",
      "甜靠\n",
      "款野\n",
      "大毛河\n",
      "野钓达\n",
      "狂钓\n",
      "造双旗\n",
      "控号\n",
      "寿字币库\n",
      "号秀换\n",
      "造七钱\n",
      "微博高仿\n",
      "抢卓伟\n",
      "虽不劲\n",
      "仁里场\n",
      "胃火太大\n",
      "张瀚力\n",
      "挺娜\n",
      "骁密会\n",
      "李沁爱得\n",
      "恋上娜\n",
      "荣置\n",
      "吴昕疑\n",
      "更美配\n",
      "上塘主\n",
      "招治好\n",
      "黄锦燊腻\n",
      "汪峰发\n",
      "希版\n",
      "望演\n",
      "毒王杰\n",
      "谈王杰\n",
      "害王杰\n",
      "卓伟别\n",
      "王杰毒\n",
      "卓伟认\n",
      "王杰别\n",
      "帮王杰\n",
      "为杰哥\n",
      "服卓伟\n",
      "破铁钱\n",
      "给玲花\n",
      "疼竟\n",
      "陈坤苦\n",
      "抖音款\n",
      "想不白\n",
      "r1l77zv\n",
      "全不找\n",
      "將至\n",
      "小三是\n",
      "機族\n",
      "谢贤用\n",
      "何震亚\n",
      "台媒成\n",
      "绿媒耍\n",
      "心战墙\n",
      "😄\n",
      "网传史\n",
      "食材常\n",
      "茶能解\n",
      "过水焯\n",
      "同溜娃\n",
      "重重的\n",
      "立夏后\n",
      "种负\n",
      "一多二少\n",
      "五连县\n",
      "大驻\n",
      "群热传\n",
      "辟得心\n",
      "因吃扎旗\n",
      "彭兰妹\n",
      "个杯面\n",
      "红大胃\n",
      "喝进去\n",
      "网传用\n",
      "曝王丽坤林\n",
      "经粪口\n",
      "减盐防\n",
      "三高易\n",
      "那么回事\n",
      "疾控家\n",
      "张母案\n",
      "柚红\n",
      "人吃瓜\n",
      "仨次\n",
      "闻味色\n",
      "听小益\n",
      "酸真会\n",
      "皮克破\n",
      "传宝能\n",
      "强拉上\n",
      "字吐槽\n",
      "零差评\n",
      "晒素颜\n",
      "打了个\n",
      "弃孙俪\n",
      "范丞丞首\n",
      "拍凰\n",
      "改捧岳云鹏\n",
      "开塞漉\n",
      "可真有\n",
      "杜杜给\n",
      "杨柘怒\n",
      "素颜甜\n",
      "完月子\n",
      "挖富\n",
      "徐坤开\n",
      "宣不认\n",
      "网传铁\n",
      "赵丽颖来\n",
      "亿秒领\n",
      "这事能\n",
      "假谢娜\n",
      "破娜昕\n",
      "邓超能\n",
      "吴京首\n",
      "吴京淡\n",
      "微博后\n",
      "某夜店\n",
      "超遭\n",
      "陈翔版\n",
      "论颜值\n",
      "鑫娱\n",
      "何炅娜姐\n",
      "两不移\n",
      "赞张杰\n",
      "吴昕微\n",
      "男主脸\n",
      "我娜姐\n",
      "快本会\n",
      "美不输\n",
      "回得去\n",
      "更爱招\n",
      "黄不补\n",
      "指呆萌\n",
      "出柜恋\n",
      "放马思纯\n",
      "两小口\n",
      "马思纯周\n",
      "藏累\n",
      "对巴神\n",
      "林允狂\n",
      "笼打\n",
      "曝方\n",
      "其手柱\n",
      "那英近\n",
      "周琦未\n",
      "太多显\n",
      "邢昭林方\n",
      "添品\n",
      "新劲刚\n",
      "牵迪丽\n",
      "屠川后\n",
      "艾神家\n",
      "样煮\n",
      "诉微\n",
      "请马云\n",
      "重瑞有\n",
      "重瑞比\n",
      "拥右护\n",
      "重瑞说\n",
      "日微博\n",
      "阿娇恋\n",
      "东茛\n",
      "财纹\n",
      "坐洋币\n",
      "奶会变\n",
      "风超美\n",
      "四美同\n",
      "晋嫣恋\n",
      "类微博\n",
      "爆罗晋\n",
      "180114\n",
      "刘空清\n",
      "后仅用\n",
      "以特币\n",
      "哈弗高\n",
      "涉独\n",
      "博破\n",
      "成罗晋\n",
      "网传罗\n",
      "翔疑\n",
      "某天团\n",
      "赵丽颖张\n",
      "粉捞\n",
      "为人所知\n",
      "可颜值\n",
      "赵丽颖开\n",
      "请范伟\n",
      "吴亦凡用\n",
      "薛之谦买\n",
      "臀九女\n",
      "扎为助\n",
      "茉上\n",
      "杨洋竟\n",
      "亲小爽\n",
      "井柏然史\n",
      "郑爽表\n",
      "杨洋狂\n",
      "致钙\n",
      "夏热特\n",
      "网红科迪\n",
      "显瘦变\n",
      "过多时\n",
      "追弗神\n",
      "磨膝\n",
      "素会致\n",
      "咳不治\n",
      "种好物\n",
      "生三女\n",
      "杨紫为\n",
      "迷妹们\n",
      "宝沃要\n",
      "16607346286\n",
      "真矿\n",
      "拘一人\n",
      "需厚植\n",
      "币算力\n",
      "赵丽颖大\n",
      "力捧连\n",
      "如孙俪\n",
      "脸获\n",
      "赵丽颖大脸\n",
      "脸大眼\n",
      "赵丽颖旧\n",
      "圆圆的\n",
      "赵丽颖火\n",
      "赵丽颖素\n",
      "王嘉尔要\n",
      "赵丽颖逆袭\n",
      "内不受\n",
      "换特雷\n",
      "文旅部\n",
      "日举国\n",
      "说华仔\n",
      "施一公因\n",
      "曝施\n",
      "一公因\n",
      "这两台\n",
      "这台家\n",
      "纸糊车\n",
      "开不烂\n",
      "89413\n",
      "传祺给\n",
      "变豪车\n",
      "团内互\n",
      "替千玺\n",
      "仨孩\n",
      "撩汉大\n",
      "新帅雅\n",
      "权健恒大才\n",
      "购纳\n",
      "因格兰\n",
      "恒大过\n",
      "真服了\n",
      "继黄子\n",
      "风百碟\n",
      "谢娜整\n",
      "类不含\n",
      "皮淡定\n",
      "唐璧华\n",
      "前真龙\n",
      "真龙终\n",
      "男圆肚\n",
      "還淡斑\n",
      "乌如润墨\n",
      "黑得加\n",
      "亿三大\n",
      "签预\n",
      "微博靠\n",
      "黑钻要\n",
      "刚荣升\n",
      "打大呼\n",
      "微信常\n",
      "雪姨成\n",
      "因谢贤\n",
      "两人下\n",
      "曝欲\n",
      "灯亮了\n",
      "闺蜜应\n",
      "卢靖姗要\n",
      "太多竟\n",
      "超柘中\n",
      "亿筑底\n",
      "真多得\n",
      "男主带\n",
      "提兰城\n",
      "詹皇明\n",
      "中大有\n",
      "主贵且\n",
      "涨不涨\n",
      "力三高\n",
      "谎记\n",
      "发苦应\n",
      "净肠肤\n",
      "加太满油\n",
      "斑妙\n",
      "当十极\n",
      "福義\n",
      "粗腿麻\n",
      "有广東\n",
      "17817938090\n",
      "价各是\n",
      "有多烦\n",
      "护心防\n",
      "小满要\n",
      "祛湿要\n",
      "勇减\n",
      "胃涤肠\n",
      "菜堪\n",
      "鹿晗们\n",
      "有藏友\n",
      "俗语说\n",
      "赵薇会\n",
      "亿赵薇\n",
      "费高达\n",
      "陈蓉分\n",
      "费引人\n",
      "费引\n",
      "小卡妹\n",
      "只为争\n",
      "清暴\n",
      "单遭\n",
      "天不干\n",
      "咬死条\n",
      "进青系\n",
      "太大遭\n",
      "中俄有\n",
      "小诺要\n",
      "塔电死\n",
      "先别染\n",
      "助糖友\n",
      "听坑\n",
      "加一菜\n",
      "陈晓帽\n",
      "配美照\n",
      "疼存\n",
      "高冰飘花\n",
      "抽六包\n",
      "瞎染\n",
      "造限\n",
      "前大骂\n",
      "韩颖华神\n",
      "锋菲恋终\n",
      "有小三且\n",
      "戏红到\n",
      "冯叔换\n",
      "孕妈会\n",
      "刚连上\n",
      "药钱省\n",
      "天清肠治\n",
      "听川普\n",
      "遭限犬办\n",
      "这得省\n",
      "马云年\n",
      "另均\n",
      "腥版\n",
      "首谈要\n",
      "个体户\n",
      "算得了\n",
      "赵丽颖学江\n",
      "玩下衣\n",
      "美白消\n",
      "有养颜\n",
      "肤抗\n",
      "养颜有\n",
      "款养颜\n",
      "养颜越\n",
      "太高降\n",
      "有三高\n",
      "吃二口\n",
      "素颜未\n",
      "那英遇\n",
      "字淡定\n",
      "说太累\n",
      "没微博\n",
      "抓疑\n",
      "吓孕妈\n",
      "秦奋狂\n",
      "秦奋称\n",
      "力挺思聪\n",
      "真能防\n",
      "这下松\n",
      "只爱天\n",
      "显大似\n",
      "从洪到\n",
      "男主遇\n",
      "胡歌苦\n",
      "帕卡致\n",
      "养肝同\n",
      "仔想演\n",
      "首起涉\n",
      "交规新\n",
      "事半功\n",
      "171114\n",
      "胖兰\n",
      "张翰素\n",
      "因帮人\n",
      "问鹿晗\n",
      "迅近\n",
      "白宇辰\n",
      "一兆兆吨\n",
      "被代驾\n",
      "骗系\n",
      "现碰瓷\n",
      "网传假\n",
      "能润发\n",
      "用神香\n",
      "深爱着\n",
      "女宝来\n",
      "盐鸿卖\n",
      "菅韧\n",
      "万比速腾\n",
      "加四驱\n",
      "万比轩\n",
      "比朗逸\n",
      "产检获\n",
      "过夏窗\n",
      "购马斯切\n",
      "帕托受\n",
      "没夺牌\n",
      "这下值\n",
      "立春后\n",
      "款養\n",
      "飲大\n",
      "不老米\n",
      "炫方\n",
      "车晓只\n",
      "需抹点\n",
      "掺来\n",
      "最克夫\n",
      "心澄子\n",
      "因维嘉\n",
      "似阔\n",
      "打隐翅虫会\n",
      "十多个\n",
      "中飘着\n",
      "曝罗志祥豪\n",
      "亿置\n",
      "罗志祥购\n",
      "那英竟\n",
      "练下去\n",
      "越好车\n",
      "咖对戏\n",
      "不生个\n",
      "平平的\n",
      "甜馨秀\n",
      "pgtwo\n",
      "备孕禁\n",
      "丢狗后\n",
      "影艺圈\n",
      "以手护\n",
      "肚似\n",
      "没逃过\n",
      "马云道\n",
      "地玩过\n",
      "尴聊\n",
      "隔一人\n",
      "结离须\n",
      "疑其为\n",
      "招撇\n",
      "幂首\n",
      "朱茵用\n",
      "宇春父\n",
      "撕刀郎\n",
      "清肠法\n",
      "肉大招\n",
      "带四驱\n",
      "不输汉兰达\n",
      "颜值帅\n",
      "伪豪\n",
      "就塞到\n",
      "看朗逸\n",
      "比锐界\n",
      "还拉风\n",
      "车颜值\n",
      "讽丽颖\n",
      "欺志玲\n",
      "带美瞳\n",
      "缓嫁\n",
      "拖下去\n",
      "超甜志玲\n",
      "疑锋菲\n",
      "迅疑\n",
      "迅受\n",
      "无子成\n",
      "这事定\n",
      "无子山\n",
      "剩豪车\n",
      "高圣远常\n",
      "禁聊\n",
      "迅方\n",
      "迅吗\n",
      "亿肥\n",
      "马廷江\n",
      "斐讯要\n",
      "马云梁\n",
      "富纹\n",
      "206041718\n",
      "有福人\n",
      "这六字\n",
      "仔撑\n",
      "疯传微\n",
      "一无牌\n",
      "有小编\n",
      "欧豪为\n",
      "利徒\n",
      "脸林允\n",
      "博变身\n",
      "变裸替\n",
      "可防脫\n",
      "闻味识\n",
      "风苓\n",
      "求娜\n",
      "房凝似\n",
      "这一吻\n",
      "别想进\n",
      "网爆纪\n",
      "下家来\n",
      "李晨分\n",
      "熊乃瑾购\n",
      "祛湿消\n",
      "立夏有\n",
      "太大减\n",
      "小一姐\n",
      "因爱起\n",
      "我颜值\n",
      "杨颖自\n",
      "进雄安\n",
      "马云辟\n",
      "首嫁\n",
      "两人见\n",
      "圣扮\n",
      "性寒易\n",
      "比如说\n",
      "吹多会\n",
      "网传颍东\n",
      "侵遭\n",
      "张艳家\n",
      "那孕妈\n",
      "需营\n",
      "会滑胎\n",
      "种孕妈\n",
      "最养胎\n",
      "上六下\n",
      "邓超怒\n",
      "闫学晶谈\n",
      "强林丹\n",
      "盼夕\n",
      "信痛\n",
      "克拜峰\n",
      "时倒点\n",
      "13596783427\n",
      "成实外\n",
      "梁伟瑜\n",
      "梅内塞\n",
      "爆王鸥\n",
      "传染给\n",
      "何炅于\n",
      "芦丁有\n",
      "火菜\n",
      "三高降\n",
      "可白过\n",
      "一波儿\n",
      "一绿萝花\n",
      "完一查\n",
      "茶威\n",
      "chx19820524\n",
      "萬億度\n",
      "立馬產黃金\n",
      "吞恆星\n",
      "令莫雷\n",
      "前六已\n",
      "怀德桥吾悦\n",
      "受马蓉\n",
      "撕马蓉\n",
      "天吃出\n",
      "太多要\n",
      "匹林同\n",
      "配阿司\n",
      "水里系\n",
      "咱不背\n",
      "淹会\n",
      "接马蓉\n",
      "证清\n",
      "宋喆后\n",
      "景甜用\n",
      "微博艾特\n",
      "宋喆怒\n",
      "强终\n",
      "敌马蓉\n",
      "等言伦\n",
      "谈马蓉\n",
      "程野宋\n",
      "曝星爷\n",
      "赶回去\n",
      "葛素珍\n",
      "桌伟要\n",
      "爆邓\n",
      "轨江\n",
      "飞上了\n",
      "因孕妈\n",
      "宝妈图\n",
      "点不输\n",
      "双待版\n",
      "黄橙褐\n",
      "肉知\n",
      "肉肉长\n",
      "研特膳\n",
      "美白治\n",
      "腹婆变\n",
      "招就够\n",
      "中天微\n",
      "商乐鑫\n",
      "博主刚\n",
      "水里配\n",
      "乔欣撞\n",
      "爬上爬下\n",
      "胖哥教\n",
      "拆太早\n",
      "需一土\n",
      "愁教\n",
      "总粘锅\n",
      "爱簪\n",
      "王思聪独\n",
      "王一博刚\n",
      "爆与富\n",
      "网传富\n",
      "带货王\n",
      "发送给\n",
      "劝颖宝\n",
      "董洁素\n",
      "颜逛\n",
      "疑谢娜\n",
      "辣眼照\n",
      "关晓彤会\n",
      "马云哥\n",
      "陈学冬靠\n",
      "洪币\n",
      "kfc200\n",
      "杀抖音\n",
      "抖音成\n",
      "网红前\n",
      "不玩抖音\n",
      "咬会学\n",
      "竟不腐\n",
      "称不实\n",
      "岁志玲\n",
      "用不上\n",
      "狼真来\n",
      "会和志玲\n",
      "韩媒错\n",
      "补刀键\n",
      "论雷军\n",
      "赵丽颖过\n",
      "赵丽颖选\n",
      "别染来\n",
      "吴绮莉近\n",
      "疑谈\n",
      "何炅大呼\n",
      "仍不敌\n",
      "非布司\n",
      "要常来\n",
      "裸亡\n",
      "人懵圈\n",
      "新交规类\n",
      "男主拟\n",
      "成女主\n",
      "演不看\n",
      "微博消\n",
      "可直联\n",
      "疯传六景\n",
      "遭本尊\n",
      "已多地\n",
      "唐山限行\n",
      "网传黎溪\n",
      "传苟家井\n",
      "岳云鹏方\n",
      "岳幕\n",
      "看正解\n",
      "系扰序\n",
      "小憨哥\n",
      "为华哥\n",
      "怀备\n",
      "后大谈生\n",
      "王诗龄录\n",
      "张继科领\n",
      "组讯\n",
      "草水加\n",
      "签格列\n",
      "内马尔该\n",
      "因梅西\n",
      "内马尔要\n",
      "必疯传\n",
      "烧不熟\n",
      "2o18\n",
      "前不焯\n",
      "大隐婚\n",
      "台补刀\n",
      "王思聪千等\n",
      "吃泰迪\n",
      "期应禁\n",
      "不愿取\n",
      "遭其怒\n",
      "壕发\n",
      "官微博\n",
      "亿吸\n",
      "筹锁\n",
      "李湘自\n",
      "正安一\n",
      "胃菌\n",
      "万寻子\n",
      "进新家\n",
      "土妙\n",
      "帮新家\n",
      "幂家似\n",
      "杰伦志颖家\n",
      "已逼平\n",
      "拥四坐\n",
      "詹皇狂\n",
      "要限贷\n",
      "郭德纲成\n",
      "微博系\n",
      "曝备\n",
      "伪卡多\n",
      "新交规来\n",
      "袭州城\n",
      "微博表\n",
      "郑爽边\n",
      "微博突\n",
      "冲蛋会\n",
      "彩巢\n",
      "南仙城\n",
      "分扣证\n",
      "嘲张翰\n",
      "陈晓欲退\n",
      "张一山引\n",
      "疑患癌\n",
      "实锤张\n",
      "添锤\n",
      "杨紫语\n",
      "一山患\n",
      "赵丽颖娜\n",
      "王源组\n",
      "最多判\n",
      "微博爆\n",
      "断均\n",
      "节晒\n",
      "谢贤放话\n",
      "挺孕\n",
      "肚晨\n",
      "掩孕肚\n",
      "张杰会\n",
      "破谢娜\n",
      "屡广\n",
      "快本斥\n",
      "邓紫棋来\n",
      "局拍\n",
      "张吉记\n",
      "娱闻星\n",
      "网叹\n",
      "改不改\n",
      "说霆锋\n",
      "好暖心\n",
      "这不怪\n",
      "小迪丽\n",
      "顶回去\n",
      "锋柏\n",
      "谢母力\n",
      "携女游\n",
      "高颜质\n",
      "晒泳\n",
      "遭人破\n",
      "过霆锋\n",
      "与霆锋\n",
      "潼谈\n",
      "谢露峰\n",
      "终和好\n",
      "要和霆锋\n",
      "富察容音\n",
      "秦岚新\n",
      "转勿传\n",
      "张继科发\n",
      "曝景甜\n",
      "这德系车\n",
      "黑景甜\n",
      "疯传景\n",
      "晒本\n",
      "泼向国\n",
      "小三够\n",
      "郝小爷\n",
      "大玩下\n",
      "快本维嘉\n",
      "郑爽粉\n",
      "塘主新\n",
      "素颜显\n",
      "蒂易\n",
      "催恋\n",
      "吴昕亲\n",
      "吴昕点\n",
      "张翰爱娜\n",
      "卢本伟凉\n",
      "网传红米\n",
      "凯仔\n",
      "晏秀\n",
      "殷金宝\n",
      "薛之谦陷\n",
      "冯珂成\n",
      "讽马云\n",
      "劈腿江\n",
      "姚笛要\n",
      "欧巴要\n",
      "韩媒大\n",
      "没钱付\n",
      "带人夜\n",
      "赵丽颖发\n",
      "微博喊\n",
      "晏谈\n",
      "nyscps\n",
      "愿留阵\n",
      "巴舒亚\n",
      "传含\n",
      "171014\n",
      "晏互粉\n",
      "人保过\n",
      "皮真能\n",
      "鲜吃遍\n",
      "服宝强\n",
      "徐峥能\n",
      "徐峥力\n",
      "黄渤携\n",
      "黄渤飙\n",
      "会升糖\n",
      "需微信\n",
      "小平小妙\n",
      "qh0971tc\n",
      "养犬要\n",
      "201807\n",
      "13567698281\n",
      "养颜补\n",
      "爆微博\n",
      "备孕妙\n",
      "二二厂\n",
      "药吃成\n",
      "很久前\n",
      "转出去\n",
      "推特近\n",
      "能买靓\n",
      "彭浦情\n",
      "范丞丞怒\n",
      "杨洋下\n",
      "批食\n",
      "有学霸\n",
      "网传华庭\n",
      "赵丽颖带\n",
      "称吊\n",
      "真逆天\n",
      "立秋过\n",
      "陈伟霆握\n",
      "维嘉能\n",
      "传快播\n",
      "kuaibo\n",
      "苟芸慧要\n",
      "薛之谦招\n",
      "胜鹿\n",
      "freepure\n",
      "菲朴\n",
      "可美白\n",
      "辞剧\n",
      "愿小卡\n",
      "年扎心\n",
      "服晚\n",
      "斤大胖\n",
      "比药强\n",
      "干过些\n",
      "桃喷\n",
      "佟丽娅雷\n",
      "食人場\n",
      "專吃\n",
      "爆中超\n",
      "西媒帮\n",
      "昆凌嫂\n",
      "神豪扎\n",
      "心佑粉\n",
      "曝阿哲\n",
      "针扎样\n",
      "微博下\n",
      "出限行\n",
      "王珂上\n",
      "美白超\n",
      "闺蜜要\n",
      "获华鼎奖\n",
      "小璐要\n",
      "排残奶\n",
      "别信别\n",
      "金新色\n",
      "真凉心\n",
      "将诺菲\n",
      "博尔告\n",
      "菲玛称\n",
      "别胡说\n",
      "孕传\n",
      "签黄斌\n",
      "一个盆\n",
      "发却文\n",
      "北多车\n",
      "陈晓过\n",
      "李晨大\n",
      "时真美\n",
      "吴绮莉藏毒\n",
      "吃会生\n",
      "生吃大\n",
      "独媒\n",
      "邀高伟\n",
      "区檀营\n",
      "悦欣汇\n",
      "张一山称\n",
      "大劲顺\n",
      "确喜\n",
      "这泰迪\n",
      "ryhpdlr\n",
      "遭狱\n",
      "需小编\n",
      "张嘎谢\n",
      "着颖宝\n",
      "赵丽颖罗晋\n",
      "需族乐\n",
      "四十个\n",
      "腰暴\n",
      "三十下\n",
      "甘薇疑\n",
      "指顾颖琼\n",
      "包好别\n",
      "黄渤一语\n",
      "会逆袭\n",
      "充算\n",
      "谷歌用\n",
      "邊充\n",
      "電邊\n",
      "上大杀\n",
      "赵丽颖楚\n",
      "情定林\n",
      "演淳儿\n",
      "遭杨颖\n",
      "赵丽颖出\n",
      "这则查\n",
      "一般来说\n",
      "看竖纹\n",
      "丢不起\n",
      "装大湿\n",
      "砖家病\n",
      "条男宝\n",
      "美白堪\n",
      "参层\n",
      "两大未解\n",
      "陈坤终\n",
      "陈坤性\n",
      "打多办\n",
      "之人终\n",
      "丐版\n",
      "辉腾味\n",
      "四驱非\n",
      "座四缸\n",
      "这车帅\n",
      "比宏光\n",
      "毒驾系\n",
      "ak4550\n",
      "网传京\n",
      "爆纪\n",
      "宝妈备\n",
      "吸一晚\n",
      "家七人\n",
      "涉雄安\n",
      "关翟\n",
      "孙怡产女\n",
      "陈晓是\n",
      "陈晓首\n",
      "希而非\n",
      "top10live\n",
      "却没能\n",
      "替刀郎\n",
      "喷刀郎\n",
      "收一女\n",
      "听十哭\n",
      "那英唱出\n",
      "听九人\n",
      "韩红想\n",
      "女刀粉\n",
      "听十人会\n",
      "英刀郎\n",
      "刀郎编\n",
      "师而战\n",
      "说刀郎\n",
      "刀郎边\n",
      "我爱刀\n",
      "不多花\n",
      "降不涨\n",
      "马云出\n",
      "收药事\n",
      "附避费\n",
      "nnjianz\n",
      "翔补\n",
      "超逼格\n",
      "马云用\n",
      "步痘\n",
      "哈中软\n",
      "癌史\n",
      "赵莉颖\n",
      "选陈妍\n",
      "希不选\n",
      "晃仁\n",
      "他得癌\n",
      "脸马伊\n",
      "签试恋\n",
      "对马伊\n",
      "达海诉\n",
      "百善孝为\n",
      "系独大\n",
      "宝陷\n",
      "曝微整\n",
      "狂浇甜馨\n",
      "券改\n",
      "获窦骁\n",
      "配爱信\n",
      "演雪姨\n",
      "今晒出\n",
      "卓伟为\n",
      "血所造\n",
      "康辉神\n",
      "老梗给\n",
      "不老菜\n",
      "称资管\n",
      "趣笑果\n",
      "网传谷\n",
      "衰养颜\n",
      "孔伯华之孙\n",
      "吃太寒\n",
      "更水嫩\n",
      "毒显\n",
      "必先养\n",
      "养颜好\n",
      "养颜且\n",
      "养颜清宿\n",
      "养颜要\n",
      "想用导\n",
      "可饱和\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对美日\n",
      "显孕态\n",
      "人留灯\n",
      "分小叉\n",
      "分大叉\n",
      "蜜鸡\n",
      "昆凌速怀\n",
      "杰微博\n",
      "真之棒\n",
      "网传夕佳\n",
      "钱多事少\n",
      "识瓜\n",
      "一拍知\n",
      "赵薇辟\n",
      "救璐\n",
      "邓超排\n",
      "范伟有\n",
      "深扒林\n",
      "讀透\n",
      "社會少\n",
      "王建林成\n",
      "陈翔家\n",
      "躲远点\n",
      "信勿转\n",
      "颜美白\n",
      "咬核\n",
      "堵教\n",
      "对景甜\n",
      "曝李玉刚\n",
      "隐婚生\n",
      "带景甜\n",
      "遭小三\n",
      "竟无一人\n",
      "暴瘦照\n",
      "爆陈羽\n",
      "七十九期\n",
      "三大点力\n",
      "杜淳家\n",
      "对海沃德\n",
      "曹云金回\n",
      "收六到\n",
      "不实系\n",
      "杨紫是\n",
      "杨紫怒\n",
      "对刀郎\n",
      "和玲花\n",
      "与玲花\n",
      "刘丹自\n",
      "如今已是\n",
      "真得瑟\n",
      "剧不红\n",
      "演小三演\n",
      "一物降\n",
      "佟丽娅成\n",
      "谁给了\n",
      "联沃家\n",
      "燃脂舞\n",
      "排尽肠毒\n",
      "刮胆经\n",
      "舞瘦\n",
      "爆汗服\n",
      "变身易\n",
      "瘦伤\n",
      "rgmofwt\n",
      "微博刚\n",
      "带辣模\n",
      "般水嫩\n",
      "水里点\n",
      "好白快\n",
      "美白品\n",
      "美白达\n",
      "组扎心\n",
      "和慈禧\n",
      "背对着\n",
      "曝闻\n",
      "艰要\n",
      "传和雷\n",
      "这小妙\n",
      "佩莱绝\n",
      "神隐近\n",
      "致墙\n",
      "张召忠评\n",
      "侯舍予\n",
      "强塞狗\n",
      "点半整\n",
      "干十连板\n",
      "哈弗方\n",
      "万比卡宴\n",
      "文之事\n",
      "节朱\n",
      "之文带\n",
      "300644\n",
      "一妖股\n",
      "更博发\n",
      "爆堪\n",
      "胡井马\n",
      "天人设\n",
      "rplxzqk\n",
      "rgvkip0\n",
      "根老长\n",
      "背寿字\n",
      "李晟生\n",
      "陈晓陪\n",
      "发不实\n",
      "窦唯过\n",
      "发六字\n",
      "葛宏向\n",
      "莧加\n",
      "男主李\n",
      "挂林兰协\n",
      "挂林兰展\n",
      "人砸展\n",
      "春春笑\n",
      "马曼玲系\n",
      "肥妞变\n",
      "问甜馨\n",
      "誓无二心\n",
      "洗白后\n",
      "送甜馨\n",
      "喜当姐\n",
      "pdone\n",
      "官博早\n",
      "腹儿\n",
      "小三找\n",
      "陈学冬帮\n",
      "曝应\n",
      "这下馨爷\n",
      "引人伶\n",
      "甜馨会\n",
      "白拉上\n",
      "瘦爆\n",
      "微博似\n",
      "萌不受\n",
      "之恩该\n",
      "遭范爷\n",
      "曝不交\n",
      "王岳伦认\n",
      "家豪到\n",
      "辨不出\n",
      "维嘉有\n",
      "用宝妈\n",
      "微博露\n",
      "选已定\n",
      "时不愿\n",
      "秤坏\n",
      "等着瞧\n",
      "仍不卖\n",
      "耳替\n",
      "小罗晋\n",
      "粉反\n",
      "一球定\n",
      "比衣品\n",
      "蒋欣竟\n",
      "疑因怀\n",
      "刘丹为\n",
      "幂成\n",
      "家庭不和\n",
      "微博疑求\n",
      "比母桃\n",
      "替宝强\n",
      "清讽\n",
      "前撒狗\n",
      "郑爽管\n",
      "井柏然求\n",
      "朱亚贤\n",
      "埃神入\n",
      "杨紫上\n",
      "身潮\n",
      "张檬整\n",
      "毛宁唱\n",
      "不老女\n",
      "这拉风\n",
      "杨颖要\n",
      "一个天\n",
      "成白富\n",
      "杨颖欲\n",
      "杨颖弃\n",
      "杨颖称\n",
      "疑马蓉\n",
      "暴瘦似\n",
      "杨颖因\n",
      "粮天\n",
      "跑出去\n",
      "婊用\n",
      "沈腾神\n",
      "嫂方媛\n",
      "照美胸\n",
      "洪明伟\n",
      "手遮肚\n",
      "丁霞斥\n",
      "用珍仪\n",
      "头椿会\n",
      "孩溺\n",
      "赵丽颖认\n",
      "朱丹为\n",
      "三两个\n",
      "三沙同\n",
      "别老去\n",
      "既不伤\n",
      "比颖宝\n",
      "两大准\n",
      "虐太惨\n",
      "微博护\n",
      "生大眼\n",
      "王大骂\n",
      "提猜\n",
      "超多炸\n",
      "这狗会\n",
      "三大珍肴\n",
      "亿怒\n",
      "天刮脂\n",
      "臭宿\n",
      "生爱新\n",
      "西虹市\n",
      "天祛痘\n",
      "萨普爱思\n",
      "博爆\n",
      "曝锋菲\n",
      "谢敢\n",
      "曾不输\n",
      "是治好\n",
      "它治好\n",
      "除菌全\n",
      "有千人\n",
      "懒理江\n",
      "江小三\n",
      "比王凯\n",
      "那古仔\n",
      "鸡无鸡\n",
      "揭鹿晗\n",
      "卓伟带\n",
      "马黛双\n",
      "成新进\n",
      "宋喆大\n",
      "女炫富\n",
      "葛军出\n",
      "株潭来\n",
      "扎演\n",
      "有多酷\n",
      "没火当\n",
      "郑爽江\n",
      "对柏芝\n",
      "天变润\n",
      "联三大\n",
      "一个通\n",
      "清肠利\n",
      "太高人\n",
      "别老靠\n",
      "十吃十降\n",
      "被拉进\n",
      "图疑\n",
      "需放个\n",
      "韬拉着\n",
      "何炅为\n",
      "种同食\n",
      "利智会\n",
      "不买包\n",
      "輕十歲\n",
      "假快播\n",
      "还护心\n",
      "降三高护\n",
      "味美有\n",
      "银隆系\n",
      "亲案\n",
      "180109\n",
      "饮巧\n",
      "˶\n",
      "‾\n",
      "᷄\n",
      "ꈊ\n",
      "᷅\n",
      "读晨记\n",
      "吴大真教\n",
      "速转求\n",
      "脚水里\n",
      "肚平\n",
      "要带头\n",
      "没黑够\n",
      "丽颖有\n",
      "因王俊凯\n",
      "年凯家\n",
      "王俊凯毒\n",
      "患小头\n",
      "美白误\n",
      "水润底\n",
      "蓝水会\n",
      "密疑\n",
      "赵丽颖颖宝\n",
      "赵丽颖起\n",
      "配一物\n",
      "灿友们\n",
      "了颖宝\n",
      "瑜许\n",
      "力挺颖宝\n",
      "郑爽暴\n",
      "黑如绸\n",
      "洗牙易\n",
      "陈皮配\n",
      "看洪金\n",
      "范丞丞用\n",
      "问范丞丞\n",
      "赵丽颖剧\n",
      "真扎心\n",
      "脸属\n",
      "涂磊会\n",
      "抵套\n",
      "某小编\n",
      "刚卓伟\n",
      "盘大棋\n",
      "前洁面\n",
      "至雄安\n",
      "摇号系\n",
      "跑上跑下\n",
      "卖吉鲁\n",
      "厄齐尔去\n",
      "谣速\n",
      "徐峥会\n",
      "翔患\n",
      "老湿毒\n",
      "有事没事\n",
      "河底下\n",
      "城坠亡\n",
      "坠亡终\n",
      "搭逆袭\n",
      "万同款\n",
      "我昕姐\n",
      "亲辟\n",
      "一个千年\n",
      "穷常\n",
      "补虚温\n",
      "之圣品\n",
      "美白片\n",
      "抢戈登\n",
      "一宝妈\n",
      "后盖谍\n",
      "养颜养\n",
      "过塞到\n",
      "洗白成\n",
      "疑人设\n",
      "博一人\n",
      "官博忙\n",
      "三大实\n",
      "张翰合\n",
      "陈嘉微博\n",
      "旧爱有\n",
      "强燃\n",
      "人扎心\n",
      "维嘉何炅疑\n",
      "山一姐\n",
      "快本散\n",
      "婚房练\n",
      "看會\n",
      "完不笑\n",
      "民熏\n",
      "白装露\n",
      "还会出\n",
      "粮吃定\n",
      "以後別\n",
      "ninepercent\n",
      "韩雪爆\n",
      "大鹿晗\n",
      "戏床\n",
      "马云输\n",
      "王凯选\n",
      "帮王凯\n",
      "争视帝\n",
      "乔恩姐\n",
      "图太暖心\n",
      "肩女\n",
      "强逆袭\n",
      "部待播\n",
      "保宋喆\n",
      "爆马蓉\n",
      "强疑\n",
      "撕马蓉力\n",
      "成双入\n",
      "由马蓉\n",
      "劝马蓉\n",
      "阔太变\n",
      "老罗微博\n",
      "称颜值\n",
      "看宝强\n",
      "需马蓉\n",
      "为的是\n",
      "讽博\n",
      "后马蓉\n",
      "宝强终\n",
      "疑宝强\n",
      "马蓉逆袭\n",
      "爆光用\n",
      "洗白真\n",
      "然卓伟\n",
      "王思聪夺\n",
      "别吃瓜\n",
      "那英继\n",
      "王思聪替\n",
      "王思聪遇\n",
      "雷军身\n",
      "思聪狂\n",
      "急称\n",
      "说白了\n",
      "预追马\n",
      "亿系\n",
      "王冰萌\n",
      "马云狂\n",
      "混下去\n",
      "英蠢\n",
      "那英摊\n",
      "当个富\n",
      "奋全火\n",
      "鲁豫方\n",
      "有迪丽\n",
      "为梦奇\n",
      "大弯区\n",
      "对鲁豫\n",
      "窦唯童\n",
      "谢贤赞\n",
      "谢贤留\n",
      "朱之文子\n",
      "別嫁\n",
      "和霆锋\n",
      "了暧昧\n",
      "仔惊\n",
      "真会拔\n",
      "第五十章\n",
      "真龙该\n",
      "身而过\n",
      "亿豪车\n",
      "李湘素\n",
      "亿竟\n",
      "球球泪\n",
      "依萍江\n",
      "赵丽颖会\n",
      "礼景甜\n",
      "碰不起\n",
      "孕味重\n",
      "备孕接\n",
      "圆逆袭\n",
      "祛湿平\n",
      "天抹出\n",
      "立懂\n",
      "越吃病\n",
      "爆准\n",
      "姐高露\n",
      "女不生\n",
      "小方治\n",
      "防不在治\n",
      "有得长\n",
      "树豆治\n",
      "可固发\n",
      "用草治\n",
      "草治猪\n",
      "不落色\n",
      "想淡斑\n",
      "钓超\n",
      "招秘制\n",
      "赵丽颖显\n",
      "坏壶\n",
      "变新壶\n",
      "對著\n",
      "杨紫娜\n",
      "吴昕泪\n",
      "多易致\n",
      "兩人關\n",
      "克林布\n",
      "玛悟饭\n",
      "发博官\n",
      "网传星\n",
      "沙松雅\n",
      "恶灵锁\n",
      "旺家运\n",
      "王鸥素\n",
      "季疑\n",
      "遭跑\n",
      "芮微\n",
      "赵丽颖恋\n",
      "打太多\n",
      "微博吐槽\n",
      "腹汤\n",
      "瘦得慢\n",
      "大吸脂\n",
      "吸脂王\n",
      "还得加\n",
      "腰太难\n",
      "这一痛\n",
      "引三高\n",
      "岁娜\n",
      "小三要\n",
      "这婚结\n",
      "接娜\n",
      "柏然互\n",
      "于莎莎要\n",
      "茂别\n",
      "有空时\n",
      "发多野\n",
      "分上色\n",
      "玉红用\n",
      "宋晓峰入\n",
      "白百何协\n",
      "似马蓉\n",
      "下架系\n",
      "人暖心\n",
      "这绿能\n",
      "探班秀\n",
      "降三高治\n",
      "黄荷娜疑\n",
      "周美白\n",
      "视其为\n",
      "封陆贞为\n",
      "系虾\n",
      "加字版\n",
      "多吃助\n",
      "微博竟\n",
      "遭夜华\n",
      "补脾能\n",
      "补不对\n",
      "咽不下\n",
      "婚房首\n",
      "牛婚\n",
      "疯康辉\n",
      "张翰点\n",
      "来拉上\n",
      "脸辣妈\n",
      "幂娜\n",
      "唐嫣动\n",
      "毯槽\n",
      "林允近\n",
      "陈恺威\n",
      "郑爽侧\n",
      "瘦疑\n",
      "模迪丽\n",
      "那英用\n",
      "刀郎用\n",
      "刀郎道\n",
      "刀郎近\n",
      "赵丽颖谈\n",
      "超般\n",
      "男神要\n",
      "素颜真\n",
      "升油能\n",
      "谈马云\n",
      "引一众\n",
      "舱弹\n",
      "张继科易\n",
      "鲁能命\n",
      "董洁用\n",
      "基情秀\n",
      "招睡\n",
      "郭智超\n",
      "可淡斑\n",
      "脸焕\n",
      "腹别\n",
      "關了\n",
      "曝陈羽\n",
      "爆肥撑\n",
      "董铭逸\n",
      "女主选角\n",
      "附男宝\n",
      "接男宝准\n",
      "明夏二选\n",
      "亿顶\n",
      "薪稳\n",
      "休城开\n",
      "赌豪阵\n",
      "追一超\n",
      "可灭勇\n",
      "有马云\n",
      "栽土里\n",
      "不长叶\n",
      "吴佳尼爱\n",
      "路央子\n",
      "长吃肉会\n",
      "酿大错\n",
      "胜万药\n",
      "腰细脸\n",
      "排净毒\n",
      "郭采洁开\n",
      "赵倩儿\n",
      "却大减\n",
      "时疑现\n",
      "曝范爷\n",
      "裙值\n",
      "婚房照\n",
      "素颜看\n",
      "岁秀智\n",
      "我勒个\n",
      "管汪峰\n",
      "谷七郎\n",
      "中真龙\n",
      "雄安真龙\n",
      "雄安股\n",
      "錄下\n",
      "上放个\n",
      "完孕妈\n",
      "毛宁差\n",
      "其和赖\n",
      "毛宁送\n",
      "混它\n",
      "连湿毒\n",
      "张杰互\n",
      "曝张杰\n",
      "爆谢娜\n",
      "孙杨有\n",
      "男朋微信\n",
      "洛江仙\n",
      "次淡斑\n",
      "斑小妙\n",
      "淡斑效\n",
      "竟淡斑\n",
      "红红的\n",
      "可年销\n",
      "万的业\n",
      "离不了\n",
      "散寒防\n",
      "天胖到\n",
      "qqzjc20120802\n",
      "辣妈生\n",
      "看美得\n",
      "粉可致\n",
      "易三高\n",
      "罗晋同\n",
      "而罗晋\n",
      "材睡\n",
      "别总去\n",
      "陈红以\n",
      "号国服\n",
      "网传国服\n",
      "端游国服\n",
      "外尔豪\n",
      "比柳岩\n",
      "充維\n",
      "反怼\n",
      "再吐槽\n",
      "说得对\n",
      "群所传\n",
      "不法行为\n",
      "人勿传\n",
      "连马云开\n",
      "网传汉军\n",
      "銀币\n",
      "造壹圆\n",
      "网传全\n",
      "桃同食\n",
      "一鸡店\n",
      "rg1dqz3\n",
      "演楚乔\n",
      "听卓伟\n",
      "字笑侃\n",
      "网红凤姐\n",
      "掀骂战\n",
      "车高达\n",
      "唐嫣气\n",
      "后首秀\n",
      "无爱真\n",
      "王石田\n",
      "微博说\n",
      "小三当\n",
      "纯素颜\n",
      "马蓉争\n",
      "阿哲连麦\n",
      "青久后\n",
      "青方媛\n",
      "罗志祥疑\n",
      "变罗太\n",
      "出大视\n",
      "罗晋婚\n",
      "这国称\n",
      "发博骂\n",
      "140630\n",
      "可闹出\n",
      "宠粉\n",
      "谈币色\n",
      "李晨求\n",
      "选李晨\n",
      "♛\n",
      "美白得\n",
      "称无药\n",
      "抵十副药\n",
      "马云下\n",
      "邀马云\n",
      "劝其生\n",
      "准一姐\n",
      "成小三\n",
      "小三闺蜜\n",
      "斑暗\n",
      "减肚\n",
      "绿叁\n",
      "要常买\n",
      "第七个\n",
      "老妻心\n",
      "合不上\n",
      "带范伟\n",
      "驾无牌\n",
      "因不愿\n",
      "锁近\n",
      "带云馨\n",
      "乐大码\n",
      "减脂期\n",
      "拿瓣\n",
      "需几瓣\n",
      "这果赛\n",
      "接必应\n",
      "十人九胖\n",
      "旭彦堂\n",
      "冯柯闹\n",
      "缺胡\n",
      "胡歌身\n",
      "因胡歌\n",
      "变御姐\n",
      "样燃脂\n",
      "再无斑\n",
      "毯罗晋\n",
      "大藥房\n",
      "胜十副药\n",
      "肩酸胀\n",
      "盐治好\n",
      "不藤\n",
      "草治好\n",
      "还百试\n",
      "顶十副药\n",
      "待播剧\n",
      "种藕养\n",
      "勤般\n",
      "爆疑\n",
      "手术台上\n",
      "进行性\n",
      "这不刚\n",
      "赵又廷组\n",
      "招醋\n",
      "张翰高\n",
      "天清肠毒\n",
      "天吃次\n",
      "秦岚掉\n",
      "积安堂\n",
      "苟芸慧齐\n",
      "地和房\n",
      "降酸有\n",
      "传范丞丞跑\n",
      "传范丞丞微博\n",
      "清为证\n",
      "因范爷\n",
      "再撒糖\n",
      "杨颖整\n",
      "李晨方\n",
      "照疯转\n",
      "好大是\n",
      "不输兰蔻\n",
      "太陽將\n",
      "养颜为\n",
      "扫码求\n",
      "宝妈发\n",
      "个字力\n",
      "用三不作\n",
      "小三向\n",
      "沈腾病\n",
      "排油治\n",
      "陈坤要\n",
      "董洁见\n",
      "这会儿\n",
      "所爱成\n",
      "蒋欣为\n",
      "认遭\n",
      "台蔚来\n",
      "徐坤疑\n",
      "薛之谦摊\n",
      "薛之谦自\n",
      "装逼立\n",
      "薛之谦演\n",
      "更爱甜\n",
      "别琐\n",
      "兰棵\n",
      "因不戒\n",
      "做小糖\n",
      "袁弘爆\n",
      "袁立别\n",
      "赵丽颖系\n",
      "不给生\n",
      "指不雅\n",
      "梵资管\n",
      "扎情\n",
      "疑因查\n",
      "后远超\n",
      "之鬼门\n",
      "关晓彤生\n",
      "讨论一下\n",
      "许晴太作\n",
      "爆恋童\n",
      "献爱王\n",
      "准不信\n",
      "烯快\n",
      "台会神\n",
      "王思聪放话\n",
      "维嘉停\n",
      "录何\n",
      "话暖心\n",
      "坐娜姐\n",
      "听林丹\n",
      "谢菲恋\n",
      "谢贤慌\n",
      "谢贤死\n",
      "谢贤邀\n",
      "字霆锋\n",
      "谢贤自\n",
      "完无一\n",
      "竟想花\n",
      "e79w32\n",
      "旧爱大\n",
      "高管互\n",
      "帮甜馨\n",
      "曝办\n",
      "给乐视\n",
      "乐视命\n",
      "赌石大牛\n",
      "奥拓换\n",
      "帕克恐\n",
      "赫子铭称\n",
      "李沁女\n",
      "赵丽颖人\n",
      "赵丽颖仅\n",
      "冯绍峰疑\n",
      "拍添\n",
      "赵丽颖冲\n",
      "你颖宝\n",
      "张翰俩\n",
      "赵丽颖长\n",
      "框演\n",
      "赵丽颖喜\n",
      "冯绍峰家\n",
      "赵丽颖官\n",
      "赵丽颖当\n",
      "何炅笑\n",
      "爆不雅照\n",
      "惹人赞\n",
      "有文替\n",
      "论卧\n",
      "赵丽颖现\n",
      "冯绍峰帅\n",
      "陈晓说\n",
      "太爽了\n",
      "曝楚\n",
      "爆楚\n",
      "乔传用\n",
      "抱替\n",
      "敲迪丽\n",
      "水里去\n",
      "看球球\n",
      "向利哥\n",
      "帮利哥\n",
      "小安九入\n",
      "曾欲雪藏\n",
      "立遗\n",
      "争仪\n",
      "见利哥\n",
      "赵武儿\n",
      "密会迪丽\n",
      "认马云\n",
      "曝和马云\n",
      "韩姨指\n",
      "乱战出\n",
      "对国足\n",
      "闺蜜学\n",
      "开纯电\n",
      "肝毒防\n",
      "亿主播\n",
      "新大招\n",
      "碰维\n",
      "艾炙来\n",
      "个月速\n",
      "大耳雷子\n",
      "娃恨\n",
      "扶车尬\n",
      "用万人\n",
      "辣竟\n",
      "二哈成\n",
      "别想申\n",
      "赵丽颖远\n",
      "吃似\n",
      "咖酚\n",
      "赵丽颖遇\n",
      "陈自瑶同\n",
      "竟能治好\n",
      "食材用\n",
      "这门炮\n",
      "韦少利\n",
      "不输迪丽\n",
      "光不舍\n",
      "郑恺祖\n",
      "因不红\n",
      "终首\n",
      "累齐\n",
      "真会藏\n",
      "高聚能\n",
      "阿雀山\n",
      "斤大蛇\n",
      "百变身\n",
      "遭指性\n",
      "邓莎用\n",
      "超哥求\n",
      "邓超江\n",
      "邓超苦\n",
      "難忍\n",
      "歲爺\n",
      "爺給\n",
      "有个富\n",
      "那英因\n",
      "抢田震\n",
      "微博关\n",
      "那英谈\n",
      "受太多\n",
      "邀刀郎\n",
      "某辅\n",
      "马云连\n",
      "昆渣\n",
      "现紧\n",
      "鹿晗力\n",
      "陈赫爆\n",
      "张翰七字\n",
      "演男主\n",
      "郑爽发\n",
      "太多暖味\n",
      "张恒吻\n",
      "张翰应\n",
      "最爱爽\n",
      "扎秀\n",
      "宋宁来\n",
      "携嫩模\n",
      "姜昆能\n",
      "郭德纲息\n",
      "逼岳云鹏\n",
      "誓疑\n",
      "说酸生\n",
      "男辣生\n",
      "悄吃\n",
      "酷宝儿\n",
      "加双摄\n",
      "三连板\n",
      "狼真要\n",
      "助之小\n",
      "皇疑涉\n",
      "陈学冬有\n",
      "拍下去\n",
      "饮粒\n",
      "那英狂\n",
      "韩颖华爆\n",
      "名女模\n",
      "逆生長\n",
      "大撒狗\n",
      "粮秀\n",
      "唐嫣定\n",
      "乃乐视\n",
      "关不多\n",
      "锋菲大婚\n",
      "谢贤站\n",
      "20180614\n",
      "万收来\n",
      "ca1350\n",
      "闪偷\n",
      "涉兰\n",
      "集赞够\n",
      "杨公寻龙\n",
      "透黑似\n",
      "阿娇赖\n",
      "助马云\n",
      "和平统一\n",
      "秦舒培要\n",
      "三四个\n",
      "拳迷为\n",
      "人奔富\n",
      "马云上\n",
      "马云不惧\n",
      "东无语\n",
      "马云乐\n",
      "亳言\n",
      "马云借\n",
      "分没到\n",
      "放新招\n",
      "马云受\n",
      "马云大\n",
      "马云拜\n",
      "无房族\n",
      "马云数\n",
      "那三大\n",
      "马云欲\n",
      "打无商\n",
      "马云挡\n",
      "人会富\n",
      "年二大\n",
      "马云脸\n",
      "马云豪车\n",
      "就业机会\n",
      "个大牛\n",
      "真不大\n",
      "萝莉呆萌\n",
      "周秀波\n",
      "郑爽照\n",
      "节众\n",
      "周夏雪\n",
      "马思纯力\n",
      "遭孟非\n",
      "鹿晗求\n",
      "爸卷\n",
      "遭四字\n",
      "马蓉怕\n",
      "学凤姐\n",
      "马蓉戏\n",
      "亿马蓉\n",
      "还宝强\n",
      "马蓉斥\n",
      "强放话\n",
      "马蓉法\n",
      "院争儿\n",
      "马蓉用\n",
      "遭颖宝\n",
      "丽颖神\n",
      "被颖宝\n",
      "马蓉载\n",
      "太马蓉\n",
      "马蓉假\n",
      "舒揭\n",
      "这方面\n",
      "能加分\n",
      "科三将\n",
      "四新规\n",
      "秦舒培过\n",
      "郑嘉颖为\n",
      "表真爱\n",
      "郑嘉颖婚\n",
      "获赞强\n",
      "薛之谦受\n",
      "女主王\n",
      "刘芷微发\n",
      "佟丽娅首\n",
      "佟丽娅用\n",
      "陈思诚发\n",
      "女主发\n",
      "用品店\n",
      "原小三\n",
      "佟丽娅情\n",
      "曝携\n",
      "勾俩\n",
      "陈思诚陷\n",
      "希晒生\n",
      "贞湛恋\n",
      "陈晓霍\n",
      "陈猎\n",
      "打狱\n",
      "大呼辣\n",
      "疑因江\n",
      "曝人设\n",
      "晒孕肚\n",
      "陈赫为\n",
      "讽借\n",
      "陈赫花\n",
      "陈赫谈\n",
      "邓超破\n",
      "陈金典\n",
      "降血高\n",
      "推韩流\n",
      "需喷点\n",
      "菜伤\n",
      "或京冀\n",
      "寻得托\n",
      "之迪丽\n",
      "继马云\n",
      "其下家\n",
      "出高货\n",
      "锋管\n",
      "鲁豫大赞\n",
      "揭霍\n",
      "杜江齐\n",
      "秦岚忙\n",
      "毒唯粉\n",
      "李佳后\n",
      "发迪丽\n",
      "发迪力\n",
      "竟拿盆接\n",
      "当志颖\n",
      "昆凌摸\n",
      "韩红办\n",
      "钱不花\n",
      "纽途丽爱\n",
      "吃梨防\n",
      "喷停\n",
      "睡范伟\n",
      "魅族乐视\n",
      "机皇真机\n",
      "莫雷笑\n",
      "先发个\n",
      "詹韦全\n",
      "董璇头\n",
      "翔恐\n",
      "霸凌患\n",
      "求凤九\n",
      "活灌\n",
      "用电户\n",
      "卓伟道\n",
      "穿肥款\n",
      "竟干出\n",
      "战黑坑\n",
      "分学霸\n",
      "新规日\n",
      "无大变\n",
      "国乒出\n",
      "连话都\n",
      "说不出来\n",
      "鸭血里\n",
      "继隐\n",
      "微博变\n",
      "对迪丽\n",
      "胖迪才\n",
      "爱豆接\n",
      "鹿晗演\n",
      "鹿晗点\n",
      "赞迪丽\n",
      "因太娘\n",
      "爆其隐\n",
      "档床\n",
      "杨颖受\n",
      "卓伟戏\n",
      "上十赌\n",
      "陈晓去\n",
      "工黄毅\n",
      "没死现\n",
      "杨颖陷\n",
      "黄渤在\n",
      "后美过\n",
      "年朴\n",
      "坐人拉货\n",
      "岁鲁豫近\n",
      "只鲁豫\n",
      "王杰同\n",
      "微博神\n",
      "董洁带\n",
      "董洁满\n",
      "真华妃\n",
      "小三引\n",
      "我想怀\n",
      "变美想\n",
      "网传放洁\n",
      "今一人\n",
      "万平事\n",
      "爆一波\n",
      "删疑\n",
      "爆其花\n",
      "在城镇\n",
      "自称为\n",
      "白萝布\n",
      "黄渤加\n",
      "黄渤三\n",
      "这微博\n",
      "三高输\n",
      "堵脑\n",
      "爆嫁\n",
      "袁立姐\n",
      "袁立友\n",
      "浙卫脸\n",
      "乐嘉力\n",
      "因太多\n",
      "张桐发\n",
      "袁立直\n",
      "称讨薪\n",
      "版迪丽\n",
      "音四子\n",
      "胡歌教\n",
      "晏恋\n",
      "晏许\n",
      "名吃瓜\n",
      "萧敬腾力\n",
      "准会降\n",
      "系拍微\n",
      "喜当爸\n",
      "与志玲\n",
      "微博透\n",
      "薛之谦同\n",
      "揭用\n",
      "许晴当\n",
      "一胖识\n",
      "赵薇命\n",
      "大醉后\n",
      "帽甜\n",
      "马云认\n",
      "贾装\n",
      "抢颖宝\n",
      "杨颖摊\n",
      "听鲁能\n",
      "爆路\n",
      "遭康辉\n",
      "巴城麻\n",
      "6395505654904652034\n",
      "曝传\n",
      "轨闹\n",
      "删秀\n",
      "维嘉疯\n",
      "岁疑\n",
      "谢贤豪车\n",
      "儿豪车\n",
      "归柏芝\n",
      "曝谢贤\n",
      "锋疑\n",
      "亿拿回\n",
      "结婚的人\n",
      "因借戏\n",
      "弃柏芝\n",
      "二子录\n",
      "买不亏\n",
      "李湘头\n",
      "艺恋\n",
      "后素颜\n",
      "赫子铭后\n",
      "爆赫子铭\n",
      "何洁别\n",
      "后赫子铭\n",
      "疑何洁现\n",
      "教甜馨\n",
      "这群神\n",
      "来美白\n",
      "有红彩\n",
      "对鲁能\n",
      "疼秒法\n",
      "宝卖萌\n",
      "事让颖宝\n",
      "赵丽颖教\n",
      "宝太有\n",
      "迪玛希新\n",
      "赵丽颖井柏然\n",
      "赵丽颖继\n",
      "何炅起\n",
      "陈伟霆会\n",
      "赵丽颖大虐\n",
      "化身为\n",
      "两大狗\n",
      "补刀疑\n",
      "刘丹怒\n",
      "与颖儿\n",
      "已石锤\n",
      "王鸥现\n",
      "说颖宝\n",
      "赵丽颖首\n",
      "这卫衣\n",
      "遭嘲\n",
      "赵丽颖快\n",
      "赵又廷迪丽\n",
      "红大婚\n",
      "郭达近\n",
      "何炅藏\n",
      "维嘉暴\n",
      "要买车\n",
      "车不崩\n",
      "唐嫣装\n",
      "曝孙俪\n",
      "找卓伟\n",
      "林丹后\n",
      "遭孙俪\n",
      "轨花\n",
      "爆想用\n",
      "邓超居\n",
      "邓超游\n",
      "马云非\n",
      "剩载\n",
      "真不浅\n",
      "冲十连板\n",
      "播鹿晗\n",
      "学霸超\n",
      "我无语\n",
      "邓超包\n",
      "此新规\n",
      "郑爽求\n",
      "爸疑\n",
      "发挥作用\n",
      "书大赞\n",
      "配纯电\n",
      "万不火\n",
      "亿农房\n",
      "网红真\n",
      "卓伟神\n",
      "带孩及\n",
      "卓伟后\n",
      "岁治好\n",
      "试不试\n",
      "速透皮\n",
      "一个顶\n",
      "老中攻\n",
      "却百治\n",
      "我三哥\n",
      "看明间\n",
      "消痛膏\n",
      "l4l5\n",
      "刺血排\n",
      "快好了\n",
      "彭突\n",
      "突全\n",
      "170922\n",
      "周爆减\n",
      "用红米\n",
      "藏友长\n",
      "薛之谦竟\n",
      "马云人\n",
      "可凉血\n",
      "全清光\n",
      "赛悍\n",
      "李易峰疑\n",
      "斑太难\n",
      "年三版\n",
      "杨颖换\n",
      "暂不接剧\n",
      "陈伟霆光\n",
      "吴亦凡秀\n",
      "和霆霆\n",
      "箱油能\n",
      "何洁用\n",
      "显而易\n",
      "网惹\n",
      "砸过去\n",
      "看鹿晗\n",
      "妹迪丽\n",
      "卫衣成\n",
      "太走心\n",
      "说太会\n",
      "坐鹿晗\n",
      "对罗晋\n",
      "人老先\n",
      "赵丽颖范爷\n",
      "马蓉酒\n",
      "邓紫棋称\n",
      "邓紫棋疑\n",
      "三五个\n",
      "曝次\n",
      "车晓是\n",
      "那英大\n",
      "没卵用\n",
      "那英首\n",
      "小三开\n",
      "打星们\n",
      "张恒新\n",
      "赵丽颖接\n",
      "张翰力\n",
      "这四字\n",
      "两人发\n",
      "爽恋\n",
      "微博珠\n",
      "微博写\n",
      "李湘爆\n",
      "接男宝进\n",
      "一食材\n",
      "一人战\n",
      "万人存\n",
      "网红为\n",
      "音惨\n",
      "关晓彤团\n",
      "关晓彤索\n",
      "假裙\n",
      "小汉教\n",
      "爆汪峰\n",
      "不来学\n",
      "顶百副药\n",
      "获多到\n",
      "手竿台\n",
      "添未解\n",
      "侠竟\n",
      "编可转\n",
      "发吃点\n",
      "一东后\n",
      "日岳阳\n",
      "不关会\n",
      "肝菜\n",
      "体大如\n",
      "闫妮认\n",
      "分狠\n",
      "如润墨\n",
      "不染头\n",
      "变乌密\n",
      "似润墨\n",
      "不抹染剂\n",
      "不学太亏\n",
      "似墨别\n",
      "发再野\n",
      "如雨落\n",
      "虽美白\n",
      "皱显\n",
      "凶白\n",
      "斥小三\n",
      "疑指赖\n",
      "公媒\n",
      "李荣浩去\n",
      "我来养\n",
      "遇收\n",
      "佟顺\n",
      "杨紫问\n",
      "男神名\n",
      "草有主\n",
      "夜互\n",
      "发照秀\n",
      "用六字\n",
      "当谢娜\n",
      "懂博越\n",
      "清肠养\n",
      "时黃瓜別\n",
      "脂掉\n",
      "有奇方\n",
      "湿毒调\n",
      "秘透\n",
      "决密\n",
      "还斗得\n",
      "mp467\n",
      "马云爆\n",
      "马云透\n",
      "吴京触\n",
      "马云分\n",
      "一个千\n",
      "穷请\n",
      "马云排\n",
      "马云财\n",
      "曝马伊\n",
      "乔恩遭\n",
      "微搏求\n",
      "微博带\n",
      "讽王\n",
      "马蓉过\n",
      "大孕肚\n",
      "鹿晗发\n",
      "打马蓉\n",
      "送宝强\n",
      "送马蓉\n",
      "马蓉扎\n",
      "叫宝强\n",
      "微博初\n",
      "买靓房\n",
      "宋喆称\n",
      "搜之马蓉\n",
      "马蓉怒\n",
      "马蓉时\n",
      "谢贤八\n",
      "微博之言\n",
      "陈坤红\n",
      "迅怒\n",
      "那英迫\n",
      "希疑\n",
      "希暗\n",
      "陈晓面\n",
      "陈晓臭\n",
      "遭瞎传\n",
      "希钓出\n",
      "林丹们\n",
      "探班白\n",
      "偏高别\n",
      "今恋\n",
      "继惠氏\n",
      "何孟怀要\n",
      "港媒称\n",
      "何孟怀于\n",
      "吻界\n",
      "空棘\n",
      "智穹\n",
      "人瞬秒\n",
      "用新锅\n",
      "列三大\n",
      "韩红邀\n",
      "韩红气\n",
      "餐坏\n",
      "最可选\n",
      "首晒孕\n",
      "批太作\n",
      "防動脈\n",
      "手麻治好\n",
      "需内调\n",
      "加橘\n",
      "完可算\n",
      "喷太\n",
      "指鹿晗\n",
      "无真爱\n",
      "配骁龙\n",
      "两大癌\n",
      "脑吃个\n",
      "rgn0jgq\n",
      "多大点\n",
      "晒妈\n",
      "赵又廷疑\n",
      "连竿到\n",
      "小白到\n",
      "保肝强\n",
      "字衫\n",
      "消脂王\n",
      "太大易\n",
      "养森\n",
      "高鑫要\n",
      "g6602\n",
      "爆闹\n",
      "虽劲道\n",
      "加两宝\n",
      "剝掉\n",
      "营尚媒\n",
      "薛之谦当\n",
      "不爱何\n",
      "张凯毅\n",
      "吃杏肉\n",
      "王思聪立\n",
      "鹿晗确\n",
      "依小三\n",
      "依继小三\n",
      "爆黄圣\n",
      "归家过\n",
      "黄渤把\n",
      "黄渤一\n",
      "洗膏\n",
      "张一山套\n",
      "Null word embeddings: 8468\n"
     ]
    }
   ],
   "source": [
    "sgns_bigram_matrix = build_embedding_matrix(sgns_bigram_embedding, embedding_size=300)\n",
    "tencent_ai_matrix = build_embedding_matrix(tencent_ai_embedding, embedding_size=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trick Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/dataset/train.csv')\n",
    "test_df = pd.read_csv('../data/dataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan <class 'float'>\n",
      "nan <class 'float'>\n",
      "nan <class 'float'>\n",
      "nan <class 'float'>\n",
      "nan <class 'float'>\n",
      "nan <class 'float'>\n",
      "nan <class 'float'>\n",
      "nan <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "rumor_words_list = ['辟谣', '谣言', '谣传', '传谣', '澄清', '真相', '假新闻', '传言', '造谣', '假消息', '不实', '勿传', '假的', '子虚乌有', '诈骗', '骗局', '以讹传讹']\n",
    "\n",
    "def is_rumor(text):\n",
    "    if type(text) != str:\n",
    "        print(text, type(text))\n",
    "        return 0\n",
    "    energy = 0\n",
    "    for rumor_word in rumor_words_list:\n",
    "        if rumor_word in text:\n",
    "            energy = 1\n",
    "    return energy\n",
    "\n",
    "def has_split_symbol(text):\n",
    "    if type(text) != str:\n",
    "        return 0\n",
    "    if '|' in text:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "for df in [train_df, test_df]:\n",
    "    df['has_|'] = df['title2_zh'].apply(has_split_symbol)\n",
    "    df['has_rumor_words'] = df['title2_zh'].apply(is_rumor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_has_rumor = train_df.has_rumor_words.values\n",
    "test_has_rumor = test_df.has_rumor_words.values\n",
    "\n",
    "trick_trains_features = np.concatenate((trains[2], train_has_rumor.reshape((-1, 1))), axis=1)\n",
    "trick_tests_features = np.concatenate((tests[2], test_has_rumor.reshape((-1, 1))), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _build_exact_match_sequences(sent_1, sent_2):\n",
    "    sent_1_char_set = set(sent_1)\n",
    "    sent_2_char_set = set(sent_2)\n",
    "    intersection = sent_1_char_set & sent_2_char_set\n",
    "    \n",
    "    sent_1_em = np.zeros_like(sent_1)\n",
    "    sent_2_em = np.zeros_like(sent_2)\n",
    "\n",
    "    for i in range(len(sent_1)):\n",
    "        if sent_1[i] == 0:\n",
    "            continue\n",
    "        if sent_1[i] in intersection:\n",
    "            sent_1_em[i] = 1\n",
    "    \n",
    "    for i in range(len(sent_2)):\n",
    "        if sent_2[i] == 0:\n",
    "            continue        \n",
    "        if sent_2[i] in intersection:\n",
    "            sent_2_em[i] = 1\n",
    "    \n",
    "    return sent_1_em, sent_2_em\n",
    "\n",
    "def build_exact_match_sequences(sents_1, sents_2):\n",
    "    sents_1_em, sents_2_em = [], []\n",
    "    for sent_1, sent_2 in zip(sents_1, sents_2):\n",
    "        sent_1_em, sent_2_em = _build_exact_match_sequences(sent_1, sent_2)\n",
    "        sents_1_em.append(sent_1_em)\n",
    "        sents_2_em.append(sent_2_em)\n",
    "    return np.array(sents_1_em), np.array(sents_2_em)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trains_1_ems, trains_2_ems = build_exact_match_sequences(trains[0], trains[1])\n",
    "tests_1_ems, tests_2_ems = build_exact_match_sequences(tests[0], tests[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train em (320552, 30) (320552, 30)\n",
      "Shape of test em (80126, 30) (80126, 30)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of train em\", trains_1_ems.shape, trains_2_ems.shape)\n",
    "print(\"Shape of test em\", tests_1_ems.shape, tests_2_ems.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "em_train_features = (trains_1_ems, trains_2_ems)\n",
    "em_test_features = (tests_1_ems, tests_2_ems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tricks ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_tricky = True\n",
    "\n",
    "if use_tricky:\n",
    "    trains = (trains[0], trains[1], trick_trains_features)\n",
    "    tests = (tests[0], tests[1], trick_tests_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_manager = ModelManager()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Ensemble Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ensemble_submission = pd.read_csv('../data/ensemble/second_level/FirstLevelPseudoLabels.csv')\n",
    "pseudo_labels = ensemble_submission[['unrelated', 'agreed', 'disagreed']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import importlib\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from iwillwin.config import model_config\n",
    "\n",
    "class ModelTrainer(object):\n",
    "\n",
    "    def __init__(self, model_stamp, epoch_num, learning_rate=1e-3,\n",
    "                 shuffle_inputs=False, verbose_round=40, early_stopping_round=8):\n",
    "        self.models = []\n",
    "        self.model_stamp = model_stamp\n",
    "        self.val_loss = -1\n",
    "        self.auc = -1\n",
    "        self.epoch_num = epoch_num\n",
    "        self.learning_rate = learning_rate\n",
    "        self.eps = 1e-10\n",
    "        self.verbose_round = verbose_round\n",
    "        self.early_stopping_round = early_stopping_round\n",
    "        self.shuffle_inputs = shuffle_inputs\n",
    "\n",
    "    def train_folds(self, X, y, fold_count, em_train_features, tests, em_test_features, pseudo_labels, batch_size, get_model_func, augments=None, skip_fold=0, patience=10, scale_sample_weight=False,\n",
    "                    class_weight=None, self_aware=False, swap_input=False):\n",
    "        X1, X2, features, = X\n",
    "        em1, em2 = em_train_features\n",
    "        features = features\n",
    "        weight_val=scale_sample_weight\n",
    "\n",
    "        fold_size = len(X1) // fold_count\n",
    "        models = []\n",
    "        fold_predictions = []\n",
    "        score = 0\n",
    "\n",
    "        for fold_id in range(0, fold_count):\n",
    "            fold_start = fold_size * fold_id\n",
    "            fold_end = fold_start + fold_size\n",
    "\n",
    "            if fold_id == fold_count - 1:\n",
    "                fold_end = len(X1)\n",
    "\n",
    "            train_x1 = np.concatenate([X1[:fold_start], X1[fold_end:], tests[0]])\n",
    "            train_x2 = np.concatenate([X2[:fold_start], X2[fold_end:], tests[1]])\n",
    "            train_features = np.concatenate([features[:fold_start], features[fold_end:], tests[2]])\n",
    "            \n",
    "            train_em_1 = np.concatenate([em1[:fold_start], em1[fold_end:], em_test_features[0]])\n",
    "            train_em_2 = np.concatenate([em2[:fold_start], em2[fold_end:], em_test_features[1]])\n",
    "            \n",
    "            train_y = np.concatenate([y[:fold_start], y[fold_end:], pseudo_labels])\n",
    "            \n",
    "            val_x1 = X1[fold_start:fold_end]\n",
    "            val_x2 = X2[fold_start:fold_end]\n",
    "            val_features = features[fold_start:fold_end]\n",
    "            val_em1 = em1[fold_start:fold_end]\n",
    "            val_em2 = em2[fold_start:fold_end]\n",
    "            val_y = y[fold_start:fold_end]\n",
    "\n",
    "            fold_pos = (np.sum(train_y) / len(train_x1))\n",
    "\n",
    "            train_data = {\n",
    "                \"first_sentences\": train_x1,\n",
    "                \"second_sentences\": train_x2,\n",
    "                \"mata-features\": train_features,\n",
    "                \"first_exact_match\": train_em_1,\n",
    "                \"second_exact_match\": train_em_2,\n",
    "            }\n",
    "\n",
    "            val_data = {\n",
    "                \"first_sentences\": val_x1,\n",
    "                \"second_sentences\": val_x2,\n",
    "                \"mata-features\": val_features,\n",
    "                \"first_exact_match\": val_em1,\n",
    "                \"second_exact_match\": val_em2,\n",
    "            }\n",
    "\n",
    "            model, bst_val_score, fold_prediction = self._train_model_by_logloss(\n",
    "                get_model_func(), batch_size, train_data, train_y, val_data, val_y, fold_id, patience, class_weight, weight_val=weight_val)\n",
    "    \n",
    "            score += bst_val_score\n",
    "            models.append(model)\n",
    "            fold_predictions.append(fold_prediction)\n",
    "\n",
    "        self.models = models\n",
    "        self.val_loss = score / fold_count\n",
    "        return models, self.val_loss, fold_predictions\n",
    "\n",
    "    def _train_model_by_logloss(self, model, batch_size, train_x, train_y, val_x, val_y, fold_id, patience):\n",
    "        # return a list which holds [models, val_loss, auc, prediction]\n",
    "        raise NotImplementedError\n",
    "\n",
    "class KerasModelTrainer(ModelTrainer):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(KerasModelTrainer, self).__init__(*args, **kwargs)\n",
    "        pass\n",
    "\n",
    "    def _train_model_by_logloss(self, model, batch_size, train_x, train_y, val_x, val_y, fold_id, patience, class_weight, weight_val):\n",
    "        early_stopping = EarlyStopping(monitor='val_weighted_accuracy', patience=patience)\n",
    "        bst_model_path = self.model_stamp + \"-pseudo-scaled-\" + str(fold_id) + '.h5'\n",
    "        print(\"Load weights from\", bst_model_path)\n",
    "        model.load_weights(bst_model_path)\n",
    "        \n",
    "        bst_model_path = self.model_stamp + \"sec-pseudo-scaled-\" + str(fold_id) + '.h5'\n",
    "        val_data =  (val_x, val_y)\n",
    "        model_checkpoint = ModelCheckpoint(bst_model_path, save_best_only=True, save_weights_only=True)\n",
    "        hist = model.fit(train_x, train_y,\n",
    "                         validation_data=val_data,\n",
    "                         epochs=self.epoch_num, batch_size=batch_size, shuffle=True,\n",
    "                         class_weight={0: 1/16, 1:1/15, 2:1/5},\n",
    "                         callbacks=[early_stopping, model_checkpoint],)\n",
    "        bst_val_score = max(hist.history['val_weighted_accuracy'])\n",
    "        model.load_weights(bst_model_path)\n",
    "        predictions = model.predict(val_x)\n",
    "\n",
    "        return model, bst_val_score, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weighted_accuracy(y_true, y_pred):\n",
    "    weight = np.array([[1/16, 1/15, 1/5]])\n",
    "    norm = [(1/16) + (1/15) + (1/5)]\n",
    "    weight_mask = weight * y_true\n",
    "    label_weights = K.max(K.cast(weight_mask, 'float32'), axis=-1)\n",
    "    \n",
    "    true_label = K.argmax(y_true, axis=-1)\n",
    "    pred_label = K.argmax(y_pred, axis=-1)\n",
    "    \n",
    "    res = K.cast(K.equal(true_label, pred_label), tf.float32) * label_weights / K.sum(label_weights)\n",
    "    res = K.sum(res)\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dense_cnn(nb_words, embedding_dim, embedding_matrix, max_sequence_length, out_size,\n",
    "    projection_dim=50, projection_hidden=0, projection_dropout=0.2,\n",
    "    compare_dim=288, compare_dropout=0.2,\n",
    "    dense_dim=50, dense_dropout=0.2,\n",
    "    lr=1e-3, activation='relu'):\n",
    "\n",
    "    q1 = Input(shape=(max_sequence_length,), name='first_sentences')\n",
    "    q2 = Input(shape=(max_sequence_length,), name='second_sentences')\n",
    "    meta_features_input = Input(shape=(36,), name='mata-features')\n",
    "    \n",
    "    \n",
    "    embedding = Embedding(nb_words, embedding_dim,\n",
    "                          weights=[embedding_matrix],\n",
    "                          input_length=max_sequence_length,\n",
    "                          trainable=False)\n",
    "    \n",
    "    q1_embed = embedding(q1)\n",
    "    q1_embed = SpatialDropout1D(0.2)(q1_embed)\n",
    "    q2_embed = embedding(q2)\n",
    "    q2_embed = SpatialDropout1D(0.2)(q2_embed)\n",
    "\n",
    "    th = TimeDistributed(Highway(activation='relu'))\n",
    "    \n",
    "    q1_encoded = th(q1_embed,)    \n",
    "    q2_encoded = th(q2_embed,)\n",
    "    \n",
    "    q1_aligned, q2_aligned = soft_attention_alignment(q1_encoded, q2_encoded)\n",
    "    q1_encoded = Concatenate()([q2_aligned, q1_encoded])\n",
    "    q2_encoded = Concatenate()([q1_aligned, q2_encoded])  \n",
    "    \n",
    "    cnn_init = Conv1D(42, 1, strides=1, padding='same', activation='relu')\n",
    "    q1_seq = cnn_init(q1_encoded)\n",
    "    q2_seq = cnn_init(q2_encoded)\n",
    "    \n",
    "    cnns = [Conv1D(42, 3, strides=1, padding='same', activation='relu') for i in range(3)]\n",
    "    trans = [Conv1D(32, 1, strides=1, padding='same', activation='relu') for i in range(3)]\n",
    "    \n",
    "    \n",
    "    for idx, cnn in enumerate(cnns):\n",
    "        q1_aligned, q2_aligned = soft_attention_alignment(q1_seq, q2_seq)\n",
    "        q1_encoded = Concatenate()([q1_seq, q2_aligned, q1_encoded])\n",
    "        q2_encoded = Concatenate()([q2_seq, q1_aligned, q2_encoded])            \n",
    "        q1_seq = cnn(q1_encoded)\n",
    "        q2_seq = cnn(q2_encoded)    \n",
    "    \n",
    "    \n",
    "    #capsule_pooling = Capsule(num_capsule=3, dim_capsule=600, routings=2, share_weights=True)\n",
    "    \n",
    "    # Pooling\n",
    "    #q1_rep = Flatten()(capsule_pooling(q1_encoded))\n",
    "    #q2_rep = Flatten()(capsule_pooling(q2_encoded))\n",
    "    \n",
    "    attn = AttentionWeightedAverage()\n",
    "    \n",
    "    \n",
    "    q1_rep = apply_multiple(q1_encoded, [GlobalAvgPool1D(), GlobalMaxPool1D(), attn])\n",
    "    q2_rep = apply_multiple(q2_encoded, [GlobalAvgPool1D(), GlobalMaxPool1D(), attn])    \n",
    "    \n",
    "    \n",
    "    #meta_features = BatchNormalization()(meta_features_input)\n",
    "    #meta_features = Dropout(0.8)(meta_features)\n",
    "    #meta_features = Highway(activation='relu')(meta_features)\n",
    "    \n",
    "    # Classifier\n",
    "    q_diff = substract(q1_rep, q2_rep)\n",
    "    q_multi = Multiply()([q1_rep, q2_rep])\n",
    "    h_all = Concatenate()([q1_rep, q2_rep, q_diff, q_multi,])\n",
    "    h_all = Dropout(0.5)(h_all)\n",
    "    #h_all = Highway(activation='relu')(h_all)\n",
    "    #h_all = Dropout(0.2)(h_all)\n",
    "    #h_all = Highway(activation='relu')(h_all)    \n",
    "    h_all = Dense(128, activation='relu')(h_all)\n",
    "    out_ = Dense(3, activation='softmax')(h_all)\n",
    "\n",
    "    model = Model(inputs=[q1, q2, meta_features_input], outputs=out_)\n",
    "    model.compile(optimizer=Adam(lr=lr, decay=1e-6, clipnorm=1), loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', weighted_accuracy])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def numpy_weighted_accuracy(y_true, y_pred):\n",
    "    weight = np.array([[1/16, 1/15, 1/5]])\n",
    "    norm = [(1/16) + (1/15) + (1/5)]\n",
    "    weight_mask = weight * y_true\n",
    "    weight_mask = np.max(weight_mask, axis=-1)\n",
    "    norms = np.sum(weight_mask)\n",
    "    \n",
    "    y_true = np.argmax(y_true, axis=-1)\n",
    "    y_pred = np.argmax(y_pred, axis=-1)\n",
    "    \n",
    "    res = ((y_true == y_pred) * weight_mask).sum() / norms\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DenseCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TenCent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Work on model 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zake7\\Anaconda3\\lib\\site-packages\\keras\\legacy\\layers.py:198: UserWarning: The `Highway` layer is deprecated and will be removed after 06/2017.\n",
      "  warnings.warn('The `Highway` layer is deprecated '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 30, 200)      20000000    first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_5 (SpatialDro (None, 30, 200)      0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_6 (SpatialDro (None, 30, 200)      0           embedding_3[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, 30, 200)      80400       spatial_dropout1d_5[0][0]        \n",
      "                                                                 spatial_dropout1d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dot_25 (Dot)                    (None, 30, 30)       0           time_distributed_3[0][0]         \n",
      "                                                                 time_distributed_3[1][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_20 (Lambda)              (None, 30, 30)       0           dot_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_9 (Permute)             (None, 30, 30)       0           lambda_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)              (None, 30, 30)       0           dot_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_27 (Dot)                    (None, 30, 200)      0           permute_9[0][0]                  \n",
      "                                                                 time_distributed_3[1][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dot_26 (Dot)                    (None, 30, 200)      0           lambda_19[0][0]                  \n",
      "                                                                 time_distributed_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 30, 400)      0           dot_27[0][0]                     \n",
      "                                                                 time_distributed_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 30, 400)      0           dot_26[0][0]                     \n",
      "                                                                 time_distributed_3[1][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 30, 42)       16842       concatenate_23[0][0]             \n",
      "                                                                 concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dot_28 (Dot)                    (None, 30, 30)       0           conv1d_15[0][0]                  \n",
      "                                                                 conv1d_15[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)              (None, 30, 30)       0           dot_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_10 (Permute)            (None, 30, 30)       0           lambda_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_21 (Lambda)              (None, 30, 30)       0           dot_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_30 (Dot)                    (None, 30, 42)       0           permute_10[0][0]                 \n",
      "                                                                 conv1d_15[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_29 (Dot)                    (None, 30, 42)       0           lambda_21[0][0]                  \n",
      "                                                                 conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 30, 484)      0           conv1d_15[0][0]                  \n",
      "                                                                 dot_30[0][0]                     \n",
      "                                                                 concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 30, 484)      0           conv1d_15[1][0]                  \n",
      "                                                                 dot_29[0][0]                     \n",
      "                                                                 concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 30, 42)       61026       concatenate_25[0][0]             \n",
      "                                                                 concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dot_31 (Dot)                    (None, 30, 30)       0           conv1d_16[0][0]                  \n",
      "                                                                 conv1d_16[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_24 (Lambda)              (None, 30, 30)       0           dot_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_11 (Permute)            (None, 30, 30)       0           lambda_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_23 (Lambda)              (None, 30, 30)       0           dot_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_33 (Dot)                    (None, 30, 42)       0           permute_11[0][0]                 \n",
      "                                                                 conv1d_16[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_32 (Dot)                    (None, 30, 42)       0           lambda_23[0][0]                  \n",
      "                                                                 conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 30, 568)      0           conv1d_16[0][0]                  \n",
      "                                                                 dot_33[0][0]                     \n",
      "                                                                 concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 30, 568)      0           conv1d_16[1][0]                  \n",
      "                                                                 dot_32[0][0]                     \n",
      "                                                                 concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 30, 42)       71610       concatenate_27[0][0]             \n",
      "                                                                 concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dot_34 (Dot)                    (None, 30, 30)       0           conv1d_17[0][0]                  \n",
      "                                                                 conv1d_17[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_26 (Lambda)              (None, 30, 30)       0           dot_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_12 (Permute)            (None, 30, 30)       0           lambda_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_25 (Lambda)              (None, 30, 30)       0           dot_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_36 (Dot)                    (None, 30, 42)       0           permute_12[0][0]                 \n",
      "                                                                 conv1d_17[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_35 (Dot)                    (None, 30, 42)       0           lambda_25[0][0]                  \n",
      "                                                                 conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 30, 652)      0           conv1d_17[0][0]                  \n",
      "                                                                 dot_36[0][0]                     \n",
      "                                                                 concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 30, 652)      0           conv1d_17[1][0]                  \n",
      "                                                                 dot_35[0][0]                     \n",
      "                                                                 concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_5 (Glo (None, 652)          0           concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_5 (GlobalM (None, 652)          0           concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_weighted_average_3 (A (None, 652)          652         concatenate_29[0][0]             \n",
      "                                                                 concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_6 (Glo (None, 652)          0           concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_6 (GlobalM (None, 652)          0           concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 1956)         0           global_average_pooling1d_5[0][0] \n",
      "                                                                 global_max_pooling1d_5[0][0]     \n",
      "                                                                 attention_weighted_average_3[0][0\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 1956)         0           global_average_pooling1d_6[0][0] \n",
      "                                                                 global_max_pooling1d_6[0][0]     \n",
      "                                                                 attention_weighted_average_3[1][0\n",
      "__________________________________________________________________________________________________\n",
      "lambda_27 (Lambda)              (None, 1956)         0           concatenate_31[0][0]             \n",
      "                                                                 concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 1956)         0           concatenate_31[0][0]             \n",
      "                                                                 concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 7824)         0           concatenate_31[0][0]             \n",
      "                                                                 concatenate_32[0][0]             \n",
      "                                                                 lambda_27[0][0]                  \n",
      "                                                                 multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 7824)         0           concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 128)          1001600     dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 3)            387         dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 21,232,517\n",
      "Trainable params: 1,232,517\n",
      "Non-trainable params: 20,000,000\n",
      "__________________________________________________________________________________________________\n",
      "Load weights from WordTC-DenseCNN5Layers-NoMeta-3P-NoEM-NoClassWeighted-3Layers-pseudo-scaled-0.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n",
      "360609/360609 [==============================] - 41s 113us/step - loss: 0.0170 - acc: 0.9084 - weighted_accuracy: 0.9069 - val_loss: 0.3071 - val_acc: 0.8648 - val_weighted_accuracy: 0.8547\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 40s 110us/step - loss: 0.0170 - acc: 0.9079 - weighted_accuracy: 0.9064 - val_loss: 0.3244 - val_acc: 0.8534 - val_weighted_accuracy: 0.8501\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 39s 109us/step - loss: 0.0169 - acc: 0.9087 - weighted_accuracy: 0.9075 - val_loss: 0.3110 - val_acc: 0.8598 - val_weighted_accuracy: 0.8532\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 39s 109us/step - loss: 0.0169 - acc: 0.9097 - weighted_accuracy: 0.9082 - val_loss: 0.3295 - val_acc: 0.8515 - val_weighted_accuracy: 0.8475\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 40s 110us/step - loss: 0.0168 - acc: 0.9099 - weighted_accuracy: 0.9087 - val_loss: 0.3345 - val_acc: 0.8493 - val_weighted_accuracy: 0.8465\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 40s 110us/step - loss: 0.0168 - acc: 0.9097 - weighted_accuracy: 0.9084 - val_loss: 0.3122 - val_acc: 0.8622 - val_weighted_accuracy: 0.8546\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 40s 111us/step - loss: 0.0168 - acc: 0.9102 - weighted_accuracy: 0.9089 - val_loss: 0.3108 - val_acc: 0.8599 - val_weighted_accuracy: 0.8537\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 30, 200)      20000000    first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_7 (SpatialDro (None, 30, 200)      0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_8 (SpatialDro (None, 30, 200)      0           embedding_4[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_4 (TimeDistrib (None, 30, 200)      80400       spatial_dropout1d_7[0][0]        \n",
      "                                                                 spatial_dropout1d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dot_37 (Dot)                    (None, 30, 30)       0           time_distributed_4[0][0]         \n",
      "                                                                 time_distributed_4[1][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_29 (Lambda)              (None, 30, 30)       0           dot_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_13 (Permute)            (None, 30, 30)       0           lambda_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_28 (Lambda)              (None, 30, 30)       0           dot_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_39 (Dot)                    (None, 30, 200)      0           permute_13[0][0]                 \n",
      "                                                                 time_distributed_4[1][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dot_38 (Dot)                    (None, 30, 200)      0           lambda_28[0][0]                  \n",
      "                                                                 time_distributed_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)    (None, 30, 400)      0           dot_39[0][0]                     \n",
      "                                                                 time_distributed_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)    (None, 30, 400)      0           dot_38[0][0]                     \n",
      "                                                                 time_distributed_4[1][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 30, 42)       16842       concatenate_34[0][0]             \n",
      "                                                                 concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dot_40 (Dot)                    (None, 30, 30)       0           conv1d_22[0][0]                  \n",
      "                                                                 conv1d_22[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_31 (Lambda)              (None, 30, 30)       0           dot_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_14 (Permute)            (None, 30, 30)       0           lambda_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_30 (Lambda)              (None, 30, 30)       0           dot_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_42 (Dot)                    (None, 30, 42)       0           permute_14[0][0]                 \n",
      "                                                                 conv1d_22[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_41 (Dot)                    (None, 30, 42)       0           lambda_30[0][0]                  \n",
      "                                                                 conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_36 (Concatenate)    (None, 30, 484)      0           conv1d_22[0][0]                  \n",
      "                                                                 dot_42[0][0]                     \n",
      "                                                                 concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_37 (Concatenate)    (None, 30, 484)      0           conv1d_22[1][0]                  \n",
      "                                                                 dot_41[0][0]                     \n",
      "                                                                 concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 30, 42)       61026       concatenate_36[0][0]             \n",
      "                                                                 concatenate_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dot_43 (Dot)                    (None, 30, 30)       0           conv1d_23[0][0]                  \n",
      "                                                                 conv1d_23[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_33 (Lambda)              (None, 30, 30)       0           dot_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_15 (Permute)            (None, 30, 30)       0           lambda_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_32 (Lambda)              (None, 30, 30)       0           dot_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_45 (Dot)                    (None, 30, 42)       0           permute_15[0][0]                 \n",
      "                                                                 conv1d_23[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_44 (Dot)                    (None, 30, 42)       0           lambda_32[0][0]                  \n",
      "                                                                 conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_38 (Concatenate)    (None, 30, 568)      0           conv1d_23[0][0]                  \n",
      "                                                                 dot_45[0][0]                     \n",
      "                                                                 concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_39 (Concatenate)    (None, 30, 568)      0           conv1d_23[1][0]                  \n",
      "                                                                 dot_44[0][0]                     \n",
      "                                                                 concatenate_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 30, 42)       71610       concatenate_38[0][0]             \n",
      "                                                                 concatenate_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dot_46 (Dot)                    (None, 30, 30)       0           conv1d_24[0][0]                  \n",
      "                                                                 conv1d_24[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_35 (Lambda)              (None, 30, 30)       0           dot_46[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_16 (Permute)            (None, 30, 30)       0           lambda_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_34 (Lambda)              (None, 30, 30)       0           dot_46[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_48 (Dot)                    (None, 30, 42)       0           permute_16[0][0]                 \n",
      "                                                                 conv1d_24[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_47 (Dot)                    (None, 30, 42)       0           lambda_34[0][0]                  \n",
      "                                                                 conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_40 (Concatenate)    (None, 30, 652)      0           conv1d_24[0][0]                  \n",
      "                                                                 dot_48[0][0]                     \n",
      "                                                                 concatenate_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_41 (Concatenate)    (None, 30, 652)      0           conv1d_24[1][0]                  \n",
      "                                                                 dot_47[0][0]                     \n",
      "                                                                 concatenate_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_7 (Glo (None, 652)          0           concatenate_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_7 (GlobalM (None, 652)          0           concatenate_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_weighted_average_4 (A (None, 652)          652         concatenate_40[0][0]             \n",
      "                                                                 concatenate_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_8 (Glo (None, 652)          0           concatenate_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_8 (GlobalM (None, 652)          0           concatenate_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_42 (Concatenate)    (None, 1956)         0           global_average_pooling1d_7[0][0] \n",
      "                                                                 global_max_pooling1d_7[0][0]     \n",
      "                                                                 attention_weighted_average_4[0][0\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_43 (Concatenate)    (None, 1956)         0           global_average_pooling1d_8[0][0] \n",
      "                                                                 global_max_pooling1d_8[0][0]     \n",
      "                                                                 attention_weighted_average_4[1][0\n",
      "__________________________________________________________________________________________________\n",
      "lambda_36 (Lambda)              (None, 1956)         0           concatenate_42[0][0]             \n",
      "                                                                 concatenate_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 1956)         0           concatenate_42[0][0]             \n",
      "                                                                 concatenate_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_44 (Concatenate)    (None, 7824)         0           concatenate_42[0][0]             \n",
      "                                                                 concatenate_43[0][0]             \n",
      "                                                                 lambda_36[0][0]                  \n",
      "                                                                 multiply_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 7824)         0           concatenate_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 128)          1001600     dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 3)            387         dense_7[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 21,232,517\n",
      "Trainable params: 1,232,517\n",
      "Non-trainable params: 20,000,000\n",
      "__________________________________________________________________________________________________\n",
      "Load weights from WordTC-DenseCNN5Layers-NoMeta-3P-NoEM-NoClassWeighted-3Layers-pseudo-scaled-1.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360609/360609 [==============================] - 41s 113us/step - loss: 0.0182 - acc: 0.9007 - weighted_accuracy: 0.8977 - val_loss: 0.2914 - val_acc: 0.8723 - val_weighted_accuracy: 0.8632\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 40s 110us/step - loss: 0.0181 - acc: 0.9016 - weighted_accuracy: 0.8988 - val_loss: 0.2757 - val_acc: 0.8797 - val_weighted_accuracy: 0.8691\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 40s 110us/step - loss: 0.0180 - acc: 0.9026 - weighted_accuracy: 0.9000 - val_loss: 0.2856 - val_acc: 0.8738 - val_weighted_accuracy: 0.8671\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 40s 110us/step - loss: 0.0179 - acc: 0.9029 - weighted_accuracy: 0.9005 - val_loss: 0.3056 - val_acc: 0.8634 - val_weighted_accuracy: 0.8595\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 39s 108us/step - loss: 0.0178 - acc: 0.9035 - weighted_accuracy: 0.9013 - val_loss: 0.2857 - val_acc: 0.8741 - val_weighted_accuracy: 0.8646\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 39s 108us/step - loss: 0.0178 - acc: 0.9035 - weighted_accuracy: 0.9009 - val_loss: 0.2811 - val_acc: 0.8755 - val_weighted_accuracy: 0.8668\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 39s 108us/step - loss: 0.0178 - acc: 0.9041 - weighted_accuracy: 0.9017 - val_loss: 0.3032 - val_acc: 0.8652 - val_weighted_accuracy: 0.8621\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 39s 108us/step - loss: 0.0177 - acc: 0.9042 - weighted_accuracy: 0.9017 - val_loss: 0.2923 - val_acc: 0.8718 - val_weighted_accuracy: 0.8628\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 30, 200)      20000000    first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_9 (SpatialDro (None, 30, 200)      0           embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_10 (SpatialDr (None, 30, 200)      0           embedding_5[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_5 (TimeDistrib (None, 30, 200)      80400       spatial_dropout1d_9[0][0]        \n",
      "                                                                 spatial_dropout1d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dot_49 (Dot)                    (None, 30, 30)       0           time_distributed_5[0][0]         \n",
      "                                                                 time_distributed_5[1][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_38 (Lambda)              (None, 30, 30)       0           dot_49[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_17 (Permute)            (None, 30, 30)       0           lambda_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_37 (Lambda)              (None, 30, 30)       0           dot_49[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_51 (Dot)                    (None, 30, 200)      0           permute_17[0][0]                 \n",
      "                                                                 time_distributed_5[1][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dot_50 (Dot)                    (None, 30, 200)      0           lambda_37[0][0]                  \n",
      "                                                                 time_distributed_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_45 (Concatenate)    (None, 30, 400)      0           dot_51[0][0]                     \n",
      "                                                                 time_distributed_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_46 (Concatenate)    (None, 30, 400)      0           dot_50[0][0]                     \n",
      "                                                                 time_distributed_5[1][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 30, 42)       16842       concatenate_45[0][0]             \n",
      "                                                                 concatenate_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dot_52 (Dot)                    (None, 30, 30)       0           conv1d_29[0][0]                  \n",
      "                                                                 conv1d_29[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_40 (Lambda)              (None, 30, 30)       0           dot_52[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_18 (Permute)            (None, 30, 30)       0           lambda_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_39 (Lambda)              (None, 30, 30)       0           dot_52[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_54 (Dot)                    (None, 30, 42)       0           permute_18[0][0]                 \n",
      "                                                                 conv1d_29[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_53 (Dot)                    (None, 30, 42)       0           lambda_39[0][0]                  \n",
      "                                                                 conv1d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_47 (Concatenate)    (None, 30, 484)      0           conv1d_29[0][0]                  \n",
      "                                                                 dot_54[0][0]                     \n",
      "                                                                 concatenate_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_48 (Concatenate)    (None, 30, 484)      0           conv1d_29[1][0]                  \n",
      "                                                                 dot_53[0][0]                     \n",
      "                                                                 concatenate_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 30, 42)       61026       concatenate_47[0][0]             \n",
      "                                                                 concatenate_48[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dot_55 (Dot)                    (None, 30, 30)       0           conv1d_30[0][0]                  \n",
      "                                                                 conv1d_30[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_42 (Lambda)              (None, 30, 30)       0           dot_55[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_19 (Permute)            (None, 30, 30)       0           lambda_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_41 (Lambda)              (None, 30, 30)       0           dot_55[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_57 (Dot)                    (None, 30, 42)       0           permute_19[0][0]                 \n",
      "                                                                 conv1d_30[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_56 (Dot)                    (None, 30, 42)       0           lambda_41[0][0]                  \n",
      "                                                                 conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_49 (Concatenate)    (None, 30, 568)      0           conv1d_30[0][0]                  \n",
      "                                                                 dot_57[0][0]                     \n",
      "                                                                 concatenate_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_50 (Concatenate)    (None, 30, 568)      0           conv1d_30[1][0]                  \n",
      "                                                                 dot_56[0][0]                     \n",
      "                                                                 concatenate_48[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)              (None, 30, 42)       71610       concatenate_49[0][0]             \n",
      "                                                                 concatenate_50[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dot_58 (Dot)                    (None, 30, 30)       0           conv1d_31[0][0]                  \n",
      "                                                                 conv1d_31[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_44 (Lambda)              (None, 30, 30)       0           dot_58[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_20 (Permute)            (None, 30, 30)       0           lambda_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_43 (Lambda)              (None, 30, 30)       0           dot_58[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_60 (Dot)                    (None, 30, 42)       0           permute_20[0][0]                 \n",
      "                                                                 conv1d_31[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_59 (Dot)                    (None, 30, 42)       0           lambda_43[0][0]                  \n",
      "                                                                 conv1d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_51 (Concatenate)    (None, 30, 652)      0           conv1d_31[0][0]                  \n",
      "                                                                 dot_60[0][0]                     \n",
      "                                                                 concatenate_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_52 (Concatenate)    (None, 30, 652)      0           conv1d_31[1][0]                  \n",
      "                                                                 dot_59[0][0]                     \n",
      "                                                                 concatenate_50[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_9 (Glo (None, 652)          0           concatenate_51[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_9 (GlobalM (None, 652)          0           concatenate_51[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_weighted_average_5 (A (None, 652)          652         concatenate_51[0][0]             \n",
      "                                                                 concatenate_52[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_10 (Gl (None, 652)          0           concatenate_52[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_10 (Global (None, 652)          0           concatenate_52[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_53 (Concatenate)    (None, 1956)         0           global_average_pooling1d_9[0][0] \n",
      "                                                                 global_max_pooling1d_9[0][0]     \n",
      "                                                                 attention_weighted_average_5[0][0\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_54 (Concatenate)    (None, 1956)         0           global_average_pooling1d_10[0][0]\n",
      "                                                                 global_max_pooling1d_10[0][0]    \n",
      "                                                                 attention_weighted_average_5[1][0\n",
      "__________________________________________________________________________________________________\n",
      "lambda_45 (Lambda)              (None, 1956)         0           concatenate_53[0][0]             \n",
      "                                                                 concatenate_54[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_5 (Multiply)           (None, 1956)         0           concatenate_53[0][0]             \n",
      "                                                                 concatenate_54[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_55 (Concatenate)    (None, 7824)         0           concatenate_53[0][0]             \n",
      "                                                                 concatenate_54[0][0]             \n",
      "                                                                 lambda_45[0][0]                  \n",
      "                                                                 multiply_5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 7824)         0           concatenate_55[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 128)          1001600     dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 3)            387         dense_9[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 21,232,517\n",
      "Trainable params: 1,232,517\n",
      "Non-trainable params: 20,000,000\n",
      "__________________________________________________________________________________________________\n",
      "Load weights from WordTC-DenseCNN5Layers-NoMeta-3P-NoEM-NoClassWeighted-3Layers-pseudo-scaled-2.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360609/360609 [==============================] - 41s 114us/step - loss: 0.0178 - acc: 0.9035 - weighted_accuracy: 0.9013 - val_loss: 0.3047 - val_acc: 0.8607 - val_weighted_accuracy: 0.8544\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 40s 111us/step - loss: 0.0177 - acc: 0.9038 - weighted_accuracy: 0.9015 - val_loss: 0.3224 - val_acc: 0.8540 - val_weighted_accuracy: 0.8476\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 40s 110us/step - loss: 0.0175 - acc: 0.9051 - weighted_accuracy: 0.9031 - val_loss: 0.3166 - val_acc: 0.8552 - val_weighted_accuracy: 0.8491\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 39s 110us/step - loss: 0.0175 - acc: 0.9050 - weighted_accuracy: 0.9029 - val_loss: 0.3223 - val_acc: 0.8547 - val_weighted_accuracy: 0.8496\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 40s 110us/step - loss: 0.0175 - acc: 0.9056 - weighted_accuracy: 0.9036 - val_loss: 0.3212 - val_acc: 0.8524 - val_weighted_accuracy: 0.8473\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 40s 110us/step - loss: 0.0174 - acc: 0.9056 - weighted_accuracy: 0.9037 - val_loss: 0.3229 - val_acc: 0.8525 - val_weighted_accuracy: 0.8489\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 40s 110us/step - loss: 0.0173 - acc: 0.9063 - weighted_accuracy: 0.9045 - val_loss: 0.3083 - val_acc: 0.8578 - val_weighted_accuracy: 0.8523\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 30, 200)      20000000    first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_11 (SpatialDr (None, 30, 200)      0           embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_12 (SpatialDr (None, 30, 200)      0           embedding_6[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_6 (TimeDistrib (None, 30, 200)      80400       spatial_dropout1d_11[0][0]       \n",
      "                                                                 spatial_dropout1d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dot_61 (Dot)                    (None, 30, 30)       0           time_distributed_6[0][0]         \n",
      "                                                                 time_distributed_6[1][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_47 (Lambda)              (None, 30, 30)       0           dot_61[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_21 (Permute)            (None, 30, 30)       0           lambda_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_46 (Lambda)              (None, 30, 30)       0           dot_61[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_63 (Dot)                    (None, 30, 200)      0           permute_21[0][0]                 \n",
      "                                                                 time_distributed_6[1][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dot_62 (Dot)                    (None, 30, 200)      0           lambda_46[0][0]                  \n",
      "                                                                 time_distributed_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_56 (Concatenate)    (None, 30, 400)      0           dot_63[0][0]                     \n",
      "                                                                 time_distributed_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_57 (Concatenate)    (None, 30, 400)      0           dot_62[0][0]                     \n",
      "                                                                 time_distributed_6[1][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)              (None, 30, 42)       16842       concatenate_56[0][0]             \n",
      "                                                                 concatenate_57[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dot_64 (Dot)                    (None, 30, 30)       0           conv1d_36[0][0]                  \n",
      "                                                                 conv1d_36[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_49 (Lambda)              (None, 30, 30)       0           dot_64[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_22 (Permute)            (None, 30, 30)       0           lambda_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_48 (Lambda)              (None, 30, 30)       0           dot_64[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_66 (Dot)                    (None, 30, 42)       0           permute_22[0][0]                 \n",
      "                                                                 conv1d_36[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_65 (Dot)                    (None, 30, 42)       0           lambda_48[0][0]                  \n",
      "                                                                 conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_58 (Concatenate)    (None, 30, 484)      0           conv1d_36[0][0]                  \n",
      "                                                                 dot_66[0][0]                     \n",
      "                                                                 concatenate_56[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_59 (Concatenate)    (None, 30, 484)      0           conv1d_36[1][0]                  \n",
      "                                                                 dot_65[0][0]                     \n",
      "                                                                 concatenate_57[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 30, 42)       61026       concatenate_58[0][0]             \n",
      "                                                                 concatenate_59[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dot_67 (Dot)                    (None, 30, 30)       0           conv1d_37[0][0]                  \n",
      "                                                                 conv1d_37[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_51 (Lambda)              (None, 30, 30)       0           dot_67[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_23 (Permute)            (None, 30, 30)       0           lambda_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_50 (Lambda)              (None, 30, 30)       0           dot_67[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_69 (Dot)                    (None, 30, 42)       0           permute_23[0][0]                 \n",
      "                                                                 conv1d_37[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_68 (Dot)                    (None, 30, 42)       0           lambda_50[0][0]                  \n",
      "                                                                 conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_60 (Concatenate)    (None, 30, 568)      0           conv1d_37[0][0]                  \n",
      "                                                                 dot_69[0][0]                     \n",
      "                                                                 concatenate_58[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_61 (Concatenate)    (None, 30, 568)      0           conv1d_37[1][0]                  \n",
      "                                                                 dot_68[0][0]                     \n",
      "                                                                 concatenate_59[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)              (None, 30, 42)       71610       concatenate_60[0][0]             \n",
      "                                                                 concatenate_61[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dot_70 (Dot)                    (None, 30, 30)       0           conv1d_38[0][0]                  \n",
      "                                                                 conv1d_38[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_53 (Lambda)              (None, 30, 30)       0           dot_70[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_24 (Permute)            (None, 30, 30)       0           lambda_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_52 (Lambda)              (None, 30, 30)       0           dot_70[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_72 (Dot)                    (None, 30, 42)       0           permute_24[0][0]                 \n",
      "                                                                 conv1d_38[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_71 (Dot)                    (None, 30, 42)       0           lambda_52[0][0]                  \n",
      "                                                                 conv1d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_62 (Concatenate)    (None, 30, 652)      0           conv1d_38[0][0]                  \n",
      "                                                                 dot_72[0][0]                     \n",
      "                                                                 concatenate_60[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_63 (Concatenate)    (None, 30, 652)      0           conv1d_38[1][0]                  \n",
      "                                                                 dot_71[0][0]                     \n",
      "                                                                 concatenate_61[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_11 (Gl (None, 652)          0           concatenate_62[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_11 (Global (None, 652)          0           concatenate_62[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_weighted_average_6 (A (None, 652)          652         concatenate_62[0][0]             \n",
      "                                                                 concatenate_63[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_12 (Gl (None, 652)          0           concatenate_63[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_12 (Global (None, 652)          0           concatenate_63[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_64 (Concatenate)    (None, 1956)         0           global_average_pooling1d_11[0][0]\n",
      "                                                                 global_max_pooling1d_11[0][0]    \n",
      "                                                                 attention_weighted_average_6[0][0\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_65 (Concatenate)    (None, 1956)         0           global_average_pooling1d_12[0][0]\n",
      "                                                                 global_max_pooling1d_12[0][0]    \n",
      "                                                                 attention_weighted_average_6[1][0\n",
      "__________________________________________________________________________________________________\n",
      "lambda_54 (Lambda)              (None, 1956)         0           concatenate_64[0][0]             \n",
      "                                                                 concatenate_65[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_6 (Multiply)           (None, 1956)         0           concatenate_64[0][0]             \n",
      "                                                                 concatenate_65[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_66 (Concatenate)    (None, 7824)         0           concatenate_64[0][0]             \n",
      "                                                                 concatenate_65[0][0]             \n",
      "                                                                 lambda_54[0][0]                  \n",
      "                                                                 multiply_6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 7824)         0           concatenate_66[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 128)          1001600     dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 3)            387         dense_11[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 21,232,517\n",
      "Trainable params: 1,232,517\n",
      "Non-trainable params: 20,000,000\n",
      "__________________________________________________________________________________________________\n",
      "Load weights from WordTC-DenseCNN5Layers-NoMeta-3P-NoEM-NoClassWeighted-3Layers-pseudo-scaled-3.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360609/360609 [==============================] - 41s 114us/step - loss: 0.0182 - acc: 0.9007 - weighted_accuracy: 0.8975 - val_loss: 0.3028 - val_acc: 0.8665 - val_weighted_accuracy: 0.8594\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 40s 110us/step - loss: 0.0181 - acc: 0.9021 - weighted_accuracy: 0.8989 - val_loss: 0.3222 - val_acc: 0.8553 - val_weighted_accuracy: 0.8535\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 40s 111us/step - loss: 0.0180 - acc: 0.9015 - weighted_accuracy: 0.8986 - val_loss: 0.3161 - val_acc: 0.8576 - val_weighted_accuracy: 0.8553\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 40s 111us/step - loss: 0.0179 - acc: 0.9029 - weighted_accuracy: 0.9003 - val_loss: 0.3037 - val_acc: 0.8648 - val_weighted_accuracy: 0.8596\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 40s 110us/step - loss: 0.0179 - acc: 0.9027 - weighted_accuracy: 0.9001 - val_loss: 0.3193 - val_acc: 0.8559 - val_weighted_accuracy: 0.8533\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 40s 110us/step - loss: 0.0178 - acc: 0.9034 - weighted_accuracy: 0.9010 - val_loss: 0.3117 - val_acc: 0.8621 - val_weighted_accuracy: 0.8593\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 39s 109us/step - loss: 0.0176 - acc: 0.9042 - weighted_accuracy: 0.9020 - val_loss: 0.3008 - val_acc: 0.8662 - val_weighted_accuracy: 0.8587\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 39s 109us/step - loss: 0.0176 - acc: 0.9047 - weighted_accuracy: 0.9025 - val_loss: 0.2995 - val_acc: 0.8679 - val_weighted_accuracy: 0.8604\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 40s 110us/step - loss: 0.0176 - acc: 0.9046 - weighted_accuracy: 0.9024 - val_loss: 0.3013 - val_acc: 0.8667 - val_weighted_accuracy: 0.8599\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 40s 110us/step - loss: 0.0175 - acc: 0.9050 - weighted_accuracy: 0.9026 - val_loss: 0.3246 - val_acc: 0.8538 - val_weighted_accuracy: 0.8535\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 40s 110us/step - loss: 0.0174 - acc: 0.9058 - weighted_accuracy: 0.9040 - val_loss: 0.3167 - val_acc: 0.8598 - val_weighted_accuracy: 0.8556\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 40s 110us/step - loss: 0.0174 - acc: 0.9061 - weighted_accuracy: 0.9039 - val_loss: 0.3052 - val_acc: 0.8647 - val_weighted_accuracy: 0.8592\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 39s 109us/step - loss: 0.0172 - acc: 0.9066 - weighted_accuracy: 0.9049 - val_loss: 0.3026 - val_acc: 0.8677 - val_weighted_accuracy: 0.8615\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 39s 109us/step - loss: 0.0172 - acc: 0.9079 - weighted_accuracy: 0.9062 - val_loss: 0.3159 - val_acc: 0.8595 - val_weighted_accuracy: 0.8555\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 40s 110us/step - loss: 0.0172 - acc: 0.9069 - weighted_accuracy: 0.9052 - val_loss: 0.3168 - val_acc: 0.8584 - val_weighted_accuracy: 0.8559\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 39s 109us/step - loss: 0.0171 - acc: 0.9076 - weighted_accuracy: 0.9060 - val_loss: 0.3087 - val_acc: 0.8617 - val_weighted_accuracy: 0.8581\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 40s 111us/step - loss: 0.0170 - acc: 0.9082 - weighted_accuracy: 0.9065 - val_loss: 0.3010 - val_acc: 0.8681 - val_weighted_accuracy: 0.8632\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 40s 110us/step - loss: 0.0170 - acc: 0.9086 - weighted_accuracy: 0.9070 - val_loss: 0.3075 - val_acc: 0.8624 - val_weighted_accuracy: 0.8591\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 40s 110us/step - loss: 0.0169 - acc: 0.9094 - weighted_accuracy: 0.9081 - val_loss: 0.3058 - val_acc: 0.8646 - val_weighted_accuracy: 0.8583\n",
      "Epoch 20/500\n",
      "360609/360609 [==============================] - 39s 109us/step - loss: 0.0169 - acc: 0.9092 - weighted_accuracy: 0.9077 - val_loss: 0.3060 - val_acc: 0.8630 - val_weighted_accuracy: 0.8584\n",
      "Epoch 21/500\n",
      "360609/360609 [==============================] - 40s 110us/step - loss: 0.0169 - acc: 0.9093 - weighted_accuracy: 0.9079 - val_loss: 0.3156 - val_acc: 0.8592 - val_weighted_accuracy: 0.8549\n",
      "Epoch 22/500\n",
      "360609/360609 [==============================] - 39s 109us/step - loss: 0.0168 - acc: 0.9105 - weighted_accuracy: 0.9094 - val_loss: 0.3127 - val_acc: 0.8616 - val_weighted_accuracy: 0.8562\n",
      "Epoch 23/500\n",
      "360609/360609 [==============================] - 41s 112us/step - loss: 0.0168 - acc: 0.9102 - weighted_accuracy: 0.9088 - val_loss: 0.3051 - val_acc: 0.8641 - val_weighted_accuracy: 0.8567\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, 30, 200)      20000000    first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_13 (SpatialDr (None, 30, 200)      0           embedding_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_14 (SpatialDr (None, 30, 200)      0           embedding_7[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_7 (TimeDistrib (None, 30, 200)      80400       spatial_dropout1d_13[0][0]       \n",
      "                                                                 spatial_dropout1d_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dot_73 (Dot)                    (None, 30, 30)       0           time_distributed_7[0][0]         \n",
      "                                                                 time_distributed_7[1][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_56 (Lambda)              (None, 30, 30)       0           dot_73[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_25 (Permute)            (None, 30, 30)       0           lambda_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_55 (Lambda)              (None, 30, 30)       0           dot_73[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_75 (Dot)                    (None, 30, 200)      0           permute_25[0][0]                 \n",
      "                                                                 time_distributed_7[1][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dot_74 (Dot)                    (None, 30, 200)      0           lambda_55[0][0]                  \n",
      "                                                                 time_distributed_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_67 (Concatenate)    (None, 30, 400)      0           dot_75[0][0]                     \n",
      "                                                                 time_distributed_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_68 (Concatenate)    (None, 30, 400)      0           dot_74[0][0]                     \n",
      "                                                                 time_distributed_7[1][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_43 (Conv1D)              (None, 30, 42)       16842       concatenate_67[0][0]             \n",
      "                                                                 concatenate_68[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dot_76 (Dot)                    (None, 30, 30)       0           conv1d_43[0][0]                  \n",
      "                                                                 conv1d_43[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_58 (Lambda)              (None, 30, 30)       0           dot_76[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_26 (Permute)            (None, 30, 30)       0           lambda_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_57 (Lambda)              (None, 30, 30)       0           dot_76[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_78 (Dot)                    (None, 30, 42)       0           permute_26[0][0]                 \n",
      "                                                                 conv1d_43[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_77 (Dot)                    (None, 30, 42)       0           lambda_57[0][0]                  \n",
      "                                                                 conv1d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_69 (Concatenate)    (None, 30, 484)      0           conv1d_43[0][0]                  \n",
      "                                                                 dot_78[0][0]                     \n",
      "                                                                 concatenate_67[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_70 (Concatenate)    (None, 30, 484)      0           conv1d_43[1][0]                  \n",
      "                                                                 dot_77[0][0]                     \n",
      "                                                                 concatenate_68[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_44 (Conv1D)              (None, 30, 42)       61026       concatenate_69[0][0]             \n",
      "                                                                 concatenate_70[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dot_79 (Dot)                    (None, 30, 30)       0           conv1d_44[0][0]                  \n",
      "                                                                 conv1d_44[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_60 (Lambda)              (None, 30, 30)       0           dot_79[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_27 (Permute)            (None, 30, 30)       0           lambda_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_59 (Lambda)              (None, 30, 30)       0           dot_79[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_81 (Dot)                    (None, 30, 42)       0           permute_27[0][0]                 \n",
      "                                                                 conv1d_44[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_80 (Dot)                    (None, 30, 42)       0           lambda_59[0][0]                  \n",
      "                                                                 conv1d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_71 (Concatenate)    (None, 30, 568)      0           conv1d_44[0][0]                  \n",
      "                                                                 dot_81[0][0]                     \n",
      "                                                                 concatenate_69[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_72 (Concatenate)    (None, 30, 568)      0           conv1d_44[1][0]                  \n",
      "                                                                 dot_80[0][0]                     \n",
      "                                                                 concatenate_70[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_45 (Conv1D)              (None, 30, 42)       71610       concatenate_71[0][0]             \n",
      "                                                                 concatenate_72[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dot_82 (Dot)                    (None, 30, 30)       0           conv1d_45[0][0]                  \n",
      "                                                                 conv1d_45[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_62 (Lambda)              (None, 30, 30)       0           dot_82[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_28 (Permute)            (None, 30, 30)       0           lambda_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_61 (Lambda)              (None, 30, 30)       0           dot_82[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_84 (Dot)                    (None, 30, 42)       0           permute_28[0][0]                 \n",
      "                                                                 conv1d_45[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_83 (Dot)                    (None, 30, 42)       0           lambda_61[0][0]                  \n",
      "                                                                 conv1d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_73 (Concatenate)    (None, 30, 652)      0           conv1d_45[0][0]                  \n",
      "                                                                 dot_84[0][0]                     \n",
      "                                                                 concatenate_71[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_74 (Concatenate)    (None, 30, 652)      0           conv1d_45[1][0]                  \n",
      "                                                                 dot_83[0][0]                     \n",
      "                                                                 concatenate_72[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_13 (Gl (None, 652)          0           concatenate_73[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_13 (Global (None, 652)          0           concatenate_73[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_weighted_average_7 (A (None, 652)          652         concatenate_73[0][0]             \n",
      "                                                                 concatenate_74[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_14 (Gl (None, 652)          0           concatenate_74[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_14 (Global (None, 652)          0           concatenate_74[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_75 (Concatenate)    (None, 1956)         0           global_average_pooling1d_13[0][0]\n",
      "                                                                 global_max_pooling1d_13[0][0]    \n",
      "                                                                 attention_weighted_average_7[0][0\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_76 (Concatenate)    (None, 1956)         0           global_average_pooling1d_14[0][0]\n",
      "                                                                 global_max_pooling1d_14[0][0]    \n",
      "                                                                 attention_weighted_average_7[1][0\n",
      "__________________________________________________________________________________________________\n",
      "lambda_63 (Lambda)              (None, 1956)         0           concatenate_75[0][0]             \n",
      "                                                                 concatenate_76[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_7 (Multiply)           (None, 1956)         0           concatenate_75[0][0]             \n",
      "                                                                 concatenate_76[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_77 (Concatenate)    (None, 7824)         0           concatenate_75[0][0]             \n",
      "                                                                 concatenate_76[0][0]             \n",
      "                                                                 lambda_63[0][0]                  \n",
      "                                                                 multiply_7[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 7824)         0           concatenate_77[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 128)          1001600     dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 3)            387         dense_13[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 21,232,517\n",
      "Trainable params: 1,232,517\n",
      "Non-trainable params: 20,000,000\n",
      "__________________________________________________________________________________________________\n",
      "Load weights from WordTC-DenseCNN5Layers-NoMeta-3P-NoEM-NoClassWeighted-3Layers-pseudo-scaled-4.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360609/360609 [==============================] - 42s 118us/step - loss: 0.0199 - acc: 0.8882 - weighted_accuracy: 0.8834 - val_loss: 0.3349 - val_acc: 0.8460 - val_weighted_accuracy: 0.8444\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 41s 114us/step - loss: 0.0196 - acc: 0.8909 - weighted_accuracy: 0.8863 - val_loss: 0.3297 - val_acc: 0.8483 - val_weighted_accuracy: 0.8453\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 41s 114us/step - loss: 0.0196 - acc: 0.8910 - weighted_accuracy: 0.8863 - val_loss: 0.3133 - val_acc: 0.8552 - val_weighted_accuracy: 0.8492\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 41s 112us/step - loss: 0.0193 - acc: 0.8935 - weighted_accuracy: 0.8893 - val_loss: 0.3273 - val_acc: 0.8494 - val_weighted_accuracy: 0.8464\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 40s 112us/step - loss: 0.0192 - acc: 0.8940 - weighted_accuracy: 0.8899 - val_loss: 0.3214 - val_acc: 0.8501 - val_weighted_accuracy: 0.8472\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 40s 112us/step - loss: 0.0191 - acc: 0.8946 - weighted_accuracy: 0.8904 - val_loss: 0.3433 - val_acc: 0.8401 - val_weighted_accuracy: 0.8393\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 40s 112us/step - loss: 0.0190 - acc: 0.8953 - weighted_accuracy: 0.8913 - val_loss: 0.3233 - val_acc: 0.8514 - val_weighted_accuracy: 0.8486\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 41s 112us/step - loss: 0.0188 - acc: 0.8966 - weighted_accuracy: 0.8928 - val_loss: 0.3353 - val_acc: 0.8441 - val_weighted_accuracy: 0.8429\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 40s 111us/step - loss: 0.0188 - acc: 0.8971 - weighted_accuracy: 0.8934 - val_loss: 0.3270 - val_acc: 0.8506 - val_weighted_accuracy: 0.8482\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)         (None, 30, 200)      20000000    first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_15 (SpatialDr (None, 30, 200)      0           embedding_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_16 (SpatialDr (None, 30, 200)      0           embedding_8[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_8 (TimeDistrib (None, 30, 200)      80400       spatial_dropout1d_15[0][0]       \n",
      "                                                                 spatial_dropout1d_16[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dot_85 (Dot)                    (None, 30, 30)       0           time_distributed_8[0][0]         \n",
      "                                                                 time_distributed_8[1][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_65 (Lambda)              (None, 30, 30)       0           dot_85[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_29 (Permute)            (None, 30, 30)       0           lambda_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_64 (Lambda)              (None, 30, 30)       0           dot_85[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_87 (Dot)                    (None, 30, 200)      0           permute_29[0][0]                 \n",
      "                                                                 time_distributed_8[1][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dot_86 (Dot)                    (None, 30, 200)      0           lambda_64[0][0]                  \n",
      "                                                                 time_distributed_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_78 (Concatenate)    (None, 30, 400)      0           dot_87[0][0]                     \n",
      "                                                                 time_distributed_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_79 (Concatenate)    (None, 30, 400)      0           dot_86[0][0]                     \n",
      "                                                                 time_distributed_8[1][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_50 (Conv1D)              (None, 30, 42)       16842       concatenate_78[0][0]             \n",
      "                                                                 concatenate_79[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dot_88 (Dot)                    (None, 30, 30)       0           conv1d_50[0][0]                  \n",
      "                                                                 conv1d_50[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_67 (Lambda)              (None, 30, 30)       0           dot_88[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_30 (Permute)            (None, 30, 30)       0           lambda_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_66 (Lambda)              (None, 30, 30)       0           dot_88[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_90 (Dot)                    (None, 30, 42)       0           permute_30[0][0]                 \n",
      "                                                                 conv1d_50[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_89 (Dot)                    (None, 30, 42)       0           lambda_66[0][0]                  \n",
      "                                                                 conv1d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_80 (Concatenate)    (None, 30, 484)      0           conv1d_50[0][0]                  \n",
      "                                                                 dot_90[0][0]                     \n",
      "                                                                 concatenate_78[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_81 (Concatenate)    (None, 30, 484)      0           conv1d_50[1][0]                  \n",
      "                                                                 dot_89[0][0]                     \n",
      "                                                                 concatenate_79[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_51 (Conv1D)              (None, 30, 42)       61026       concatenate_80[0][0]             \n",
      "                                                                 concatenate_81[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dot_91 (Dot)                    (None, 30, 30)       0           conv1d_51[0][0]                  \n",
      "                                                                 conv1d_51[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_69 (Lambda)              (None, 30, 30)       0           dot_91[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_31 (Permute)            (None, 30, 30)       0           lambda_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_68 (Lambda)              (None, 30, 30)       0           dot_91[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_93 (Dot)                    (None, 30, 42)       0           permute_31[0][0]                 \n",
      "                                                                 conv1d_51[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_92 (Dot)                    (None, 30, 42)       0           lambda_68[0][0]                  \n",
      "                                                                 conv1d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_82 (Concatenate)    (None, 30, 568)      0           conv1d_51[0][0]                  \n",
      "                                                                 dot_93[0][0]                     \n",
      "                                                                 concatenate_80[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_83 (Concatenate)    (None, 30, 568)      0           conv1d_51[1][0]                  \n",
      "                                                                 dot_92[0][0]                     \n",
      "                                                                 concatenate_81[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_52 (Conv1D)              (None, 30, 42)       71610       concatenate_82[0][0]             \n",
      "                                                                 concatenate_83[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dot_94 (Dot)                    (None, 30, 30)       0           conv1d_52[0][0]                  \n",
      "                                                                 conv1d_52[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_71 (Lambda)              (None, 30, 30)       0           dot_94[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_32 (Permute)            (None, 30, 30)       0           lambda_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_70 (Lambda)              (None, 30, 30)       0           dot_94[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_96 (Dot)                    (None, 30, 42)       0           permute_32[0][0]                 \n",
      "                                                                 conv1d_52[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_95 (Dot)                    (None, 30, 42)       0           lambda_70[0][0]                  \n",
      "                                                                 conv1d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_84 (Concatenate)    (None, 30, 652)      0           conv1d_52[0][0]                  \n",
      "                                                                 dot_96[0][0]                     \n",
      "                                                                 concatenate_82[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_85 (Concatenate)    (None, 30, 652)      0           conv1d_52[1][0]                  \n",
      "                                                                 dot_95[0][0]                     \n",
      "                                                                 concatenate_83[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_15 (Gl (None, 652)          0           concatenate_84[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_15 (Global (None, 652)          0           concatenate_84[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_weighted_average_8 (A (None, 652)          652         concatenate_84[0][0]             \n",
      "                                                                 concatenate_85[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_16 (Gl (None, 652)          0           concatenate_85[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_16 (Global (None, 652)          0           concatenate_85[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_86 (Concatenate)    (None, 1956)         0           global_average_pooling1d_15[0][0]\n",
      "                                                                 global_max_pooling1d_15[0][0]    \n",
      "                                                                 attention_weighted_average_8[0][0\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_87 (Concatenate)    (None, 1956)         0           global_average_pooling1d_16[0][0]\n",
      "                                                                 global_max_pooling1d_16[0][0]    \n",
      "                                                                 attention_weighted_average_8[1][0\n",
      "__________________________________________________________________________________________________\n",
      "lambda_72 (Lambda)              (None, 1956)         0           concatenate_86[0][0]             \n",
      "                                                                 concatenate_87[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_8 (Multiply)           (None, 1956)         0           concatenate_86[0][0]             \n",
      "                                                                 concatenate_87[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_88 (Concatenate)    (None, 7824)         0           concatenate_86[0][0]             \n",
      "                                                                 concatenate_87[0][0]             \n",
      "                                                                 lambda_72[0][0]                  \n",
      "                                                                 multiply_8[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 7824)         0           concatenate_88[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 128)          1001600     dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 3)            387         dense_15[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 21,232,517\n",
      "Trainable params: 1,232,517\n",
      "Non-trainable params: 20,000,000\n",
      "__________________________________________________________________________________________________\n",
      "Load weights from WordTC-DenseCNN5Layers-NoMeta-3P-NoEM-NoClassWeighted-3Layers-pseudo-scaled-5.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360609/360609 [==============================] - 41s 115us/step - loss: 0.0179 - acc: 0.9026 - weighted_accuracy: 0.8996 - val_loss: 0.3466 - val_acc: 0.8352 - val_weighted_accuracy: 0.8289\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 40s 112us/step - loss: 0.0177 - acc: 0.9045 - weighted_accuracy: 0.9018 - val_loss: 0.3487 - val_acc: 0.8375 - val_weighted_accuracy: 0.8298\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 40s 111us/step - loss: 0.0178 - acc: 0.9039 - weighted_accuracy: 0.9010 - val_loss: 0.3268 - val_acc: 0.8490 - val_weighted_accuracy: 0.8353\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 40s 111us/step - loss: 0.0176 - acc: 0.9051 - weighted_accuracy: 0.9022 - val_loss: 0.3352 - val_acc: 0.8431 - val_weighted_accuracy: 0.8363\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 40s 110us/step - loss: 0.0175 - acc: 0.9056 - weighted_accuracy: 0.9031 - val_loss: 0.3362 - val_acc: 0.8456 - val_weighted_accuracy: 0.8369\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 40s 110us/step - loss: 0.0175 - acc: 0.9049 - weighted_accuracy: 0.9025 - val_loss: 0.3228 - val_acc: 0.8512 - val_weighted_accuracy: 0.8390\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 40s 111us/step - loss: 0.0174 - acc: 0.9062 - weighted_accuracy: 0.9040 - val_loss: 0.3421 - val_acc: 0.8421 - val_weighted_accuracy: 0.8357\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 40s 110us/step - loss: 0.0173 - acc: 0.9069 - weighted_accuracy: 0.9047 - val_loss: 0.3327 - val_acc: 0.8434 - val_weighted_accuracy: 0.8353\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 40s 111us/step - loss: 0.0172 - acc: 0.9077 - weighted_accuracy: 0.9056 - val_loss: 0.3376 - val_acc: 0.8407 - val_weighted_accuracy: 0.8308\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 40s 110us/step - loss: 0.0172 - acc: 0.9072 - weighted_accuracy: 0.9050 - val_loss: 0.3251 - val_acc: 0.8503 - val_weighted_accuracy: 0.8399\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 40s 110us/step - loss: 0.0171 - acc: 0.9081 - weighted_accuracy: 0.9060 - val_loss: 0.3334 - val_acc: 0.8453 - val_weighted_accuracy: 0.8383\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 40s 110us/step - loss: 0.0171 - acc: 0.9084 - weighted_accuracy: 0.9063 - val_loss: 0.3420 - val_acc: 0.8382 - val_weighted_accuracy: 0.8346\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 39s 109us/step - loss: 0.0170 - acc: 0.9088 - weighted_accuracy: 0.9069 - val_loss: 0.3250 - val_acc: 0.8495 - val_weighted_accuracy: 0.8428\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 40s 110us/step - loss: 0.0170 - acc: 0.9097 - weighted_accuracy: 0.9079 - val_loss: 0.3257 - val_acc: 0.8488 - val_weighted_accuracy: 0.8382\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 40s 111us/step - loss: 0.0169 - acc: 0.9102 - weighted_accuracy: 0.9082 - val_loss: 0.3353 - val_acc: 0.8455 - val_weighted_accuracy: 0.8388\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 40s 110us/step - loss: 0.0168 - acc: 0.9101 - weighted_accuracy: 0.9082 - val_loss: 0.3469 - val_acc: 0.8395 - val_weighted_accuracy: 0.8376\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 40s 110us/step - loss: 0.0168 - acc: 0.9096 - weighted_accuracy: 0.9080 - val_loss: 0.3426 - val_acc: 0.8398 - val_weighted_accuracy: 0.8349\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 40s 111us/step - loss: 0.0168 - acc: 0.9107 - weighted_accuracy: 0.9090 - val_loss: 0.3367 - val_acc: 0.8420 - val_weighted_accuracy: 0.8368\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 40s 111us/step - loss: 0.0166 - acc: 0.9112 - weighted_accuracy: 0.9097 - val_loss: 0.3334 - val_acc: 0.8470 - val_weighted_accuracy: 0.8434\n",
      "Epoch 20/500\n",
      "360609/360609 [==============================] - 40s 112us/step - loss: 0.0166 - acc: 0.9111 - weighted_accuracy: 0.9099 - val_loss: 0.3334 - val_acc: 0.8476 - val_weighted_accuracy: 0.8326\n",
      "Epoch 21/500\n",
      "360609/360609 [==============================] - 41s 113us/step - loss: 0.0166 - acc: 0.9113 - weighted_accuracy: 0.9097 - val_loss: 0.3383 - val_acc: 0.8448 - val_weighted_accuracy: 0.8398\n",
      "Epoch 22/500\n",
      "360609/360609 [==============================] - 40s 111us/step - loss: 0.0165 - acc: 0.9121 - weighted_accuracy: 0.9108 - val_loss: 0.3381 - val_acc: 0.8435 - val_weighted_accuracy: 0.8384\n",
      "Epoch 23/500\n",
      "360609/360609 [==============================] - 40s 110us/step - loss: 0.0165 - acc: 0.9122 - weighted_accuracy: 0.9109 - val_loss: 0.3334 - val_acc: 0.8473 - val_weighted_accuracy: 0.8380\n",
      "Epoch 24/500\n",
      "360609/360609 [==============================] - 39s 109us/step - loss: 0.0164 - acc: 0.9128 - weighted_accuracy: 0.9115 - val_loss: 0.3546 - val_acc: 0.8383 - val_weighted_accuracy: 0.8321\n",
      "Epoch 25/500\n",
      "360609/360609 [==============================] - 40s 110us/step - loss: 0.0164 - acc: 0.9125 - weighted_accuracy: 0.9111 - val_loss: 0.3331 - val_acc: 0.8458 - val_weighted_accuracy: 0.8360\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_9 (Embedding)         (None, 30, 200)      20000000    first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_17 (SpatialDr (None, 30, 200)      0           embedding_9[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_18 (SpatialDr (None, 30, 200)      0           embedding_9[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_9 (TimeDistrib (None, 30, 200)      80400       spatial_dropout1d_17[0][0]       \n",
      "                                                                 spatial_dropout1d_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dot_97 (Dot)                    (None, 30, 30)       0           time_distributed_9[0][0]         \n",
      "                                                                 time_distributed_9[1][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_74 (Lambda)              (None, 30, 30)       0           dot_97[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_33 (Permute)            (None, 30, 30)       0           lambda_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_73 (Lambda)              (None, 30, 30)       0           dot_97[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_99 (Dot)                    (None, 30, 200)      0           permute_33[0][0]                 \n",
      "                                                                 time_distributed_9[1][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dot_98 (Dot)                    (None, 30, 200)      0           lambda_73[0][0]                  \n",
      "                                                                 time_distributed_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_89 (Concatenate)    (None, 30, 400)      0           dot_99[0][0]                     \n",
      "                                                                 time_distributed_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_90 (Concatenate)    (None, 30, 400)      0           dot_98[0][0]                     \n",
      "                                                                 time_distributed_9[1][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_57 (Conv1D)              (None, 30, 42)       16842       concatenate_89[0][0]             \n",
      "                                                                 concatenate_90[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dot_100 (Dot)                   (None, 30, 30)       0           conv1d_57[0][0]                  \n",
      "                                                                 conv1d_57[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_76 (Lambda)              (None, 30, 30)       0           dot_100[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_34 (Permute)            (None, 30, 30)       0           lambda_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_75 (Lambda)              (None, 30, 30)       0           dot_100[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_102 (Dot)                   (None, 30, 42)       0           permute_34[0][0]                 \n",
      "                                                                 conv1d_57[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_101 (Dot)                   (None, 30, 42)       0           lambda_75[0][0]                  \n",
      "                                                                 conv1d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_91 (Concatenate)    (None, 30, 484)      0           conv1d_57[0][0]                  \n",
      "                                                                 dot_102[0][0]                    \n",
      "                                                                 concatenate_89[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_92 (Concatenate)    (None, 30, 484)      0           conv1d_57[1][0]                  \n",
      "                                                                 dot_101[0][0]                    \n",
      "                                                                 concatenate_90[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_58 (Conv1D)              (None, 30, 42)       61026       concatenate_91[0][0]             \n",
      "                                                                 concatenate_92[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dot_103 (Dot)                   (None, 30, 30)       0           conv1d_58[0][0]                  \n",
      "                                                                 conv1d_58[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_78 (Lambda)              (None, 30, 30)       0           dot_103[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_35 (Permute)            (None, 30, 30)       0           lambda_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_77 (Lambda)              (None, 30, 30)       0           dot_103[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_105 (Dot)                   (None, 30, 42)       0           permute_35[0][0]                 \n",
      "                                                                 conv1d_58[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_104 (Dot)                   (None, 30, 42)       0           lambda_77[0][0]                  \n",
      "                                                                 conv1d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_93 (Concatenate)    (None, 30, 568)      0           conv1d_58[0][0]                  \n",
      "                                                                 dot_105[0][0]                    \n",
      "                                                                 concatenate_91[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_94 (Concatenate)    (None, 30, 568)      0           conv1d_58[1][0]                  \n",
      "                                                                 dot_104[0][0]                    \n",
      "                                                                 concatenate_92[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_59 (Conv1D)              (None, 30, 42)       71610       concatenate_93[0][0]             \n",
      "                                                                 concatenate_94[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dot_106 (Dot)                   (None, 30, 30)       0           conv1d_59[0][0]                  \n",
      "                                                                 conv1d_59[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_80 (Lambda)              (None, 30, 30)       0           dot_106[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_36 (Permute)            (None, 30, 30)       0           lambda_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_79 (Lambda)              (None, 30, 30)       0           dot_106[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_108 (Dot)                   (None, 30, 42)       0           permute_36[0][0]                 \n",
      "                                                                 conv1d_59[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_107 (Dot)                   (None, 30, 42)       0           lambda_79[0][0]                  \n",
      "                                                                 conv1d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_95 (Concatenate)    (None, 30, 652)      0           conv1d_59[0][0]                  \n",
      "                                                                 dot_108[0][0]                    \n",
      "                                                                 concatenate_93[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_96 (Concatenate)    (None, 30, 652)      0           conv1d_59[1][0]                  \n",
      "                                                                 dot_107[0][0]                    \n",
      "                                                                 concatenate_94[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_17 (Gl (None, 652)          0           concatenate_95[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_17 (Global (None, 652)          0           concatenate_95[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_weighted_average_9 (A (None, 652)          652         concatenate_95[0][0]             \n",
      "                                                                 concatenate_96[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_18 (Gl (None, 652)          0           concatenate_96[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_18 (Global (None, 652)          0           concatenate_96[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_97 (Concatenate)    (None, 1956)         0           global_average_pooling1d_17[0][0]\n",
      "                                                                 global_max_pooling1d_17[0][0]    \n",
      "                                                                 attention_weighted_average_9[0][0\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_98 (Concatenate)    (None, 1956)         0           global_average_pooling1d_18[0][0]\n",
      "                                                                 global_max_pooling1d_18[0][0]    \n",
      "                                                                 attention_weighted_average_9[1][0\n",
      "__________________________________________________________________________________________________\n",
      "lambda_81 (Lambda)              (None, 1956)         0           concatenate_97[0][0]             \n",
      "                                                                 concatenate_98[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_9 (Multiply)           (None, 1956)         0           concatenate_97[0][0]             \n",
      "                                                                 concatenate_98[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_99 (Concatenate)    (None, 7824)         0           concatenate_97[0][0]             \n",
      "                                                                 concatenate_98[0][0]             \n",
      "                                                                 lambda_81[0][0]                  \n",
      "                                                                 multiply_9[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 7824)         0           concatenate_99[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 128)          1001600     dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 3)            387         dense_17[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 21,232,517\n",
      "Trainable params: 1,232,517\n",
      "Non-trainable params: 20,000,000\n",
      "__________________________________________________________________________________________________\n",
      "Load weights from WordTC-DenseCNN5Layers-NoMeta-3P-NoEM-NoClassWeighted-3Layers-pseudo-scaled-6.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360609/360609 [==============================] - 41s 114us/step - loss: 0.0181 - acc: 0.9003 - weighted_accuracy: 0.8975 - val_loss: 0.3084 - val_acc: 0.8639 - val_weighted_accuracy: 0.8577\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 40s 110us/step - loss: 0.0181 - acc: 0.9004 - weighted_accuracy: 0.8976 - val_loss: 0.3011 - val_acc: 0.8653 - val_weighted_accuracy: 0.8599\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 40s 110us/step - loss: 0.0180 - acc: 0.9020 - weighted_accuracy: 0.8992 - val_loss: 0.3014 - val_acc: 0.8666 - val_weighted_accuracy: 0.8604\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 39s 109us/step - loss: 0.0180 - acc: 0.9018 - weighted_accuracy: 0.8992 - val_loss: 0.3097 - val_acc: 0.8642 - val_weighted_accuracy: 0.8596\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 40s 110us/step - loss: 0.0179 - acc: 0.9024 - weighted_accuracy: 0.9000 - val_loss: 0.3131 - val_acc: 0.8606 - val_weighted_accuracy: 0.8581\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 40s 111us/step - loss: 0.0178 - acc: 0.9028 - weighted_accuracy: 0.9002 - val_loss: 0.3047 - val_acc: 0.8651 - val_weighted_accuracy: 0.8599\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 40s 110us/step - loss: 0.0178 - acc: 0.9035 - weighted_accuracy: 0.9010 - val_loss: 0.3135 - val_acc: 0.8632 - val_weighted_accuracy: 0.8576\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 39s 109us/step - loss: 0.0177 - acc: 0.9036 - weighted_accuracy: 0.9013 - val_loss: 0.3055 - val_acc: 0.8633 - val_weighted_accuracy: 0.8595\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 40s 110us/step - loss: 0.0176 - acc: 0.9041 - weighted_accuracy: 0.9019 - val_loss: 0.3121 - val_acc: 0.8599 - val_weighted_accuracy: 0.8580\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_10 (Embedding)        (None, 30, 200)      20000000    first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_19 (SpatialDr (None, 30, 200)      0           embedding_10[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_20 (SpatialDr (None, 30, 200)      0           embedding_10[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_10 (TimeDistri (None, 30, 200)      80400       spatial_dropout1d_19[0][0]       \n",
      "                                                                 spatial_dropout1d_20[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dot_109 (Dot)                   (None, 30, 30)       0           time_distributed_10[0][0]        \n",
      "                                                                 time_distributed_10[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_83 (Lambda)              (None, 30, 30)       0           dot_109[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_37 (Permute)            (None, 30, 30)       0           lambda_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_82 (Lambda)              (None, 30, 30)       0           dot_109[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_111 (Dot)                   (None, 30, 200)      0           permute_37[0][0]                 \n",
      "                                                                 time_distributed_10[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dot_110 (Dot)                   (None, 30, 200)      0           lambda_82[0][0]                  \n",
      "                                                                 time_distributed_10[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_100 (Concatenate)   (None, 30, 400)      0           dot_111[0][0]                    \n",
      "                                                                 time_distributed_10[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_101 (Concatenate)   (None, 30, 400)      0           dot_110[0][0]                    \n",
      "                                                                 time_distributed_10[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_64 (Conv1D)              (None, 30, 42)       16842       concatenate_100[0][0]            \n",
      "                                                                 concatenate_101[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot_112 (Dot)                   (None, 30, 30)       0           conv1d_64[0][0]                  \n",
      "                                                                 conv1d_64[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_85 (Lambda)              (None, 30, 30)       0           dot_112[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_38 (Permute)            (None, 30, 30)       0           lambda_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_84 (Lambda)              (None, 30, 30)       0           dot_112[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_114 (Dot)                   (None, 30, 42)       0           permute_38[0][0]                 \n",
      "                                                                 conv1d_64[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_113 (Dot)                   (None, 30, 42)       0           lambda_84[0][0]                  \n",
      "                                                                 conv1d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_102 (Concatenate)   (None, 30, 484)      0           conv1d_64[0][0]                  \n",
      "                                                                 dot_114[0][0]                    \n",
      "                                                                 concatenate_100[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_103 (Concatenate)   (None, 30, 484)      0           conv1d_64[1][0]                  \n",
      "                                                                 dot_113[0][0]                    \n",
      "                                                                 concatenate_101[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_65 (Conv1D)              (None, 30, 42)       61026       concatenate_102[0][0]            \n",
      "                                                                 concatenate_103[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot_115 (Dot)                   (None, 30, 30)       0           conv1d_65[0][0]                  \n",
      "                                                                 conv1d_65[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_87 (Lambda)              (None, 30, 30)       0           dot_115[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_39 (Permute)            (None, 30, 30)       0           lambda_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_86 (Lambda)              (None, 30, 30)       0           dot_115[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_117 (Dot)                   (None, 30, 42)       0           permute_39[0][0]                 \n",
      "                                                                 conv1d_65[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_116 (Dot)                   (None, 30, 42)       0           lambda_86[0][0]                  \n",
      "                                                                 conv1d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_104 (Concatenate)   (None, 30, 568)      0           conv1d_65[0][0]                  \n",
      "                                                                 dot_117[0][0]                    \n",
      "                                                                 concatenate_102[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_105 (Concatenate)   (None, 30, 568)      0           conv1d_65[1][0]                  \n",
      "                                                                 dot_116[0][0]                    \n",
      "                                                                 concatenate_103[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_66 (Conv1D)              (None, 30, 42)       71610       concatenate_104[0][0]            \n",
      "                                                                 concatenate_105[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot_118 (Dot)                   (None, 30, 30)       0           conv1d_66[0][0]                  \n",
      "                                                                 conv1d_66[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_89 (Lambda)              (None, 30, 30)       0           dot_118[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_40 (Permute)            (None, 30, 30)       0           lambda_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_88 (Lambda)              (None, 30, 30)       0           dot_118[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_120 (Dot)                   (None, 30, 42)       0           permute_40[0][0]                 \n",
      "                                                                 conv1d_66[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_119 (Dot)                   (None, 30, 42)       0           lambda_88[0][0]                  \n",
      "                                                                 conv1d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_106 (Concatenate)   (None, 30, 652)      0           conv1d_66[0][0]                  \n",
      "                                                                 dot_120[0][0]                    \n",
      "                                                                 concatenate_104[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_107 (Concatenate)   (None, 30, 652)      0           conv1d_66[1][0]                  \n",
      "                                                                 dot_119[0][0]                    \n",
      "                                                                 concatenate_105[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_19 (Gl (None, 652)          0           concatenate_106[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_19 (Global (None, 652)          0           concatenate_106[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_weighted_average_10 ( (None, 652)          652         concatenate_106[0][0]            \n",
      "                                                                 concatenate_107[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_20 (Gl (None, 652)          0           concatenate_107[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_20 (Global (None, 652)          0           concatenate_107[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_108 (Concatenate)   (None, 1956)         0           global_average_pooling1d_19[0][0]\n",
      "                                                                 global_max_pooling1d_19[0][0]    \n",
      "                                                                 attention_weighted_average_10[0][\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_109 (Concatenate)   (None, 1956)         0           global_average_pooling1d_20[0][0]\n",
      "                                                                 global_max_pooling1d_20[0][0]    \n",
      "                                                                 attention_weighted_average_10[1][\n",
      "__________________________________________________________________________________________________\n",
      "lambda_90 (Lambda)              (None, 1956)         0           concatenate_108[0][0]            \n",
      "                                                                 concatenate_109[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_10 (Multiply)          (None, 1956)         0           concatenate_108[0][0]            \n",
      "                                                                 concatenate_109[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_110 (Concatenate)   (None, 7824)         0           concatenate_108[0][0]            \n",
      "                                                                 concatenate_109[0][0]            \n",
      "                                                                 lambda_90[0][0]                  \n",
      "                                                                 multiply_10[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 7824)         0           concatenate_110[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 128)          1001600     dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 3)            387         dense_19[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 21,232,517\n",
      "Trainable params: 1,232,517\n",
      "Non-trainable params: 20,000,000\n",
      "__________________________________________________________________________________________________\n",
      "Load weights from WordTC-DenseCNN5Layers-NoMeta-3P-NoEM-NoClassWeighted-3Layers-pseudo-scaled-7.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360609/360609 [==============================] - 41s 115us/step - loss: 0.0171 - acc: 0.9074 - weighted_accuracy: 0.9059 - val_loss: 0.2866 - val_acc: 0.8708 - val_weighted_accuracy: 0.8607\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 40s 111us/step - loss: 0.0171 - acc: 0.9086 - weighted_accuracy: 0.9068 - val_loss: 0.3022 - val_acc: 0.8601 - val_weighted_accuracy: 0.8566\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 40s 111us/step - loss: 0.0170 - acc: 0.9081 - weighted_accuracy: 0.9068 - val_loss: 0.2923 - val_acc: 0.8681 - val_weighted_accuracy: 0.8605\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 40s 112us/step - loss: 0.0170 - acc: 0.9083 - weighted_accuracy: 0.9070 - val_loss: 0.3030 - val_acc: 0.8630 - val_weighted_accuracy: 0.8566\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 40s 111us/step - loss: 0.0170 - acc: 0.9094 - weighted_accuracy: 0.9079 - val_loss: 0.2989 - val_acc: 0.8661 - val_weighted_accuracy: 0.8577\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 40s 110us/step - loss: 0.0168 - acc: 0.9098 - weighted_accuracy: 0.9086 - val_loss: 0.2934 - val_acc: 0.8662 - val_weighted_accuracy: 0.8593\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 40s 111us/step - loss: 0.0168 - acc: 0.9106 - weighted_accuracy: 0.9094 - val_loss: 0.2886 - val_acc: 0.8711 - val_weighted_accuracy: 0.8620\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 40s 111us/step - loss: 0.0168 - acc: 0.9109 - weighted_accuracy: 0.9096 - val_loss: 0.2971 - val_acc: 0.8674 - val_weighted_accuracy: 0.8598\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 40s 111us/step - loss: 0.0167 - acc: 0.9113 - weighted_accuracy: 0.9101 - val_loss: 0.2956 - val_acc: 0.8669 - val_weighted_accuracy: 0.8587\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 40s 111us/step - loss: 0.0166 - acc: 0.9113 - weighted_accuracy: 0.9101 - val_loss: 0.2935 - val_acc: 0.8697 - val_weighted_accuracy: 0.8628\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 40s 111us/step - loss: 0.0166 - acc: 0.9116 - weighted_accuracy: 0.9107 - val_loss: 0.2987 - val_acc: 0.8657 - val_weighted_accuracy: 0.8597\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 40s 111us/step - loss: 0.0166 - acc: 0.9116 - weighted_accuracy: 0.9107 - val_loss: 0.2843 - val_acc: 0.8722 - val_weighted_accuracy: 0.8628\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 40s 112us/step - loss: 0.0165 - acc: 0.9128 - weighted_accuracy: 0.9121 - val_loss: 0.2948 - val_acc: 0.8667 - val_weighted_accuracy: 0.8597\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 40s 111us/step - loss: 0.0164 - acc: 0.9130 - weighted_accuracy: 0.9120 - val_loss: 0.2920 - val_acc: 0.8699 - val_weighted_accuracy: 0.8609\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 40s 110us/step - loss: 0.0164 - acc: 0.9127 - weighted_accuracy: 0.9119 - val_loss: 0.2882 - val_acc: 0.8691 - val_weighted_accuracy: 0.8603\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 40s 110us/step - loss: 0.0163 - acc: 0.9134 - weighted_accuracy: 0.9127 - val_loss: 0.2837 - val_acc: 0.8740 - val_weighted_accuracy: 0.8616\n",
      "score 0.8571360821309314\n",
      "Predicting training results...\n",
      "Predicting testing results...\n",
      "80126/80126 [==============================] - 4s 45us/step\n",
      "80126/80126 [==============================] - 4s 45us/step\n",
      "80126/80126 [==============================] - 4s 45us/step\n",
      "80126/80126 [==============================] - 4s 45us/step\n",
      "80126/80126 [==============================] - 4s 46us/step\n",
      "80126/80126 [==============================] - 4s 46us/step\n",
      "80126/80126 [==============================] - 4s 48us/step\n",
      "80126/80126 [==============================] - 4s 49us/step\n",
      "Predicting labeled testing results...\n"
     ]
    }
   ],
   "source": [
    "fold_count = 8\n",
    "#embedding_matrix = sgns_bigram_matrix\n",
    "embedding_matrix = tencent_ai_matrix\n",
    "EMBEDDING_DIM = 200\n",
    "\n",
    "for i in range(1, len(model_manager.models_tag)):\n",
    "    print(\"Work on model\", i)\n",
    "    model_tag = model_manager.models_tag[i]\n",
    "    model_func = model_manager.model_funcs[i]\n",
    "    #models_checkpoints_path = model_manager.models_checkpoints_pathes[i]\n",
    "    models_checkpoints_path = \"WordTC-DenseCNN5Layers-NoMeta-3P-NoEM-NoClassWeighted-3Layers\"\n",
    "\n",
    "    model_submit_prefix = model_manager.submit_predix[i]\n",
    "    model_class_weights = model_manager.model_class_weights[i]\n",
    "    model_class_weights = None\n",
    "    model_scale_sample_weights = model_manager.model_scale_sample_weights[i]\n",
    "    model_scale_sample_weights = None\n",
    "    model_patiences = model_manager.model_patiences[i]\n",
    "    \n",
    "    #model_class_weights = {0:100, 1:1.5, 0.9: 3}\n",
    "    \n",
    "    def _agent_get_model():\n",
    "        return get_dense_cnn(NB_WORDS, EMBEDDING_DIM, embedding_matrix, MAX_SEQUENCE_LENGTH, OUT_SIZE)\n",
    "        return model_func(NB_WORDS, EMBEDDING_DIM, embedding_matrix, MAX_SEQUENCE_LENGTH, OUT_SIZE)\n",
    "    \n",
    "    test_predicts_list = []\n",
    "    oofs_predictions = []\n",
    "    pre_trained_models = []\n",
    "\n",
    "    trainer = KerasModelTrainer(model_stamp=models_checkpoints_path, epoch_num=500)\n",
    "    models, score, folds_preds = trainer.train_folds(X=trains, y=labels, tests=tests, augments=None, fold_count=fold_count, batch_size=1024,\n",
    "        em_train_features=em_train_features, em_test_features=em_test_features, pseudo_labels=pseudo_labels,                                      \n",
    "        scale_sample_weight=model_scale_sample_weights, class_weight=model_class_weights,\n",
    "        get_model_func=_agent_get_model, \n",
    "        patience=6)\n",
    "\n",
    "    print(\"score\", score)\n",
    "    oofs_dir = \"../data/pseudo/oofs/\"\n",
    "    output_dir = \"../data/pseudo/output/\"\n",
    "    onehot_pred_dir = \"../data/pseudo/one_hot_pred/\"\n",
    "\n",
    "    model_submit_prefix = \"PSWordSGNS-DenseCNN5Layers-NoMeta-3P-NoEM-NoClassWeighted-3Layers\"\n",
    "    \n",
    "    oofs_path = oofs_dir + model_submit_prefix\n",
    "    output_path = output_dir + model_submit_prefix\n",
    "    one_hot_pred_path = onehot_pred_dir + \"One-Hot\" + model_submit_prefix\n",
    "\n",
    "    print(\"Predicting training results...\")\n",
    "    train_predicts = np.concatenate(folds_preds, axis=0)\n",
    "    oofs = pd.DataFrame({\"unrelated\": train_predicts[:, 0], \"agreed\": train_predicts[:, 1], \"disagreed\": train_predicts[:, 2]})\n",
    "    score = numpy_weighted_accuracy(labels, oofs[['unrelated', 'agreed', 'disagreed']].values)\n",
    "    submit_path = oofs_path + \"-Train-L{:4f}-NB{:d}.csv\".format(score, NB_WORDS)\n",
    "    oofs.to_csv(submit_path, index=False)\n",
    "    \n",
    "\n",
    "    print(\"Predicting testing results...\")\n",
    "    test_predicts_list = []\n",
    "    for fold_id, model in enumerate(models):\n",
    "        test_predicts = model.predict({\"first_sentences\":tests[0],\n",
    "                                       \"second_sentences\":tests[1],\n",
    "                                       \"mata-features\":tests[2],\n",
    "                                       \"first_exact_match\": tests_1_ems,\n",
    "                                       \"second_exact_match\": tests_2_ems,\n",
    "                                      }, batch_size=128, verbose=1)\n",
    "\n",
    "        test_predicts_list.append(test_predicts)\n",
    "\n",
    "    test_predicts = np.zeros(test_predicts_list[0].shape)\n",
    "    for fold_predict in test_predicts_list:\n",
    "        test_predicts += fold_predict\n",
    "    test_predicts /= len(test_predicts_list)\n",
    "\n",
    "    test_predicts = pd.DataFrame({\"unrelated\": test_predicts[:, 0], \"agreed\": test_predicts[:, 1], \"disagreed\": test_predicts[:, 2]})\n",
    "    submit_path = output_path + \"-L{:4f}-NB{:d}.csv\".format(score, NB_WORDS)\n",
    "    test_predicts.to_csv(submit_path, index=False) # 0.3343\n",
    "    \n",
    "    print(\"Predicting labeled testing results...\")\n",
    "    ids = pd.read_csv(\"../data/dataset/test.csv\")\n",
    "    pred_labels = test_predicts.idxmax(axis=1)\n",
    "    sub = pd.DataFrame({\"Id\": ids['id'].values, \"Category\": pred_labels})\n",
    "    submit_path = one_hot_pred_path + \"-L{:4f}-NB{:d}.csv\".format(score, NB_WORDS)\n",
    "    sub.to_csv(submit_path, index=False)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8550714133718949"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_weighted_accuracy(labels, oofs[['unrelated', 'agreed', 'disagreed']].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Work on model 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zake7\\Anaconda3\\lib\\site-packages\\keras\\legacy\\layers.py:198: UserWarning: The `Highway` layer is deprecated and will be removed after 06/2017.\n",
      "  warnings.warn('The `Highway` layer is deprecated '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_9 (Embedding)         (None, 30, 300)      30000000    first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_17 (SpatialDr (None, 30, 300)      0           embedding_9[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_18 (SpatialDr (None, 30, 300)      0           embedding_9[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_9 (TimeDistrib (None, 30, 300)      180600      spatial_dropout1d_17[0][0]       \n",
      "                                                                 spatial_dropout1d_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dot_97 (Dot)                    (None, 30, 30)       0           time_distributed_9[0][0]         \n",
      "                                                                 time_distributed_9[1][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_74 (Lambda)              (None, 30, 30)       0           dot_97[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_33 (Permute)            (None, 30, 30)       0           lambda_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_73 (Lambda)              (None, 30, 30)       0           dot_97[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_99 (Dot)                    (None, 30, 300)      0           permute_33[0][0]                 \n",
      "                                                                 time_distributed_9[1][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dot_98 (Dot)                    (None, 30, 300)      0           lambda_73[0][0]                  \n",
      "                                                                 time_distributed_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_89 (Concatenate)    (None, 30, 600)      0           dot_99[0][0]                     \n",
      "                                                                 time_distributed_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_90 (Concatenate)    (None, 30, 600)      0           dot_98[0][0]                     \n",
      "                                                                 time_distributed_9[1][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_57 (Conv1D)              (None, 30, 42)       25242       concatenate_89[0][0]             \n",
      "                                                                 concatenate_90[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dot_100 (Dot)                   (None, 30, 30)       0           conv1d_57[0][0]                  \n",
      "                                                                 conv1d_57[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_76 (Lambda)              (None, 30, 30)       0           dot_100[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_34 (Permute)            (None, 30, 30)       0           lambda_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_75 (Lambda)              (None, 30, 30)       0           dot_100[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_102 (Dot)                   (None, 30, 42)       0           permute_34[0][0]                 \n",
      "                                                                 conv1d_57[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_101 (Dot)                   (None, 30, 42)       0           lambda_75[0][0]                  \n",
      "                                                                 conv1d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_91 (Concatenate)    (None, 30, 684)      0           conv1d_57[0][0]                  \n",
      "                                                                 dot_102[0][0]                    \n",
      "                                                                 concatenate_89[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_92 (Concatenate)    (None, 30, 684)      0           conv1d_57[1][0]                  \n",
      "                                                                 dot_101[0][0]                    \n",
      "                                                                 concatenate_90[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_58 (Conv1D)              (None, 30, 42)       86226       concatenate_91[0][0]             \n",
      "                                                                 concatenate_92[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dot_103 (Dot)                   (None, 30, 30)       0           conv1d_58[0][0]                  \n",
      "                                                                 conv1d_58[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_78 (Lambda)              (None, 30, 30)       0           dot_103[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_35 (Permute)            (None, 30, 30)       0           lambda_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_77 (Lambda)              (None, 30, 30)       0           dot_103[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_105 (Dot)                   (None, 30, 42)       0           permute_35[0][0]                 \n",
      "                                                                 conv1d_58[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_104 (Dot)                   (None, 30, 42)       0           lambda_77[0][0]                  \n",
      "                                                                 conv1d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_93 (Concatenate)    (None, 30, 768)      0           conv1d_58[0][0]                  \n",
      "                                                                 dot_105[0][0]                    \n",
      "                                                                 concatenate_91[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_94 (Concatenate)    (None, 30, 768)      0           conv1d_58[1][0]                  \n",
      "                                                                 dot_104[0][0]                    \n",
      "                                                                 concatenate_92[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_59 (Conv1D)              (None, 30, 42)       96810       concatenate_93[0][0]             \n",
      "                                                                 concatenate_94[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dot_106 (Dot)                   (None, 30, 30)       0           conv1d_59[0][0]                  \n",
      "                                                                 conv1d_59[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_80 (Lambda)              (None, 30, 30)       0           dot_106[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_36 (Permute)            (None, 30, 30)       0           lambda_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_79 (Lambda)              (None, 30, 30)       0           dot_106[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_108 (Dot)                   (None, 30, 42)       0           permute_36[0][0]                 \n",
      "                                                                 conv1d_59[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_107 (Dot)                   (None, 30, 42)       0           lambda_79[0][0]                  \n",
      "                                                                 conv1d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_95 (Concatenate)    (None, 30, 852)      0           conv1d_59[0][0]                  \n",
      "                                                                 dot_108[0][0]                    \n",
      "                                                                 concatenate_93[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_96 (Concatenate)    (None, 30, 852)      0           conv1d_59[1][0]                  \n",
      "                                                                 dot_107[0][0]                    \n",
      "                                                                 concatenate_94[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_17 (Gl (None, 852)          0           concatenate_95[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_17 (Global (None, 852)          0           concatenate_95[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_weighted_average_9 (A (None, 852)          852         concatenate_95[0][0]             \n",
      "                                                                 concatenate_96[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_18 (Gl (None, 852)          0           concatenate_96[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_18 (Global (None, 852)          0           concatenate_96[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_97 (Concatenate)    (None, 2556)         0           global_average_pooling1d_17[0][0]\n",
      "                                                                 global_max_pooling1d_17[0][0]    \n",
      "                                                                 attention_weighted_average_9[0][0\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_98 (Concatenate)    (None, 2556)         0           global_average_pooling1d_18[0][0]\n",
      "                                                                 global_max_pooling1d_18[0][0]    \n",
      "                                                                 attention_weighted_average_9[1][0\n",
      "__________________________________________________________________________________________________\n",
      "lambda_81 (Lambda)              (None, 2556)         0           concatenate_97[0][0]             \n",
      "                                                                 concatenate_98[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_9 (Multiply)           (None, 2556)         0           concatenate_97[0][0]             \n",
      "                                                                 concatenate_98[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_99 (Concatenate)    (None, 10224)        0           concatenate_97[0][0]             \n",
      "                                                                 concatenate_98[0][0]             \n",
      "                                                                 lambda_81[0][0]                  \n",
      "                                                                 multiply_9[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 10224)        0           concatenate_99[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 128)          1308800     dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 3)            387         dense_17[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 31,698,917\n",
      "Trainable params: 1,698,917\n",
      "Non-trainable params: 30,000,000\n",
      "__________________________________________________________________________________________________\n",
      "Load weights from WordSGNS-DenseCNN5Layers-NoMeta-3P-NoEM-NoClassWeighted-3Layers0.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360609/360609 [==============================] - 57s 157us/step - loss: 0.0192 - acc: 0.8939 - weighted_accuracy: 0.8896 - val_loss: 0.3014 - val_acc: 0.8634 - val_weighted_accuracy: 0.8497\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0187 - acc: 0.8971 - weighted_accuracy: 0.8937 - val_loss: 0.3203 - val_acc: 0.8531 - val_weighted_accuracy: 0.8464\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0182 - acc: 0.9002 - weighted_accuracy: 0.8973 - val_loss: 0.3190 - val_acc: 0.8537 - val_weighted_accuracy: 0.8461\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0179 - acc: 0.9022 - weighted_accuracy: 0.8997 - val_loss: 0.3303 - val_acc: 0.8495 - val_weighted_accuracy: 0.8449\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0175 - acc: 0.9042 - weighted_accuracy: 0.9019 - val_loss: 0.3143 - val_acc: 0.8564 - val_weighted_accuracy: 0.8485\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0173 - acc: 0.9061 - weighted_accuracy: 0.9042 - val_loss: 0.3075 - val_acc: 0.8629 - val_weighted_accuracy: 0.8519\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0170 - acc: 0.9080 - weighted_accuracy: 0.9061 - val_loss: 0.3091 - val_acc: 0.8600 - val_weighted_accuracy: 0.8511\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0168 - acc: 0.9098 - weighted_accuracy: 0.9082 - val_loss: 0.3058 - val_acc: 0.8616 - val_weighted_accuracy: 0.8506\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0167 - acc: 0.9102 - weighted_accuracy: 0.9089 - val_loss: 0.3052 - val_acc: 0.8636 - val_weighted_accuracy: 0.8529\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0165 - acc: 0.9111 - weighted_accuracy: 0.9103 - val_loss: 0.3054 - val_acc: 0.8626 - val_weighted_accuracy: 0.8503\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0163 - acc: 0.9127 - weighted_accuracy: 0.9117 - val_loss: 0.3109 - val_acc: 0.8597 - val_weighted_accuracy: 0.8491\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0160 - acc: 0.9142 - weighted_accuracy: 0.9136 - val_loss: 0.3116 - val_acc: 0.8647 - val_weighted_accuracy: 0.8538\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0158 - acc: 0.9160 - weighted_accuracy: 0.9156 - val_loss: 0.3078 - val_acc: 0.8657 - val_weighted_accuracy: 0.8545\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0157 - acc: 0.9171 - weighted_accuracy: 0.9168 - val_loss: 0.3121 - val_acc: 0.8610 - val_weighted_accuracy: 0.8507\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0156 - acc: 0.9172 - weighted_accuracy: 0.9168 - val_loss: 0.3135 - val_acc: 0.8614 - val_weighted_accuracy: 0.8513\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0155 - acc: 0.9182 - weighted_accuracy: 0.9181 - val_loss: 0.3107 - val_acc: 0.8607 - val_weighted_accuracy: 0.8514\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0154 - acc: 0.9188 - weighted_accuracy: 0.9187 - val_loss: 0.3255 - val_acc: 0.8569 - val_weighted_accuracy: 0.8500\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0152 - acc: 0.9200 - weighted_accuracy: 0.9200 - val_loss: 0.3407 - val_acc: 0.8501 - val_weighted_accuracy: 0.8442\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0151 - acc: 0.9203 - weighted_accuracy: 0.9207 - val_loss: 0.3150 - val_acc: 0.8618 - val_weighted_accuracy: 0.8519\n",
      "Epoch 20/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0149 - acc: 0.9219 - weighted_accuracy: 0.9224 - val_loss: 0.3204 - val_acc: 0.8664 - val_weighted_accuracy: 0.8556\n",
      "Epoch 21/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0149 - acc: 0.9225 - weighted_accuracy: 0.9229 - val_loss: 0.3158 - val_acc: 0.8648 - val_weighted_accuracy: 0.8537\n",
      "Epoch 22/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0148 - acc: 0.9221 - weighted_accuracy: 0.9226 - val_loss: 0.3058 - val_acc: 0.8692 - val_weighted_accuracy: 0.8575\n",
      "Epoch 23/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0147 - acc: 0.9239 - weighted_accuracy: 0.9246 - val_loss: 0.3141 - val_acc: 0.8656 - val_weighted_accuracy: 0.8527\n",
      "Epoch 24/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0146 - acc: 0.9241 - weighted_accuracy: 0.9247 - val_loss: 0.3169 - val_acc: 0.8668 - val_weighted_accuracy: 0.8536\n",
      "Epoch 25/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0146 - acc: 0.9243 - weighted_accuracy: 0.9250 - val_loss: 0.3160 - val_acc: 0.8675 - val_weighted_accuracy: 0.8559\n",
      "Epoch 26/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0145 - acc: 0.9247 - weighted_accuracy: 0.9256 - val_loss: 0.3264 - val_acc: 0.8639 - val_weighted_accuracy: 0.8521\n",
      "Epoch 27/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0144 - acc: 0.9259 - weighted_accuracy: 0.9269 - val_loss: 0.3276 - val_acc: 0.8609 - val_weighted_accuracy: 0.8505\n",
      "Epoch 28/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0143 - acc: 0.9262 - weighted_accuracy: 0.9271 - val_loss: 0.3160 - val_acc: 0.8653 - val_weighted_accuracy: 0.8538\n",
      "Epoch 29/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0142 - acc: 0.9272 - weighted_accuracy: 0.9280 - val_loss: 0.3215 - val_acc: 0.8676 - val_weighted_accuracy: 0.8541\n",
      "Epoch 30/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0141 - acc: 0.9276 - weighted_accuracy: 0.9284 - val_loss: 0.3170 - val_acc: 0.8637 - val_weighted_accuracy: 0.8542\n",
      "Epoch 31/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0140 - acc: 0.9278 - weighted_accuracy: 0.9290 - val_loss: 0.3214 - val_acc: 0.8657 - val_weighted_accuracy: 0.8542\n",
      "Epoch 32/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0141 - acc: 0.9280 - weighted_accuracy: 0.9290 - val_loss: 0.3342 - val_acc: 0.8668 - val_weighted_accuracy: 0.8534\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_10 (Embedding)        (None, 30, 300)      30000000    first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_19 (SpatialDr (None, 30, 300)      0           embedding_10[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_20 (SpatialDr (None, 30, 300)      0           embedding_10[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_10 (TimeDistri (None, 30, 300)      180600      spatial_dropout1d_19[0][0]       \n",
      "                                                                 spatial_dropout1d_20[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dot_109 (Dot)                   (None, 30, 30)       0           time_distributed_10[0][0]        \n",
      "                                                                 time_distributed_10[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_83 (Lambda)              (None, 30, 30)       0           dot_109[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_37 (Permute)            (None, 30, 30)       0           lambda_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_82 (Lambda)              (None, 30, 30)       0           dot_109[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_111 (Dot)                   (None, 30, 300)      0           permute_37[0][0]                 \n",
      "                                                                 time_distributed_10[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dot_110 (Dot)                   (None, 30, 300)      0           lambda_82[0][0]                  \n",
      "                                                                 time_distributed_10[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_100 (Concatenate)   (None, 30, 600)      0           dot_111[0][0]                    \n",
      "                                                                 time_distributed_10[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_101 (Concatenate)   (None, 30, 600)      0           dot_110[0][0]                    \n",
      "                                                                 time_distributed_10[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_64 (Conv1D)              (None, 30, 42)       25242       concatenate_100[0][0]            \n",
      "                                                                 concatenate_101[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot_112 (Dot)                   (None, 30, 30)       0           conv1d_64[0][0]                  \n",
      "                                                                 conv1d_64[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_85 (Lambda)              (None, 30, 30)       0           dot_112[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_38 (Permute)            (None, 30, 30)       0           lambda_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_84 (Lambda)              (None, 30, 30)       0           dot_112[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_114 (Dot)                   (None, 30, 42)       0           permute_38[0][0]                 \n",
      "                                                                 conv1d_64[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_113 (Dot)                   (None, 30, 42)       0           lambda_84[0][0]                  \n",
      "                                                                 conv1d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_102 (Concatenate)   (None, 30, 684)      0           conv1d_64[0][0]                  \n",
      "                                                                 dot_114[0][0]                    \n",
      "                                                                 concatenate_100[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_103 (Concatenate)   (None, 30, 684)      0           conv1d_64[1][0]                  \n",
      "                                                                 dot_113[0][0]                    \n",
      "                                                                 concatenate_101[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_65 (Conv1D)              (None, 30, 42)       86226       concatenate_102[0][0]            \n",
      "                                                                 concatenate_103[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot_115 (Dot)                   (None, 30, 30)       0           conv1d_65[0][0]                  \n",
      "                                                                 conv1d_65[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_87 (Lambda)              (None, 30, 30)       0           dot_115[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_39 (Permute)            (None, 30, 30)       0           lambda_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_86 (Lambda)              (None, 30, 30)       0           dot_115[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_117 (Dot)                   (None, 30, 42)       0           permute_39[0][0]                 \n",
      "                                                                 conv1d_65[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_116 (Dot)                   (None, 30, 42)       0           lambda_86[0][0]                  \n",
      "                                                                 conv1d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_104 (Concatenate)   (None, 30, 768)      0           conv1d_65[0][0]                  \n",
      "                                                                 dot_117[0][0]                    \n",
      "                                                                 concatenate_102[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_105 (Concatenate)   (None, 30, 768)      0           conv1d_65[1][0]                  \n",
      "                                                                 dot_116[0][0]                    \n",
      "                                                                 concatenate_103[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_66 (Conv1D)              (None, 30, 42)       96810       concatenate_104[0][0]            \n",
      "                                                                 concatenate_105[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot_118 (Dot)                   (None, 30, 30)       0           conv1d_66[0][0]                  \n",
      "                                                                 conv1d_66[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_89 (Lambda)              (None, 30, 30)       0           dot_118[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_40 (Permute)            (None, 30, 30)       0           lambda_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_88 (Lambda)              (None, 30, 30)       0           dot_118[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_120 (Dot)                   (None, 30, 42)       0           permute_40[0][0]                 \n",
      "                                                                 conv1d_66[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_119 (Dot)                   (None, 30, 42)       0           lambda_88[0][0]                  \n",
      "                                                                 conv1d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_106 (Concatenate)   (None, 30, 852)      0           conv1d_66[0][0]                  \n",
      "                                                                 dot_120[0][0]                    \n",
      "                                                                 concatenate_104[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_107 (Concatenate)   (None, 30, 852)      0           conv1d_66[1][0]                  \n",
      "                                                                 dot_119[0][0]                    \n",
      "                                                                 concatenate_105[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_19 (Gl (None, 852)          0           concatenate_106[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_19 (Global (None, 852)          0           concatenate_106[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_weighted_average_10 ( (None, 852)          852         concatenate_106[0][0]            \n",
      "                                                                 concatenate_107[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_20 (Gl (None, 852)          0           concatenate_107[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_20 (Global (None, 852)          0           concatenate_107[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_108 (Concatenate)   (None, 2556)         0           global_average_pooling1d_19[0][0]\n",
      "                                                                 global_max_pooling1d_19[0][0]    \n",
      "                                                                 attention_weighted_average_10[0][\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_109 (Concatenate)   (None, 2556)         0           global_average_pooling1d_20[0][0]\n",
      "                                                                 global_max_pooling1d_20[0][0]    \n",
      "                                                                 attention_weighted_average_10[1][\n",
      "__________________________________________________________________________________________________\n",
      "lambda_90 (Lambda)              (None, 2556)         0           concatenate_108[0][0]            \n",
      "                                                                 concatenate_109[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_10 (Multiply)          (None, 2556)         0           concatenate_108[0][0]            \n",
      "                                                                 concatenate_109[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_110 (Concatenate)   (None, 10224)        0           concatenate_108[0][0]            \n",
      "                                                                 concatenate_109[0][0]            \n",
      "                                                                 lambda_90[0][0]                  \n",
      "                                                                 multiply_10[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 10224)        0           concatenate_110[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 128)          1308800     dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 3)            387         dense_19[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 31,698,917\n",
      "Trainable params: 1,698,917\n",
      "Non-trainable params: 30,000,000\n",
      "__________________________________________________________________________________________________\n",
      "Load weights from WordSGNS-DenseCNN5Layers-NoMeta-3P-NoEM-NoClassWeighted-3Layers1.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360609/360609 [==============================] - 56s 155us/step - loss: 0.0188 - acc: 0.8959 - weighted_accuracy: 0.8919 - val_loss: 0.3054 - val_acc: 0.8621 - val_weighted_accuracy: 0.8570\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0183 - acc: 0.9002 - weighted_accuracy: 0.8968 - val_loss: 0.2857 - val_acc: 0.8704 - val_weighted_accuracy: 0.8594\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0180 - acc: 0.9019 - weighted_accuracy: 0.8988 - val_loss: 0.2863 - val_acc: 0.8726 - val_weighted_accuracy: 0.8607\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0177 - acc: 0.9042 - weighted_accuracy: 0.9014 - val_loss: 0.2903 - val_acc: 0.8693 - val_weighted_accuracy: 0.8607\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0174 - acc: 0.9054 - weighted_accuracy: 0.9032 - val_loss: 0.2926 - val_acc: 0.8675 - val_weighted_accuracy: 0.8601\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0172 - acc: 0.9069 - weighted_accuracy: 0.9050 - val_loss: 0.2880 - val_acc: 0.8702 - val_weighted_accuracy: 0.8599\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0170 - acc: 0.9086 - weighted_accuracy: 0.9070 - val_loss: 0.2856 - val_acc: 0.8732 - val_weighted_accuracy: 0.8598\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0167 - acc: 0.9102 - weighted_accuracy: 0.9091 - val_loss: 0.2900 - val_acc: 0.8729 - val_weighted_accuracy: 0.8614\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0165 - acc: 0.9113 - weighted_accuracy: 0.9102 - val_loss: 0.2919 - val_acc: 0.8695 - val_weighted_accuracy: 0.8594\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0163 - acc: 0.9127 - weighted_accuracy: 0.9120 - val_loss: 0.2982 - val_acc: 0.8693 - val_weighted_accuracy: 0.8610\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0162 - acc: 0.9137 - weighted_accuracy: 0.9129 - val_loss: 0.2875 - val_acc: 0.8753 - val_weighted_accuracy: 0.8630\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0160 - acc: 0.9144 - weighted_accuracy: 0.9137 - val_loss: 0.2864 - val_acc: 0.8744 - val_weighted_accuracy: 0.8630\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0159 - acc: 0.9155 - weighted_accuracy: 0.9152 - val_loss: 0.2867 - val_acc: 0.8728 - val_weighted_accuracy: 0.8613\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0158 - acc: 0.9159 - weighted_accuracy: 0.9158 - val_loss: 0.2876 - val_acc: 0.8739 - val_weighted_accuracy: 0.8609\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0156 - acc: 0.9170 - weighted_accuracy: 0.9171 - val_loss: 0.2869 - val_acc: 0.8732 - val_weighted_accuracy: 0.8612\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0155 - acc: 0.9185 - weighted_accuracy: 0.9187 - val_loss: 0.2936 - val_acc: 0.8704 - val_weighted_accuracy: 0.8613\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0154 - acc: 0.9191 - weighted_accuracy: 0.9191 - val_loss: 0.2959 - val_acc: 0.8700 - val_weighted_accuracy: 0.8605\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0153 - acc: 0.9191 - weighted_accuracy: 0.9193 - val_loss: 0.2973 - val_acc: 0.8739 - val_weighted_accuracy: 0.8626\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0151 - acc: 0.9206 - weighted_accuracy: 0.9210 - val_loss: 0.2922 - val_acc: 0.8745 - val_weighted_accuracy: 0.8621\n",
      "Epoch 20/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0150 - acc: 0.9209 - weighted_accuracy: 0.9214 - val_loss: 0.2892 - val_acc: 0.8745 - val_weighted_accuracy: 0.8615\n",
      "Epoch 21/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0149 - acc: 0.9223 - weighted_accuracy: 0.9225 - val_loss: 0.2947 - val_acc: 0.8722 - val_weighted_accuracy: 0.8613\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_11 (Embedding)        (None, 30, 300)      30000000    first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_21 (SpatialDr (None, 30, 300)      0           embedding_11[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_22 (SpatialDr (None, 30, 300)      0           embedding_11[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_11 (TimeDistri (None, 30, 300)      180600      spatial_dropout1d_21[0][0]       \n",
      "                                                                 spatial_dropout1d_22[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dot_121 (Dot)                   (None, 30, 30)       0           time_distributed_11[0][0]        \n",
      "                                                                 time_distributed_11[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_92 (Lambda)              (None, 30, 30)       0           dot_121[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_41 (Permute)            (None, 30, 30)       0           lambda_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_91 (Lambda)              (None, 30, 30)       0           dot_121[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_123 (Dot)                   (None, 30, 300)      0           permute_41[0][0]                 \n",
      "                                                                 time_distributed_11[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dot_122 (Dot)                   (None, 30, 300)      0           lambda_91[0][0]                  \n",
      "                                                                 time_distributed_11[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_111 (Concatenate)   (None, 30, 600)      0           dot_123[0][0]                    \n",
      "                                                                 time_distributed_11[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_112 (Concatenate)   (None, 30, 600)      0           dot_122[0][0]                    \n",
      "                                                                 time_distributed_11[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_71 (Conv1D)              (None, 30, 42)       25242       concatenate_111[0][0]            \n",
      "                                                                 concatenate_112[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot_124 (Dot)                   (None, 30, 30)       0           conv1d_71[0][0]                  \n",
      "                                                                 conv1d_71[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_94 (Lambda)              (None, 30, 30)       0           dot_124[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_42 (Permute)            (None, 30, 30)       0           lambda_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_93 (Lambda)              (None, 30, 30)       0           dot_124[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_126 (Dot)                   (None, 30, 42)       0           permute_42[0][0]                 \n",
      "                                                                 conv1d_71[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_125 (Dot)                   (None, 30, 42)       0           lambda_93[0][0]                  \n",
      "                                                                 conv1d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_113 (Concatenate)   (None, 30, 684)      0           conv1d_71[0][0]                  \n",
      "                                                                 dot_126[0][0]                    \n",
      "                                                                 concatenate_111[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_114 (Concatenate)   (None, 30, 684)      0           conv1d_71[1][0]                  \n",
      "                                                                 dot_125[0][0]                    \n",
      "                                                                 concatenate_112[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_72 (Conv1D)              (None, 30, 42)       86226       concatenate_113[0][0]            \n",
      "                                                                 concatenate_114[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot_127 (Dot)                   (None, 30, 30)       0           conv1d_72[0][0]                  \n",
      "                                                                 conv1d_72[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_96 (Lambda)              (None, 30, 30)       0           dot_127[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_43 (Permute)            (None, 30, 30)       0           lambda_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_95 (Lambda)              (None, 30, 30)       0           dot_127[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_129 (Dot)                   (None, 30, 42)       0           permute_43[0][0]                 \n",
      "                                                                 conv1d_72[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_128 (Dot)                   (None, 30, 42)       0           lambda_95[0][0]                  \n",
      "                                                                 conv1d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_115 (Concatenate)   (None, 30, 768)      0           conv1d_72[0][0]                  \n",
      "                                                                 dot_129[0][0]                    \n",
      "                                                                 concatenate_113[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_116 (Concatenate)   (None, 30, 768)      0           conv1d_72[1][0]                  \n",
      "                                                                 dot_128[0][0]                    \n",
      "                                                                 concatenate_114[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_73 (Conv1D)              (None, 30, 42)       96810       concatenate_115[0][0]            \n",
      "                                                                 concatenate_116[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot_130 (Dot)                   (None, 30, 30)       0           conv1d_73[0][0]                  \n",
      "                                                                 conv1d_73[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_98 (Lambda)              (None, 30, 30)       0           dot_130[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_44 (Permute)            (None, 30, 30)       0           lambda_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_97 (Lambda)              (None, 30, 30)       0           dot_130[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_132 (Dot)                   (None, 30, 42)       0           permute_44[0][0]                 \n",
      "                                                                 conv1d_73[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_131 (Dot)                   (None, 30, 42)       0           lambda_97[0][0]                  \n",
      "                                                                 conv1d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_117 (Concatenate)   (None, 30, 852)      0           conv1d_73[0][0]                  \n",
      "                                                                 dot_132[0][0]                    \n",
      "                                                                 concatenate_115[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_118 (Concatenate)   (None, 30, 852)      0           conv1d_73[1][0]                  \n",
      "                                                                 dot_131[0][0]                    \n",
      "                                                                 concatenate_116[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_21 (Gl (None, 852)          0           concatenate_117[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_21 (Global (None, 852)          0           concatenate_117[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_weighted_average_11 ( (None, 852)          852         concatenate_117[0][0]            \n",
      "                                                                 concatenate_118[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_22 (Gl (None, 852)          0           concatenate_118[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_22 (Global (None, 852)          0           concatenate_118[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_119 (Concatenate)   (None, 2556)         0           global_average_pooling1d_21[0][0]\n",
      "                                                                 global_max_pooling1d_21[0][0]    \n",
      "                                                                 attention_weighted_average_11[0][\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_120 (Concatenate)   (None, 2556)         0           global_average_pooling1d_22[0][0]\n",
      "                                                                 global_max_pooling1d_22[0][0]    \n",
      "                                                                 attention_weighted_average_11[1][\n",
      "__________________________________________________________________________________________________\n",
      "lambda_99 (Lambda)              (None, 2556)         0           concatenate_119[0][0]            \n",
      "                                                                 concatenate_120[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_11 (Multiply)          (None, 2556)         0           concatenate_119[0][0]            \n",
      "                                                                 concatenate_120[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_121 (Concatenate)   (None, 10224)        0           concatenate_119[0][0]            \n",
      "                                                                 concatenate_120[0][0]            \n",
      "                                                                 lambda_99[0][0]                  \n",
      "                                                                 multiply_11[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 10224)        0           concatenate_121[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 128)          1308800     dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 3)            387         dense_21[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 31,698,917\n",
      "Trainable params: 1,698,917\n",
      "Non-trainable params: 30,000,000\n",
      "__________________________________________________________________________________________________\n",
      "Load weights from WordSGNS-DenseCNN5Layers-NoMeta-3P-NoEM-NoClassWeighted-3Layers2.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360609/360609 [==============================] - 56s 156us/step - loss: 0.0196 - acc: 0.8915 - weighted_accuracy: 0.8866 - val_loss: 0.3213 - val_acc: 0.8523 - val_weighted_accuracy: 0.8499\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0191 - acc: 0.8951 - weighted_accuracy: 0.8910 - val_loss: 0.3167 - val_acc: 0.8536 - val_weighted_accuracy: 0.8472\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0187 - acc: 0.8972 - weighted_accuracy: 0.8936 - val_loss: 0.3040 - val_acc: 0.8618 - val_weighted_accuracy: 0.8545\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0184 - acc: 0.8993 - weighted_accuracy: 0.8960 - val_loss: 0.3036 - val_acc: 0.8641 - val_weighted_accuracy: 0.8555\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0181 - acc: 0.9010 - weighted_accuracy: 0.8978 - val_loss: 0.3018 - val_acc: 0.8614 - val_weighted_accuracy: 0.8521\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0179 - acc: 0.9030 - weighted_accuracy: 0.9004 - val_loss: 0.3028 - val_acc: 0.8623 - val_weighted_accuracy: 0.8548\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0176 - acc: 0.9041 - weighted_accuracy: 0.9017 - val_loss: 0.3041 - val_acc: 0.8603 - val_weighted_accuracy: 0.8544\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0174 - acc: 0.9055 - weighted_accuracy: 0.9034 - val_loss: 0.3027 - val_acc: 0.8634 - val_weighted_accuracy: 0.8580\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0172 - acc: 0.9068 - weighted_accuracy: 0.9049 - val_loss: 0.3263 - val_acc: 0.8520 - val_weighted_accuracy: 0.8505\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0170 - acc: 0.9078 - weighted_accuracy: 0.9061 - val_loss: 0.3049 - val_acc: 0.8640 - val_weighted_accuracy: 0.8569\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0168 - acc: 0.9095 - weighted_accuracy: 0.9079 - val_loss: 0.3019 - val_acc: 0.8638 - val_weighted_accuracy: 0.8589\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0167 - acc: 0.9101 - weighted_accuracy: 0.9088 - val_loss: 0.3144 - val_acc: 0.8554 - val_weighted_accuracy: 0.8519\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0165 - acc: 0.9110 - weighted_accuracy: 0.9098 - val_loss: 0.3038 - val_acc: 0.8639 - val_weighted_accuracy: 0.8567\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0164 - acc: 0.9123 - weighted_accuracy: 0.9113 - val_loss: 0.3145 - val_acc: 0.8584 - val_weighted_accuracy: 0.8525\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0162 - acc: 0.9135 - weighted_accuracy: 0.9129 - val_loss: 0.3022 - val_acc: 0.8647 - val_weighted_accuracy: 0.8545\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0160 - acc: 0.9140 - weighted_accuracy: 0.9136 - val_loss: 0.3069 - val_acc: 0.8626 - val_weighted_accuracy: 0.8543\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0159 - acc: 0.9147 - weighted_accuracy: 0.9146 - val_loss: 0.3147 - val_acc: 0.8594 - val_weighted_accuracy: 0.8532\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0159 - acc: 0.9153 - weighted_accuracy: 0.9150 - val_loss: 0.2979 - val_acc: 0.8649 - val_weighted_accuracy: 0.8560\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0157 - acc: 0.9162 - weighted_accuracy: 0.9160 - val_loss: 0.3067 - val_acc: 0.8621 - val_weighted_accuracy: 0.8552\n",
      "Epoch 20/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0156 - acc: 0.9176 - weighted_accuracy: 0.9176 - val_loss: 0.3056 - val_acc: 0.8624 - val_weighted_accuracy: 0.8561\n",
      "Epoch 21/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0155 - acc: 0.9177 - weighted_accuracy: 0.9177 - val_loss: 0.3201 - val_acc: 0.8557 - val_weighted_accuracy: 0.8525\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_12 (Embedding)        (None, 30, 300)      30000000    first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_23 (SpatialDr (None, 30, 300)      0           embedding_12[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_24 (SpatialDr (None, 30, 300)      0           embedding_12[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_12 (TimeDistri (None, 30, 300)      180600      spatial_dropout1d_23[0][0]       \n",
      "                                                                 spatial_dropout1d_24[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dot_133 (Dot)                   (None, 30, 30)       0           time_distributed_12[0][0]        \n",
      "                                                                 time_distributed_12[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_101 (Lambda)             (None, 30, 30)       0           dot_133[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_45 (Permute)            (None, 30, 30)       0           lambda_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_100 (Lambda)             (None, 30, 30)       0           dot_133[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_135 (Dot)                   (None, 30, 300)      0           permute_45[0][0]                 \n",
      "                                                                 time_distributed_12[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dot_134 (Dot)                   (None, 30, 300)      0           lambda_100[0][0]                 \n",
      "                                                                 time_distributed_12[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_122 (Concatenate)   (None, 30, 600)      0           dot_135[0][0]                    \n",
      "                                                                 time_distributed_12[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_123 (Concatenate)   (None, 30, 600)      0           dot_134[0][0]                    \n",
      "                                                                 time_distributed_12[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_78 (Conv1D)              (None, 30, 42)       25242       concatenate_122[0][0]            \n",
      "                                                                 concatenate_123[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot_136 (Dot)                   (None, 30, 30)       0           conv1d_78[0][0]                  \n",
      "                                                                 conv1d_78[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_103 (Lambda)             (None, 30, 30)       0           dot_136[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_46 (Permute)            (None, 30, 30)       0           lambda_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_102 (Lambda)             (None, 30, 30)       0           dot_136[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_138 (Dot)                   (None, 30, 42)       0           permute_46[0][0]                 \n",
      "                                                                 conv1d_78[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_137 (Dot)                   (None, 30, 42)       0           lambda_102[0][0]                 \n",
      "                                                                 conv1d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_124 (Concatenate)   (None, 30, 684)      0           conv1d_78[0][0]                  \n",
      "                                                                 dot_138[0][0]                    \n",
      "                                                                 concatenate_122[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_125 (Concatenate)   (None, 30, 684)      0           conv1d_78[1][0]                  \n",
      "                                                                 dot_137[0][0]                    \n",
      "                                                                 concatenate_123[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_79 (Conv1D)              (None, 30, 42)       86226       concatenate_124[0][0]            \n",
      "                                                                 concatenate_125[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot_139 (Dot)                   (None, 30, 30)       0           conv1d_79[0][0]                  \n",
      "                                                                 conv1d_79[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_105 (Lambda)             (None, 30, 30)       0           dot_139[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_47 (Permute)            (None, 30, 30)       0           lambda_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_104 (Lambda)             (None, 30, 30)       0           dot_139[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_141 (Dot)                   (None, 30, 42)       0           permute_47[0][0]                 \n",
      "                                                                 conv1d_79[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_140 (Dot)                   (None, 30, 42)       0           lambda_104[0][0]                 \n",
      "                                                                 conv1d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_126 (Concatenate)   (None, 30, 768)      0           conv1d_79[0][0]                  \n",
      "                                                                 dot_141[0][0]                    \n",
      "                                                                 concatenate_124[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_127 (Concatenate)   (None, 30, 768)      0           conv1d_79[1][0]                  \n",
      "                                                                 dot_140[0][0]                    \n",
      "                                                                 concatenate_125[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_80 (Conv1D)              (None, 30, 42)       96810       concatenate_126[0][0]            \n",
      "                                                                 concatenate_127[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot_142 (Dot)                   (None, 30, 30)       0           conv1d_80[0][0]                  \n",
      "                                                                 conv1d_80[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_107 (Lambda)             (None, 30, 30)       0           dot_142[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_48 (Permute)            (None, 30, 30)       0           lambda_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_106 (Lambda)             (None, 30, 30)       0           dot_142[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_144 (Dot)                   (None, 30, 42)       0           permute_48[0][0]                 \n",
      "                                                                 conv1d_80[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_143 (Dot)                   (None, 30, 42)       0           lambda_106[0][0]                 \n",
      "                                                                 conv1d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_128 (Concatenate)   (None, 30, 852)      0           conv1d_80[0][0]                  \n",
      "                                                                 dot_144[0][0]                    \n",
      "                                                                 concatenate_126[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_129 (Concatenate)   (None, 30, 852)      0           conv1d_80[1][0]                  \n",
      "                                                                 dot_143[0][0]                    \n",
      "                                                                 concatenate_127[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_23 (Gl (None, 852)          0           concatenate_128[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_23 (Global (None, 852)          0           concatenate_128[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_weighted_average_12 ( (None, 852)          852         concatenate_128[0][0]            \n",
      "                                                                 concatenate_129[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_24 (Gl (None, 852)          0           concatenate_129[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_24 (Global (None, 852)          0           concatenate_129[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_130 (Concatenate)   (None, 2556)         0           global_average_pooling1d_23[0][0]\n",
      "                                                                 global_max_pooling1d_23[0][0]    \n",
      "                                                                 attention_weighted_average_12[0][\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_131 (Concatenate)   (None, 2556)         0           global_average_pooling1d_24[0][0]\n",
      "                                                                 global_max_pooling1d_24[0][0]    \n",
      "                                                                 attention_weighted_average_12[1][\n",
      "__________________________________________________________________________________________________\n",
      "lambda_108 (Lambda)             (None, 2556)         0           concatenate_130[0][0]            \n",
      "                                                                 concatenate_131[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_12 (Multiply)          (None, 2556)         0           concatenate_130[0][0]            \n",
      "                                                                 concatenate_131[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_132 (Concatenate)   (None, 10224)        0           concatenate_130[0][0]            \n",
      "                                                                 concatenate_131[0][0]            \n",
      "                                                                 lambda_108[0][0]                 \n",
      "                                                                 multiply_12[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 10224)        0           concatenate_132[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 128)          1308800     dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 3)            387         dense_23[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 31,698,917\n",
      "Trainable params: 1,698,917\n",
      "Non-trainable params: 30,000,000\n",
      "__________________________________________________________________________________________________\n",
      "Load weights from WordSGNS-DenseCNN5Layers-NoMeta-3P-NoEM-NoClassWeighted-3Layers3.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360609/360609 [==============================] - 56s 156us/step - loss: 0.0195 - acc: 0.8923 - weighted_accuracy: 0.8879 - val_loss: 0.3005 - val_acc: 0.8662 - val_weighted_accuracy: 0.8527\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0189 - acc: 0.8953 - weighted_accuracy: 0.8914 - val_loss: 0.3040 - val_acc: 0.8671 - val_weighted_accuracy: 0.8550\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0185 - acc: 0.8985 - weighted_accuracy: 0.8949 - val_loss: 0.2995 - val_acc: 0.8679 - val_weighted_accuracy: 0.8551\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0181 - acc: 0.9013 - weighted_accuracy: 0.8981 - val_loss: 0.3016 - val_acc: 0.8677 - val_weighted_accuracy: 0.8595\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0178 - acc: 0.9036 - weighted_accuracy: 0.9007 - val_loss: 0.3047 - val_acc: 0.8650 - val_weighted_accuracy: 0.8566\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0175 - acc: 0.9046 - weighted_accuracy: 0.9022 - val_loss: 0.3036 - val_acc: 0.8657 - val_weighted_accuracy: 0.8575\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0173 - acc: 0.9064 - weighted_accuracy: 0.9045 - val_loss: 0.2949 - val_acc: 0.8713 - val_weighted_accuracy: 0.8578\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0170 - acc: 0.9084 - weighted_accuracy: 0.9067 - val_loss: 0.3137 - val_acc: 0.8616 - val_weighted_accuracy: 0.8562\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0168 - acc: 0.9094 - weighted_accuracy: 0.9080 - val_loss: 0.3050 - val_acc: 0.8670 - val_weighted_accuracy: 0.8602\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0166 - acc: 0.9111 - weighted_accuracy: 0.9100 - val_loss: 0.3092 - val_acc: 0.8606 - val_weighted_accuracy: 0.8549\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0164 - acc: 0.9124 - weighted_accuracy: 0.9115 - val_loss: 0.3057 - val_acc: 0.8640 - val_weighted_accuracy: 0.8576\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0162 - acc: 0.9133 - weighted_accuracy: 0.9126 - val_loss: 0.3030 - val_acc: 0.8654 - val_weighted_accuracy: 0.8560\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0161 - acc: 0.9140 - weighted_accuracy: 0.9136 - val_loss: 0.2981 - val_acc: 0.8680 - val_weighted_accuracy: 0.8569\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0159 - acc: 0.9153 - weighted_accuracy: 0.9149 - val_loss: 0.3174 - val_acc: 0.8601 - val_weighted_accuracy: 0.8523\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0157 - acc: 0.9167 - weighted_accuracy: 0.9165 - val_loss: 0.3066 - val_acc: 0.8662 - val_weighted_accuracy: 0.8590\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0156 - acc: 0.9181 - weighted_accuracy: 0.9181 - val_loss: 0.3054 - val_acc: 0.8673 - val_weighted_accuracy: 0.8577\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0155 - acc: 0.9185 - weighted_accuracy: 0.9186 - val_loss: 0.2980 - val_acc: 0.8702 - val_weighted_accuracy: 0.8581\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0153 - acc: 0.9198 - weighted_accuracy: 0.9197 - val_loss: 0.3101 - val_acc: 0.8635 - val_weighted_accuracy: 0.8575\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0152 - acc: 0.9199 - weighted_accuracy: 0.9200 - val_loss: 0.3050 - val_acc: 0.8671 - val_weighted_accuracy: 0.8585\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_13 (Embedding)        (None, 30, 300)      30000000    first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_25 (SpatialDr (None, 30, 300)      0           embedding_13[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_26 (SpatialDr (None, 30, 300)      0           embedding_13[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_13 (TimeDistri (None, 30, 300)      180600      spatial_dropout1d_25[0][0]       \n",
      "                                                                 spatial_dropout1d_26[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dot_145 (Dot)                   (None, 30, 30)       0           time_distributed_13[0][0]        \n",
      "                                                                 time_distributed_13[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_110 (Lambda)             (None, 30, 30)       0           dot_145[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_49 (Permute)            (None, 30, 30)       0           lambda_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_109 (Lambda)             (None, 30, 30)       0           dot_145[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_147 (Dot)                   (None, 30, 300)      0           permute_49[0][0]                 \n",
      "                                                                 time_distributed_13[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dot_146 (Dot)                   (None, 30, 300)      0           lambda_109[0][0]                 \n",
      "                                                                 time_distributed_13[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_133 (Concatenate)   (None, 30, 600)      0           dot_147[0][0]                    \n",
      "                                                                 time_distributed_13[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_134 (Concatenate)   (None, 30, 600)      0           dot_146[0][0]                    \n",
      "                                                                 time_distributed_13[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_85 (Conv1D)              (None, 30, 42)       25242       concatenate_133[0][0]            \n",
      "                                                                 concatenate_134[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot_148 (Dot)                   (None, 30, 30)       0           conv1d_85[0][0]                  \n",
      "                                                                 conv1d_85[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_112 (Lambda)             (None, 30, 30)       0           dot_148[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_50 (Permute)            (None, 30, 30)       0           lambda_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_111 (Lambda)             (None, 30, 30)       0           dot_148[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_150 (Dot)                   (None, 30, 42)       0           permute_50[0][0]                 \n",
      "                                                                 conv1d_85[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_149 (Dot)                   (None, 30, 42)       0           lambda_111[0][0]                 \n",
      "                                                                 conv1d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_135 (Concatenate)   (None, 30, 684)      0           conv1d_85[0][0]                  \n",
      "                                                                 dot_150[0][0]                    \n",
      "                                                                 concatenate_133[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_136 (Concatenate)   (None, 30, 684)      0           conv1d_85[1][0]                  \n",
      "                                                                 dot_149[0][0]                    \n",
      "                                                                 concatenate_134[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_86 (Conv1D)              (None, 30, 42)       86226       concatenate_135[0][0]            \n",
      "                                                                 concatenate_136[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot_151 (Dot)                   (None, 30, 30)       0           conv1d_86[0][0]                  \n",
      "                                                                 conv1d_86[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_114 (Lambda)             (None, 30, 30)       0           dot_151[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_51 (Permute)            (None, 30, 30)       0           lambda_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_113 (Lambda)             (None, 30, 30)       0           dot_151[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_153 (Dot)                   (None, 30, 42)       0           permute_51[0][0]                 \n",
      "                                                                 conv1d_86[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_152 (Dot)                   (None, 30, 42)       0           lambda_113[0][0]                 \n",
      "                                                                 conv1d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_137 (Concatenate)   (None, 30, 768)      0           conv1d_86[0][0]                  \n",
      "                                                                 dot_153[0][0]                    \n",
      "                                                                 concatenate_135[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_138 (Concatenate)   (None, 30, 768)      0           conv1d_86[1][0]                  \n",
      "                                                                 dot_152[0][0]                    \n",
      "                                                                 concatenate_136[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_87 (Conv1D)              (None, 30, 42)       96810       concatenate_137[0][0]            \n",
      "                                                                 concatenate_138[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot_154 (Dot)                   (None, 30, 30)       0           conv1d_87[0][0]                  \n",
      "                                                                 conv1d_87[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_116 (Lambda)             (None, 30, 30)       0           dot_154[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_52 (Permute)            (None, 30, 30)       0           lambda_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_115 (Lambda)             (None, 30, 30)       0           dot_154[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_156 (Dot)                   (None, 30, 42)       0           permute_52[0][0]                 \n",
      "                                                                 conv1d_87[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_155 (Dot)                   (None, 30, 42)       0           lambda_115[0][0]                 \n",
      "                                                                 conv1d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_139 (Concatenate)   (None, 30, 852)      0           conv1d_87[0][0]                  \n",
      "                                                                 dot_156[0][0]                    \n",
      "                                                                 concatenate_137[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_140 (Concatenate)   (None, 30, 852)      0           conv1d_87[1][0]                  \n",
      "                                                                 dot_155[0][0]                    \n",
      "                                                                 concatenate_138[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_25 (Gl (None, 852)          0           concatenate_139[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_25 (Global (None, 852)          0           concatenate_139[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_weighted_average_13 ( (None, 852)          852         concatenate_139[0][0]            \n",
      "                                                                 concatenate_140[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_26 (Gl (None, 852)          0           concatenate_140[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_26 (Global (None, 852)          0           concatenate_140[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_141 (Concatenate)   (None, 2556)         0           global_average_pooling1d_25[0][0]\n",
      "                                                                 global_max_pooling1d_25[0][0]    \n",
      "                                                                 attention_weighted_average_13[0][\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_142 (Concatenate)   (None, 2556)         0           global_average_pooling1d_26[0][0]\n",
      "                                                                 global_max_pooling1d_26[0][0]    \n",
      "                                                                 attention_weighted_average_13[1][\n",
      "__________________________________________________________________________________________________\n",
      "lambda_117 (Lambda)             (None, 2556)         0           concatenate_141[0][0]            \n",
      "                                                                 concatenate_142[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_13 (Multiply)          (None, 2556)         0           concatenate_141[0][0]            \n",
      "                                                                 concatenate_142[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_143 (Concatenate)   (None, 10224)        0           concatenate_141[0][0]            \n",
      "                                                                 concatenate_142[0][0]            \n",
      "                                                                 lambda_117[0][0]                 \n",
      "                                                                 multiply_13[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 10224)        0           concatenate_143[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 128)          1308800     dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 3)            387         dense_25[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 31,698,917\n",
      "Trainable params: 1,698,917\n",
      "Non-trainable params: 30,000,000\n",
      "__________________________________________________________________________________________________\n",
      "Load weights from WordSGNS-DenseCNN5Layers-NoMeta-3P-NoEM-NoClassWeighted-3Layers4.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360609/360609 [==============================] - 56s 156us/step - loss: 0.0195 - acc: 0.8920 - weighted_accuracy: 0.8863 - val_loss: 0.3295 - val_acc: 0.8497 - val_weighted_accuracy: 0.8467\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0190 - acc: 0.8956 - weighted_accuracy: 0.8912 - val_loss: 0.3157 - val_acc: 0.8577 - val_weighted_accuracy: 0.8490\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0185 - acc: 0.8988 - weighted_accuracy: 0.8949 - val_loss: 0.3292 - val_acc: 0.8505 - val_weighted_accuracy: 0.8471\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0183 - acc: 0.9004 - weighted_accuracy: 0.8967 - val_loss: 0.3223 - val_acc: 0.8520 - val_weighted_accuracy: 0.8474\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0179 - acc: 0.9024 - weighted_accuracy: 0.8992 - val_loss: 0.3113 - val_acc: 0.8564 - val_weighted_accuracy: 0.8480\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0177 - acc: 0.9047 - weighted_accuracy: 0.9017 - val_loss: 0.3293 - val_acc: 0.8500 - val_weighted_accuracy: 0.8484\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0174 - acc: 0.9059 - weighted_accuracy: 0.9032 - val_loss: 0.3131 - val_acc: 0.8584 - val_weighted_accuracy: 0.8526\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0172 - acc: 0.9074 - weighted_accuracy: 0.9051 - val_loss: 0.3122 - val_acc: 0.8566 - val_weighted_accuracy: 0.8495\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0169 - acc: 0.9095 - weighted_accuracy: 0.9075 - val_loss: 0.3164 - val_acc: 0.8573 - val_weighted_accuracy: 0.8507\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0167 - acc: 0.9107 - weighted_accuracy: 0.9091 - val_loss: 0.3066 - val_acc: 0.8617 - val_weighted_accuracy: 0.8500\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0165 - acc: 0.9114 - weighted_accuracy: 0.9098 - val_loss: 0.3074 - val_acc: 0.8596 - val_weighted_accuracy: 0.8456\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0164 - acc: 0.9126 - weighted_accuracy: 0.9110 - val_loss: 0.3242 - val_acc: 0.8567 - val_weighted_accuracy: 0.8518\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0162 - acc: 0.9140 - weighted_accuracy: 0.9127 - val_loss: 0.3191 - val_acc: 0.8581 - val_weighted_accuracy: 0.8482\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0160 - acc: 0.9149 - weighted_accuracy: 0.9140 - val_loss: 0.3182 - val_acc: 0.8575 - val_weighted_accuracy: 0.8505\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0159 - acc: 0.9159 - weighted_accuracy: 0.9151 - val_loss: 0.3166 - val_acc: 0.8559 - val_weighted_accuracy: 0.8486\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0158 - acc: 0.9165 - weighted_accuracy: 0.9158 - val_loss: 0.3225 - val_acc: 0.8535 - val_weighted_accuracy: 0.8496\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0157 - acc: 0.9172 - weighted_accuracy: 0.9167 - val_loss: 0.3251 - val_acc: 0.8522 - val_weighted_accuracy: 0.8488\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_14 (Embedding)        (None, 30, 300)      30000000    first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_27 (SpatialDr (None, 30, 300)      0           embedding_14[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_28 (SpatialDr (None, 30, 300)      0           embedding_14[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_14 (TimeDistri (None, 30, 300)      180600      spatial_dropout1d_27[0][0]       \n",
      "                                                                 spatial_dropout1d_28[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dot_157 (Dot)                   (None, 30, 30)       0           time_distributed_14[0][0]        \n",
      "                                                                 time_distributed_14[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_119 (Lambda)             (None, 30, 30)       0           dot_157[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_53 (Permute)            (None, 30, 30)       0           lambda_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_118 (Lambda)             (None, 30, 30)       0           dot_157[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_159 (Dot)                   (None, 30, 300)      0           permute_53[0][0]                 \n",
      "                                                                 time_distributed_14[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dot_158 (Dot)                   (None, 30, 300)      0           lambda_118[0][0]                 \n",
      "                                                                 time_distributed_14[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_144 (Concatenate)   (None, 30, 600)      0           dot_159[0][0]                    \n",
      "                                                                 time_distributed_14[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_145 (Concatenate)   (None, 30, 600)      0           dot_158[0][0]                    \n",
      "                                                                 time_distributed_14[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_92 (Conv1D)              (None, 30, 42)       25242       concatenate_144[0][0]            \n",
      "                                                                 concatenate_145[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot_160 (Dot)                   (None, 30, 30)       0           conv1d_92[0][0]                  \n",
      "                                                                 conv1d_92[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_121 (Lambda)             (None, 30, 30)       0           dot_160[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_54 (Permute)            (None, 30, 30)       0           lambda_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_120 (Lambda)             (None, 30, 30)       0           dot_160[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_162 (Dot)                   (None, 30, 42)       0           permute_54[0][0]                 \n",
      "                                                                 conv1d_92[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_161 (Dot)                   (None, 30, 42)       0           lambda_120[0][0]                 \n",
      "                                                                 conv1d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_146 (Concatenate)   (None, 30, 684)      0           conv1d_92[0][0]                  \n",
      "                                                                 dot_162[0][0]                    \n",
      "                                                                 concatenate_144[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_147 (Concatenate)   (None, 30, 684)      0           conv1d_92[1][0]                  \n",
      "                                                                 dot_161[0][0]                    \n",
      "                                                                 concatenate_145[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_93 (Conv1D)              (None, 30, 42)       86226       concatenate_146[0][0]            \n",
      "                                                                 concatenate_147[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot_163 (Dot)                   (None, 30, 30)       0           conv1d_93[0][0]                  \n",
      "                                                                 conv1d_93[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_123 (Lambda)             (None, 30, 30)       0           dot_163[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_55 (Permute)            (None, 30, 30)       0           lambda_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_122 (Lambda)             (None, 30, 30)       0           dot_163[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_165 (Dot)                   (None, 30, 42)       0           permute_55[0][0]                 \n",
      "                                                                 conv1d_93[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_164 (Dot)                   (None, 30, 42)       0           lambda_122[0][0]                 \n",
      "                                                                 conv1d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_148 (Concatenate)   (None, 30, 768)      0           conv1d_93[0][0]                  \n",
      "                                                                 dot_165[0][0]                    \n",
      "                                                                 concatenate_146[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_149 (Concatenate)   (None, 30, 768)      0           conv1d_93[1][0]                  \n",
      "                                                                 dot_164[0][0]                    \n",
      "                                                                 concatenate_147[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_94 (Conv1D)              (None, 30, 42)       96810       concatenate_148[0][0]            \n",
      "                                                                 concatenate_149[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot_166 (Dot)                   (None, 30, 30)       0           conv1d_94[0][0]                  \n",
      "                                                                 conv1d_94[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_125 (Lambda)             (None, 30, 30)       0           dot_166[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_56 (Permute)            (None, 30, 30)       0           lambda_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_124 (Lambda)             (None, 30, 30)       0           dot_166[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_168 (Dot)                   (None, 30, 42)       0           permute_56[0][0]                 \n",
      "                                                                 conv1d_94[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_167 (Dot)                   (None, 30, 42)       0           lambda_124[0][0]                 \n",
      "                                                                 conv1d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_150 (Concatenate)   (None, 30, 852)      0           conv1d_94[0][0]                  \n",
      "                                                                 dot_168[0][0]                    \n",
      "                                                                 concatenate_148[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_151 (Concatenate)   (None, 30, 852)      0           conv1d_94[1][0]                  \n",
      "                                                                 dot_167[0][0]                    \n",
      "                                                                 concatenate_149[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_27 (Gl (None, 852)          0           concatenate_150[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_27 (Global (None, 852)          0           concatenate_150[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_weighted_average_14 ( (None, 852)          852         concatenate_150[0][0]            \n",
      "                                                                 concatenate_151[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_28 (Gl (None, 852)          0           concatenate_151[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_28 (Global (None, 852)          0           concatenate_151[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_152 (Concatenate)   (None, 2556)         0           global_average_pooling1d_27[0][0]\n",
      "                                                                 global_max_pooling1d_27[0][0]    \n",
      "                                                                 attention_weighted_average_14[0][\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_153 (Concatenate)   (None, 2556)         0           global_average_pooling1d_28[0][0]\n",
      "                                                                 global_max_pooling1d_28[0][0]    \n",
      "                                                                 attention_weighted_average_14[1][\n",
      "__________________________________________________________________________________________________\n",
      "lambda_126 (Lambda)             (None, 2556)         0           concatenate_152[0][0]            \n",
      "                                                                 concatenate_153[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_14 (Multiply)          (None, 2556)         0           concatenate_152[0][0]            \n",
      "                                                                 concatenate_153[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_154 (Concatenate)   (None, 10224)        0           concatenate_152[0][0]            \n",
      "                                                                 concatenate_153[0][0]            \n",
      "                                                                 lambda_126[0][0]                 \n",
      "                                                                 multiply_14[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 10224)        0           concatenate_154[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 128)          1308800     dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 3)            387         dense_27[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 31,698,917\n",
      "Trainable params: 1,698,917\n",
      "Non-trainable params: 30,000,000\n",
      "__________________________________________________________________________________________________\n",
      "Load weights from WordSGNS-DenseCNN5Layers-NoMeta-3P-NoEM-NoClassWeighted-3Layers5.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360609/360609 [==============================] - 57s 157us/step - loss: 0.0196 - acc: 0.8908 - weighted_accuracy: 0.8860 - val_loss: 0.3387 - val_acc: 0.8427 - val_weighted_accuracy: 0.8311\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0191 - acc: 0.8943 - weighted_accuracy: 0.8898 - val_loss: 0.3362 - val_acc: 0.8421 - val_weighted_accuracy: 0.8279\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0187 - acc: 0.8972 - weighted_accuracy: 0.8931 - val_loss: 0.3462 - val_acc: 0.8368 - val_weighted_accuracy: 0.8234\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0184 - acc: 0.8988 - weighted_accuracy: 0.8952 - val_loss: 0.3275 - val_acc: 0.8482 - val_weighted_accuracy: 0.8290\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0181 - acc: 0.9009 - weighted_accuracy: 0.8974 - val_loss: 0.3262 - val_acc: 0.8508 - val_weighted_accuracy: 0.8278\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0178 - acc: 0.9025 - weighted_accuracy: 0.8996 - val_loss: 0.3352 - val_acc: 0.8473 - val_weighted_accuracy: 0.8355\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0176 - acc: 0.9044 - weighted_accuracy: 0.9014 - val_loss: 0.3317 - val_acc: 0.8482 - val_weighted_accuracy: 0.8339\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0173 - acc: 0.9064 - weighted_accuracy: 0.9035 - val_loss: 0.3324 - val_acc: 0.8468 - val_weighted_accuracy: 0.8325\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0171 - acc: 0.9072 - weighted_accuracy: 0.9046 - val_loss: 0.3287 - val_acc: 0.8521 - val_weighted_accuracy: 0.8344\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0169 - acc: 0.9091 - weighted_accuracy: 0.9068 - val_loss: 0.3306 - val_acc: 0.8465 - val_weighted_accuracy: 0.8344\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0168 - acc: 0.9097 - weighted_accuracy: 0.9078 - val_loss: 0.3251 - val_acc: 0.8526 - val_weighted_accuracy: 0.8352\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0166 - acc: 0.9113 - weighted_accuracy: 0.9093 - val_loss: 0.3489 - val_acc: 0.8393 - val_weighted_accuracy: 0.8287\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0164 - acc: 0.9121 - weighted_accuracy: 0.9104 - val_loss: 0.3360 - val_acc: 0.8437 - val_weighted_accuracy: 0.8334\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0163 - acc: 0.9133 - weighted_accuracy: 0.9119 - val_loss: 0.3328 - val_acc: 0.8493 - val_weighted_accuracy: 0.8345\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0161 - acc: 0.9143 - weighted_accuracy: 0.9129 - val_loss: 0.3380 - val_acc: 0.8450 - val_weighted_accuracy: 0.8331\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0160 - acc: 0.9149 - weighted_accuracy: 0.9140 - val_loss: 0.3478 - val_acc: 0.8422 - val_weighted_accuracy: 0.8309\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_15 (Embedding)        (None, 30, 300)      30000000    first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_29 (SpatialDr (None, 30, 300)      0           embedding_15[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_30 (SpatialDr (None, 30, 300)      0           embedding_15[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_15 (TimeDistri (None, 30, 300)      180600      spatial_dropout1d_29[0][0]       \n",
      "                                                                 spatial_dropout1d_30[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dot_169 (Dot)                   (None, 30, 30)       0           time_distributed_15[0][0]        \n",
      "                                                                 time_distributed_15[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_128 (Lambda)             (None, 30, 30)       0           dot_169[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_57 (Permute)            (None, 30, 30)       0           lambda_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_127 (Lambda)             (None, 30, 30)       0           dot_169[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_171 (Dot)                   (None, 30, 300)      0           permute_57[0][0]                 \n",
      "                                                                 time_distributed_15[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dot_170 (Dot)                   (None, 30, 300)      0           lambda_127[0][0]                 \n",
      "                                                                 time_distributed_15[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_155 (Concatenate)   (None, 30, 600)      0           dot_171[0][0]                    \n",
      "                                                                 time_distributed_15[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_156 (Concatenate)   (None, 30, 600)      0           dot_170[0][0]                    \n",
      "                                                                 time_distributed_15[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_99 (Conv1D)              (None, 30, 42)       25242       concatenate_155[0][0]            \n",
      "                                                                 concatenate_156[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot_172 (Dot)                   (None, 30, 30)       0           conv1d_99[0][0]                  \n",
      "                                                                 conv1d_99[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_130 (Lambda)             (None, 30, 30)       0           dot_172[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_58 (Permute)            (None, 30, 30)       0           lambda_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_129 (Lambda)             (None, 30, 30)       0           dot_172[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_174 (Dot)                   (None, 30, 42)       0           permute_58[0][0]                 \n",
      "                                                                 conv1d_99[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_173 (Dot)                   (None, 30, 42)       0           lambda_129[0][0]                 \n",
      "                                                                 conv1d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_157 (Concatenate)   (None, 30, 684)      0           conv1d_99[0][0]                  \n",
      "                                                                 dot_174[0][0]                    \n",
      "                                                                 concatenate_155[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_158 (Concatenate)   (None, 30, 684)      0           conv1d_99[1][0]                  \n",
      "                                                                 dot_173[0][0]                    \n",
      "                                                                 concatenate_156[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_100 (Conv1D)             (None, 30, 42)       86226       concatenate_157[0][0]            \n",
      "                                                                 concatenate_158[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot_175 (Dot)                   (None, 30, 30)       0           conv1d_100[0][0]                 \n",
      "                                                                 conv1d_100[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_132 (Lambda)             (None, 30, 30)       0           dot_175[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_59 (Permute)            (None, 30, 30)       0           lambda_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_131 (Lambda)             (None, 30, 30)       0           dot_175[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_177 (Dot)                   (None, 30, 42)       0           permute_59[0][0]                 \n",
      "                                                                 conv1d_100[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_176 (Dot)                   (None, 30, 42)       0           lambda_131[0][0]                 \n",
      "                                                                 conv1d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_159 (Concatenate)   (None, 30, 768)      0           conv1d_100[0][0]                 \n",
      "                                                                 dot_177[0][0]                    \n",
      "                                                                 concatenate_157[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_160 (Concatenate)   (None, 30, 768)      0           conv1d_100[1][0]                 \n",
      "                                                                 dot_176[0][0]                    \n",
      "                                                                 concatenate_158[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_101 (Conv1D)             (None, 30, 42)       96810       concatenate_159[0][0]            \n",
      "                                                                 concatenate_160[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot_178 (Dot)                   (None, 30, 30)       0           conv1d_101[0][0]                 \n",
      "                                                                 conv1d_101[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_134 (Lambda)             (None, 30, 30)       0           dot_178[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_60 (Permute)            (None, 30, 30)       0           lambda_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_133 (Lambda)             (None, 30, 30)       0           dot_178[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_180 (Dot)                   (None, 30, 42)       0           permute_60[0][0]                 \n",
      "                                                                 conv1d_101[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_179 (Dot)                   (None, 30, 42)       0           lambda_133[0][0]                 \n",
      "                                                                 conv1d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_161 (Concatenate)   (None, 30, 852)      0           conv1d_101[0][0]                 \n",
      "                                                                 dot_180[0][0]                    \n",
      "                                                                 concatenate_159[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_162 (Concatenate)   (None, 30, 852)      0           conv1d_101[1][0]                 \n",
      "                                                                 dot_179[0][0]                    \n",
      "                                                                 concatenate_160[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_29 (Gl (None, 852)          0           concatenate_161[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_29 (Global (None, 852)          0           concatenate_161[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_weighted_average_15 ( (None, 852)          852         concatenate_161[0][0]            \n",
      "                                                                 concatenate_162[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_30 (Gl (None, 852)          0           concatenate_162[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_30 (Global (None, 852)          0           concatenate_162[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_163 (Concatenate)   (None, 2556)         0           global_average_pooling1d_29[0][0]\n",
      "                                                                 global_max_pooling1d_29[0][0]    \n",
      "                                                                 attention_weighted_average_15[0][\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_164 (Concatenate)   (None, 2556)         0           global_average_pooling1d_30[0][0]\n",
      "                                                                 global_max_pooling1d_30[0][0]    \n",
      "                                                                 attention_weighted_average_15[1][\n",
      "__________________________________________________________________________________________________\n",
      "lambda_135 (Lambda)             (None, 2556)         0           concatenate_163[0][0]            \n",
      "                                                                 concatenate_164[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_15 (Multiply)          (None, 2556)         0           concatenate_163[0][0]            \n",
      "                                                                 concatenate_164[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_165 (Concatenate)   (None, 10224)        0           concatenate_163[0][0]            \n",
      "                                                                 concatenate_164[0][0]            \n",
      "                                                                 lambda_135[0][0]                 \n",
      "                                                                 multiply_15[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 10224)        0           concatenate_165[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 128)          1308800     dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 3)            387         dense_29[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 31,698,917\n",
      "Trainable params: 1,698,917\n",
      "Non-trainable params: 30,000,000\n",
      "__________________________________________________________________________________________________\n",
      "Load weights from WordSGNS-DenseCNN5Layers-NoMeta-3P-NoEM-NoClassWeighted-3Layers6.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360609/360609 [==============================] - 57s 157us/step - loss: 0.0202 - acc: 0.8868 - weighted_accuracy: 0.8817 - val_loss: 0.3147 - val_acc: 0.8594 - val_weighted_accuracy: 0.8527\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0196 - acc: 0.8903 - weighted_accuracy: 0.8861 - val_loss: 0.3020 - val_acc: 0.8670 - val_weighted_accuracy: 0.8540\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0190 - acc: 0.8948 - weighted_accuracy: 0.8908 - val_loss: 0.3036 - val_acc: 0.8625 - val_weighted_accuracy: 0.8547\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0186 - acc: 0.8975 - weighted_accuracy: 0.8939 - val_loss: 0.2969 - val_acc: 0.8675 - val_weighted_accuracy: 0.8543\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0182 - acc: 0.9000 - weighted_accuracy: 0.8970 - val_loss: 0.3024 - val_acc: 0.8665 - val_weighted_accuracy: 0.8540\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0179 - acc: 0.9024 - weighted_accuracy: 0.8995 - val_loss: 0.3087 - val_acc: 0.8626 - val_weighted_accuracy: 0.8558\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0176 - acc: 0.9043 - weighted_accuracy: 0.9018 - val_loss: 0.3031 - val_acc: 0.8656 - val_weighted_accuracy: 0.8563\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0173 - acc: 0.9064 - weighted_accuracy: 0.9043 - val_loss: 0.3034 - val_acc: 0.8661 - val_weighted_accuracy: 0.8564\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0171 - acc: 0.9070 - weighted_accuracy: 0.9050 - val_loss: 0.3029 - val_acc: 0.8671 - val_weighted_accuracy: 0.8562\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0169 - acc: 0.9089 - weighted_accuracy: 0.9074 - val_loss: 0.3001 - val_acc: 0.8674 - val_weighted_accuracy: 0.8576\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0166 - acc: 0.9106 - weighted_accuracy: 0.9093 - val_loss: 0.3107 - val_acc: 0.8614 - val_weighted_accuracy: 0.8558\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0164 - acc: 0.9121 - weighted_accuracy: 0.9110 - val_loss: 0.3007 - val_acc: 0.8689 - val_weighted_accuracy: 0.8567\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0162 - acc: 0.9131 - weighted_accuracy: 0.9123 - val_loss: 0.3062 - val_acc: 0.8650 - val_weighted_accuracy: 0.8566\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0161 - acc: 0.9142 - weighted_accuracy: 0.9135 - val_loss: 0.3094 - val_acc: 0.8625 - val_weighted_accuracy: 0.8560\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0159 - acc: 0.9153 - weighted_accuracy: 0.9150 - val_loss: 0.3092 - val_acc: 0.8639 - val_weighted_accuracy: 0.8567\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0158 - acc: 0.9159 - weighted_accuracy: 0.9156 - val_loss: 0.3062 - val_acc: 0.8660 - val_weighted_accuracy: 0.8566\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0155 - acc: 0.9173 - weighted_accuracy: 0.9172 - val_loss: 0.3025 - val_acc: 0.8678 - val_weighted_accuracy: 0.8556\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0154 - acc: 0.9181 - weighted_accuracy: 0.9180 - val_loss: 0.3081 - val_acc: 0.8644 - val_weighted_accuracy: 0.8566\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0154 - acc: 0.9185 - weighted_accuracy: 0.9184 - val_loss: 0.3055 - val_acc: 0.8649 - val_weighted_accuracy: 0.8548\n",
      "Epoch 20/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0152 - acc: 0.9202 - weighted_accuracy: 0.9205 - val_loss: 0.3028 - val_acc: 0.8690 - val_weighted_accuracy: 0.8581\n",
      "Epoch 21/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0151 - acc: 0.9209 - weighted_accuracy: 0.9213 - val_loss: 0.3154 - val_acc: 0.8677 - val_weighted_accuracy: 0.8538\n",
      "Epoch 22/500\n",
      "360609/360609 [==============================] - 55s 152us/step - loss: 0.0151 - acc: 0.9207 - weighted_accuracy: 0.9209 - val_loss: 0.3218 - val_acc: 0.8595 - val_weighted_accuracy: 0.8537\n",
      "Epoch 23/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0149 - acc: 0.9222 - weighted_accuracy: 0.9225 - val_loss: 0.3099 - val_acc: 0.8666 - val_weighted_accuracy: 0.8541\n",
      "Epoch 24/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0148 - acc: 0.9231 - weighted_accuracy: 0.9236 - val_loss: 0.3152 - val_acc: 0.8651 - val_weighted_accuracy: 0.8577\n",
      "Epoch 25/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0147 - acc: 0.9237 - weighted_accuracy: 0.9242 - val_loss: 0.3098 - val_acc: 0.8674 - val_weighted_accuracy: 0.8547\n",
      "Epoch 26/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0146 - acc: 0.9242 - weighted_accuracy: 0.9249 - val_loss: 0.3170 - val_acc: 0.8641 - val_weighted_accuracy: 0.8570\n",
      "Epoch 27/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0146 - acc: 0.9248 - weighted_accuracy: 0.9253 - val_loss: 0.3149 - val_acc: 0.8666 - val_weighted_accuracy: 0.8576\n",
      "Epoch 28/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0145 - acc: 0.9250 - weighted_accuracy: 0.9259 - val_loss: 0.3110 - val_acc: 0.8658 - val_weighted_accuracy: 0.8568\n",
      "Epoch 29/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0144 - acc: 0.9259 - weighted_accuracy: 0.9266 - val_loss: 0.3160 - val_acc: 0.8651 - val_weighted_accuracy: 0.8548\n",
      "Epoch 30/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0143 - acc: 0.9267 - weighted_accuracy: 0.9274 - val_loss: 0.3073 - val_acc: 0.8686 - val_weighted_accuracy: 0.8559\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_16 (Embedding)        (None, 30, 300)      30000000    first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_31 (SpatialDr (None, 30, 300)      0           embedding_16[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_32 (SpatialDr (None, 30, 300)      0           embedding_16[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_16 (TimeDistri (None, 30, 300)      180600      spatial_dropout1d_31[0][0]       \n",
      "                                                                 spatial_dropout1d_32[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dot_181 (Dot)                   (None, 30, 30)       0           time_distributed_16[0][0]        \n",
      "                                                                 time_distributed_16[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_137 (Lambda)             (None, 30, 30)       0           dot_181[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_61 (Permute)            (None, 30, 30)       0           lambda_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_136 (Lambda)             (None, 30, 30)       0           dot_181[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_183 (Dot)                   (None, 30, 300)      0           permute_61[0][0]                 \n",
      "                                                                 time_distributed_16[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dot_182 (Dot)                   (None, 30, 300)      0           lambda_136[0][0]                 \n",
      "                                                                 time_distributed_16[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_166 (Concatenate)   (None, 30, 600)      0           dot_183[0][0]                    \n",
      "                                                                 time_distributed_16[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_167 (Concatenate)   (None, 30, 600)      0           dot_182[0][0]                    \n",
      "                                                                 time_distributed_16[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_106 (Conv1D)             (None, 30, 42)       25242       concatenate_166[0][0]            \n",
      "                                                                 concatenate_167[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot_184 (Dot)                   (None, 30, 30)       0           conv1d_106[0][0]                 \n",
      "                                                                 conv1d_106[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_139 (Lambda)             (None, 30, 30)       0           dot_184[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_62 (Permute)            (None, 30, 30)       0           lambda_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_138 (Lambda)             (None, 30, 30)       0           dot_184[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_186 (Dot)                   (None, 30, 42)       0           permute_62[0][0]                 \n",
      "                                                                 conv1d_106[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_185 (Dot)                   (None, 30, 42)       0           lambda_138[0][0]                 \n",
      "                                                                 conv1d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_168 (Concatenate)   (None, 30, 684)      0           conv1d_106[0][0]                 \n",
      "                                                                 dot_186[0][0]                    \n",
      "                                                                 concatenate_166[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_169 (Concatenate)   (None, 30, 684)      0           conv1d_106[1][0]                 \n",
      "                                                                 dot_185[0][0]                    \n",
      "                                                                 concatenate_167[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_107 (Conv1D)             (None, 30, 42)       86226       concatenate_168[0][0]            \n",
      "                                                                 concatenate_169[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot_187 (Dot)                   (None, 30, 30)       0           conv1d_107[0][0]                 \n",
      "                                                                 conv1d_107[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_141 (Lambda)             (None, 30, 30)       0           dot_187[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_63 (Permute)            (None, 30, 30)       0           lambda_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_140 (Lambda)             (None, 30, 30)       0           dot_187[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_189 (Dot)                   (None, 30, 42)       0           permute_63[0][0]                 \n",
      "                                                                 conv1d_107[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_188 (Dot)                   (None, 30, 42)       0           lambda_140[0][0]                 \n",
      "                                                                 conv1d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_170 (Concatenate)   (None, 30, 768)      0           conv1d_107[0][0]                 \n",
      "                                                                 dot_189[0][0]                    \n",
      "                                                                 concatenate_168[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_171 (Concatenate)   (None, 30, 768)      0           conv1d_107[1][0]                 \n",
      "                                                                 dot_188[0][0]                    \n",
      "                                                                 concatenate_169[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_108 (Conv1D)             (None, 30, 42)       96810       concatenate_170[0][0]            \n",
      "                                                                 concatenate_171[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot_190 (Dot)                   (None, 30, 30)       0           conv1d_108[0][0]                 \n",
      "                                                                 conv1d_108[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_143 (Lambda)             (None, 30, 30)       0           dot_190[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_64 (Permute)            (None, 30, 30)       0           lambda_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_142 (Lambda)             (None, 30, 30)       0           dot_190[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_192 (Dot)                   (None, 30, 42)       0           permute_64[0][0]                 \n",
      "                                                                 conv1d_108[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_191 (Dot)                   (None, 30, 42)       0           lambda_142[0][0]                 \n",
      "                                                                 conv1d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_172 (Concatenate)   (None, 30, 852)      0           conv1d_108[0][0]                 \n",
      "                                                                 dot_192[0][0]                    \n",
      "                                                                 concatenate_170[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_173 (Concatenate)   (None, 30, 852)      0           conv1d_108[1][0]                 \n",
      "                                                                 dot_191[0][0]                    \n",
      "                                                                 concatenate_171[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_31 (Gl (None, 852)          0           concatenate_172[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_31 (Global (None, 852)          0           concatenate_172[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_weighted_average_16 ( (None, 852)          852         concatenate_172[0][0]            \n",
      "                                                                 concatenate_173[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_32 (Gl (None, 852)          0           concatenate_173[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_32 (Global (None, 852)          0           concatenate_173[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_174 (Concatenate)   (None, 2556)         0           global_average_pooling1d_31[0][0]\n",
      "                                                                 global_max_pooling1d_31[0][0]    \n",
      "                                                                 attention_weighted_average_16[0][\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_175 (Concatenate)   (None, 2556)         0           global_average_pooling1d_32[0][0]\n",
      "                                                                 global_max_pooling1d_32[0][0]    \n",
      "                                                                 attention_weighted_average_16[1][\n",
      "__________________________________________________________________________________________________\n",
      "lambda_144 (Lambda)             (None, 2556)         0           concatenate_174[0][0]            \n",
      "                                                                 concatenate_175[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_16 (Multiply)          (None, 2556)         0           concatenate_174[0][0]            \n",
      "                                                                 concatenate_175[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_176 (Concatenate)   (None, 10224)        0           concatenate_174[0][0]            \n",
      "                                                                 concatenate_175[0][0]            \n",
      "                                                                 lambda_144[0][0]                 \n",
      "                                                                 multiply_16[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 10224)        0           concatenate_176[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 128)          1308800     dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 3)            387         dense_31[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 31,698,917\n",
      "Trainable params: 1,698,917\n",
      "Non-trainable params: 30,000,000\n",
      "__________________________________________________________________________________________________\n",
      "Load weights from WordSGNS-DenseCNN5Layers-NoMeta-3P-NoEM-NoClassWeighted-3Layers7.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360609/360609 [==============================] - 57s 158us/step - loss: 0.0192 - acc: 0.8929 - weighted_accuracy: 0.8889 - val_loss: 0.2956 - val_acc: 0.8663 - val_weighted_accuracy: 0.8544\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 55s 152us/step - loss: 0.0187 - acc: 0.8967 - weighted_accuracy: 0.8931 - val_loss: 0.3027 - val_acc: 0.8630 - val_weighted_accuracy: 0.8570\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 55s 152us/step - loss: 0.0184 - acc: 0.8992 - weighted_accuracy: 0.8956 - val_loss: 0.3069 - val_acc: 0.8585 - val_weighted_accuracy: 0.8513\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 55s 152us/step - loss: 0.0180 - acc: 0.9020 - weighted_accuracy: 0.8991 - val_loss: 0.2966 - val_acc: 0.8680 - val_weighted_accuracy: 0.8556\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0178 - acc: 0.9032 - weighted_accuracy: 0.9006 - val_loss: 0.2858 - val_acc: 0.8716 - val_weighted_accuracy: 0.8584\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0175 - acc: 0.9057 - weighted_accuracy: 0.9032 - val_loss: 0.3120 - val_acc: 0.8591 - val_weighted_accuracy: 0.8483\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0173 - acc: 0.9065 - weighted_accuracy: 0.9045 - val_loss: 0.3035 - val_acc: 0.8630 - val_weighted_accuracy: 0.8530\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0170 - acc: 0.9084 - weighted_accuracy: 0.9068 - val_loss: 0.3044 - val_acc: 0.8634 - val_weighted_accuracy: 0.8532\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0168 - acc: 0.9095 - weighted_accuracy: 0.9082 - val_loss: 0.2916 - val_acc: 0.8692 - val_weighted_accuracy: 0.8570\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0166 - acc: 0.9110 - weighted_accuracy: 0.9098 - val_loss: 0.2961 - val_acc: 0.8656 - val_weighted_accuracy: 0.8563\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0164 - acc: 0.9123 - weighted_accuracy: 0.9110 - val_loss: 0.2950 - val_acc: 0.8709 - val_weighted_accuracy: 0.8582\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0163 - acc: 0.9131 - weighted_accuracy: 0.9121 - val_loss: 0.3086 - val_acc: 0.8615 - val_weighted_accuracy: 0.8549\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0161 - acc: 0.9143 - weighted_accuracy: 0.9136 - val_loss: 0.2909 - val_acc: 0.8677 - val_weighted_accuracy: 0.8548\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 55s 151us/step - loss: 0.0159 - acc: 0.9155 - weighted_accuracy: 0.9151 - val_loss: 0.2932 - val_acc: 0.8702 - val_weighted_accuracy: 0.8548\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 54s 151us/step - loss: 0.0159 - acc: 0.9160 - weighted_accuracy: 0.9157 - val_loss: 0.2999 - val_acc: 0.8671 - val_weighted_accuracy: 0.8569\n",
      "score 0.8555160966380843\n",
      "Predicting training results...\n",
      "Predicting testing results...\n",
      "80126/80126 [==============================] - 5s 59us/step\n",
      "80126/80126 [==============================] - 5s 58us/step\n",
      "80126/80126 [==============================] - 5s 58us/step\n",
      "80126/80126 [==============================] - 5s 58us/step\n",
      "80126/80126 [==============================] - 5s 58us/step\n",
      "80126/80126 [==============================] - 5s 58us/step\n",
      "80126/80126 [==============================] - 5s 58us/step\n",
      "80126/80126 [==============================] - 5s 58us/step\n",
      "Predicting labeled testing results...\n"
     ]
    }
   ],
   "source": [
    "fold_count = 8\n",
    "embedding_matrix = sgns_bigram_matrix\n",
    "#embedding_matrix = tencent_ai_matrix\n",
    "EMBEDDING_DIM = 300\n",
    "\n",
    "for i in range(1, len(model_manager.models_tag)):\n",
    "    print(\"Work on model\", i)\n",
    "    model_tag = model_manager.models_tag[i]\n",
    "    model_func = model_manager.model_funcs[i]\n",
    "    #models_checkpoints_path = model_manager.models_checkpoints_pathes[i]\n",
    "    models_checkpoints_path = \"WordSGNS-DenseCNN5Layers-NoMeta-3P-NoEM-NoClassWeighted-3Layers\"\n",
    "\n",
    "    model_submit_prefix = model_manager.submit_predix[i]\n",
    "    model_class_weights = model_manager.model_class_weights[i]\n",
    "    model_class_weights = None\n",
    "    model_scale_sample_weights = model_manager.model_scale_sample_weights[i]\n",
    "    model_scale_sample_weights = None\n",
    "    model_patiences = model_manager.model_patiences[i]\n",
    "    \n",
    "    #model_class_weights = {0:100, 1:1.5, 0.9: 3}\n",
    "    \n",
    "    def _agent_get_model():\n",
    "        return get_dense_cnn(NB_WORDS, EMBEDDING_DIM, embedding_matrix, MAX_SEQUENCE_LENGTH, OUT_SIZE)\n",
    "        return model_func(NB_WORDS, EMBEDDING_DIM, embedding_matrix, MAX_SEQUENCE_LENGTH, OUT_SIZE)\n",
    "    \n",
    "    test_predicts_list = []\n",
    "    oofs_predictions = []\n",
    "    pre_trained_models = []\n",
    "        \n",
    "    trainer = KerasModelTrainer(model_stamp=models_checkpoints_path, epoch_num=500)\n",
    "    models, score, folds_preds = trainer.train_folds(X=trains, y=labels, tests=tests, augments=None, fold_count=fold_count, batch_size=1024,\n",
    "        em_train_features=em_train_features, em_test_features=em_test_features, pseudo_labels=pseudo_labels,                                      \n",
    "        scale_sample_weight=model_scale_sample_weights, class_weight=model_class_weights,\n",
    "        get_model_func=_agent_get_model, \n",
    "        patience=10)\n",
    "\n",
    "    print(\"score\", score)\n",
    "    oofs_dir = \"../data/pseudo/oofs/\"\n",
    "    output_dir = \"../data/pseudo/output/\"\n",
    "    onehot_pred_dir = \"../data/pseudo/one_hot_pred/\"\n",
    "\n",
    "    model_submit_prefix = \"PSWordSGNS-DenseCNN5Layers-NoMeta-3P-NoEM-NoClassWeighted-3Layers\"\n",
    "    \n",
    "    oofs_path = oofs_dir + model_submit_prefix\n",
    "    output_path = output_dir + model_submit_prefix\n",
    "    one_hot_pred_path = onehot_pred_dir + \"One-Hot\" + model_submit_prefix\n",
    "\n",
    "    print(\"Predicting training results...\")\n",
    "    train_predicts = np.concatenate(folds_preds, axis=0)\n",
    "    oofs = pd.DataFrame({\"unrelated\": train_predicts[:, 0], \"agreed\": train_predicts[:, 1], \"disagreed\": train_predicts[:, 2]})\n",
    "    score = numpy_weighted_accuracy(labels, oofs[['unrelated', 'agreed', 'disagreed']].values)\n",
    "    submit_path = oofs_path + \"-Train-L{:4f}-NB{:d}.csv\".format(score, NB_WORDS)\n",
    "    oofs.to_csv(submit_path, index=False)\n",
    "    \n",
    "\n",
    "    print(\"Predicting testing results...\")\n",
    "    test_predicts_list = []\n",
    "    for fold_id, model in enumerate(models):\n",
    "        test_predicts = model.predict({\"first_sentences\":tests[0],\n",
    "                                       \"second_sentences\":tests[1],\n",
    "                                       \"mata-features\":tests[2],\n",
    "                                       \"first_exact_match\": tests_1_ems,\n",
    "                                       \"second_exact_match\": tests_2_ems,\n",
    "                                      }, batch_size=128, verbose=1)\n",
    "\n",
    "        test_predicts_list.append(test_predicts)\n",
    "\n",
    "    test_predicts = np.zeros(test_predicts_list[0].shape)\n",
    "    for fold_predict in test_predicts_list:\n",
    "        test_predicts += fold_predict\n",
    "    test_predicts /= len(test_predicts_list)\n",
    "\n",
    "    test_predicts = pd.DataFrame({\"unrelated\": test_predicts[:, 0], \"agreed\": test_predicts[:, 1], \"disagreed\": test_predicts[:, 2]})\n",
    "    submit_path = output_path + \"-L{:4f}-NB{:d}.csv\".format(score, NB_WORDS)\n",
    "    test_predicts.to_csv(submit_path, index=False) # 0.3343\n",
    "    \n",
    "    print(\"Predicting labeled testing results...\")\n",
    "    ids = pd.read_csv(\"../data/dataset/test.csv\")\n",
    "    pred_labels = test_predicts.idxmax(axis=1)\n",
    "    sub = pd.DataFrame({\"Id\": ids['id'].values, \"Category\": pred_labels})\n",
    "    submit_path = one_hot_pred_path + \"-L{:4f}-NB{:d}.csv\".format(score, NB_WORDS)\n",
    "    sub.to_csv(submit_path, index=False)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8519272497594231"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_weighted_accuracy(labels, oofs[['unrelated', 'agreed', 'disagreed']].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "def get_ESIM(nb_words, embedding_dim, embedding_matrix, max_sequence_length, out_size,\n",
    "    projection_dim=50, projection_hidden=0, projection_dropout=0.2,\n",
    "    compare_dim=288, compare_dropout=0.2,\n",
    "    dense_dim=50, dense_dropout=0.2,\n",
    "    lr=1e-3, activation='relu'):\n",
    "\n",
    "    q1 = Input(shape=(max_sequence_length,), name='first_sentences')\n",
    "    q2 = Input(shape=(max_sequence_length,), name='second_sentences')\n",
    "    q1_exact_match = Input(shape=(max_sequence_length,), name='first_exact_match')\n",
    "    q2_exact_match = Input(shape=(max_sequence_length,), name='second_exact_match')\n",
    "    \n",
    "    input_layer_3 = Input(shape=(36,), name='mata-features', dtype=\"float32\")\n",
    "    \n",
    "    embedding = Embedding(nb_words, embedding_dim,\n",
    "                          weights=[embedding_matrix],\n",
    "                          input_length=max_sequence_length,\n",
    "                          trainable=False)\n",
    "    \n",
    "    q1_embed = embedding(q1)\n",
    "    q1_embed = SpatialDropout1D(0.1)(q1_embed)\n",
    "    q2_embed = embedding(q2)\n",
    "    q2_embed = SpatialDropout1D(0.1)(q2_embed)\n",
    "\n",
    "    batch_norm = BatchNormalization(axis=-1)\n",
    "    q1_embed = batch_norm(q1_embed,)\n",
    "    q2_embed = batch_norm(q2_embed,)  \n",
    "    \n",
    "    aggreation_gru = Bidirectional(CuDNNLSTM(100, return_sequences=True))\n",
    " \n",
    "    q1_seq = aggreation_gru(q1_embed)\n",
    "    q2_seq = aggreation_gru(q2_embed)\n",
    "        \n",
    "    q1_aligned, q2_aligned = soft_attention_alignment(q1_seq, q2_seq)\n",
    "    \n",
    "    q1_vec = Concatenate()([q1_seq, q2_aligned, substract(q1_seq, q2_aligned), Multiply()([q1_seq, q2_aligned])])\n",
    "    q2_vec = Concatenate()([q2_seq, q1_aligned, substract(q2_seq, q1_aligned), Multiply()([q2_seq, q1_aligned])])\n",
    "    \n",
    "    compare_gru = Bidirectional(CuDNNLSTM(100, return_sequences=True))\n",
    "    \n",
    "    q1_rep = compare_gru(q1_vec)\n",
    "    q2_rep = compare_gru(q2_vec)\n",
    "    \n",
    "    q1_rep = apply_multiple(q1_rep, [GlobalAvgPool1D(), GlobalMaxPool1D()])\n",
    "    q2_rep = apply_multiple(q2_rep, [GlobalAvgPool1D(), GlobalMaxPool1D()])    \n",
    "    \n",
    "    h_all = Concatenate()([q1_rep, q2_rep])\n",
    "    h_all = BatchNormalization()(h_all)\n",
    "    \n",
    "    h_all = Dense(256, activation='elu')(h_all)\n",
    "    h_all = BatchNormalization()(h_all)\n",
    "    h_all = Dropout(0.5)(h_all)\n",
    "    \n",
    "    h_all = Dense(256, activation='elu')(h_all)\n",
    "    h_all = BatchNormalization()(h_all)\n",
    "    h_all = Dropout(0.5)(h_all)\n",
    "   \n",
    "    out_ = Dense(3, activation='softmax')(h_all)\n",
    "    \n",
    "    model = Model(inputs=[q1, q2, input_layer_3, q1_exact_match, q2_exact_match], outputs=out_)\n",
    "    model.compile(optimizer=Adam(lr=lr, decay=1e-6, clipnorm=1.5,), loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', weighted_accuracy])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## TenCent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Work on model 1\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_17 (Embedding)        (None, 30, 200)      20000000    first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_33 (SpatialDr (None, 30, 200)      0           embedding_17[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_34 (SpatialDr (None, 30, 200)      0           embedding_17[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 30, 200)      800         spatial_dropout1d_33[0][0]       \n",
      "                                                                 spatial_dropout1d_34[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 30, 200)      241600      batch_normalization_1[0][0]      \n",
      "                                                                 batch_normalization_1[1][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dot_193 (Dot)                   (None, 30, 30)       0           bidirectional_1[0][0]            \n",
      "                                                                 bidirectional_1[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_146 (Lambda)             (None, 30, 30)       0           dot_193[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_65 (Permute)            (None, 30, 30)       0           lambda_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_145 (Lambda)             (None, 30, 30)       0           dot_193[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_195 (Dot)                   (None, 30, 200)      0           permute_65[0][0]                 \n",
      "                                                                 bidirectional_1[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot_194 (Dot)                   (None, 30, 200)      0           lambda_145[0][0]                 \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_147 (Lambda)             (None, 30, 200)      0           bidirectional_1[0][0]            \n",
      "                                                                 dot_195[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_17 (Multiply)          (None, 30, 200)      0           bidirectional_1[0][0]            \n",
      "                                                                 dot_195[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_148 (Lambda)             (None, 30, 200)      0           bidirectional_1[1][0]            \n",
      "                                                                 dot_194[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_18 (Multiply)          (None, 30, 200)      0           bidirectional_1[1][0]            \n",
      "                                                                 dot_194[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_177 (Concatenate)   (None, 30, 800)      0           bidirectional_1[0][0]            \n",
      "                                                                 dot_195[0][0]                    \n",
      "                                                                 lambda_147[0][0]                 \n",
      "                                                                 multiply_17[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_178 (Concatenate)   (None, 30, 800)      0           bidirectional_1[1][0]            \n",
      "                                                                 dot_194[0][0]                    \n",
      "                                                                 lambda_148[0][0]                 \n",
      "                                                                 multiply_18[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 30, 200)      721600      concatenate_177[0][0]            \n",
      "                                                                 concatenate_178[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_33 (Gl (None, 200)          0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_33 (Global (None, 200)          0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_34 (Gl (None, 200)          0           bidirectional_2[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_34 (Global (None, 200)          0           bidirectional_2[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_179 (Concatenate)   (None, 400)          0           global_average_pooling1d_33[0][0]\n",
      "                                                                 global_max_pooling1d_33[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_180 (Concatenate)   (None, 400)          0           global_average_pooling1d_34[0][0]\n",
      "                                                                 global_max_pooling1d_34[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_181 (Concatenate)   (None, 800)          0           concatenate_179[0][0]            \n",
      "                                                                 concatenate_180[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 800)          3200        concatenate_181[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 256)          205056      batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 256)          1024        dense_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 256)          0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_34 (Dense)                (None, 256)          65792       dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 256)          1024        dense_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 256)          0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_35 (Dense)                (None, 3)            771         dropout_18[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 21,240,867\n",
      "Trainable params: 1,237,843\n",
      "Non-trainable params: 20,003,024\n",
      "__________________________________________________________________________________________________\n",
      "Load weights from WordTC-ESIM-NoMeta-3P-NoEM-NoClassWeighted-3Layers0.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360609/360609 [==============================] - 147s 407us/step - loss: 0.0196 - acc: 0.8922 - weighted_accuracy: 0.8877 - val_loss: 0.3226 - val_acc: 0.8534 - val_weighted_accuracy: 0.8522\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 144s 400us/step - loss: 0.0189 - acc: 0.8981 - weighted_accuracy: 0.8942 - val_loss: 0.3269 - val_acc: 0.8513 - val_weighted_accuracy: 0.8488\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 145s 403us/step - loss: 0.0182 - acc: 0.9021 - weighted_accuracy: 0.8989 - val_loss: 0.3242 - val_acc: 0.8568 - val_weighted_accuracy: 0.8518\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 142s 393us/step - loss: 0.0176 - acc: 0.9058 - weighted_accuracy: 0.9033 - val_loss: 0.3091 - val_acc: 0.8622 - val_weighted_accuracy: 0.8552\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 145s 402us/step - loss: 0.0171 - acc: 0.9094 - weighted_accuracy: 0.9074 - val_loss: 0.3141 - val_acc: 0.8574 - val_weighted_accuracy: 0.8533\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 141s 392us/step - loss: 0.0166 - acc: 0.9128 - weighted_accuracy: 0.9114 - val_loss: 0.3094 - val_acc: 0.8636 - val_weighted_accuracy: 0.8582\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 144s 400us/step - loss: 0.0162 - acc: 0.9165 - weighted_accuracy: 0.9154 - val_loss: 0.3189 - val_acc: 0.8557 - val_weighted_accuracy: 0.8537\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 141s 392us/step - loss: 0.0158 - acc: 0.9190 - weighted_accuracy: 0.9181 - val_loss: 0.3055 - val_acc: 0.8651 - val_weighted_accuracy: 0.8607\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 138s 384us/step - loss: 0.0154 - acc: 0.9207 - weighted_accuracy: 0.9204 - val_loss: 0.3048 - val_acc: 0.8685 - val_weighted_accuracy: 0.8601\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 142s 393us/step - loss: 0.0150 - acc: 0.9232 - weighted_accuracy: 0.9232 - val_loss: 0.3006 - val_acc: 0.8697 - val_weighted_accuracy: 0.8632\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 141s 391us/step - loss: 0.0147 - acc: 0.9250 - weighted_accuracy: 0.9250 - val_loss: 0.3175 - val_acc: 0.8586 - val_weighted_accuracy: 0.8544\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 143s 395us/step - loss: 0.0144 - acc: 0.9274 - weighted_accuracy: 0.9277 - val_loss: 0.3063 - val_acc: 0.8673 - val_weighted_accuracy: 0.8606\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 143s 395us/step - loss: 0.0141 - acc: 0.9294 - weighted_accuracy: 0.9299 - val_loss: 0.3045 - val_acc: 0.8701 - val_weighted_accuracy: 0.8629\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 146s 404us/step - loss: 0.0139 - acc: 0.9304 - weighted_accuracy: 0.9310 - val_loss: 0.3207 - val_acc: 0.8629 - val_weighted_accuracy: 0.8578\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 145s 401us/step - loss: 0.0136 - acc: 0.9322 - weighted_accuracy: 0.9331 - val_loss: 0.3086 - val_acc: 0.8673 - val_weighted_accuracy: 0.8610\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 141s 391us/step - loss: 0.0133 - acc: 0.9347 - weighted_accuracy: 0.9357 - val_loss: 0.3114 - val_acc: 0.8733 - val_weighted_accuracy: 0.8643\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 146s 405us/step - loss: 0.0130 - acc: 0.9360 - weighted_accuracy: 0.9371 - val_loss: 0.3065 - val_acc: 0.8694 - val_weighted_accuracy: 0.8620\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 144s 400us/step - loss: 0.0129 - acc: 0.9374 - weighted_accuracy: 0.9387 - val_loss: 0.3202 - val_acc: 0.8671 - val_weighted_accuracy: 0.8603\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 145s 401us/step - loss: 0.0126 - acc: 0.9385 - weighted_accuracy: 0.9398 - val_loss: 0.3455 - val_acc: 0.8596 - val_weighted_accuracy: 0.8548\n",
      "Epoch 20/500\n",
      "360609/360609 [==============================] - 146s 404us/step - loss: 0.0125 - acc: 0.9400 - weighted_accuracy: 0.9415 - val_loss: 0.3253 - val_acc: 0.8704 - val_weighted_accuracy: 0.8609\n",
      "Epoch 21/500\n",
      "360609/360609 [==============================] - 144s 400us/step - loss: 0.0123 - acc: 0.9407 - weighted_accuracy: 0.9424 - val_loss: 0.3307 - val_acc: 0.8699 - val_weighted_accuracy: 0.8593\n",
      "Epoch 22/500\n",
      "360609/360609 [==============================] - 146s 405us/step - loss: 0.0121 - acc: 0.9422 - weighted_accuracy: 0.9437 - val_loss: 0.3378 - val_acc: 0.8657 - val_weighted_accuracy: 0.8568\n",
      "Epoch 23/500\n",
      "360609/360609 [==============================] - 146s 404us/step - loss: 0.0119 - acc: 0.9437 - weighted_accuracy: 0.9453 - val_loss: 0.3299 - val_acc: 0.8682 - val_weighted_accuracy: 0.8573\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_18 (Embedding)        (None, 30, 200)      20000000    first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_35 (SpatialDr (None, 30, 200)      0           embedding_18[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_36 (SpatialDr (None, 30, 200)      0           embedding_18[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 30, 200)      800         spatial_dropout1d_35[0][0]       \n",
      "                                                                 spatial_dropout1d_36[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 30, 200)      241600      batch_normalization_5[0][0]      \n",
      "                                                                 batch_normalization_5[1][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dot_196 (Dot)                   (None, 30, 30)       0           bidirectional_3[0][0]            \n",
      "                                                                 bidirectional_3[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_150 (Lambda)             (None, 30, 30)       0           dot_196[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_66 (Permute)            (None, 30, 30)       0           lambda_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_149 (Lambda)             (None, 30, 30)       0           dot_196[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_198 (Dot)                   (None, 30, 200)      0           permute_66[0][0]                 \n",
      "                                                                 bidirectional_3[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot_197 (Dot)                   (None, 30, 200)      0           lambda_149[0][0]                 \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_151 (Lambda)             (None, 30, 200)      0           bidirectional_3[0][0]            \n",
      "                                                                 dot_198[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_19 (Multiply)          (None, 30, 200)      0           bidirectional_3[0][0]            \n",
      "                                                                 dot_198[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_152 (Lambda)             (None, 30, 200)      0           bidirectional_3[1][0]            \n",
      "                                                                 dot_197[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_20 (Multiply)          (None, 30, 200)      0           bidirectional_3[1][0]            \n",
      "                                                                 dot_197[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_182 (Concatenate)   (None, 30, 800)      0           bidirectional_3[0][0]            \n",
      "                                                                 dot_198[0][0]                    \n",
      "                                                                 lambda_151[0][0]                 \n",
      "                                                                 multiply_19[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_183 (Concatenate)   (None, 30, 800)      0           bidirectional_3[1][0]            \n",
      "                                                                 dot_197[0][0]                    \n",
      "                                                                 lambda_152[0][0]                 \n",
      "                                                                 multiply_20[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 30, 200)      721600      concatenate_182[0][0]            \n",
      "                                                                 concatenate_183[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_35 (Gl (None, 200)          0           bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_35 (Global (None, 200)          0           bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_36 (Gl (None, 200)          0           bidirectional_4[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_36 (Global (None, 200)          0           bidirectional_4[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_184 (Concatenate)   (None, 400)          0           global_average_pooling1d_35[0][0]\n",
      "                                                                 global_max_pooling1d_35[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_185 (Concatenate)   (None, 400)          0           global_average_pooling1d_36[0][0]\n",
      "                                                                 global_max_pooling1d_36[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_186 (Concatenate)   (None, 800)          0           concatenate_184[0][0]            \n",
      "                                                                 concatenate_185[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 800)          3200        concatenate_186[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_36 (Dense)                (None, 256)          205056      batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 256)          1024        dense_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 256)          0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_37 (Dense)                (None, 256)          65792       dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 256)          1024        dense_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 256)          0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_38 (Dense)                (None, 3)            771         dropout_20[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 21,240,867\n",
      "Trainable params: 1,237,843\n",
      "Non-trainable params: 20,003,024\n",
      "__________________________________________________________________________________________________\n",
      "Load weights from WordTC-ESIM-NoMeta-3P-NoEM-NoClassWeighted-3Layers1.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360609/360609 [==============================] - 147s 408us/step - loss: 0.0186 - acc: 0.9001 - weighted_accuracy: 0.8959 - val_loss: 0.2860 - val_acc: 0.8759 - val_weighted_accuracy: 0.8673\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 145s 403us/step - loss: 0.0180 - acc: 0.9045 - weighted_accuracy: 0.9012 - val_loss: 0.2847 - val_acc: 0.8728 - val_weighted_accuracy: 0.8659\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 142s 394us/step - loss: 0.0174 - acc: 0.9080 - weighted_accuracy: 0.9052 - val_loss: 0.2853 - val_acc: 0.8740 - val_weighted_accuracy: 0.8667\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 141s 391us/step - loss: 0.0169 - acc: 0.9118 - weighted_accuracy: 0.9093 - val_loss: 0.2873 - val_acc: 0.8741 - val_weighted_accuracy: 0.8686\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 146s 406us/step - loss: 0.0164 - acc: 0.9149 - weighted_accuracy: 0.9130 - val_loss: 0.2801 - val_acc: 0.8778 - val_weighted_accuracy: 0.8711\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 145s 402us/step - loss: 0.0160 - acc: 0.9166 - weighted_accuracy: 0.9155 - val_loss: 0.3001 - val_acc: 0.8683 - val_weighted_accuracy: 0.8646\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 147s 407us/step - loss: 0.0156 - acc: 0.9203 - weighted_accuracy: 0.9195 - val_loss: 0.2723 - val_acc: 0.8823 - val_weighted_accuracy: 0.8718\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 146s 403us/step - loss: 0.0152 - acc: 0.9223 - weighted_accuracy: 0.9217 - val_loss: 0.3067 - val_acc: 0.8668 - val_weighted_accuracy: 0.8638\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 144s 400us/step - loss: 0.0148 - acc: 0.9249 - weighted_accuracy: 0.9247 - val_loss: 0.2891 - val_acc: 0.8754 - val_weighted_accuracy: 0.8697\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 140s 389us/step - loss: 0.0146 - acc: 0.9267 - weighted_accuracy: 0.9268 - val_loss: 0.2868 - val_acc: 0.8789 - val_weighted_accuracy: 0.8720\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 145s 401us/step - loss: 0.0142 - acc: 0.9291 - weighted_accuracy: 0.9294 - val_loss: 0.2803 - val_acc: 0.8830 - val_weighted_accuracy: 0.8750\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 142s 394us/step - loss: 0.0140 - acc: 0.9308 - weighted_accuracy: 0.9312 - val_loss: 0.2905 - val_acc: 0.8769 - val_weighted_accuracy: 0.87000.0140 - acc: 0.\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 141s 390us/step - loss: 0.0137 - acc: 0.9322 - weighted_accuracy: 0.9331 - val_loss: 0.2913 - val_acc: 0.8777 - val_weighted_accuracy: 0.8712\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 142s 393us/step - loss: 0.0135 - acc: 0.9327 - weighted_accuracy: 0.9334 - val_loss: 0.2885 - val_acc: 0.8807 - val_weighted_accuracy: 0.8730\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 142s 395us/step - loss: 0.0133 - acc: 0.9349 - weighted_accuracy: 0.9359 - val_loss: 0.2976 - val_acc: 0.8778 - val_weighted_accuracy: 0.8697\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 142s 395us/step - loss: 0.0130 - acc: 0.9368 - weighted_accuracy: 0.9380 - val_loss: 0.2899 - val_acc: 0.8806 - val_weighted_accuracy: 0.8710\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 146s 405us/step - loss: 0.0127 - acc: 0.9387 - weighted_accuracy: 0.9398 - val_loss: 0.2869 - val_acc: 0.8829 - val_weighted_accuracy: 0.8711\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 142s 394us/step - loss: 0.0126 - acc: 0.9395 - weighted_accuracy: 0.9408 - val_loss: 0.2990 - val_acc: 0.8801 - val_weighted_accuracy: 0.8709\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_19 (Embedding)        (None, 30, 200)      20000000    first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_37 (SpatialDr (None, 30, 200)      0           embedding_19[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_38 (SpatialDr (None, 30, 200)      0           embedding_19[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 30, 200)      800         spatial_dropout1d_37[0][0]       \n",
      "                                                                 spatial_dropout1d_38[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 30, 200)      241600      batch_normalization_9[0][0]      \n",
      "                                                                 batch_normalization_9[1][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dot_199 (Dot)                   (None, 30, 30)       0           bidirectional_5[0][0]            \n",
      "                                                                 bidirectional_5[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_154 (Lambda)             (None, 30, 30)       0           dot_199[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_67 (Permute)            (None, 30, 30)       0           lambda_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_153 (Lambda)             (None, 30, 30)       0           dot_199[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_201 (Dot)                   (None, 30, 200)      0           permute_67[0][0]                 \n",
      "                                                                 bidirectional_5[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot_200 (Dot)                   (None, 30, 200)      0           lambda_153[0][0]                 \n",
      "                                                                 bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_155 (Lambda)             (None, 30, 200)      0           bidirectional_5[0][0]            \n",
      "                                                                 dot_201[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_21 (Multiply)          (None, 30, 200)      0           bidirectional_5[0][0]            \n",
      "                                                                 dot_201[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_156 (Lambda)             (None, 30, 200)      0           bidirectional_5[1][0]            \n",
      "                                                                 dot_200[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_22 (Multiply)          (None, 30, 200)      0           bidirectional_5[1][0]            \n",
      "                                                                 dot_200[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_187 (Concatenate)   (None, 30, 800)      0           bidirectional_5[0][0]            \n",
      "                                                                 dot_201[0][0]                    \n",
      "                                                                 lambda_155[0][0]                 \n",
      "                                                                 multiply_21[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_188 (Concatenate)   (None, 30, 800)      0           bidirectional_5[1][0]            \n",
      "                                                                 dot_200[0][0]                    \n",
      "                                                                 lambda_156[0][0]                 \n",
      "                                                                 multiply_22[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, 30, 200)      721600      concatenate_187[0][0]            \n",
      "                                                                 concatenate_188[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_37 (Gl (None, 200)          0           bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_37 (Global (None, 200)          0           bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_38 (Gl (None, 200)          0           bidirectional_6[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_38 (Global (None, 200)          0           bidirectional_6[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_189 (Concatenate)   (None, 400)          0           global_average_pooling1d_37[0][0]\n",
      "                                                                 global_max_pooling1d_37[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_190 (Concatenate)   (None, 400)          0           global_average_pooling1d_38[0][0]\n",
      "                                                                 global_max_pooling1d_38[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_191 (Concatenate)   (None, 800)          0           concatenate_189[0][0]            \n",
      "                                                                 concatenate_190[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 800)          3200        concatenate_191[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_39 (Dense)                (None, 256)          205056      batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 256)          1024        dense_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 256)          0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_40 (Dense)                (None, 256)          65792       dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 256)          1024        dense_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 256)          0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_41 (Dense)                (None, 3)            771         dropout_22[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 21,240,867\n",
      "Trainable params: 1,237,843\n",
      "Non-trainable params: 20,003,024\n",
      "__________________________________________________________________________________________________\n",
      "Load weights from WordTC-ESIM-NoMeta-3P-NoEM-NoClassWeighted-3Layers2.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360609/360609 [==============================] - 146s 404us/step - loss: 0.0203 - acc: 0.8883 - weighted_accuracy: 0.8830 - val_loss: 0.3067 - val_acc: 0.8616 - val_weighted_accuracy: 0.8562\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 145s 403us/step - loss: 0.0195 - acc: 0.8932 - weighted_accuracy: 0.8888 - val_loss: 0.3091 - val_acc: 0.8592 - val_weighted_accuracy: 0.8574\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 141s 391us/step - loss: 0.0187 - acc: 0.8990 - weighted_accuracy: 0.8950 - val_loss: 0.3087 - val_acc: 0.8640 - val_weighted_accuracy: 0.8605\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 142s 393us/step - loss: 0.0182 - acc: 0.9021 - weighted_accuracy: 0.8989 - val_loss: 0.3226 - val_acc: 0.8512 - val_weighted_accuracy: 0.8496\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 145s 402us/step - loss: 0.0175 - acc: 0.9071 - weighted_accuracy: 0.9045 - val_loss: 0.2997 - val_acc: 0.8665 - val_weighted_accuracy: 0.8605\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 147s 409us/step - loss: 0.0171 - acc: 0.9099 - weighted_accuracy: 0.9077 - val_loss: 0.3187 - val_acc: 0.8568 - val_weighted_accuracy: 0.8574\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 145s 401us/step - loss: 0.0166 - acc: 0.9132 - weighted_accuracy: 0.9115 - val_loss: 0.3027 - val_acc: 0.8634 - val_weighted_accuracy: 0.8584\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 146s 405us/step - loss: 0.0161 - acc: 0.9164 - weighted_accuracy: 0.9153 - val_loss: 0.3017 - val_acc: 0.8652 - val_weighted_accuracy: 0.8592\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 147s 407us/step - loss: 0.0157 - acc: 0.9190 - weighted_accuracy: 0.9182 - val_loss: 0.3072 - val_acc: 0.8660 - val_weighted_accuracy: 0.8619\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 147s 407us/step - loss: 0.0154 - acc: 0.9215 - weighted_accuracy: 0.9210 - val_loss: 0.3218 - val_acc: 0.8548 - val_weighted_accuracy: 0.8537\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 143s 396us/step - loss: 0.0150 - acc: 0.9231 - weighted_accuracy: 0.9229 - val_loss: 0.3051 - val_acc: 0.8662 - val_weighted_accuracy: 0.8618\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 145s 402us/step - loss: 0.0147 - acc: 0.9255 - weighted_accuracy: 0.9254 - val_loss: 0.3269 - val_acc: 0.8582 - val_weighted_accuracy: 0.8557\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 148s 411us/step - loss: 0.0143 - acc: 0.9283 - weighted_accuracy: 0.9284 - val_loss: 0.3015 - val_acc: 0.8713 - val_weighted_accuracy: 0.8613\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 143s 396us/step - loss: 0.0141 - acc: 0.9292 - weighted_accuracy: 0.9297 - val_loss: 0.3251 - val_acc: 0.8607 - val_weighted_accuracy: 0.8554\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 147s 407us/step - loss: 0.0138 - acc: 0.9304 - weighted_accuracy: 0.9310 - val_loss: 0.3004 - val_acc: 0.8706 - val_weighted_accuracy: 0.8623\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 145s 401us/step - loss: 0.0136 - acc: 0.9321 - weighted_accuracy: 0.9329 - val_loss: 0.3120 - val_acc: 0.8637 - val_weighted_accuracy: 0.8587\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 144s 400us/step - loss: 0.0133 - acc: 0.9343 - weighted_accuracy: 0.9352 - val_loss: 0.3147 - val_acc: 0.8670 - val_weighted_accuracy: 0.8607\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 144s 400us/step - loss: 0.0131 - acc: 0.9362 - weighted_accuracy: 0.9371 - val_loss: 0.3361 - val_acc: 0.8596 - val_weighted_accuracy: 0.8541\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 143s 397us/step - loss: 0.0129 - acc: 0.9369 - weighted_accuracy: 0.9381 - val_loss: 0.3110 - val_acc: 0.8672 - val_weighted_accuracy: 0.8616\n",
      "Epoch 20/500\n",
      "360609/360609 [==============================] - 148s 409us/step - loss: 0.0127 - acc: 0.9380 - weighted_accuracy: 0.9394 - val_loss: 0.3248 - val_acc: 0.8635 - val_weighted_accuracy: 0.8577\n",
      "Epoch 21/500\n",
      "360609/360609 [==============================] - 140s 388us/step - loss: 0.0125 - acc: 0.9397 - weighted_accuracy: 0.9408 - val_loss: 0.3160 - val_acc: 0.8716 - val_weighted_accuracy: 0.8640\n",
      "Epoch 22/500\n",
      "360609/360609 [==============================] - 139s 385us/step - loss: 0.0123 - acc: 0.9414 - weighted_accuracy: 0.9429 - val_loss: 0.3234 - val_acc: 0.8683 - val_weighted_accuracy: 0.8622\n",
      "Epoch 23/500\n",
      "360609/360609 [==============================] - 143s 396us/step - loss: 0.0122 - acc: 0.9418 - weighted_accuracy: 0.9431 - val_loss: 0.3140 - val_acc: 0.8676 - val_weighted_accuracy: 0.8603\n",
      "Epoch 24/500\n",
      "360609/360609 [==============================] - 142s 393us/step - loss: 0.0119 - acc: 0.9434 - weighted_accuracy: 0.9450 - val_loss: 0.3239 - val_acc: 0.8645 - val_weighted_accuracy: 0.8577\n",
      "Epoch 25/500\n",
      "360609/360609 [==============================] - 145s 401us/step - loss: 0.0118 - acc: 0.9437 - weighted_accuracy: 0.9453 - val_loss: 0.3328 - val_acc: 0.8655 - val_weighted_accuracy: 0.8594\n",
      "Epoch 26/500\n",
      "360609/360609 [==============================] - 145s 403us/step - loss: 0.0117 - acc: 0.9450 - weighted_accuracy: 0.9467 - val_loss: 0.3462 - val_acc: 0.8567 - val_weighted_accuracy: 0.8522\n",
      "Epoch 27/500\n",
      "360609/360609 [==============================] - 147s 407us/step - loss: 0.0115 - acc: 0.9456 - weighted_accuracy: 0.9472 - val_loss: 0.3346 - val_acc: 0.8682 - val_weighted_accuracy: 0.8611\n",
      "Epoch 28/500\n",
      "360609/360609 [==============================] - 144s 400us/step - loss: 0.0113 - acc: 0.9473 - weighted_accuracy: 0.9491 - val_loss: 0.3397 - val_acc: 0.8673 - val_weighted_accuracy: 0.8600\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_20 (Embedding)        (None, 30, 200)      20000000    first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_39 (SpatialDr (None, 30, 200)      0           embedding_20[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_40 (SpatialDr (None, 30, 200)      0           embedding_20[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 30, 200)      800         spatial_dropout1d_39[0][0]       \n",
      "                                                                 spatial_dropout1d_40[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, 30, 200)      241600      batch_normalization_13[0][0]     \n",
      "                                                                 batch_normalization_13[1][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dot_202 (Dot)                   (None, 30, 30)       0           bidirectional_7[0][0]            \n",
      "                                                                 bidirectional_7[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_158 (Lambda)             (None, 30, 30)       0           dot_202[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_68 (Permute)            (None, 30, 30)       0           lambda_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_157 (Lambda)             (None, 30, 30)       0           dot_202[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_204 (Dot)                   (None, 30, 200)      0           permute_68[0][0]                 \n",
      "                                                                 bidirectional_7[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot_203 (Dot)                   (None, 30, 200)      0           lambda_157[0][0]                 \n",
      "                                                                 bidirectional_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_159 (Lambda)             (None, 30, 200)      0           bidirectional_7[0][0]            \n",
      "                                                                 dot_204[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_23 (Multiply)          (None, 30, 200)      0           bidirectional_7[0][0]            \n",
      "                                                                 dot_204[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_160 (Lambda)             (None, 30, 200)      0           bidirectional_7[1][0]            \n",
      "                                                                 dot_203[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_24 (Multiply)          (None, 30, 200)      0           bidirectional_7[1][0]            \n",
      "                                                                 dot_203[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_192 (Concatenate)   (None, 30, 800)      0           bidirectional_7[0][0]            \n",
      "                                                                 dot_204[0][0]                    \n",
      "                                                                 lambda_159[0][0]                 \n",
      "                                                                 multiply_23[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_193 (Concatenate)   (None, 30, 800)      0           bidirectional_7[1][0]            \n",
      "                                                                 dot_203[0][0]                    \n",
      "                                                                 lambda_160[0][0]                 \n",
      "                                                                 multiply_24[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, 30, 200)      721600      concatenate_192[0][0]            \n",
      "                                                                 concatenate_193[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_39 (Gl (None, 200)          0           bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_39 (Global (None, 200)          0           bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_40 (Gl (None, 200)          0           bidirectional_8[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_40 (Global (None, 200)          0           bidirectional_8[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_194 (Concatenate)   (None, 400)          0           global_average_pooling1d_39[0][0]\n",
      "                                                                 global_max_pooling1d_39[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_195 (Concatenate)   (None, 400)          0           global_average_pooling1d_40[0][0]\n",
      "                                                                 global_max_pooling1d_40[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_196 (Concatenate)   (None, 800)          0           concatenate_194[0][0]            \n",
      "                                                                 concatenate_195[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 800)          3200        concatenate_196[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_42 (Dense)                (None, 256)          205056      batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 256)          1024        dense_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 256)          0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_43 (Dense)                (None, 256)          65792       dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 256)          1024        dense_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 256)          0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_44 (Dense)                (None, 3)            771         dropout_24[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 21,240,867\n",
      "Trainable params: 1,237,843\n",
      "Non-trainable params: 20,003,024\n",
      "__________________________________________________________________________________________________\n",
      "Load weights from WordTC-ESIM-NoMeta-3P-NoEM-NoClassWeighted-3Layers3.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360609/360609 [==============================] - 149s 413us/step - loss: 0.0185 - acc: 0.9012 - weighted_accuracy: 0.8970 - val_loss: 0.3037 - val_acc: 0.8637 - val_weighted_accuracy: 0.8580\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 147s 408us/step - loss: 0.0178 - acc: 0.9053 - weighted_accuracy: 0.9020 - val_loss: 0.3093 - val_acc: 0.8634 - val_weighted_accuracy: 0.8610\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 148s 410us/step - loss: 0.0173 - acc: 0.9088 - weighted_accuracy: 0.9061 - val_loss: 0.3074 - val_acc: 0.8623 - val_weighted_accuracy: 0.8572\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 143s 397us/step - loss: 0.0167 - acc: 0.9123 - weighted_accuracy: 0.9101 - val_loss: 0.3014 - val_acc: 0.8656 - val_weighted_accuracy: 0.8622\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 147s 407us/step - loss: 0.0163 - acc: 0.9153 - weighted_accuracy: 0.9136 - val_loss: 0.2990 - val_acc: 0.8676 - val_weighted_accuracy: 0.8628\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 144s 398us/step - loss: 0.0158 - acc: 0.9181 - weighted_accuracy: 0.9172 - val_loss: 0.3027 - val_acc: 0.8659 - val_weighted_accuracy: 0.8628\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 146s 405us/step - loss: 0.0154 - acc: 0.9206 - weighted_accuracy: 0.9199 - val_loss: 0.3141 - val_acc: 0.8649 - val_weighted_accuracy: 0.8621\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 146s 405us/step - loss: 0.0151 - acc: 0.9229 - weighted_accuracy: 0.9222 - val_loss: 0.3118 - val_acc: 0.8625 - val_weighted_accuracy: 0.8594\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 146s 405us/step - loss: 0.0148 - acc: 0.9252 - weighted_accuracy: 0.9248 - val_loss: 0.3013 - val_acc: 0.8682 - val_weighted_accuracy: 0.8611\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 144s 400us/step - loss: 0.0145 - acc: 0.9271 - weighted_accuracy: 0.9271 - val_loss: 0.3202 - val_acc: 0.8614 - val_weighted_accuracy: 0.8582\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 144s 400us/step - loss: 0.0141 - acc: 0.9289 - weighted_accuracy: 0.9292 - val_loss: 0.3057 - val_acc: 0.8678 - val_weighted_accuracy: 0.8614\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 148s 411us/step - loss: 0.0139 - acc: 0.9311 - weighted_accuracy: 0.9314 - val_loss: 0.3129 - val_acc: 0.8680 - val_weighted_accuracy: 0.8615\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_21 (Embedding)        (None, 30, 200)      20000000    first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_41 (SpatialDr (None, 30, 200)      0           embedding_21[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_42 (SpatialDr (None, 30, 200)      0           embedding_21[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 30, 200)      800         spatial_dropout1d_41[0][0]       \n",
      "                                                                 spatial_dropout1d_42[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, 30, 200)      241600      batch_normalization_17[0][0]     \n",
      "                                                                 batch_normalization_17[1][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dot_205 (Dot)                   (None, 30, 30)       0           bidirectional_9[0][0]            \n",
      "                                                                 bidirectional_9[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_162 (Lambda)             (None, 30, 30)       0           dot_205[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_69 (Permute)            (None, 30, 30)       0           lambda_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_161 (Lambda)             (None, 30, 30)       0           dot_205[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_207 (Dot)                   (None, 30, 200)      0           permute_69[0][0]                 \n",
      "                                                                 bidirectional_9[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot_206 (Dot)                   (None, 30, 200)      0           lambda_161[0][0]                 \n",
      "                                                                 bidirectional_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_163 (Lambda)             (None, 30, 200)      0           bidirectional_9[0][0]            \n",
      "                                                                 dot_207[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_25 (Multiply)          (None, 30, 200)      0           bidirectional_9[0][0]            \n",
      "                                                                 dot_207[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_164 (Lambda)             (None, 30, 200)      0           bidirectional_9[1][0]            \n",
      "                                                                 dot_206[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_26 (Multiply)          (None, 30, 200)      0           bidirectional_9[1][0]            \n",
      "                                                                 dot_206[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_197 (Concatenate)   (None, 30, 800)      0           bidirectional_9[0][0]            \n",
      "                                                                 dot_207[0][0]                    \n",
      "                                                                 lambda_163[0][0]                 \n",
      "                                                                 multiply_25[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_198 (Concatenate)   (None, 30, 800)      0           bidirectional_9[1][0]            \n",
      "                                                                 dot_206[0][0]                    \n",
      "                                                                 lambda_164[0][0]                 \n",
      "                                                                 multiply_26[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, 30, 200)      721600      concatenate_197[0][0]            \n",
      "                                                                 concatenate_198[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_41 (Gl (None, 200)          0           bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_41 (Global (None, 200)          0           bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_42 (Gl (None, 200)          0           bidirectional_10[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_42 (Global (None, 200)          0           bidirectional_10[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_199 (Concatenate)   (None, 400)          0           global_average_pooling1d_41[0][0]\n",
      "                                                                 global_max_pooling1d_41[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_200 (Concatenate)   (None, 400)          0           global_average_pooling1d_42[0][0]\n",
      "                                                                 global_max_pooling1d_42[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_201 (Concatenate)   (None, 800)          0           concatenate_199[0][0]            \n",
      "                                                                 concatenate_200[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 800)          3200        concatenate_201[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_45 (Dense)                (None, 256)          205056      batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 256)          1024        dense_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 256)          0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_46 (Dense)                (None, 256)          65792       dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 256)          1024        dense_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 256)          0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_47 (Dense)                (None, 3)            771         dropout_26[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 21,240,867\n",
      "Trainable params: 1,237,843\n",
      "Non-trainable params: 20,003,024\n",
      "__________________________________________________________________________________________________\n",
      "Load weights from WordTC-ESIM-NoMeta-3P-NoEM-NoClassWeighted-3Layers4.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360609/360609 [==============================] - 151s 420us/step - loss: 0.0190 - acc: 0.8974 - weighted_accuracy: 0.8931 - val_loss: 0.3290 - val_acc: 0.8524 - val_weighted_accuracy: 0.8500\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 149s 412us/step - loss: 0.0184 - acc: 0.9015 - weighted_accuracy: 0.8979 - val_loss: 0.3119 - val_acc: 0.8580 - val_weighted_accuracy: 0.8528\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 148s 411us/step - loss: 0.0177 - acc: 0.9052 - weighted_accuracy: 0.9024 - val_loss: 0.3099 - val_acc: 0.8610 - val_weighted_accuracy: 0.8546\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 148s 411us/step - loss: 0.0173 - acc: 0.9089 - weighted_accuracy: 0.9063 - val_loss: 0.3102 - val_acc: 0.8630 - val_weighted_accuracy: 0.8569\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 146s 404us/step - loss: 0.0168 - acc: 0.9112 - weighted_accuracy: 0.9092 - val_loss: 0.3158 - val_acc: 0.8564 - val_weighted_accuracy: 0.8536\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 148s 409us/step - loss: 0.0163 - acc: 0.9151 - weighted_accuracy: 0.9135 - val_loss: 0.3085 - val_acc: 0.8618 - val_weighted_accuracy: 0.8578\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 145s 401us/step - loss: 0.0159 - acc: 0.9177 - weighted_accuracy: 0.9165 - val_loss: 0.3135 - val_acc: 0.8632 - val_weighted_accuracy: 0.8574\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 143s 398us/step - loss: 0.0155 - acc: 0.9204 - weighted_accuracy: 0.9195 - val_loss: 0.3042 - val_acc: 0.8625 - val_weighted_accuracy: 0.8566\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 145s 401us/step - loss: 0.0151 - acc: 0.9225 - weighted_accuracy: 0.9222 - val_loss: 0.3240 - val_acc: 0.8613 - val_weighted_accuracy: 0.8568\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 142s 393us/step - loss: 0.0148 - acc: 0.9247 - weighted_accuracy: 0.9247 - val_loss: 0.3046 - val_acc: 0.8669 - val_weighted_accuracy: 0.8609\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 142s 394us/step - loss: 0.0144 - acc: 0.9265 - weighted_accuracy: 0.9264 - val_loss: 0.3105 - val_acc: 0.8656 - val_weighted_accuracy: 0.8579\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 141s 392us/step - loss: 0.0142 - acc: 0.9285 - weighted_accuracy: 0.9286 - val_loss: 0.3183 - val_acc: 0.8619 - val_weighted_accuracy: 0.8579\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 143s 396us/step - loss: 0.0140 - acc: 0.9300 - weighted_accuracy: 0.9302 - val_loss: 0.3251 - val_acc: 0.8612 - val_weighted_accuracy: 0.8573\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 141s 391us/step - loss: 0.0137 - acc: 0.9314 - weighted_accuracy: 0.9322 - val_loss: 0.3139 - val_acc: 0.8633 - val_weighted_accuracy: 0.8577\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 144s 399us/step - loss: 0.0135 - acc: 0.9331 - weighted_accuracy: 0.9341 - val_loss: 0.3286 - val_acc: 0.8629 - val_weighted_accuracy: 0.8572\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 142s 392us/step - loss: 0.0132 - acc: 0.9349 - weighted_accuracy: 0.9358 - val_loss: 0.3165 - val_acc: 0.8632 - val_weighted_accuracy: 0.8573\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 142s 394us/step - loss: 0.0130 - acc: 0.9363 - weighted_accuracy: 0.9374 - val_loss: 0.3358 - val_acc: 0.8625 - val_weighted_accuracy: 0.8560\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_22 (Embedding)        (None, 30, 200)      20000000    first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_43 (SpatialDr (None, 30, 200)      0           embedding_22[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_44 (SpatialDr (None, 30, 200)      0           embedding_22[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 30, 200)      800         spatial_dropout1d_43[0][0]       \n",
      "                                                                 spatial_dropout1d_44[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional (None, 30, 200)      241600      batch_normalization_21[0][0]     \n",
      "                                                                 batch_normalization_21[1][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dot_208 (Dot)                   (None, 30, 30)       0           bidirectional_11[0][0]           \n",
      "                                                                 bidirectional_11[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_166 (Lambda)             (None, 30, 30)       0           dot_208[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_70 (Permute)            (None, 30, 30)       0           lambda_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_165 (Lambda)             (None, 30, 30)       0           dot_208[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_210 (Dot)                   (None, 30, 200)      0           permute_70[0][0]                 \n",
      "                                                                 bidirectional_11[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dot_209 (Dot)                   (None, 30, 200)      0           lambda_165[0][0]                 \n",
      "                                                                 bidirectional_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_167 (Lambda)             (None, 30, 200)      0           bidirectional_11[0][0]           \n",
      "                                                                 dot_210[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_27 (Multiply)          (None, 30, 200)      0           bidirectional_11[0][0]           \n",
      "                                                                 dot_210[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_168 (Lambda)             (None, 30, 200)      0           bidirectional_11[1][0]           \n",
      "                                                                 dot_209[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_28 (Multiply)          (None, 30, 200)      0           bidirectional_11[1][0]           \n",
      "                                                                 dot_209[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_202 (Concatenate)   (None, 30, 800)      0           bidirectional_11[0][0]           \n",
      "                                                                 dot_210[0][0]                    \n",
      "                                                                 lambda_167[0][0]                 \n",
      "                                                                 multiply_27[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_203 (Concatenate)   (None, 30, 800)      0           bidirectional_11[1][0]           \n",
      "                                                                 dot_209[0][0]                    \n",
      "                                                                 lambda_168[0][0]                 \n",
      "                                                                 multiply_28[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional (None, 30, 200)      721600      concatenate_202[0][0]            \n",
      "                                                                 concatenate_203[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_43 (Gl (None, 200)          0           bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_43 (Global (None, 200)          0           bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_44 (Gl (None, 200)          0           bidirectional_12[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_44 (Global (None, 200)          0           bidirectional_12[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_204 (Concatenate)   (None, 400)          0           global_average_pooling1d_43[0][0]\n",
      "                                                                 global_max_pooling1d_43[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_205 (Concatenate)   (None, 400)          0           global_average_pooling1d_44[0][0]\n",
      "                                                                 global_max_pooling1d_44[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_206 (Concatenate)   (None, 800)          0           concatenate_204[0][0]            \n",
      "                                                                 concatenate_205[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 800)          3200        concatenate_206[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_48 (Dense)                (None, 256)          205056      batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 256)          1024        dense_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 256)          0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_49 (Dense)                (None, 256)          65792       dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 256)          1024        dense_49[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 256)          0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_50 (Dense)                (None, 3)            771         dropout_28[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 21,240,867\n",
      "Trainable params: 1,237,843\n",
      "Non-trainable params: 20,003,024\n",
      "__________________________________________________________________________________________________\n",
      "Load weights from WordTC-ESIM-NoMeta-3P-NoEM-NoClassWeighted-3Layers5.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360609/360609 [==============================] - 145s 403us/step - loss: 0.0173 - acc: 0.9085 - weighted_accuracy: 0.9049 - val_loss: 0.3222 - val_acc: 0.8545 - val_weighted_accuracy: 0.8424\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 143s 396us/step - loss: 0.0168 - acc: 0.9121 - weighted_accuracy: 0.9095 - val_loss: 0.3221 - val_acc: 0.8559 - val_weighted_accuracy: 0.8460\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 143s 397us/step - loss: 0.0163 - acc: 0.9155 - weighted_accuracy: 0.9131 - val_loss: 0.3253 - val_acc: 0.8540 - val_weighted_accuracy: 0.8442\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 142s 394us/step - loss: 0.0158 - acc: 0.9184 - weighted_accuracy: 0.9165 - val_loss: 0.3321 - val_acc: 0.8482 - val_weighted_accuracy: 0.8412\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 140s 388us/step - loss: 0.0154 - acc: 0.9205 - weighted_accuracy: 0.9192 - val_loss: 0.3241 - val_acc: 0.8546 - val_weighted_accuracy: 0.8449\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 142s 393us/step - loss: 0.0151 - acc: 0.9226 - weighted_accuracy: 0.9220 - val_loss: 0.3277 - val_acc: 0.8563 - val_weighted_accuracy: 0.8440\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 144s 398us/step - loss: 0.0147 - acc: 0.9262 - weighted_accuracy: 0.9256 - val_loss: 0.3282 - val_acc: 0.8551 - val_weighted_accuracy: 0.8457\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 143s 396us/step - loss: 0.0144 - acc: 0.9274 - weighted_accuracy: 0.9271 - val_loss: 0.3306 - val_acc: 0.8536 - val_weighted_accuracy: 0.8440\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 142s 394us/step - loss: 0.0141 - acc: 0.9293 - weighted_accuracy: 0.9295 - val_loss: 0.3247 - val_acc: 0.8596 - val_weighted_accuracy: 0.8471\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 141s 392us/step - loss: 0.0138 - acc: 0.9320 - weighted_accuracy: 0.9323 - val_loss: 0.3359 - val_acc: 0.8554 - val_weighted_accuracy: 0.8439\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 142s 393us/step - loss: 0.0135 - acc: 0.9327 - weighted_accuracy: 0.9332 - val_loss: 0.3349 - val_acc: 0.8568 - val_weighted_accuracy: 0.8423\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 143s 396us/step - loss: 0.0132 - acc: 0.9348 - weighted_accuracy: 0.9355 - val_loss: 0.3455 - val_acc: 0.8541 - val_weighted_accuracy: 0.8444\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 142s 393us/step - loss: 0.0130 - acc: 0.9364 - weighted_accuracy: 0.9372 - val_loss: 0.3397 - val_acc: 0.8574 - val_weighted_accuracy: 0.8426\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 142s 392us/step - loss: 0.0128 - acc: 0.9376 - weighted_accuracy: 0.9387 - val_loss: 0.3432 - val_acc: 0.8541 - val_weighted_accuracy: 0.8428\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 143s 396us/step - loss: 0.0126 - acc: 0.9390 - weighted_accuracy: 0.9403 - val_loss: 0.3512 - val_acc: 0.8521 - val_weighted_accuracy: 0.8421\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 142s 393us/step - loss: 0.0123 - acc: 0.9408 - weighted_accuracy: 0.9419 - val_loss: 0.3553 - val_acc: 0.8548 - val_weighted_accuracy: 0.8404\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_23 (Embedding)        (None, 30, 200)      20000000    first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_45 (SpatialDr (None, 30, 200)      0           embedding_23[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_46 (SpatialDr (None, 30, 200)      0           embedding_23[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 30, 200)      800         spatial_dropout1d_45[0][0]       \n",
      "                                                                 spatial_dropout1d_46[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_13 (Bidirectional (None, 30, 200)      241600      batch_normalization_25[0][0]     \n",
      "                                                                 batch_normalization_25[1][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dot_211 (Dot)                   (None, 30, 30)       0           bidirectional_13[0][0]           \n",
      "                                                                 bidirectional_13[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_170 (Lambda)             (None, 30, 30)       0           dot_211[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_71 (Permute)            (None, 30, 30)       0           lambda_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_169 (Lambda)             (None, 30, 30)       0           dot_211[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_213 (Dot)                   (None, 30, 200)      0           permute_71[0][0]                 \n",
      "                                                                 bidirectional_13[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dot_212 (Dot)                   (None, 30, 200)      0           lambda_169[0][0]                 \n",
      "                                                                 bidirectional_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_171 (Lambda)             (None, 30, 200)      0           bidirectional_13[0][0]           \n",
      "                                                                 dot_213[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_29 (Multiply)          (None, 30, 200)      0           bidirectional_13[0][0]           \n",
      "                                                                 dot_213[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_172 (Lambda)             (None, 30, 200)      0           bidirectional_13[1][0]           \n",
      "                                                                 dot_212[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_30 (Multiply)          (None, 30, 200)      0           bidirectional_13[1][0]           \n",
      "                                                                 dot_212[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_207 (Concatenate)   (None, 30, 800)      0           bidirectional_13[0][0]           \n",
      "                                                                 dot_213[0][0]                    \n",
      "                                                                 lambda_171[0][0]                 \n",
      "                                                                 multiply_29[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_208 (Concatenate)   (None, 30, 800)      0           bidirectional_13[1][0]           \n",
      "                                                                 dot_212[0][0]                    \n",
      "                                                                 lambda_172[0][0]                 \n",
      "                                                                 multiply_30[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_14 (Bidirectional (None, 30, 200)      721600      concatenate_207[0][0]            \n",
      "                                                                 concatenate_208[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_45 (Gl (None, 200)          0           bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_45 (Global (None, 200)          0           bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_46 (Gl (None, 200)          0           bidirectional_14[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_46 (Global (None, 200)          0           bidirectional_14[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_209 (Concatenate)   (None, 400)          0           global_average_pooling1d_45[0][0]\n",
      "                                                                 global_max_pooling1d_45[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_210 (Concatenate)   (None, 400)          0           global_average_pooling1d_46[0][0]\n",
      "                                                                 global_max_pooling1d_46[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_211 (Concatenate)   (None, 800)          0           concatenate_209[0][0]            \n",
      "                                                                 concatenate_210[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 800)          3200        concatenate_211[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_51 (Dense)                (None, 256)          205056      batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 256)          1024        dense_51[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 256)          0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_52 (Dense)                (None, 256)          65792       dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 256)          1024        dense_52[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 256)          0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_53 (Dense)                (None, 3)            771         dropout_30[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 21,240,867\n",
      "Trainable params: 1,237,843\n",
      "Non-trainable params: 20,003,024\n",
      "__________________________________________________________________________________________________\n",
      "Load weights from WordTC-ESIM-NoMeta-3P-NoEM-NoClassWeighted-3Layers6.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360609/360609 [==============================] - 147s 407us/step - loss: 0.0197 - acc: 0.8921 - weighted_accuracy: 0.8872 - val_loss: 0.3052 - val_acc: 0.8653 - val_weighted_accuracy: 0.8610\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 142s 394us/step - loss: 0.0188 - acc: 0.8977 - weighted_accuracy: 0.8936 - val_loss: 0.3008 - val_acc: 0.8670 - val_weighted_accuracy: 0.8616\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 143s 397us/step - loss: 0.0183 - acc: 0.9016 - weighted_accuracy: 0.8982 - val_loss: 0.3042 - val_acc: 0.8650 - val_weighted_accuracy: 0.8610\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 143s 397us/step - loss: 0.0176 - acc: 0.9058 - weighted_accuracy: 0.9033 - val_loss: 0.2997 - val_acc: 0.8675 - val_weighted_accuracy: 0.8636\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 143s 398us/step - loss: 0.0172 - acc: 0.9093 - weighted_accuracy: 0.9070 - val_loss: 0.2887 - val_acc: 0.8726 - val_weighted_accuracy: 0.8632\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 143s 397us/step - loss: 0.0166 - acc: 0.9132 - weighted_accuracy: 0.9116 - val_loss: 0.3080 - val_acc: 0.8648 - val_weighted_accuracy: 0.8620\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 142s 393us/step - loss: 0.0162 - acc: 0.9153 - weighted_accuracy: 0.9139 - val_loss: 0.2934 - val_acc: 0.8739 - val_weighted_accuracy: 0.8679\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 142s 395us/step - loss: 0.0157 - acc: 0.9179 - weighted_accuracy: 0.9171 - val_loss: 0.2984 - val_acc: 0.8690 - val_weighted_accuracy: 0.8649\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 142s 394us/step - loss: 0.0154 - acc: 0.9211 - weighted_accuracy: 0.9207 - val_loss: 0.2891 - val_acc: 0.8751 - val_weighted_accuracy: 0.8650\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 143s 396us/step - loss: 0.0150 - acc: 0.9228 - weighted_accuracy: 0.9223 - val_loss: 0.3164 - val_acc: 0.8626 - val_weighted_accuracy: 0.8606\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 143s 397us/step - loss: 0.0147 - acc: 0.9250 - weighted_accuracy: 0.9250 - val_loss: 0.2987 - val_acc: 0.8749 - val_weighted_accuracy: 0.8677\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 144s 398us/step - loss: 0.0144 - acc: 0.9266 - weighted_accuracy: 0.9270 - val_loss: 0.3028 - val_acc: 0.8693 - val_weighted_accuracy: 0.8630\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 144s 398us/step - loss: 0.0142 - acc: 0.9290 - weighted_accuracy: 0.9294 - val_loss: 0.3052 - val_acc: 0.8699 - val_weighted_accuracy: 0.8647\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 142s 394us/step - loss: 0.0139 - acc: 0.9307 - weighted_accuracy: 0.9310 - val_loss: 0.2986 - val_acc: 0.8734 - val_weighted_accuracy: 0.8668\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_24 (Embedding)        (None, 30, 200)      20000000    first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_47 (SpatialDr (None, 30, 200)      0           embedding_24[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_48 (SpatialDr (None, 30, 200)      0           embedding_24[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 30, 200)      800         spatial_dropout1d_47[0][0]       \n",
      "                                                                 spatial_dropout1d_48[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_15 (Bidirectional (None, 30, 200)      241600      batch_normalization_29[0][0]     \n",
      "                                                                 batch_normalization_29[1][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dot_214 (Dot)                   (None, 30, 30)       0           bidirectional_15[0][0]           \n",
      "                                                                 bidirectional_15[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_174 (Lambda)             (None, 30, 30)       0           dot_214[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_72 (Permute)            (None, 30, 30)       0           lambda_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_173 (Lambda)             (None, 30, 30)       0           dot_214[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_216 (Dot)                   (None, 30, 200)      0           permute_72[0][0]                 \n",
      "                                                                 bidirectional_15[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dot_215 (Dot)                   (None, 30, 200)      0           lambda_173[0][0]                 \n",
      "                                                                 bidirectional_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_175 (Lambda)             (None, 30, 200)      0           bidirectional_15[0][0]           \n",
      "                                                                 dot_216[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_31 (Multiply)          (None, 30, 200)      0           bidirectional_15[0][0]           \n",
      "                                                                 dot_216[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_176 (Lambda)             (None, 30, 200)      0           bidirectional_15[1][0]           \n",
      "                                                                 dot_215[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_32 (Multiply)          (None, 30, 200)      0           bidirectional_15[1][0]           \n",
      "                                                                 dot_215[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_212 (Concatenate)   (None, 30, 800)      0           bidirectional_15[0][0]           \n",
      "                                                                 dot_216[0][0]                    \n",
      "                                                                 lambda_175[0][0]                 \n",
      "                                                                 multiply_31[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_213 (Concatenate)   (None, 30, 800)      0           bidirectional_15[1][0]           \n",
      "                                                                 dot_215[0][0]                    \n",
      "                                                                 lambda_176[0][0]                 \n",
      "                                                                 multiply_32[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_16 (Bidirectional (None, 30, 200)      721600      concatenate_212[0][0]            \n",
      "                                                                 concatenate_213[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_47 (Gl (None, 200)          0           bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_47 (Global (None, 200)          0           bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_48 (Gl (None, 200)          0           bidirectional_16[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_48 (Global (None, 200)          0           bidirectional_16[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_214 (Concatenate)   (None, 400)          0           global_average_pooling1d_47[0][0]\n",
      "                                                                 global_max_pooling1d_47[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_215 (Concatenate)   (None, 400)          0           global_average_pooling1d_48[0][0]\n",
      "                                                                 global_max_pooling1d_48[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_216 (Concatenate)   (None, 800)          0           concatenate_214[0][0]            \n",
      "                                                                 concatenate_215[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 800)          3200        concatenate_216[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_54 (Dense)                (None, 256)          205056      batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 256)          1024        dense_54[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 256)          0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_55 (Dense)                (None, 256)          65792       dropout_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 256)          1024        dense_55[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 256)          0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_56 (Dense)                (None, 3)            771         dropout_32[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 21,240,867\n",
      "Trainable params: 1,237,843\n",
      "Non-trainable params: 20,003,024\n",
      "__________________________________________________________________________________________________\n",
      "Load weights from WordTC-ESIM-NoMeta-3P-NoEM-NoClassWeighted-3Layers7.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360609/360609 [==============================] - 150s 417us/step - loss: 0.0192 - acc: 0.8952 - weighted_accuracy: 0.8911 - val_loss: 0.2923 - val_acc: 0.8672 - val_weighted_accuracy: 0.8588\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 144s 399us/step - loss: 0.0185 - acc: 0.8998 - weighted_accuracy: 0.8968 - val_loss: 0.2955 - val_acc: 0.8644 - val_weighted_accuracy: 0.8595\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 143s 395us/step - loss: 0.0179 - acc: 0.9039 - weighted_accuracy: 0.9012 - val_loss: 0.2902 - val_acc: 0.8695 - val_weighted_accuracy: 0.8644\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 143s 397us/step - loss: 0.0173 - acc: 0.9075 - weighted_accuracy: 0.9057 - val_loss: 0.2769 - val_acc: 0.8751 - val_weighted_accuracy: 0.8657\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 145s 402us/step - loss: 0.0168 - acc: 0.9112 - weighted_accuracy: 0.9097 - val_loss: 0.2946 - val_acc: 0.8702 - val_weighted_accuracy: 0.8635\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 143s 396us/step - loss: 0.0164 - acc: 0.9136 - weighted_accuracy: 0.9124 - val_loss: 0.2815 - val_acc: 0.8777 - val_weighted_accuracy: 0.8669\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 143s 396us/step - loss: 0.0160 - acc: 0.9167 - weighted_accuracy: 0.9161 - val_loss: 0.2869 - val_acc: 0.8728 - val_weighted_accuracy: 0.8651\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 144s 400us/step - loss: 0.0156 - acc: 0.9188 - weighted_accuracy: 0.9185 - val_loss: 0.2889 - val_acc: 0.8721 - val_weighted_accuracy: 0.8643\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 144s 399us/step - loss: 0.0153 - acc: 0.9214 - weighted_accuracy: 0.9211 - val_loss: 0.2837 - val_acc: 0.8748 - val_weighted_accuracy: 0.8655\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 141s 391us/step - loss: 0.0148 - acc: 0.9237 - weighted_accuracy: 0.9240 - val_loss: 0.2818 - val_acc: 0.8763 - val_weighted_accuracy: 0.8676\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 142s 393us/step - loss: 0.0146 - acc: 0.9251 - weighted_accuracy: 0.9255 - val_loss: 0.2931 - val_acc: 0.8744 - val_weighted_accuracy: 0.8660\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 142s 395us/step - loss: 0.0143 - acc: 0.9274 - weighted_accuracy: 0.9282 - val_loss: 0.2898 - val_acc: 0.8712 - val_weighted_accuracy: 0.8640\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 141s 391us/step - loss: 0.0141 - acc: 0.9291 - weighted_accuracy: 0.9299 - val_loss: 0.2874 - val_acc: 0.8749 - val_weighted_accuracy: 0.8649\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 141s 391us/step - loss: 0.0138 - acc: 0.9312 - weighted_accuracy: 0.9323 - val_loss: 0.2923 - val_acc: 0.8765 - val_weighted_accuracy: 0.8673\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 141s 390us/step - loss: 0.0135 - acc: 0.9330 - weighted_accuracy: 0.9341 - val_loss: 0.2906 - val_acc: 0.8733 - val_weighted_accuracy: 0.8644\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 141s 391us/step - loss: 0.0133 - acc: 0.9344 - weighted_accuracy: 0.9357 - val_loss: 0.2853 - val_acc: 0.8759 - val_weighted_accuracy: 0.8659\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 141s 391us/step - loss: 0.0131 - acc: 0.9351 - weighted_accuracy: 0.9364 - val_loss: 0.2956 - val_acc: 0.8742 - val_weighted_accuracy: 0.8653\n",
      "score 0.8636994488988597\n",
      "Predicting training results...\n",
      "Predicting testing results...\n",
      "80126/80126 [==============================] - 7s 87us/step\n",
      "80126/80126 [==============================] - 7s 85us/step\n",
      "80126/80126 [==============================] - 7s 85us/step\n",
      "80126/80126 [==============================] - 7s 85us/step\n",
      "80126/80126 [==============================] - 7s 84us/step\n",
      "80126/80126 [==============================] - 7s 85us/step\n",
      "80126/80126 [==============================] - 7s 85us/step\n",
      "80126/80126 [==============================] - 7s 85us/step\n",
      "Predicting labeled testing results...\n"
     ]
    }
   ],
   "source": [
    "fold_count = 8\n",
    "#embedding_matrix = sgns_bigram_matrix\n",
    "embedding_matrix = tencent_ai_matrix\n",
    "EMBEDDING_DIM = 200\n",
    "\n",
    "for i in range(1, len(model_manager.models_tag)):\n",
    "    print(\"Work on model\", i)\n",
    "    model_tag = model_manager.models_tag[i]\n",
    "    model_func = model_manager.model_funcs[i]\n",
    "    #models_checkpoints_path = model_manager.models_checkpoints_pathes[i]\n",
    "    models_checkpoints_path = \"WordTC-ESIM-NoMeta-3P-NoEM-NoClassWeighted-3Layers\"\n",
    "\n",
    "    model_submit_prefix = model_manager.submit_predix[i]\n",
    "    model_class_weights = model_manager.model_class_weights[i]\n",
    "    model_scale_sample_weights = model_manager.model_scale_sample_weights[i]\n",
    "    model_patiences = model_manager.model_patiences[i]\n",
    "    \n",
    "    model_class_weights = None\n",
    "    \n",
    "    def _agent_get_model():\n",
    "        return get_ESIM(NB_WORDS, EMBEDDING_DIM, embedding_matrix, MAX_SEQUENCE_LENGTH, OUT_SIZE, lr=4e-4)\n",
    "        return get_dense_cnn(NB_WORDS, EMBEDDING_DIM, embedding_matrix, MAX_SEQUENCE_LENGTH, OUT_SIZE)\n",
    "        return model_func(NB_WORDS, EMBEDDING_DIM, embedding_matrix, MAX_SEQUENCE_LENGTH, OUT_SIZE)\n",
    "    \n",
    "    test_predicts_list = []\n",
    "    oofs_predictions = []\n",
    "    pre_trained_models = []\n",
    "        \n",
    "    trainer = KerasModelTrainer(model_stamp=models_checkpoints_path, epoch_num=500)\n",
    "    models, score, folds_preds = trainer.train_folds(X=trains, y=labels, tests=tests, augments=None, fold_count=fold_count, batch_size=64,\n",
    "        em_train_features=em_train_features, em_test_features=em_test_features, pseudo_labels=pseudo_labels,                                      \n",
    "        scale_sample_weight=model_scale_sample_weights, class_weight=model_class_weights,\n",
    "        get_model_func=_agent_get_model, \n",
    "        patience=7)\n",
    "\n",
    "    print(\"score\", score)\n",
    "    oofs_dir = \"../data/pseudo/oofs/\"\n",
    "    output_dir = \"../data/pseudo/output/\"\n",
    "    onehot_pred_dir = \"../data/pseudo/one_hot_pred/\"\n",
    "\n",
    "    model_submit_prefix = \"PSWordTC-ESIM-NoMeta-3P-NoEM-NoClassWeighted-3Layers\"\n",
    "    \n",
    "    oofs_path = oofs_dir + model_submit_prefix\n",
    "    output_path = output_dir + model_submit_prefix\n",
    "    one_hot_pred_path = onehot_pred_dir + \"One-Hot\" + model_submit_prefix\n",
    "\n",
    "    print(\"Predicting training results...\")\n",
    "    train_predicts = np.concatenate(folds_preds, axis=0)\n",
    "    oofs = pd.DataFrame({\"unrelated\": train_predicts[:, 0], \"agreed\": train_predicts[:, 1], \"disagreed\": train_predicts[:, 2]})\n",
    "    submit_path = oofs_path + \"-Train-L{:4f}-NB{:d}.csv\".format(score, NB_WORDS)\n",
    "    oofs.to_csv(submit_path, index=False)\n",
    "\n",
    "    print(\"Predicting testing results...\")\n",
    "    test_predicts_list = []\n",
    "    for fold_id, model in enumerate(models):\n",
    "        test_predicts = model.predict({\"first_sentences\":tests[0],\n",
    "                                       \"second_sentences\":tests[1],\n",
    "                                       \"mata-features\":tests[2],\n",
    "                                       \"first_exact_match\": tests_1_ems,\n",
    "                                       \"second_exact_match\": tests_2_ems,\n",
    "                                      }, batch_size=128, verbose=1)\n",
    "\n",
    "        test_predicts_list.append(test_predicts)\n",
    "\n",
    "    test_predicts = np.zeros(test_predicts_list[0].shape)\n",
    "    for fold_predict in test_predicts_list:\n",
    "        test_predicts += fold_predict\n",
    "    test_predicts /= len(test_predicts_list)\n",
    "\n",
    "    test_predicts = pd.DataFrame({\"unrelated\": test_predicts[:, 0], \"agreed\": test_predicts[:, 1], \"disagreed\": test_predicts[:, 2]})\n",
    "    submit_path = output_path + \"-L{:4f}-NB{:d}.csv\".format(score, NB_WORDS)\n",
    "    test_predicts.to_csv(submit_path, index=False) # 0.3343\n",
    "    \n",
    "    print(\"Predicting labeled testing results...\")\n",
    "    ids = pd.read_csv(\"../data/dataset/test.csv\")\n",
    "    pred_labels = test_predicts.idxmax(axis=1)\n",
    "    sub = pd.DataFrame({\"Id\": ids['id'].values, \"Category\": pred_labels})\n",
    "    submit_path = one_hot_pred_path + \"-L{:4f}-NB{:d}.csv\".format(score, NB_WORDS)\n",
    "    sub.to_csv(submit_path, index=False)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'numpy_weighted_accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-17ec6d0dbd04>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnumpy_weighted_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moofs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'unrelated'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'agreed'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'disagreed'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'numpy_weighted_accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "numpy_weighted_accuracy(labels, oofs[['unrelated', 'agreed', 'disagreed']].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## SGNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Work on model 1\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_17 (Embedding)        (None, 30, 300)      30000000    first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_17 (SpatialDr (None, 30, 300)      0           embedding_17[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_18 (SpatialDr (None, 30, 300)      0           embedding_17[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 30, 300)      1200        spatial_dropout1d_17[0][0]       \n",
      "                                                                 spatial_dropout1d_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_25 (Bidirectional (None, 30, 200)      321600      batch_normalization_1[0][0]      \n",
      "                                                                 batch_normalization_1[1][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dot_73 (Dot)                    (None, 30, 30)       0           bidirectional_25[0][0]           \n",
      "                                                                 bidirectional_25[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_58 (Lambda)              (None, 30, 30)       0           dot_73[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_25 (Permute)            (None, 30, 30)       0           lambda_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_57 (Lambda)              (None, 30, 30)       0           dot_73[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_75 (Dot)                    (None, 30, 200)      0           permute_25[0][0]                 \n",
      "                                                                 bidirectional_25[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dot_74 (Dot)                    (None, 30, 200)      0           lambda_57[0][0]                  \n",
      "                                                                 bidirectional_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_59 (Lambda)              (None, 30, 200)      0           bidirectional_25[0][0]           \n",
      "                                                                 dot_75[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_9 (Multiply)           (None, 30, 200)      0           bidirectional_25[0][0]           \n",
      "                                                                 dot_75[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_60 (Lambda)              (None, 30, 200)      0           bidirectional_25[1][0]           \n",
      "                                                                 dot_74[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_10 (Multiply)          (None, 30, 200)      0           bidirectional_25[1][0]           \n",
      "                                                                 dot_74[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_89 (Concatenate)    (None, 30, 800)      0           bidirectional_25[0][0]           \n",
      "                                                                 dot_75[0][0]                     \n",
      "                                                                 lambda_59[0][0]                  \n",
      "                                                                 multiply_9[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_90 (Concatenate)    (None, 30, 800)      0           bidirectional_25[1][0]           \n",
      "                                                                 dot_74[0][0]                     \n",
      "                                                                 lambda_60[0][0]                  \n",
      "                                                                 multiply_10[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_26 (Bidirectional (None, 30, 200)      721600      concatenate_89[0][0]             \n",
      "                                                                 concatenate_90[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_17 (Gl (None, 200)          0           bidirectional_26[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_17 (Global (None, 200)          0           bidirectional_26[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_18 (Gl (None, 200)          0           bidirectional_26[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_18 (Global (None, 200)          0           bidirectional_26[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_91 (Concatenate)    (None, 400)          0           global_average_pooling1d_17[0][0]\n",
      "                                                                 global_max_pooling1d_17[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_92 (Concatenate)    (None, 400)          0           global_average_pooling1d_18[0][0]\n",
      "                                                                 global_max_pooling1d_18[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_93 (Concatenate)    (None, 800)          0           concatenate_91[0][0]             \n",
      "                                                                 concatenate_92[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 800)          3200        concatenate_93[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 256)          205056      batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 256)          1024        dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_73 (Dropout)            (None, 256)          0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 256)          65792       dropout_73[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 256)          1024        dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_74 (Dropout)            (None, 256)          0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 3)            771         dropout_74[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 31,321,267\n",
      "Trainable params: 1,318,043\n",
      "Non-trainable params: 30,003,224\n",
      "__________________________________________________________________________________________________\n",
      "Load weights from WordSGNS-ESIM-NoMeta-3P-NoEM-NoClassWeighted-3Layers0.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360609/360609 [==============================] - 146s 406us/step - loss: 0.0189 - acc: 0.8987 - weighted_accuracy: 0.8944 - val_loss: 0.3103 - val_acc: 0.8617 - val_weighted_accuracy: 0.8527\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 144s 399us/step - loss: 0.0183 - acc: 0.9025 - weighted_accuracy: 0.8987 - val_loss: 0.3142 - val_acc: 0.8607 - val_weighted_accuracy: 0.8532\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 146s 404us/step - loss: 0.0177 - acc: 0.9056 - weighted_accuracy: 0.9026 - val_loss: 0.3249 - val_acc: 0.8510 - val_weighted_accuracy: 0.8475\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 141s 391us/step - loss: 0.0173 - acc: 0.9076 - weighted_accuracy: 0.9056 - val_loss: 0.3044 - val_acc: 0.8651 - val_weighted_accuracy: 0.8572\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 143s 397us/step - loss: 0.0169 - acc: 0.9106 - weighted_accuracy: 0.9083 - val_loss: 0.3222 - val_acc: 0.8604 - val_weighted_accuracy: 0.8526\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 141s 392us/step - loss: 0.0165 - acc: 0.9135 - weighted_accuracy: 0.9119 - val_loss: 0.3213 - val_acc: 0.8625 - val_weighted_accuracy: 0.8537\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 142s 395us/step - loss: 0.0162 - acc: 0.9151 - weighted_accuracy: 0.9135 - val_loss: 0.3360 - val_acc: 0.8596 - val_weighted_accuracy: 0.8524\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 142s 393us/step - loss: 0.0159 - acc: 0.9176 - weighted_accuracy: 0.9162 - val_loss: 0.3247 - val_acc: 0.8581 - val_weighted_accuracy: 0.8529\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 143s 396us/step - loss: 0.0156 - acc: 0.9192 - weighted_accuracy: 0.9183 - val_loss: 0.3463 - val_acc: 0.8481 - val_weighted_accuracy: 0.8431\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 145s 403us/step - loss: 0.0154 - acc: 0.9206 - weighted_accuracy: 0.9202 - val_loss: 0.3240 - val_acc: 0.8613 - val_weighted_accuracy: 0.8541\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 143s 396us/step - loss: 0.0152 - acc: 0.9222 - weighted_accuracy: 0.9221 - val_loss: 0.3341 - val_acc: 0.8518 - val_weighted_accuracy: 0.8484\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_18 (Embedding)        (None, 30, 300)      30000000    first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_19 (SpatialDr (None, 30, 300)      0           embedding_18[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_20 (SpatialDr (None, 30, 300)      0           embedding_18[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 30, 300)      1200        spatial_dropout1d_19[0][0]       \n",
      "                                                                 spatial_dropout1d_20[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_27 (Bidirectional (None, 30, 200)      321600      batch_normalization_5[0][0]      \n",
      "                                                                 batch_normalization_5[1][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dot_76 (Dot)                    (None, 30, 30)       0           bidirectional_27[0][0]           \n",
      "                                                                 bidirectional_27[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_62 (Lambda)              (None, 30, 30)       0           dot_76[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_26 (Permute)            (None, 30, 30)       0           lambda_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_61 (Lambda)              (None, 30, 30)       0           dot_76[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_78 (Dot)                    (None, 30, 200)      0           permute_26[0][0]                 \n",
      "                                                                 bidirectional_27[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dot_77 (Dot)                    (None, 30, 200)      0           lambda_61[0][0]                  \n",
      "                                                                 bidirectional_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_63 (Lambda)              (None, 30, 200)      0           bidirectional_27[0][0]           \n",
      "                                                                 dot_78[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_11 (Multiply)          (None, 30, 200)      0           bidirectional_27[0][0]           \n",
      "                                                                 dot_78[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_64 (Lambda)              (None, 30, 200)      0           bidirectional_27[1][0]           \n",
      "                                                                 dot_77[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_12 (Multiply)          (None, 30, 200)      0           bidirectional_27[1][0]           \n",
      "                                                                 dot_77[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_94 (Concatenate)    (None, 30, 800)      0           bidirectional_27[0][0]           \n",
      "                                                                 dot_78[0][0]                     \n",
      "                                                                 lambda_63[0][0]                  \n",
      "                                                                 multiply_11[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_95 (Concatenate)    (None, 30, 800)      0           bidirectional_27[1][0]           \n",
      "                                                                 dot_77[0][0]                     \n",
      "                                                                 lambda_64[0][0]                  \n",
      "                                                                 multiply_12[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_28 (Bidirectional (None, 30, 200)      721600      concatenate_94[0][0]             \n",
      "                                                                 concatenate_95[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_19 (Gl (None, 200)          0           bidirectional_28[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_19 (Global (None, 200)          0           bidirectional_28[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_20 (Gl (None, 200)          0           bidirectional_28[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_20 (Global (None, 200)          0           bidirectional_28[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_96 (Concatenate)    (None, 400)          0           global_average_pooling1d_19[0][0]\n",
      "                                                                 global_max_pooling1d_19[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_97 (Concatenate)    (None, 400)          0           global_average_pooling1d_20[0][0]\n",
      "                                                                 global_max_pooling1d_20[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_98 (Concatenate)    (None, 800)          0           concatenate_96[0][0]             \n",
      "                                                                 concatenate_97[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 800)          3200        concatenate_98[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 256)          205056      batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 256)          1024        dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_75 (Dropout)            (None, 256)          0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 256)          65792       dropout_75[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 256)          1024        dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_76 (Dropout)            (None, 256)          0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 3)            771         dropout_76[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 31,321,267\n",
      "Trainable params: 1,318,043\n",
      "Non-trainable params: 30,003,224\n",
      "__________________________________________________________________________________________________\n",
      "Load weights from WordSGNS-ESIM-NoMeta-3P-NoEM-NoClassWeighted-3Layers1.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360609/360609 [==============================] - 147s 408us/step - loss: 0.0173 - acc: 0.9091 - weighted_accuracy: 0.9062 - val_loss: 0.2846 - val_acc: 0.8796 - val_weighted_accuracy: 0.8673\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 143s 395us/step - loss: 0.0170 - acc: 0.9110 - weighted_accuracy: 0.9086 - val_loss: 0.2973 - val_acc: 0.8719 - val_weighted_accuracy: 0.8653\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 143s 398us/step - loss: 0.0167 - acc: 0.9134 - weighted_accuracy: 0.9114 - val_loss: 0.2867 - val_acc: 0.8745 - val_weighted_accuracy: 0.8659\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 142s 393us/step - loss: 0.0163 - acc: 0.9145 - weighted_accuracy: 0.9132 - val_loss: 0.2883 - val_acc: 0.8743 - val_weighted_accuracy: 0.8664\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 143s 397us/step - loss: 0.0160 - acc: 0.9169 - weighted_accuracy: 0.9157 - val_loss: 0.2846 - val_acc: 0.8761 - val_weighted_accuracy: 0.8651\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 142s 393us/step - loss: 0.0158 - acc: 0.9183 - weighted_accuracy: 0.9174 - val_loss: 0.3031 - val_acc: 0.8646 - val_weighted_accuracy: 0.8608\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 140s 389us/step - loss: 0.0155 - acc: 0.9195 - weighted_accuracy: 0.9188 - val_loss: 0.2865 - val_acc: 0.8761 - val_weighted_accuracy: 0.8669\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 140s 387us/step - loss: 0.0153 - acc: 0.9216 - weighted_accuracy: 0.9212 - val_loss: 0.2891 - val_acc: 0.8761 - val_weighted_accuracy: 0.8672\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_19 (Embedding)        (None, 30, 300)      30000000    first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_21 (SpatialDr (None, 30, 300)      0           embedding_19[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_22 (SpatialDr (None, 30, 300)      0           embedding_19[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 30, 300)      1200        spatial_dropout1d_21[0][0]       \n",
      "                                                                 spatial_dropout1d_22[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_29 (Bidirectional (None, 30, 200)      321600      batch_normalization_9[0][0]      \n",
      "                                                                 batch_normalization_9[1][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dot_79 (Dot)                    (None, 30, 30)       0           bidirectional_29[0][0]           \n",
      "                                                                 bidirectional_29[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_66 (Lambda)              (None, 30, 30)       0           dot_79[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_27 (Permute)            (None, 30, 30)       0           lambda_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_65 (Lambda)              (None, 30, 30)       0           dot_79[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_81 (Dot)                    (None, 30, 200)      0           permute_27[0][0]                 \n",
      "                                                                 bidirectional_29[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dot_80 (Dot)                    (None, 30, 200)      0           lambda_65[0][0]                  \n",
      "                                                                 bidirectional_29[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_67 (Lambda)              (None, 30, 200)      0           bidirectional_29[0][0]           \n",
      "                                                                 dot_81[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_13 (Multiply)          (None, 30, 200)      0           bidirectional_29[0][0]           \n",
      "                                                                 dot_81[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_68 (Lambda)              (None, 30, 200)      0           bidirectional_29[1][0]           \n",
      "                                                                 dot_80[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_14 (Multiply)          (None, 30, 200)      0           bidirectional_29[1][0]           \n",
      "                                                                 dot_80[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_99 (Concatenate)    (None, 30, 800)      0           bidirectional_29[0][0]           \n",
      "                                                                 dot_81[0][0]                     \n",
      "                                                                 lambda_67[0][0]                  \n",
      "                                                                 multiply_13[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_100 (Concatenate)   (None, 30, 800)      0           bidirectional_29[1][0]           \n",
      "                                                                 dot_80[0][0]                     \n",
      "                                                                 lambda_68[0][0]                  \n",
      "                                                                 multiply_14[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_30 (Bidirectional (None, 30, 200)      721600      concatenate_99[0][0]             \n",
      "                                                                 concatenate_100[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_21 (Gl (None, 200)          0           bidirectional_30[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_21 (Global (None, 200)          0           bidirectional_30[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_22 (Gl (None, 200)          0           bidirectional_30[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_22 (Global (None, 200)          0           bidirectional_30[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_101 (Concatenate)   (None, 400)          0           global_average_pooling1d_21[0][0]\n",
      "                                                                 global_max_pooling1d_21[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_102 (Concatenate)   (None, 400)          0           global_average_pooling1d_22[0][0]\n",
      "                                                                 global_max_pooling1d_22[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_103 (Concatenate)   (None, 800)          0           concatenate_101[0][0]            \n",
      "                                                                 concatenate_102[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 800)          3200        concatenate_103[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 256)          205056      batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 256)          1024        dense_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_77 (Dropout)            (None, 256)          0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 256)          65792       dropout_77[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 256)          1024        dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_78 (Dropout)            (None, 256)          0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 3)            771         dropout_78[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 31,321,267\n",
      "Trainable params: 1,318,043\n",
      "Non-trainable params: 30,003,224\n",
      "__________________________________________________________________________________________________\n",
      "Load weights from WordSGNS-ESIM-NoMeta-3P-NoEM-NoClassWeighted-3Layers2.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360609/360609 [==============================] - 146s 406us/step - loss: 0.0186 - acc: 0.9011 - weighted_accuracy: 0.8970 - val_loss: 0.3121 - val_acc: 0.8600 - val_weighted_accuracy: 0.8524\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 144s 400us/step - loss: 0.0181 - acc: 0.9038 - weighted_accuracy: 0.9001 - val_loss: 0.3110 - val_acc: 0.8603 - val_weighted_accuracy: 0.8573\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 143s 398us/step - loss: 0.0176 - acc: 0.9065 - weighted_accuracy: 0.9037 - val_loss: 0.3048 - val_acc: 0.8625 - val_weighted_accuracy: 0.8575\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 141s 390us/step - loss: 0.0173 - acc: 0.9095 - weighted_accuracy: 0.9071 - val_loss: 0.3115 - val_acc: 0.8565 - val_weighted_accuracy: 0.8539\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 142s 394us/step - loss: 0.0168 - acc: 0.9119 - weighted_accuracy: 0.9101 - val_loss: 0.3052 - val_acc: 0.8621 - val_weighted_accuracy: 0.8571\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 144s 400us/step - loss: 0.0165 - acc: 0.9133 - weighted_accuracy: 0.9118 - val_loss: 0.2990 - val_acc: 0.8700 - val_weighted_accuracy: 0.8631\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 142s 394us/step - loss: 0.0162 - acc: 0.9157 - weighted_accuracy: 0.9147 - val_loss: 0.3052 - val_acc: 0.8655 - val_weighted_accuracy: 0.8591\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 143s 396us/step - loss: 0.0160 - acc: 0.9170 - weighted_accuracy: 0.9161 - val_loss: 0.3096 - val_acc: 0.8616 - val_weighted_accuracy: 0.8579\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 141s 392us/step - loss: 0.0157 - acc: 0.9186 - weighted_accuracy: 0.9178 - val_loss: 0.3058 - val_acc: 0.8663 - val_weighted_accuracy: 0.8593\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 141s 392us/step - loss: 0.0155 - acc: 0.9203 - weighted_accuracy: 0.9198 - val_loss: 0.3041 - val_acc: 0.8659 - val_weighted_accuracy: 0.8607\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 142s 393us/step - loss: 0.0152 - acc: 0.9216 - weighted_accuracy: 0.9212 - val_loss: 0.3089 - val_acc: 0.8628 - val_weighted_accuracy: 0.8571\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 143s 396us/step - loss: 0.0150 - acc: 0.9236 - weighted_accuracy: 0.9234 - val_loss: 0.3005 - val_acc: 0.8642 - val_weighted_accuracy: 0.8588\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 142s 395us/step - loss: 0.0148 - acc: 0.9243 - weighted_accuracy: 0.9244 - val_loss: 0.3054 - val_acc: 0.8665 - val_weighted_accuracy: 0.8594\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_20 (Embedding)        (None, 30, 300)      30000000    first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_23 (SpatialDr (None, 30, 300)      0           embedding_20[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_24 (SpatialDr (None, 30, 300)      0           embedding_20[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 30, 300)      1200        spatial_dropout1d_23[0][0]       \n",
      "                                                                 spatial_dropout1d_24[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_31 (Bidirectional (None, 30, 200)      321600      batch_normalization_13[0][0]     \n",
      "                                                                 batch_normalization_13[1][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dot_82 (Dot)                    (None, 30, 30)       0           bidirectional_31[0][0]           \n",
      "                                                                 bidirectional_31[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_70 (Lambda)              (None, 30, 30)       0           dot_82[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_28 (Permute)            (None, 30, 30)       0           lambda_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_69 (Lambda)              (None, 30, 30)       0           dot_82[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_84 (Dot)                    (None, 30, 200)      0           permute_28[0][0]                 \n",
      "                                                                 bidirectional_31[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dot_83 (Dot)                    (None, 30, 200)      0           lambda_69[0][0]                  \n",
      "                                                                 bidirectional_31[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_71 (Lambda)              (None, 30, 200)      0           bidirectional_31[0][0]           \n",
      "                                                                 dot_84[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_15 (Multiply)          (None, 30, 200)      0           bidirectional_31[0][0]           \n",
      "                                                                 dot_84[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_72 (Lambda)              (None, 30, 200)      0           bidirectional_31[1][0]           \n",
      "                                                                 dot_83[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_16 (Multiply)          (None, 30, 200)      0           bidirectional_31[1][0]           \n",
      "                                                                 dot_83[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_104 (Concatenate)   (None, 30, 800)      0           bidirectional_31[0][0]           \n",
      "                                                                 dot_84[0][0]                     \n",
      "                                                                 lambda_71[0][0]                  \n",
      "                                                                 multiply_15[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_105 (Concatenate)   (None, 30, 800)      0           bidirectional_31[1][0]           \n",
      "                                                                 dot_83[0][0]                     \n",
      "                                                                 lambda_72[0][0]                  \n",
      "                                                                 multiply_16[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_32 (Bidirectional (None, 30, 200)      721600      concatenate_104[0][0]            \n",
      "                                                                 concatenate_105[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_23 (Gl (None, 200)          0           bidirectional_32[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_23 (Global (None, 200)          0           bidirectional_32[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_24 (Gl (None, 200)          0           bidirectional_32[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_24 (Global (None, 200)          0           bidirectional_32[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_106 (Concatenate)   (None, 400)          0           global_average_pooling1d_23[0][0]\n",
      "                                                                 global_max_pooling1d_23[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_107 (Concatenate)   (None, 400)          0           global_average_pooling1d_24[0][0]\n",
      "                                                                 global_max_pooling1d_24[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_108 (Concatenate)   (None, 800)          0           concatenate_106[0][0]            \n",
      "                                                                 concatenate_107[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 800)          3200        concatenate_108[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 256)          205056      batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 256)          1024        dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_79 (Dropout)            (None, 256)          0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 256)          65792       dropout_79[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 256)          1024        dense_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_80 (Dropout)            (None, 256)          0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 3)            771         dropout_80[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 31,321,267\n",
      "Trainable params: 1,318,043\n",
      "Non-trainable params: 30,003,224\n",
      "__________________________________________________________________________________________________\n",
      "Load weights from WordSGNS-ESIM-NoMeta-3P-NoEM-NoClassWeighted-3Layers3.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360609/360609 [==============================] - 146s 406us/step - loss: 0.0190 - acc: 0.8976 - weighted_accuracy: 0.8934 - val_loss: 0.3063 - val_acc: 0.8620 - val_weighted_accuracy: 0.8541\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 142s 395us/step - loss: 0.0184 - acc: 0.9011 - weighted_accuracy: 0.8975 - val_loss: 0.3051 - val_acc: 0.8646 - val_weighted_accuracy: 0.8592\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 140s 388us/step - loss: 0.0178 - acc: 0.9046 - weighted_accuracy: 0.9013 - val_loss: 0.2955 - val_acc: 0.8702 - val_weighted_accuracy: 0.8611\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 144s 400us/step - loss: 0.0175 - acc: 0.9068 - weighted_accuracy: 0.9044 - val_loss: 0.3054 - val_acc: 0.8647 - val_weighted_accuracy: 0.8598\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 143s 396us/step - loss: 0.0170 - acc: 0.9101 - weighted_accuracy: 0.9079 - val_loss: 0.3173 - val_acc: 0.8617 - val_weighted_accuracy: 0.8599\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 141s 392us/step - loss: 0.0167 - acc: 0.9119 - weighted_accuracy: 0.9101 - val_loss: 0.3001 - val_acc: 0.8704 - val_weighted_accuracy: 0.8633\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 141s 391us/step - loss: 0.0163 - acc: 0.9139 - weighted_accuracy: 0.9128 - val_loss: 0.3044 - val_acc: 0.8670 - val_weighted_accuracy: 0.8609\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 141s 391us/step - loss: 0.0161 - acc: 0.9154 - weighted_accuracy: 0.9146 - val_loss: 0.3077 - val_acc: 0.8667 - val_weighted_accuracy: 0.8622\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 140s 388us/step - loss: 0.0158 - acc: 0.9169 - weighted_accuracy: 0.9161 - val_loss: 0.2949 - val_acc: 0.8739 - val_weighted_accuracy: 0.8669\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 141s 390us/step - loss: 0.0155 - acc: 0.9189 - weighted_accuracy: 0.9184 - val_loss: 0.3070 - val_acc: 0.8661 - val_weighted_accuracy: 0.8617\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 141s 390us/step - loss: 0.0153 - acc: 0.9205 - weighted_accuracy: 0.9202 - val_loss: 0.3000 - val_acc: 0.8697 - val_weighted_accuracy: 0.8616\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 141s 390us/step - loss: 0.0151 - acc: 0.9223 - weighted_accuracy: 0.9222 - val_loss: 0.3040 - val_acc: 0.8681 - val_weighted_accuracy: 0.8623\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 140s 388us/step - loss: 0.0149 - acc: 0.9234 - weighted_accuracy: 0.9235 - val_loss: 0.3043 - val_acc: 0.8693 - val_weighted_accuracy: 0.8614\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 140s 389us/step - loss: 0.0147 - acc: 0.9248 - weighted_accuracy: 0.9251 - val_loss: 0.3169 - val_acc: 0.8649 - val_weighted_accuracy: 0.8612\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 141s 390us/step - loss: 0.0145 - acc: 0.9262 - weighted_accuracy: 0.9264 - val_loss: 0.3154 - val_acc: 0.8654 - val_weighted_accuracy: 0.8596\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 141s 390us/step - loss: 0.0144 - acc: 0.9270 - weighted_accuracy: 0.9274 - val_loss: 0.3099 - val_acc: 0.8677 - val_weighted_accuracy: 0.8618\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_21 (Embedding)        (None, 30, 300)      30000000    first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_25 (SpatialDr (None, 30, 300)      0           embedding_21[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_26 (SpatialDr (None, 30, 300)      0           embedding_21[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 30, 300)      1200        spatial_dropout1d_25[0][0]       \n",
      "                                                                 spatial_dropout1d_26[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_33 (Bidirectional (None, 30, 200)      321600      batch_normalization_17[0][0]     \n",
      "                                                                 batch_normalization_17[1][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dot_85 (Dot)                    (None, 30, 30)       0           bidirectional_33[0][0]           \n",
      "                                                                 bidirectional_33[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_74 (Lambda)              (None, 30, 30)       0           dot_85[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_29 (Permute)            (None, 30, 30)       0           lambda_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_73 (Lambda)              (None, 30, 30)       0           dot_85[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_87 (Dot)                    (None, 30, 200)      0           permute_29[0][0]                 \n",
      "                                                                 bidirectional_33[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dot_86 (Dot)                    (None, 30, 200)      0           lambda_73[0][0]                  \n",
      "                                                                 bidirectional_33[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_75 (Lambda)              (None, 30, 200)      0           bidirectional_33[0][0]           \n",
      "                                                                 dot_87[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_17 (Multiply)          (None, 30, 200)      0           bidirectional_33[0][0]           \n",
      "                                                                 dot_87[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_76 (Lambda)              (None, 30, 200)      0           bidirectional_33[1][0]           \n",
      "                                                                 dot_86[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_18 (Multiply)          (None, 30, 200)      0           bidirectional_33[1][0]           \n",
      "                                                                 dot_86[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_109 (Concatenate)   (None, 30, 800)      0           bidirectional_33[0][0]           \n",
      "                                                                 dot_87[0][0]                     \n",
      "                                                                 lambda_75[0][0]                  \n",
      "                                                                 multiply_17[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_110 (Concatenate)   (None, 30, 800)      0           bidirectional_33[1][0]           \n",
      "                                                                 dot_86[0][0]                     \n",
      "                                                                 lambda_76[0][0]                  \n",
      "                                                                 multiply_18[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_34 (Bidirectional (None, 30, 200)      721600      concatenate_109[0][0]            \n",
      "                                                                 concatenate_110[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_25 (Gl (None, 200)          0           bidirectional_34[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_25 (Global (None, 200)          0           bidirectional_34[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_26 (Gl (None, 200)          0           bidirectional_34[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_26 (Global (None, 200)          0           bidirectional_34[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_111 (Concatenate)   (None, 400)          0           global_average_pooling1d_25[0][0]\n",
      "                                                                 global_max_pooling1d_25[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_112 (Concatenate)   (None, 400)          0           global_average_pooling1d_26[0][0]\n",
      "                                                                 global_max_pooling1d_26[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_113 (Concatenate)   (None, 800)          0           concatenate_111[0][0]            \n",
      "                                                                 concatenate_112[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 800)          3200        concatenate_113[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 256)          205056      batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 256)          1024        dense_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_81 (Dropout)            (None, 256)          0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 256)          65792       dropout_81[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 256)          1024        dense_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_82 (Dropout)            (None, 256)          0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 3)            771         dropout_82[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 31,321,267\n",
      "Trainable params: 1,318,043\n",
      "Non-trainable params: 30,003,224\n",
      "__________________________________________________________________________________________________\n",
      "Load weights from WordSGNS-ESIM-NoMeta-3P-NoEM-NoClassWeighted-3Layers4.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360609/360609 [==============================] - 146s 405us/step - loss: 0.0191 - acc: 0.8972 - weighted_accuracy: 0.8925 - val_loss: 0.3178 - val_acc: 0.8546 - val_weighted_accuracy: 0.8493\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 142s 393us/step - loss: 0.0184 - acc: 0.9013 - weighted_accuracy: 0.8974 - val_loss: 0.3110 - val_acc: 0.8599 - val_weighted_accuracy: 0.8499\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 142s 394us/step - loss: 0.0180 - acc: 0.9046 - weighted_accuracy: 0.9014 - val_loss: 0.3140 - val_acc: 0.8578 - val_weighted_accuracy: 0.8513\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 142s 394us/step - loss: 0.0175 - acc: 0.9080 - weighted_accuracy: 0.9053 - val_loss: 0.3230 - val_acc: 0.8545 - val_weighted_accuracy: 0.8496\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 142s 393us/step - loss: 0.0171 - acc: 0.9097 - weighted_accuracy: 0.9075 - val_loss: 0.3112 - val_acc: 0.8607 - val_weighted_accuracy: 0.8537\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 141s 392us/step - loss: 0.0168 - acc: 0.9115 - weighted_accuracy: 0.9099 - val_loss: 0.3090 - val_acc: 0.8615 - val_weighted_accuracy: 0.8559\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 143s 396us/step - loss: 0.0164 - acc: 0.9141 - weighted_accuracy: 0.9128 - val_loss: 0.3121 - val_acc: 0.8593 - val_weighted_accuracy: 0.8546\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 141s 391us/step - loss: 0.0161 - acc: 0.9159 - weighted_accuracy: 0.9149 - val_loss: 0.3290 - val_acc: 0.8562 - val_weighted_accuracy: 0.8516\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 141s 392us/step - loss: 0.0158 - acc: 0.9179 - weighted_accuracy: 0.9172 - val_loss: 0.3197 - val_acc: 0.8616 - val_weighted_accuracy: 0.8562\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 140s 389us/step - loss: 0.0156 - acc: 0.9189 - weighted_accuracy: 0.9183 - val_loss: 0.3240 - val_acc: 0.8559 - val_weighted_accuracy: 0.8527\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 141s 391us/step - loss: 0.0153 - acc: 0.9207 - weighted_accuracy: 0.9203 - val_loss: 0.3143 - val_acc: 0.8597 - val_weighted_accuracy: 0.8534\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 141s 392us/step - loss: 0.0151 - acc: 0.9224 - weighted_accuracy: 0.9222 - val_loss: 0.3208 - val_acc: 0.8593 - val_weighted_accuracy: 0.8538\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 141s 392us/step - loss: 0.0148 - acc: 0.9233 - weighted_accuracy: 0.9235 - val_loss: 0.3149 - val_acc: 0.8603 - val_weighted_accuracy: 0.8541\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 141s 391us/step - loss: 0.0147 - acc: 0.9250 - weighted_accuracy: 0.9251 - val_loss: 0.3096 - val_acc: 0.8651 - val_weighted_accuracy: 0.8553\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 142s 394us/step - loss: 0.0145 - acc: 0.9266 - weighted_accuracy: 0.9269 - val_loss: 0.3345 - val_acc: 0.8545 - val_weighted_accuracy: 0.8524\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 141s 390us/step - loss: 0.0142 - acc: 0.9277 - weighted_accuracy: 0.9282 - val_loss: 0.3219 - val_acc: 0.8587 - val_weighted_accuracy: 0.8534\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_22 (Embedding)        (None, 30, 300)      30000000    first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_27 (SpatialDr (None, 30, 300)      0           embedding_22[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_28 (SpatialDr (None, 30, 300)      0           embedding_22[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 30, 300)      1200        spatial_dropout1d_27[0][0]       \n",
      "                                                                 spatial_dropout1d_28[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_35 (Bidirectional (None, 30, 200)      321600      batch_normalization_21[0][0]     \n",
      "                                                                 batch_normalization_21[1][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dot_88 (Dot)                    (None, 30, 30)       0           bidirectional_35[0][0]           \n",
      "                                                                 bidirectional_35[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_78 (Lambda)              (None, 30, 30)       0           dot_88[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_30 (Permute)            (None, 30, 30)       0           lambda_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_77 (Lambda)              (None, 30, 30)       0           dot_88[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_90 (Dot)                    (None, 30, 200)      0           permute_30[0][0]                 \n",
      "                                                                 bidirectional_35[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dot_89 (Dot)                    (None, 30, 200)      0           lambda_77[0][0]                  \n",
      "                                                                 bidirectional_35[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_79 (Lambda)              (None, 30, 200)      0           bidirectional_35[0][0]           \n",
      "                                                                 dot_90[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_19 (Multiply)          (None, 30, 200)      0           bidirectional_35[0][0]           \n",
      "                                                                 dot_90[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_80 (Lambda)              (None, 30, 200)      0           bidirectional_35[1][0]           \n",
      "                                                                 dot_89[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_20 (Multiply)          (None, 30, 200)      0           bidirectional_35[1][0]           \n",
      "                                                                 dot_89[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_114 (Concatenate)   (None, 30, 800)      0           bidirectional_35[0][0]           \n",
      "                                                                 dot_90[0][0]                     \n",
      "                                                                 lambda_79[0][0]                  \n",
      "                                                                 multiply_19[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_115 (Concatenate)   (None, 30, 800)      0           bidirectional_35[1][0]           \n",
      "                                                                 dot_89[0][0]                     \n",
      "                                                                 lambda_80[0][0]                  \n",
      "                                                                 multiply_20[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_36 (Bidirectional (None, 30, 200)      721600      concatenate_114[0][0]            \n",
      "                                                                 concatenate_115[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_27 (Gl (None, 200)          0           bidirectional_36[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_27 (Global (None, 200)          0           bidirectional_36[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_28 (Gl (None, 200)          0           bidirectional_36[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_28 (Global (None, 200)          0           bidirectional_36[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_116 (Concatenate)   (None, 400)          0           global_average_pooling1d_27[0][0]\n",
      "                                                                 global_max_pooling1d_27[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_117 (Concatenate)   (None, 400)          0           global_average_pooling1d_28[0][0]\n",
      "                                                                 global_max_pooling1d_28[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_118 (Concatenate)   (None, 800)          0           concatenate_116[0][0]            \n",
      "                                                                 concatenate_117[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 800)          3200        concatenate_118[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 256)          205056      batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 256)          1024        dense_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_83 (Dropout)            (None, 256)          0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 256)          65792       dropout_83[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 256)          1024        dense_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_84 (Dropout)            (None, 256)          0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_34 (Dense)                (None, 3)            771         dropout_84[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 31,321,267\n",
      "Trainable params: 1,318,043\n",
      "Non-trainable params: 30,003,224\n",
      "__________________________________________________________________________________________________\n",
      "Load weights from WordSGNS-ESIM-NoMeta-3P-NoEM-NoClassWeighted-3Layers5.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360609/360609 [==============================] - 147s 406us/step - loss: 0.0184 - acc: 0.9021 - weighted_accuracy: 0.8981 - val_loss: 0.3381 - val_acc: 0.8464 - val_weighted_accuracy: 0.8381\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 142s 393us/step - loss: 0.0177 - acc: 0.9058 - weighted_accuracy: 0.9025 - val_loss: 0.3313 - val_acc: 0.8487 - val_weighted_accuracy: 0.8394\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 143s 395us/step - loss: 0.0173 - acc: 0.9091 - weighted_accuracy: 0.9062 - val_loss: 0.3341 - val_acc: 0.8487 - val_weighted_accuracy: 0.8362\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 142s 395us/step - loss: 0.0169 - acc: 0.9106 - weighted_accuracy: 0.9082 - val_loss: 0.3352 - val_acc: 0.8447 - val_weighted_accuracy: 0.8352\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 141s 392us/step - loss: 0.0165 - acc: 0.9132 - weighted_accuracy: 0.9111 - val_loss: 0.3271 - val_acc: 0.8515 - val_weighted_accuracy: 0.8385\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 142s 394us/step - loss: 0.0162 - acc: 0.9151 - weighted_accuracy: 0.9136 - val_loss: 0.3520 - val_acc: 0.8413 - val_weighted_accuracy: 0.8373\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 142s 393us/step - loss: 0.0159 - acc: 0.9172 - weighted_accuracy: 0.9161 - val_loss: 0.3345 - val_acc: 0.8535 - val_weighted_accuracy: 0.8427\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 142s 394us/step - loss: 0.0156 - acc: 0.9196 - weighted_accuracy: 0.9188 - val_loss: 0.3432 - val_acc: 0.8452 - val_weighted_accuracy: 0.8404\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 142s 393us/step - loss: 0.0154 - acc: 0.9203 - weighted_accuracy: 0.9198 - val_loss: 0.3297 - val_acc: 0.8552 - val_weighted_accuracy: 0.8445\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 142s 393us/step - loss: 0.0152 - acc: 0.9220 - weighted_accuracy: 0.9216 - val_loss: 0.3279 - val_acc: 0.8527 - val_weighted_accuracy: 0.8442\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 142s 395us/step - loss: 0.0149 - acc: 0.9233 - weighted_accuracy: 0.9233 - val_loss: 0.3292 - val_acc: 0.8521 - val_weighted_accuracy: 0.8431\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 142s 394us/step - loss: 0.0147 - acc: 0.9251 - weighted_accuracy: 0.9250 - val_loss: 0.3340 - val_acc: 0.8517 - val_weighted_accuracy: 0.8407\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 141s 392us/step - loss: 0.0144 - acc: 0.9266 - weighted_accuracy: 0.9267 - val_loss: 0.3351 - val_acc: 0.8539 - val_weighted_accuracy: 0.8432\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 142s 394us/step - loss: 0.0142 - acc: 0.9281 - weighted_accuracy: 0.9285 - val_loss: 0.3398 - val_acc: 0.8517 - val_weighted_accuracy: 0.8441\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 142s 393us/step - loss: 0.0141 - acc: 0.9287 - weighted_accuracy: 0.9291 - val_loss: 0.3320 - val_acc: 0.8549 - val_weighted_accuracy: 0.8419\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 142s 393us/step - loss: 0.0139 - acc: 0.9302 - weighted_accuracy: 0.9309 - val_loss: 0.3373 - val_acc: 0.8530 - val_weighted_accuracy: 0.8421\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_23 (Embedding)        (None, 30, 300)      30000000    first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_29 (SpatialDr (None, 30, 300)      0           embedding_23[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_30 (SpatialDr (None, 30, 300)      0           embedding_23[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 30, 300)      1200        spatial_dropout1d_29[0][0]       \n",
      "                                                                 spatial_dropout1d_30[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_37 (Bidirectional (None, 30, 200)      321600      batch_normalization_25[0][0]     \n",
      "                                                                 batch_normalization_25[1][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dot_91 (Dot)                    (None, 30, 30)       0           bidirectional_37[0][0]           \n",
      "                                                                 bidirectional_37[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_82 (Lambda)              (None, 30, 30)       0           dot_91[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_31 (Permute)            (None, 30, 30)       0           lambda_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_81 (Lambda)              (None, 30, 30)       0           dot_91[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_93 (Dot)                    (None, 30, 200)      0           permute_31[0][0]                 \n",
      "                                                                 bidirectional_37[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dot_92 (Dot)                    (None, 30, 200)      0           lambda_81[0][0]                  \n",
      "                                                                 bidirectional_37[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_83 (Lambda)              (None, 30, 200)      0           bidirectional_37[0][0]           \n",
      "                                                                 dot_93[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_21 (Multiply)          (None, 30, 200)      0           bidirectional_37[0][0]           \n",
      "                                                                 dot_93[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_84 (Lambda)              (None, 30, 200)      0           bidirectional_37[1][0]           \n",
      "                                                                 dot_92[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_22 (Multiply)          (None, 30, 200)      0           bidirectional_37[1][0]           \n",
      "                                                                 dot_92[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_119 (Concatenate)   (None, 30, 800)      0           bidirectional_37[0][0]           \n",
      "                                                                 dot_93[0][0]                     \n",
      "                                                                 lambda_83[0][0]                  \n",
      "                                                                 multiply_21[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_120 (Concatenate)   (None, 30, 800)      0           bidirectional_37[1][0]           \n",
      "                                                                 dot_92[0][0]                     \n",
      "                                                                 lambda_84[0][0]                  \n",
      "                                                                 multiply_22[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_38 (Bidirectional (None, 30, 200)      721600      concatenate_119[0][0]            \n",
      "                                                                 concatenate_120[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_29 (Gl (None, 200)          0           bidirectional_38[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_29 (Global (None, 200)          0           bidirectional_38[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_30 (Gl (None, 200)          0           bidirectional_38[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_30 (Global (None, 200)          0           bidirectional_38[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_121 (Concatenate)   (None, 400)          0           global_average_pooling1d_29[0][0]\n",
      "                                                                 global_max_pooling1d_29[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_122 (Concatenate)   (None, 400)          0           global_average_pooling1d_30[0][0]\n",
      "                                                                 global_max_pooling1d_30[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_123 (Concatenate)   (None, 800)          0           concatenate_121[0][0]            \n",
      "                                                                 concatenate_122[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 800)          3200        concatenate_123[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_35 (Dense)                (None, 256)          205056      batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 256)          1024        dense_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_85 (Dropout)            (None, 256)          0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_36 (Dense)                (None, 256)          65792       dropout_85[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 256)          1024        dense_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_86 (Dropout)            (None, 256)          0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_37 (Dense)                (None, 3)            771         dropout_86[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 31,321,267\n",
      "Trainable params: 1,318,043\n",
      "Non-trainable params: 30,003,224\n",
      "__________________________________________________________________________________________________\n",
      "Load weights from WordSGNS-ESIM-NoMeta-3P-NoEM-NoClassWeighted-3Layers6.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360609/360609 [==============================] - 148s 411us/step - loss: 0.0171 - acc: 0.9111 - weighted_accuracy: 0.9080 - val_loss: 0.3040 - val_acc: 0.8680 - val_weighted_accuracy: 0.8600\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 143s 396us/step - loss: 0.0167 - acc: 0.9136 - weighted_accuracy: 0.9111 - val_loss: 0.3022 - val_acc: 0.8696 - val_weighted_accuracy: 0.8610\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 143s 396us/step - loss: 0.0164 - acc: 0.9154 - weighted_accuracy: 0.9134 - val_loss: 0.3067 - val_acc: 0.8658 - val_weighted_accuracy: 0.8612\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 143s 396us/step - loss: 0.0161 - acc: 0.9172 - weighted_accuracy: 0.9155 - val_loss: 0.3111 - val_acc: 0.8638 - val_weighted_accuracy: 0.8589\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 143s 395us/step - loss: 0.0157 - acc: 0.9192 - weighted_accuracy: 0.9180 - val_loss: 0.3131 - val_acc: 0.8688 - val_weighted_accuracy: 0.8629\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 143s 397us/step - loss: 0.0155 - acc: 0.9202 - weighted_accuracy: 0.9191 - val_loss: 0.3203 - val_acc: 0.8655 - val_weighted_accuracy: 0.8609\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 142s 394us/step - loss: 0.0153 - acc: 0.9216 - weighted_accuracy: 0.9207 - val_loss: 0.3007 - val_acc: 0.8677 - val_weighted_accuracy: 0.8626\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 143s 396us/step - loss: 0.0150 - acc: 0.9226 - weighted_accuracy: 0.9222 - val_loss: 0.3079 - val_acc: 0.8674 - val_weighted_accuracy: 0.8635\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 143s 397us/step - loss: 0.0148 - acc: 0.9252 - weighted_accuracy: 0.9250 - val_loss: 0.3127 - val_acc: 0.8637 - val_weighted_accuracy: 0.8608\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 143s 396us/step - loss: 0.0146 - acc: 0.9260 - weighted_accuracy: 0.9261 - val_loss: 0.3163 - val_acc: 0.8640 - val_weighted_accuracy: 0.8602\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 143s 397us/step - loss: 0.0144 - acc: 0.9270 - weighted_accuracy: 0.9273 - val_loss: 0.3098 - val_acc: 0.8682 - val_weighted_accuracy: 0.8621\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 143s 396us/step - loss: 0.0143 - acc: 0.9285 - weighted_accuracy: 0.9288 - val_loss: 0.3133 - val_acc: 0.8689 - val_weighted_accuracy: 0.8615\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 143s 395us/step - loss: 0.0141 - acc: 0.9289 - weighted_accuracy: 0.9293 - val_loss: 0.3139 - val_acc: 0.8656 - val_weighted_accuracy: 0.8613\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 143s 397us/step - loss: 0.0139 - acc: 0.9302 - weighted_accuracy: 0.9307 - val_loss: 0.3083 - val_acc: 0.8681 - val_weighted_accuracy: 0.8642\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 143s 396us/step - loss: 0.0137 - acc: 0.9316 - weighted_accuracy: 0.9322 - val_loss: 0.3097 - val_acc: 0.8715 - val_weighted_accuracy: 0.8641\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 143s 396us/step - loss: 0.0136 - acc: 0.9321 - weighted_accuracy: 0.9329 - val_loss: 0.3075 - val_acc: 0.8716 - val_weighted_accuracy: 0.8646\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 143s 397us/step - loss: 0.0134 - acc: 0.9340 - weighted_accuracy: 0.9348 - val_loss: 0.3126 - val_acc: 0.8692 - val_weighted_accuracy: 0.8636\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 143s 397us/step - loss: 0.0132 - acc: 0.9349 - weighted_accuracy: 0.9359 - val_loss: 0.3073 - val_acc: 0.8709 - val_weighted_accuracy: 0.8654\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 142s 394us/step - loss: 0.0131 - acc: 0.9356 - weighted_accuracy: 0.9367 - val_loss: 0.3121 - val_acc: 0.8717 - val_weighted_accuracy: 0.8650\n",
      "Epoch 20/500\n",
      "360609/360609 [==============================] - 143s 397us/step - loss: 0.0130 - acc: 0.9362 - weighted_accuracy: 0.9374 - val_loss: 0.3191 - val_acc: 0.8672 - val_weighted_accuracy: 0.8626\n",
      "Epoch 21/500\n",
      "360609/360609 [==============================] - 142s 394us/step - loss: 0.0128 - acc: 0.9374 - weighted_accuracy: 0.9387 - val_loss: 0.3214 - val_acc: 0.8675 - val_weighted_accuracy: 0.8626\n",
      "Epoch 22/500\n",
      "360609/360609 [==============================] - 143s 397us/step - loss: 0.0126 - acc: 0.9379 - weighted_accuracy: 0.9394 - val_loss: 0.3093 - val_acc: 0.8699 - val_weighted_accuracy: 0.8641\n",
      "Epoch 23/500\n",
      "360609/360609 [==============================] - 143s 396us/step - loss: 0.0125 - acc: 0.9396 - weighted_accuracy: 0.9408 - val_loss: 0.3201 - val_acc: 0.8713 - val_weighted_accuracy: 0.8647\n",
      "Epoch 24/500\n",
      "360609/360609 [==============================] - 143s 395us/step - loss: 0.0124 - acc: 0.9396 - weighted_accuracy: 0.9411 - val_loss: 0.3237 - val_acc: 0.8700 - val_weighted_accuracy: 0.8647\n",
      "Epoch 25/500\n",
      "360609/360609 [==============================] - 143s 396us/step - loss: 0.0123 - acc: 0.9404 - weighted_accuracy: 0.9419 - val_loss: 0.3244 - val_acc: 0.8702 - val_weighted_accuracy: 0.8638\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_24 (Embedding)        (None, 30, 300)      30000000    first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_31 (SpatialDr (None, 30, 300)      0           embedding_24[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_32 (SpatialDr (None, 30, 300)      0           embedding_24[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 30, 300)      1200        spatial_dropout1d_31[0][0]       \n",
      "                                                                 spatial_dropout1d_32[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_39 (Bidirectional (None, 30, 200)      321600      batch_normalization_29[0][0]     \n",
      "                                                                 batch_normalization_29[1][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dot_94 (Dot)                    (None, 30, 30)       0           bidirectional_39[0][0]           \n",
      "                                                                 bidirectional_39[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_86 (Lambda)              (None, 30, 30)       0           dot_94[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_32 (Permute)            (None, 30, 30)       0           lambda_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_85 (Lambda)              (None, 30, 30)       0           dot_94[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_96 (Dot)                    (None, 30, 200)      0           permute_32[0][0]                 \n",
      "                                                                 bidirectional_39[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dot_95 (Dot)                    (None, 30, 200)      0           lambda_85[0][0]                  \n",
      "                                                                 bidirectional_39[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_87 (Lambda)              (None, 30, 200)      0           bidirectional_39[0][0]           \n",
      "                                                                 dot_96[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_23 (Multiply)          (None, 30, 200)      0           bidirectional_39[0][0]           \n",
      "                                                                 dot_96[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_88 (Lambda)              (None, 30, 200)      0           bidirectional_39[1][0]           \n",
      "                                                                 dot_95[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_24 (Multiply)          (None, 30, 200)      0           bidirectional_39[1][0]           \n",
      "                                                                 dot_95[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_124 (Concatenate)   (None, 30, 800)      0           bidirectional_39[0][0]           \n",
      "                                                                 dot_96[0][0]                     \n",
      "                                                                 lambda_87[0][0]                  \n",
      "                                                                 multiply_23[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_125 (Concatenate)   (None, 30, 800)      0           bidirectional_39[1][0]           \n",
      "                                                                 dot_95[0][0]                     \n",
      "                                                                 lambda_88[0][0]                  \n",
      "                                                                 multiply_24[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_40 (Bidirectional (None, 30, 200)      721600      concatenate_124[0][0]            \n",
      "                                                                 concatenate_125[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_31 (Gl (None, 200)          0           bidirectional_40[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_31 (Global (None, 200)          0           bidirectional_40[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_32 (Gl (None, 200)          0           bidirectional_40[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_32 (Global (None, 200)          0           bidirectional_40[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_126 (Concatenate)   (None, 400)          0           global_average_pooling1d_31[0][0]\n",
      "                                                                 global_max_pooling1d_31[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_127 (Concatenate)   (None, 400)          0           global_average_pooling1d_32[0][0]\n",
      "                                                                 global_max_pooling1d_32[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_128 (Concatenate)   (None, 800)          0           concatenate_126[0][0]            \n",
      "                                                                 concatenate_127[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 800)          3200        concatenate_128[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_38 (Dense)                (None, 256)          205056      batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 256)          1024        dense_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_87 (Dropout)            (None, 256)          0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_39 (Dense)                (None, 256)          65792       dropout_87[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 256)          1024        dense_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_88 (Dropout)            (None, 256)          0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_40 (Dense)                (None, 3)            771         dropout_88[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 31,321,267\n",
      "Trainable params: 1,318,043\n",
      "Non-trainable params: 30,003,224\n",
      "__________________________________________________________________________________________________\n",
      "Load weights from WordSGNS-ESIM-NoMeta-3P-NoEM-NoClassWeighted-3Layers7.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360609/360609 [==============================] - 148s 411us/step - loss: 0.0193 - acc: 0.8960 - weighted_accuracy: 0.8918 - val_loss: 0.2825 - val_acc: 0.8771 - val_weighted_accuracy: 0.8587\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 143s 398us/step - loss: 0.0187 - acc: 0.8991 - weighted_accuracy: 0.8957 - val_loss: 0.2952 - val_acc: 0.8664 - val_weighted_accuracy: 0.8597\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 143s 398us/step - loss: 0.0182 - acc: 0.9027 - weighted_accuracy: 0.8997 - val_loss: 0.3120 - val_acc: 0.8583 - val_weighted_accuracy: 0.8500\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 145s 402us/step - loss: 0.0177 - acc: 0.9061 - weighted_accuracy: 0.9037 - val_loss: 0.2879 - val_acc: 0.8735 - val_weighted_accuracy: 0.8623\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 143s 398us/step - loss: 0.0172 - acc: 0.9084 - weighted_accuracy: 0.9065 - val_loss: 0.2989 - val_acc: 0.8679 - val_weighted_accuracy: 0.8597\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 143s 398us/step - loss: 0.0169 - acc: 0.9110 - weighted_accuracy: 0.9095 - val_loss: 0.2910 - val_acc: 0.8700 - val_weighted_accuracy: 0.8619\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 143s 397us/step - loss: 0.0165 - acc: 0.9125 - weighted_accuracy: 0.9113 - val_loss: 0.2870 - val_acc: 0.8772 - val_weighted_accuracy: 0.8639\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 143s 397us/step - loss: 0.0163 - acc: 0.9151 - weighted_accuracy: 0.9142 - val_loss: 0.2905 - val_acc: 0.8720 - val_weighted_accuracy: 0.8633\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 143s 396us/step - loss: 0.0159 - acc: 0.9171 - weighted_accuracy: 0.9164 - val_loss: 0.2828 - val_acc: 0.8781 - val_weighted_accuracy: 0.8670\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 143s 397us/step - loss: 0.0157 - acc: 0.9189 - weighted_accuracy: 0.9185 - val_loss: 0.2997 - val_acc: 0.8693 - val_weighted_accuracy: 0.8634\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 143s 397us/step - loss: 0.0154 - acc: 0.9199 - weighted_accuracy: 0.9197 - val_loss: 0.2931 - val_acc: 0.8712 - val_weighted_accuracy: 0.8645\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 144s 398us/step - loss: 0.0152 - acc: 0.9215 - weighted_accuracy: 0.9217 - val_loss: 0.2916 - val_acc: 0.8735 - val_weighted_accuracy: 0.8629\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 142s 394us/step - loss: 0.0150 - acc: 0.9231 - weighted_accuracy: 0.9234 - val_loss: 0.2890 - val_acc: 0.8762 - val_weighted_accuracy: 0.8661\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 144s 398us/step - loss: 0.0148 - acc: 0.9242 - weighted_accuracy: 0.9247 - val_loss: 0.3051 - val_acc: 0.8645 - val_weighted_accuracy: 0.8590\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 144s 398us/step - loss: 0.0146 - acc: 0.9256 - weighted_accuracy: 0.9263 - val_loss: 0.2900 - val_acc: 0.8745 - val_weighted_accuracy: 0.8637\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 143s 397us/step - loss: 0.0144 - acc: 0.9262 - weighted_accuracy: 0.9267 - val_loss: 0.3018 - val_acc: 0.8711 - val_weighted_accuracy: 0.8631\n",
      "score 0.8609507292969848\n",
      "Predicting training results...\n",
      "Predicting testing results...\n",
      "80126/80126 [==============================] - 7s 89us/step\n",
      "80126/80126 [==============================] - 7s 89us/step\n",
      "80126/80126 [==============================] - 7s 91us/step\n",
      "80126/80126 [==============================] - 7s 89us/step\n",
      "80126/80126 [==============================] - 7s 89us/step\n",
      "80126/80126 [==============================] - 7s 89us/step\n",
      "80126/80126 [==============================] - 7s 89us/step\n",
      "80126/80126 [==============================] - 7s 90us/step\n",
      "Predicting labeled testing results...\n"
     ]
    }
   ],
   "source": [
    "fold_count = 8\n",
    "embedding_matrix = sgns_bigram_matrix\n",
    "#embedding_matrix = tencent_ai_matrix\n",
    "EMBEDDING_DIM = 300\n",
    "\n",
    "for i in range(1, len(model_manager.models_tag)):\n",
    "    print(\"Work on model\", i)\n",
    "    model_tag = model_manager.models_tag[i]\n",
    "    model_func = model_manager.model_funcs[i]\n",
    "    #models_checkpoints_path = model_manager.models_checkpoints_pathes[i]\n",
    "    models_checkpoints_path = \"WordSGNS-ESIM-NoMeta-3P-NoEM-NoClassWeighted-3Layers\"\n",
    "\n",
    "    model_submit_prefix = model_manager.submit_predix[i]\n",
    "    model_class_weights = model_manager.model_class_weights[i]\n",
    "    model_scale_sample_weights = model_manager.model_scale_sample_weights[i]\n",
    "    model_patiences = model_manager.model_patiences[i]\n",
    "    \n",
    "    model_class_weights = None\n",
    "    \n",
    "    def _agent_get_model():\n",
    "        return get_ESIM(NB_WORDS, EMBEDDING_DIM, embedding_matrix, MAX_SEQUENCE_LENGTH, OUT_SIZE)\n",
    "        return get_dense_cnn(NB_WORDS, EMBEDDING_DIM, embedding_matrix, MAX_SEQUENCE_LENGTH, OUT_SIZE)\n",
    "        return model_func(NB_WORDS, EMBEDDING_DIM, embedding_matrix, MAX_SEQUENCE_LENGTH, OUT_SIZE)\n",
    "    \n",
    "    test_predicts_list = []\n",
    "    oofs_predictions = []\n",
    "    pre_trained_models = []\n",
    "        \n",
    "    trainer = KerasModelTrainer(model_stamp=models_checkpoints_path, epoch_num=500)\n",
    "    models, score, folds_preds = trainer.train_folds(X=trains, y=labels, tests=tests, augments=None, fold_count=fold_count, batch_size=64,\n",
    "        em_train_features=em_train_features, em_test_features=em_test_features, pseudo_labels=pseudo_labels,                                      \n",
    "        scale_sample_weight=model_scale_sample_weights, class_weight=model_class_weights,\n",
    "        get_model_func=_agent_get_model, \n",
    "        patience=7)\n",
    "\n",
    "    print(\"score\", score)\n",
    "    oofs_dir = \"../data/pseudo/oofs/\"\n",
    "    output_dir = \"../data/pseudo/output/\"\n",
    "    onehot_pred_dir = \"../data/pseudo/one_hot_pred/\"\n",
    "\n",
    "    model_submit_prefix = \"PSWordSGNS-ESIM-NoMeta-3P-NoEM-NoClassWeighted-3Layers\"\n",
    "    \n",
    "    oofs_path = oofs_dir + model_submit_prefix\n",
    "    output_path = output_dir + model_submit_prefix\n",
    "    one_hot_pred_path = onehot_pred_dir + \"One-Hot\" + model_submit_prefix\n",
    "\n",
    "    print(\"Predicting training results...\")\n",
    "    train_predicts = np.concatenate(folds_preds, axis=0)\n",
    "    oofs = pd.DataFrame({\"unrelated\": train_predicts[:, 0], \"agreed\": train_predicts[:, 1], \"disagreed\": train_predicts[:, 2]})\n",
    "    submit_path = oofs_path + \"-Train-L{:4f}-NB{:d}.csv\".format(score, NB_WORDS)\n",
    "    oofs.to_csv(submit_path, index=False)\n",
    "\n",
    "    print(\"Predicting testing results...\")\n",
    "    test_predicts_list = []\n",
    "    for fold_id, model in enumerate(models):\n",
    "        test_predicts = model.predict({\"first_sentences\":tests[0],\n",
    "                                       \"second_sentences\":tests[1],\n",
    "                                       \"mata-features\":tests[2],\n",
    "                                       \"first_exact_match\": tests_1_ems,\n",
    "                                       \"second_exact_match\": tests_2_ems,\n",
    "                                      }, batch_size=128, verbose=1)\n",
    "\n",
    "        test_predicts_list.append(test_predicts)\n",
    "\n",
    "    test_predicts = np.zeros(test_predicts_list[0].shape)\n",
    "    for fold_predict in test_predicts_list:\n",
    "        test_predicts += fold_predict\n",
    "    test_predicts /= len(test_predicts_list)\n",
    "\n",
    "    test_predicts = pd.DataFrame({\"unrelated\": test_predicts[:, 0], \"agreed\": test_predicts[:, 1], \"disagreed\": test_predicts[:, 2]})\n",
    "    submit_path = output_path + \"-L{:4f}-NB{:d}.csv\".format(score, NB_WORDS)\n",
    "    test_predicts.to_csv(submit_path, index=False) # 0.3343\n",
    "    \n",
    "    print(\"Predicting labeled testing results...\")\n",
    "    ids = pd.read_csv(\"../data/dataset/test.csv\")\n",
    "    pred_labels = test_predicts.idxmax(axis=1)\n",
    "    sub = pd.DataFrame({\"Id\": ids['id'].values, \"Category\": pred_labels})\n",
    "    submit_path = one_hot_pred_path + \"-L{:4f}-NB{:d}.csv\".format(score, NB_WORDS)\n",
    "    sub.to_csv(submit_path, index=False)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numpy_weighted_accuracy(labels, oofs[['unrelated', 'agreed', 'disagreed']].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DenseRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "def get_darnn(nb_words, embedding_dim, embedding_matrix, max_sequence_length, out_size,\n",
    "    projection_dim=50, projection_hidden=0, projection_dropout=0.2,\n",
    "    compare_dim=288, compare_dropout=0.2,\n",
    "    dense_dim=50, dense_dropout=0.2,\n",
    "    lr=1e-3, activation='relu'):\n",
    "\n",
    "    q1 = Input(shape=(max_sequence_length,), name='first_sentences')\n",
    "    q2 = Input(shape=(max_sequence_length,), name='second_sentences')\n",
    "\n",
    "    q1_exact_match = Input(shape=(max_sequence_length,), name='first_exact_match')\n",
    "    q2_exact_match = Input(shape=(max_sequence_length,), name='second_exact_match')    \n",
    "    input_layer_3 = Input(shape=(36,), name='mata-features', dtype=\"float32\")\n",
    "    \n",
    "    embedding = Embedding(nb_words, embedding_dim,\n",
    "                          weights=[embedding_matrix],\n",
    "                          input_length=max_sequence_length,\n",
    "                          trainable=False)\n",
    "    \n",
    "    em_embeddings = Embedding(2, 1,\n",
    "                     input_length=max_sequence_length,\n",
    "                     trainable=True)   \n",
    "    \n",
    "    q1_embed = embedding(q1)\n",
    "    q1_embed = SpatialDropout1D(0.1)(q1_embed)\n",
    "    \n",
    "    q2_embed = embedding(q2)\n",
    "    q2_embed = SpatialDropout1D(0.1)(q2_embed)\n",
    "\n",
    "    th = TimeDistributed(Highway(activation='relu'))\n",
    "    q1_embed = Dropout(0.1)(th(q1_embed,))\n",
    "    q2_embed = Dropout(0.1)(th(q2_embed,))    \n",
    "    \n",
    "    rnns = [Bidirectional(CuDNNGRU(42, return_sequences=True)) for i in range(3)]\n",
    "    \n",
    "    q1_res = []\n",
    "    q2_res = []\n",
    "    \n",
    "    \n",
    "    for idx, rnn in enumerate(rnns):\n",
    "        q1_seq = rnn(q1_embed)\n",
    "        q1_seq = Dropout(0.15)(q1_seq)\n",
    "        q2_seq = rnn(q2_embed)\n",
    "        q2_seq = Dropout(0.15)(q2_seq)\n",
    "        q1_aligned, q2_aligned = soft_attention_alignment(q1_seq, q2_seq)\n",
    "        \n",
    "        q1_res.append(q2_aligned)\n",
    "        q1_res.append(q1_seq)\n",
    "        \n",
    "        q2_res.append(q1_aligned)\n",
    "        q2_res.append(q2_seq)\n",
    "        \n",
    "        q1_embed = Concatenate()([q1_embed, q1_seq, q2_aligned,])\n",
    "        q2_embed = Concatenate()([q2_embed, q2_seq, q1_aligned,])            \n",
    "        \n",
    "    # Pooling\n",
    "    #q1_rep = Flatten()(capsule_pooling(q1_encoded))\n",
    "    #q2_rep = Flatten()(capsule_pooling(q2_encoded))\n",
    "\n",
    "    q1_res = Concatenate()(q1_res)\n",
    "    q2_res = Concatenate()(q2_res)\n",
    "    \n",
    "    attn = AttentionWeightedAverage()\n",
    "    q1_rep = apply_multiple(q1_embed, [GlobalAvgPool1D(), GlobalMaxPool1D(), attn])\n",
    "    q2_rep = apply_multiple(q2_embed, [GlobalAvgPool1D(), GlobalMaxPool1D(), attn])   \n",
    "    \n",
    "    # Classifier\n",
    "    q_diff = substract(q1_rep, q2_rep)\n",
    "    q_multi = Multiply()([q1_rep, q2_rep])\n",
    "    h_all = Concatenate()([q1_rep, q2_rep, q_diff, q_multi,])\n",
    "    h_all = Dropout(0.35)(h_all)\n",
    "    h_all = Dense(300, activation='relu')(h_all)\n",
    "    out_ = Dense(3, activation='softmax')(h_all)\n",
    "\n",
    "    model = Model(inputs=[q1, q2, input_layer_3, q1_exact_match, q2_exact_match], outputs=out_)\n",
    "    model.compile(optimizer=Adam(lr=lr, decay=1e-6, clipvalue=1.5), loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', weighted_accuracy])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TenCent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Work on model 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zake7\\Anaconda3\\lib\\site-packages\\keras\\legacy\\layers.py:198: UserWarning: The `Highway` layer is deprecated and will be removed after 06/2017.\n",
      "  warnings.warn('The `Highway` layer is deprecated '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 30, 200)      20000000    first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 30, 200)      0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_2 (SpatialDro (None, 30, 200)      0           embedding_1[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 30, 200)      80400       spatial_dropout1d_1[0][0]        \n",
      "                                                                 spatial_dropout1d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 30, 200)      0           time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 30, 200)      0           time_distributed_1[1][0]         \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 30, 84)       61488       dropout_1[0][0]                  \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 30, 84)       0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 30, 84)       0           bidirectional_1[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 30, 30)       0           dropout_3[0][0]                  \n",
      "                                                                 dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 30, 30)       0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 30, 30)       0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 30, 30)       0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dot_3 (Dot)                     (None, 30, 84)       0           permute_1[0][0]                  \n",
      "                                                                 dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_2 (Dot)                     (None, 30, 84)       0           lambda_1[0][0]                   \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 30, 368)      0           dropout_1[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "                                                                 dot_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 30, 368)      0           dropout_2[0][0]                  \n",
      "                                                                 dropout_4[0][0]                  \n",
      "                                                                 dot_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 30, 84)       103824      concatenate_1[0][0]              \n",
      "                                                                 concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 30, 84)       0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 30, 84)       0           bidirectional_2[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot_4 (Dot)                     (None, 30, 30)       0           dropout_5[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 30, 30)       0           dot_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "permute_2 (Permute)             (None, 30, 30)       0           lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 30, 30)       0           dot_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dot_6 (Dot)                     (None, 30, 84)       0           permute_2[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_5 (Dot)                     (None, 30, 84)       0           lambda_3[0][0]                   \n",
      "                                                                 dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 30, 536)      0           concatenate_1[0][0]              \n",
      "                                                                 dropout_5[0][0]                  \n",
      "                                                                 dot_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 30, 536)      0           concatenate_2[0][0]              \n",
      "                                                                 dropout_6[0][0]                  \n",
      "                                                                 dot_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 30, 84)       146160      concatenate_3[0][0]              \n",
      "                                                                 concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 30, 84)       0           bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 30, 84)       0           bidirectional_3[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot_7 (Dot)                     (None, 30, 30)       0           dropout_7[0][0]                  \n",
      "                                                                 dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 30, 30)       0           dot_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "permute_3 (Permute)             (None, 30, 30)       0           lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 30, 30)       0           dot_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dot_9 (Dot)                     (None, 30, 84)       0           permute_3[0][0]                  \n",
      "                                                                 dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_8 (Dot)                     (None, 30, 84)       0           lambda_5[0][0]                   \n",
      "                                                                 dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 30, 704)      0           concatenate_3[0][0]              \n",
      "                                                                 dropout_7[0][0]                  \n",
      "                                                                 dot_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 30, 704)      0           concatenate_4[0][0]              \n",
      "                                                                 dropout_8[0][0]                  \n",
      "                                                                 dot_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 704)          0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 704)          0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "attention_weighted_average_1 (A (None, 704)          704         concatenate_5[0][0]              \n",
      "                                                                 concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_2 (Glo (None, 704)          0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 704)          0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 2112)         0           global_average_pooling1d_1[0][0] \n",
      "                                                                 global_max_pooling1d_1[0][0]     \n",
      "                                                                 attention_weighted_average_1[0][0\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 2112)         0           global_average_pooling1d_2[0][0] \n",
      "                                                                 global_max_pooling1d_2[0][0]     \n",
      "                                                                 attention_weighted_average_1[1][0\n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 2112)         0           concatenate_9[0][0]              \n",
      "                                                                 concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 2112)         0           concatenate_9[0][0]              \n",
      "                                                                 concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 8448)         0           concatenate_9[0][0]              \n",
      "                                                                 concatenate_10[0][0]             \n",
      "                                                                 lambda_7[0][0]                   \n",
      "                                                                 multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 8448)         0           concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 300)          2534700     dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 3)            903         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 22,928,179\n",
      "Trainable params: 2,928,179\n",
      "Non-trainable params: 20,000,000\n",
      "__________________________________________________________________________________________________\n",
      "Load weights from WordTC-DenseRNN-NoMeta-3P-NoEM-NoClassWeighted-3Layers0.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360609/360609 [==============================] - 65s 181us/step - loss: 0.0190 - acc: 0.8945 - weighted_accuracy: 0.8905 - val_loss: 0.3223 - val_acc: 0.8523 - val_weighted_accuracy: 0.8476\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 62s 173us/step - loss: 0.0185 - acc: 0.8972 - weighted_accuracy: 0.8937 - val_loss: 0.3054 - val_acc: 0.8612 - val_weighted_accuracy: 0.8521\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 63s 174us/step - loss: 0.0183 - acc: 0.8995 - weighted_accuracy: 0.8961 - val_loss: 0.3228 - val_acc: 0.8482 - val_weighted_accuracy: 0.8432\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 63s 174us/step - loss: 0.0180 - acc: 0.9000 - weighted_accuracy: 0.8971 - val_loss: 0.3213 - val_acc: 0.8510 - val_weighted_accuracy: 0.8473\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 63s 174us/step - loss: 0.0179 - acc: 0.9022 - weighted_accuracy: 0.8994 - val_loss: 0.3113 - val_acc: 0.8585 - val_weighted_accuracy: 0.8531\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 61s 170us/step - loss: 0.0177 - acc: 0.9035 - weighted_accuracy: 0.9009 - val_loss: 0.2989 - val_acc: 0.8631 - val_weighted_accuracy: 0.8545\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 61s 170us/step - loss: 0.0174 - acc: 0.9051 - weighted_accuracy: 0.9030 - val_loss: 0.3156 - val_acc: 0.8580 - val_weighted_accuracy: 0.8526\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 63s 175us/step - loss: 0.0173 - acc: 0.9055 - weighted_accuracy: 0.9035 - val_loss: 0.3209 - val_acc: 0.8522 - val_weighted_accuracy: 0.8501\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 63s 175us/step - loss: 0.0171 - acc: 0.9067 - weighted_accuracy: 0.9049 - val_loss: 0.3005 - val_acc: 0.8672 - val_weighted_accuracy: 0.8579\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 62s 173us/step - loss: 0.0170 - acc: 0.9076 - weighted_accuracy: 0.9061 - val_loss: 0.3582 - val_acc: 0.8342 - val_weighted_accuracy: 0.8343\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 63s 175us/step - loss: 0.0168 - acc: 0.9089 - weighted_accuracy: 0.9075 - val_loss: 0.3156 - val_acc: 0.8597 - val_weighted_accuracy: 0.8528\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 62s 173us/step - loss: 0.0166 - acc: 0.9100 - weighted_accuracy: 0.9089 - val_loss: 0.3492 - val_acc: 0.8426 - val_weighted_accuracy: 0.8401\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 63s 174us/step - loss: 0.0165 - acc: 0.9110 - weighted_accuracy: 0.9099 - val_loss: 0.3146 - val_acc: 0.8577 - val_weighted_accuracy: 0.8498\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 62s 172us/step - loss: 0.0164 - acc: 0.9118 - weighted_accuracy: 0.9110 - val_loss: 0.3184 - val_acc: 0.8588 - val_weighted_accuracy: 0.8514\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 63s 174us/step - loss: 0.0162 - acc: 0.9128 - weighted_accuracy: 0.9119 - val_loss: 0.3284 - val_acc: 0.8529 - val_weighted_accuracy: 0.8499\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 62s 173us/step - loss: 0.0161 - acc: 0.9135 - weighted_accuracy: 0.9127 - val_loss: 0.3224 - val_acc: 0.8563 - val_weighted_accuracy: 0.8513\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 62s 172us/step - loss: 0.0159 - acc: 0.9149 - weighted_accuracy: 0.9144 - val_loss: 0.3042 - val_acc: 0.8663 - val_weighted_accuracy: 0.8583\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 62s 172us/step - loss: 0.0159 - acc: 0.9155 - weighted_accuracy: 0.9150 - val_loss: 0.3111 - val_acc: 0.8632 - val_weighted_accuracy: 0.8571\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0157 - acc: 0.9160 - weighted_accuracy: 0.9158 - val_loss: 0.3115 - val_acc: 0.8621 - val_weighted_accuracy: 0.8556\n",
      "Epoch 20/500\n",
      "360609/360609 [==============================] - 62s 172us/step - loss: 0.0156 - acc: 0.9169 - weighted_accuracy: 0.9168 - val_loss: 0.2879 - val_acc: 0.8751 - val_weighted_accuracy: 0.8658\n",
      "Epoch 21/500\n",
      "360609/360609 [==============================] - 62s 172us/step - loss: 0.0155 - acc: 0.9180 - weighted_accuracy: 0.9179 - val_loss: 0.3137 - val_acc: 0.8623 - val_weighted_accuracy: 0.8561\n",
      "Epoch 22/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0154 - acc: 0.9180 - weighted_accuracy: 0.9181 - val_loss: 0.3115 - val_acc: 0.8616 - val_weighted_accuracy: 0.8553\n",
      "Epoch 23/500\n",
      "360609/360609 [==============================] - 63s 174us/step - loss: 0.0153 - acc: 0.9194 - weighted_accuracy: 0.9192 - val_loss: 0.3083 - val_acc: 0.8641 - val_weighted_accuracy: 0.8585\n",
      "Epoch 24/500\n",
      "360609/360609 [==============================] - 62s 173us/step - loss: 0.0152 - acc: 0.9205 - weighted_accuracy: 0.9208 - val_loss: 0.3123 - val_acc: 0.8621 - val_weighted_accuracy: 0.8547\n",
      "Epoch 25/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0151 - acc: 0.9204 - weighted_accuracy: 0.9205 - val_loss: 0.3380 - val_acc: 0.8561 - val_weighted_accuracy: 0.8508\n",
      "Epoch 26/500\n",
      "360609/360609 [==============================] - 61s 171us/step - loss: 0.0151 - acc: 0.9201 - weighted_accuracy: 0.9204 - val_loss: 0.2981 - val_acc: 0.8749 - val_weighted_accuracy: 0.8631\n",
      "Epoch 27/500\n",
      "360609/360609 [==============================] - 61s 170us/step - loss: 0.0150 - acc: 0.9205 - weighted_accuracy: 0.9211 - val_loss: 0.3066 - val_acc: 0.8693 - val_weighted_accuracy: 0.8591\n",
      "Epoch 28/500\n",
      "360609/360609 [==============================] - 62s 172us/step - loss: 0.0149 - acc: 0.9225 - weighted_accuracy: 0.9231 - val_loss: 0.3182 - val_acc: 0.8609 - val_weighted_accuracy: 0.8536\n",
      "Epoch 29/500\n",
      "360609/360609 [==============================] - 63s 174us/step - loss: 0.0149 - acc: 0.9215 - weighted_accuracy: 0.9221 - val_loss: 0.3078 - val_acc: 0.8669 - val_weighted_accuracy: 0.8586\n",
      "Epoch 30/500\n",
      "360609/360609 [==============================] - 62s 172us/step - loss: 0.0147 - acc: 0.9233 - weighted_accuracy: 0.9238 - val_loss: 0.3095 - val_acc: 0.8677 - val_weighted_accuracy: 0.8589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zake7\\Anaconda3\\lib\\site-packages\\keras\\legacy\\layers.py:198: UserWarning: The `Highway` layer is deprecated and will be removed after 06/2017.\n",
      "  warnings.warn('The `Highway` layer is deprecated '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 30, 200)      20000000    first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_3 (SpatialDro (None, 30, 200)      0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_4 (SpatialDro (None, 30, 200)      0           embedding_3[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 30, 200)      80400       spatial_dropout1d_3[0][0]        \n",
      "                                                                 spatial_dropout1d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 30, 200)      0           time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 30, 200)      0           time_distributed_2[1][0]         \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 30, 84)       61488       dropout_10[0][0]                 \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 30, 84)       0           bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 30, 84)       0           bidirectional_4[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot_10 (Dot)                    (None, 30, 30)       0           dropout_12[0][0]                 \n",
      "                                                                 dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 30, 30)       0           dot_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_4 (Permute)             (None, 30, 30)       0           lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 30, 30)       0           dot_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_12 (Dot)                    (None, 30, 84)       0           permute_4[0][0]                  \n",
      "                                                                 dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_11 (Dot)                    (None, 30, 84)       0           lambda_8[0][0]                   \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 30, 368)      0           dropout_10[0][0]                 \n",
      "                                                                 dropout_12[0][0]                 \n",
      "                                                                 dot_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 30, 368)      0           dropout_11[0][0]                 \n",
      "                                                                 dropout_13[0][0]                 \n",
      "                                                                 dot_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 30, 84)       103824      concatenate_12[0][0]             \n",
      "                                                                 concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 30, 84)       0           bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 30, 84)       0           bidirectional_5[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot_13 (Dot)                    (None, 30, 30)       0           dropout_14[0][0]                 \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 30, 30)       0           dot_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_5 (Permute)             (None, 30, 30)       0           lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 30, 30)       0           dot_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_15 (Dot)                    (None, 30, 84)       0           permute_5[0][0]                  \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_14 (Dot)                    (None, 30, 84)       0           lambda_10[0][0]                  \n",
      "                                                                 dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 30, 536)      0           concatenate_12[0][0]             \n",
      "                                                                 dropout_14[0][0]                 \n",
      "                                                                 dot_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 30, 536)      0           concatenate_13[0][0]             \n",
      "                                                                 dropout_15[0][0]                 \n",
      "                                                                 dot_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, 30, 84)       146160      concatenate_14[0][0]             \n",
      "                                                                 concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 30, 84)       0           bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 30, 84)       0           bidirectional_6[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot_16 (Dot)                    (None, 30, 30)       0           dropout_16[0][0]                 \n",
      "                                                                 dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 30, 30)       0           dot_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_6 (Permute)             (None, 30, 30)       0           lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 30, 30)       0           dot_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_18 (Dot)                    (None, 30, 84)       0           permute_6[0][0]                  \n",
      "                                                                 dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_17 (Dot)                    (None, 30, 84)       0           lambda_12[0][0]                  \n",
      "                                                                 dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 30, 704)      0           concatenate_14[0][0]             \n",
      "                                                                 dropout_16[0][0]                 \n",
      "                                                                 dot_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 30, 704)      0           concatenate_15[0][0]             \n",
      "                                                                 dropout_17[0][0]                 \n",
      "                                                                 dot_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_3 (Glo (None, 704)          0           concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalM (None, 704)          0           concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_weighted_average_2 (A (None, 704)          704         concatenate_16[0][0]             \n",
      "                                                                 concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_4 (Glo (None, 704)          0           concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_4 (GlobalM (None, 704)          0           concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 2112)         0           global_average_pooling1d_3[0][0] \n",
      "                                                                 global_max_pooling1d_3[0][0]     \n",
      "                                                                 attention_weighted_average_2[0][0\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 2112)         0           global_average_pooling1d_4[0][0] \n",
      "                                                                 global_max_pooling1d_4[0][0]     \n",
      "                                                                 attention_weighted_average_2[1][0\n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 2112)         0           concatenate_20[0][0]             \n",
      "                                                                 concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 2112)         0           concatenate_20[0][0]             \n",
      "                                                                 concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 8448)         0           concatenate_20[0][0]             \n",
      "                                                                 concatenate_21[0][0]             \n",
      "                                                                 lambda_14[0][0]                  \n",
      "                                                                 multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 8448)         0           concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 300)          2534700     dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 3)            903         dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 22,928,179\n",
      "Trainable params: 2,928,179\n",
      "Non-trainable params: 20,000,000\n",
      "__________________________________________________________________________________________________\n",
      "Load weights from WordTC-DenseRNN-NoMeta-3P-NoEM-NoClassWeighted-3Layers1.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360609/360609 [==============================] - 65s 180us/step - loss: 0.0186 - acc: 0.8981 - weighted_accuracy: 0.8942 - val_loss: 0.2956 - val_acc: 0.8665 - val_weighted_accuracy: 0.8633\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 63s 176us/step - loss: 0.0183 - acc: 0.8998 - weighted_accuracy: 0.8963 - val_loss: 0.2809 - val_acc: 0.8750 - val_weighted_accuracy: 0.8658\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 63s 174us/step - loss: 0.0180 - acc: 0.9018 - weighted_accuracy: 0.8987 - val_loss: 0.2738 - val_acc: 0.8764 - val_weighted_accuracy: 0.8659\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 64s 176us/step - loss: 0.0178 - acc: 0.9026 - weighted_accuracy: 0.8998 - val_loss: 0.2952 - val_acc: 0.8696 - val_weighted_accuracy: 0.8642\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 64s 177us/step - loss: 0.0176 - acc: 0.9039 - weighted_accuracy: 0.9014 - val_loss: 0.2726 - val_acc: 0.8784 - val_weighted_accuracy: 0.8694\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 63s 175us/step - loss: 0.0174 - acc: 0.9055 - weighted_accuracy: 0.9033 - val_loss: 0.2865 - val_acc: 0.8711 - val_weighted_accuracy: 0.8665\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 64s 177us/step - loss: 0.0172 - acc: 0.9067 - weighted_accuracy: 0.9045 - val_loss: 0.2793 - val_acc: 0.8752 - val_weighted_accuracy: 0.8687\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 64s 176us/step - loss: 0.0171 - acc: 0.9076 - weighted_accuracy: 0.9056 - val_loss: 0.2788 - val_acc: 0.8748 - val_weighted_accuracy: 0.8676\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 63s 174us/step - loss: 0.0169 - acc: 0.9089 - weighted_accuracy: 0.9075 - val_loss: 0.2903 - val_acc: 0.8703 - val_weighted_accuracy: 0.8633\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 62s 173us/step - loss: 0.0168 - acc: 0.9098 - weighted_accuracy: 0.9081 - val_loss: 0.2832 - val_acc: 0.8739 - val_weighted_accuracy: 0.8672\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 62s 172us/step - loss: 0.0166 - acc: 0.9108 - weighted_accuracy: 0.9093 - val_loss: 0.2816 - val_acc: 0.8764 - val_weighted_accuracy: 0.8683\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 62s 172us/step - loss: 0.0165 - acc: 0.9110 - weighted_accuracy: 0.9098 - val_loss: 0.2868 - val_acc: 0.8719 - val_weighted_accuracy: 0.8669\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 62s 172us/step - loss: 0.0164 - acc: 0.9124 - weighted_accuracy: 0.9113 - val_loss: 0.2764 - val_acc: 0.8789 - val_weighted_accuracy: 0.8693\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0162 - acc: 0.9136 - weighted_accuracy: 0.9127 - val_loss: 0.2873 - val_acc: 0.8748 - val_weighted_accuracy: 0.8688\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0161 - acc: 0.9143 - weighted_accuracy: 0.9134 - val_loss: 0.2900 - val_acc: 0.8707 - val_weighted_accuracy: 0.8646\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 30, 200)      20000000    first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_5 (SpatialDro (None, 30, 200)      0           embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_6 (SpatialDro (None, 30, 200)      0           embedding_5[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, 30, 200)      80400       spatial_dropout1d_5[0][0]        \n",
      "                                                                 spatial_dropout1d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 30, 200)      0           time_distributed_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 30, 200)      0           time_distributed_3[1][0]         \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, 30, 84)       61488       dropout_19[0][0]                 \n",
      "                                                                 dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 30, 84)       0           bidirectional_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 30, 84)       0           bidirectional_7[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot_19 (Dot)                    (None, 30, 30)       0           dropout_21[0][0]                 \n",
      "                                                                 dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 30, 30)       0           dot_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_7 (Permute)             (None, 30, 30)       0           lambda_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 30, 30)       0           dot_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_21 (Dot)                    (None, 30, 84)       0           permute_7[0][0]                  \n",
      "                                                                 dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_20 (Dot)                    (None, 30, 84)       0           lambda_15[0][0]                  \n",
      "                                                                 dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 30, 368)      0           dropout_19[0][0]                 \n",
      "                                                                 dropout_21[0][0]                 \n",
      "                                                                 dot_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 30, 368)      0           dropout_20[0][0]                 \n",
      "                                                                 dropout_22[0][0]                 \n",
      "                                                                 dot_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, 30, 84)       103824      concatenate_23[0][0]             \n",
      "                                                                 concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 30, 84)       0           bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 30, 84)       0           bidirectional_8[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot_22 (Dot)                    (None, 30, 30)       0           dropout_23[0][0]                 \n",
      "                                                                 dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (None, 30, 30)       0           dot_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_8 (Permute)             (None, 30, 30)       0           lambda_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)              (None, 30, 30)       0           dot_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_24 (Dot)                    (None, 30, 84)       0           permute_8[0][0]                  \n",
      "                                                                 dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_23 (Dot)                    (None, 30, 84)       0           lambda_17[0][0]                  \n",
      "                                                                 dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 30, 536)      0           concatenate_23[0][0]             \n",
      "                                                                 dropout_23[0][0]                 \n",
      "                                                                 dot_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 30, 536)      0           concatenate_24[0][0]             \n",
      "                                                                 dropout_24[0][0]                 \n",
      "                                                                 dot_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, 30, 84)       146160      concatenate_25[0][0]             \n",
      "                                                                 concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 30, 84)       0           bidirectional_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 30, 84)       0           bidirectional_9[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dot_25 (Dot)                    (None, 30, 30)       0           dropout_25[0][0]                 \n",
      "                                                                 dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_20 (Lambda)              (None, 30, 30)       0           dot_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_9 (Permute)             (None, 30, 30)       0           lambda_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)              (None, 30, 30)       0           dot_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_27 (Dot)                    (None, 30, 84)       0           permute_9[0][0]                  \n",
      "                                                                 dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_26 (Dot)                    (None, 30, 84)       0           lambda_19[0][0]                  \n",
      "                                                                 dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 30, 704)      0           concatenate_25[0][0]             \n",
      "                                                                 dropout_25[0][0]                 \n",
      "                                                                 dot_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 30, 704)      0           concatenate_26[0][0]             \n",
      "                                                                 dropout_26[0][0]                 \n",
      "                                                                 dot_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_5 (Glo (None, 704)          0           concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_5 (GlobalM (None, 704)          0           concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_weighted_average_3 (A (None, 704)          704         concatenate_27[0][0]             \n",
      "                                                                 concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_6 (Glo (None, 704)          0           concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_6 (GlobalM (None, 704)          0           concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 2112)         0           global_average_pooling1d_5[0][0] \n",
      "                                                                 global_max_pooling1d_5[0][0]     \n",
      "                                                                 attention_weighted_average_3[0][0\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 2112)         0           global_average_pooling1d_6[0][0] \n",
      "                                                                 global_max_pooling1d_6[0][0]     \n",
      "                                                                 attention_weighted_average_3[1][0\n",
      "__________________________________________________________________________________________________\n",
      "lambda_21 (Lambda)              (None, 2112)         0           concatenate_31[0][0]             \n",
      "                                                                 concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 2112)         0           concatenate_31[0][0]             \n",
      "                                                                 concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 8448)         0           concatenate_31[0][0]             \n",
      "                                                                 concatenate_32[0][0]             \n",
      "                                                                 lambda_21[0][0]                  \n",
      "                                                                 multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 8448)         0           concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 300)          2534700     dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 3)            903         dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 22,928,179\n",
      "Trainable params: 2,928,179\n",
      "Non-trainable params: 20,000,000\n",
      "__________________________________________________________________________________________________\n",
      "Load weights from WordTC-DenseRNN-NoMeta-3P-NoEM-NoClassWeighted-3Layers2.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360609/360609 [==============================] - 66s 182us/step - loss: 0.0189 - acc: 0.8960 - weighted_accuracy: 0.8917 - val_loss: 0.3455 - val_acc: 0.8397 - val_weighted_accuracy: 0.8401\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 62s 173us/step - loss: 0.0185 - acc: 0.8982 - weighted_accuracy: 0.8944 - val_loss: 0.3213 - val_acc: 0.8518 - val_weighted_accuracy: 0.8490\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 62s 173us/step - loss: 0.0183 - acc: 0.8997 - weighted_accuracy: 0.8960 - val_loss: 0.2949 - val_acc: 0.8652 - val_weighted_accuracy: 0.8547\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 62s 172us/step - loss: 0.0181 - acc: 0.9012 - weighted_accuracy: 0.8979 - val_loss: 0.3083 - val_acc: 0.8577 - val_weighted_accuracy: 0.8536\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 62s 172us/step - loss: 0.0179 - acc: 0.9024 - weighted_accuracy: 0.8994 - val_loss: 0.3152 - val_acc: 0.8529 - val_weighted_accuracy: 0.8488\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 62s 172us/step - loss: 0.0177 - acc: 0.9038 - weighted_accuracy: 0.9011 - val_loss: 0.3315 - val_acc: 0.8475 - val_weighted_accuracy: 0.8480\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 62s 172us/step - loss: 0.0176 - acc: 0.9040 - weighted_accuracy: 0.9018 - val_loss: 0.3026 - val_acc: 0.8601 - val_weighted_accuracy: 0.8519\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 62s 172us/step - loss: 0.0173 - acc: 0.9063 - weighted_accuracy: 0.9039 - val_loss: 0.3172 - val_acc: 0.8558 - val_weighted_accuracy: 0.8521\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 62s 172us/step - loss: 0.0172 - acc: 0.9072 - weighted_accuracy: 0.9050 - val_loss: 0.2963 - val_acc: 0.8653 - val_weighted_accuracy: 0.8576\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 62s 172us/step - loss: 0.0171 - acc: 0.9075 - weighted_accuracy: 0.9055 - val_loss: 0.3056 - val_acc: 0.8594 - val_weighted_accuracy: 0.8562\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 62s 172us/step - loss: 0.0169 - acc: 0.9085 - weighted_accuracy: 0.9069 - val_loss: 0.3000 - val_acc: 0.8618 - val_weighted_accuracy: 0.8540\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 61s 170us/step - loss: 0.0167 - acc: 0.9106 - weighted_accuracy: 0.9090 - val_loss: 0.3000 - val_acc: 0.8625 - val_weighted_accuracy: 0.8554\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 61s 170us/step - loss: 0.0166 - acc: 0.9105 - weighted_accuracy: 0.9088 - val_loss: 0.3330 - val_acc: 0.8467 - val_weighted_accuracy: 0.8452\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 61s 169us/step - loss: 0.0165 - acc: 0.9112 - weighted_accuracy: 0.9100 - val_loss: 0.2943 - val_acc: 0.8667 - val_weighted_accuracy: 0.8576\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 61s 169us/step - loss: 0.0163 - acc: 0.9121 - weighted_accuracy: 0.9111 - val_loss: 0.3204 - val_acc: 0.8552 - val_weighted_accuracy: 0.8489\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 61s 170us/step - loss: 0.0163 - acc: 0.9129 - weighted_accuracy: 0.9122 - val_loss: 0.3205 - val_acc: 0.8554 - val_weighted_accuracy: 0.8476\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 61s 169us/step - loss: 0.0161 - acc: 0.9146 - weighted_accuracy: 0.9136 - val_loss: 0.3095 - val_acc: 0.8583 - val_weighted_accuracy: 0.8506\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 61s 169us/step - loss: 0.0160 - acc: 0.9143 - weighted_accuracy: 0.9136 - val_loss: 0.3037 - val_acc: 0.8645 - val_weighted_accuracy: 0.8575\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 61s 169us/step - loss: 0.0158 - acc: 0.9155 - weighted_accuracy: 0.9151 - val_loss: 0.3072 - val_acc: 0.8595 - val_weighted_accuracy: 0.8528\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, 30, 200)      20000000    first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_7 (SpatialDro (None, 30, 200)      0           embedding_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_8 (SpatialDro (None, 30, 200)      0           embedding_7[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_4 (TimeDistrib (None, 30, 200)      80400       spatial_dropout1d_7[0][0]        \n",
      "                                                                 spatial_dropout1d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 30, 200)      0           time_distributed_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 30, 200)      0           time_distributed_4[1][0]         \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, 30, 84)       61488       dropout_28[0][0]                 \n",
      "                                                                 dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 30, 84)       0           bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 30, 84)       0           bidirectional_10[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dot_28 (Dot)                    (None, 30, 30)       0           dropout_30[0][0]                 \n",
      "                                                                 dropout_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_23 (Lambda)              (None, 30, 30)       0           dot_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_10 (Permute)            (None, 30, 30)       0           lambda_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)              (None, 30, 30)       0           dot_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_30 (Dot)                    (None, 30, 84)       0           permute_10[0][0]                 \n",
      "                                                                 dropout_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_29 (Dot)                    (None, 30, 84)       0           lambda_22[0][0]                  \n",
      "                                                                 dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)    (None, 30, 368)      0           dropout_28[0][0]                 \n",
      "                                                                 dropout_30[0][0]                 \n",
      "                                                                 dot_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)    (None, 30, 368)      0           dropout_29[0][0]                 \n",
      "                                                                 dropout_31[0][0]                 \n",
      "                                                                 dot_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional (None, 30, 84)       103824      concatenate_34[0][0]             \n",
      "                                                                 concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 30, 84)       0           bidirectional_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 30, 84)       0           bidirectional_11[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dot_31 (Dot)                    (None, 30, 30)       0           dropout_32[0][0]                 \n",
      "                                                                 dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_25 (Lambda)              (None, 30, 30)       0           dot_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_11 (Permute)            (None, 30, 30)       0           lambda_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_24 (Lambda)              (None, 30, 30)       0           dot_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_33 (Dot)                    (None, 30, 84)       0           permute_11[0][0]                 \n",
      "                                                                 dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_32 (Dot)                    (None, 30, 84)       0           lambda_24[0][0]                  \n",
      "                                                                 dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_36 (Concatenate)    (None, 30, 536)      0           concatenate_34[0][0]             \n",
      "                                                                 dropout_32[0][0]                 \n",
      "                                                                 dot_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_37 (Concatenate)    (None, 30, 536)      0           concatenate_35[0][0]             \n",
      "                                                                 dropout_33[0][0]                 \n",
      "                                                                 dot_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional (None, 30, 84)       146160      concatenate_36[0][0]             \n",
      "                                                                 concatenate_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 30, 84)       0           bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 30, 84)       0           bidirectional_12[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dot_34 (Dot)                    (None, 30, 30)       0           dropout_34[0][0]                 \n",
      "                                                                 dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_27 (Lambda)              (None, 30, 30)       0           dot_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_12 (Permute)            (None, 30, 30)       0           lambda_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_26 (Lambda)              (None, 30, 30)       0           dot_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_36 (Dot)                    (None, 30, 84)       0           permute_12[0][0]                 \n",
      "                                                                 dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_35 (Dot)                    (None, 30, 84)       0           lambda_26[0][0]                  \n",
      "                                                                 dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_38 (Concatenate)    (None, 30, 704)      0           concatenate_36[0][0]             \n",
      "                                                                 dropout_34[0][0]                 \n",
      "                                                                 dot_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_39 (Concatenate)    (None, 30, 704)      0           concatenate_37[0][0]             \n",
      "                                                                 dropout_35[0][0]                 \n",
      "                                                                 dot_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_7 (Glo (None, 704)          0           concatenate_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_7 (GlobalM (None, 704)          0           concatenate_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_weighted_average_4 (A (None, 704)          704         concatenate_38[0][0]             \n",
      "                                                                 concatenate_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_8 (Glo (None, 704)          0           concatenate_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_8 (GlobalM (None, 704)          0           concatenate_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_42 (Concatenate)    (None, 2112)         0           global_average_pooling1d_7[0][0] \n",
      "                                                                 global_max_pooling1d_7[0][0]     \n",
      "                                                                 attention_weighted_average_4[0][0\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_43 (Concatenate)    (None, 2112)         0           global_average_pooling1d_8[0][0] \n",
      "                                                                 global_max_pooling1d_8[0][0]     \n",
      "                                                                 attention_weighted_average_4[1][0\n",
      "__________________________________________________________________________________________________\n",
      "lambda_28 (Lambda)              (None, 2112)         0           concatenate_42[0][0]             \n",
      "                                                                 concatenate_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 2112)         0           concatenate_42[0][0]             \n",
      "                                                                 concatenate_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_44 (Concatenate)    (None, 8448)         0           concatenate_42[0][0]             \n",
      "                                                                 concatenate_43[0][0]             \n",
      "                                                                 lambda_28[0][0]                  \n",
      "                                                                 multiply_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 8448)         0           concatenate_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 300)          2534700     dropout_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 3)            903         dense_7[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 22,928,179\n",
      "Trainable params: 2,928,179\n",
      "Non-trainable params: 20,000,000\n",
      "__________________________________________________________________________________________________\n",
      "Load weights from WordTC-DenseRNN-NoMeta-3P-NoEM-NoClassWeighted-3Layers3.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360609/360609 [==============================] - 63s 176us/step - loss: 0.0191 - acc: 0.8937 - weighted_accuracy: 0.8893 - val_loss: 0.3227 - val_acc: 0.8516 - val_weighted_accuracy: 0.8512\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 61s 169us/step - loss: 0.0187 - acc: 0.8961 - weighted_accuracy: 0.8921 - val_loss: 0.3090 - val_acc: 0.8638 - val_weighted_accuracy: 0.8593\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 61s 169us/step - loss: 0.0185 - acc: 0.8983 - weighted_accuracy: 0.8946 - val_loss: 0.3090 - val_acc: 0.8594 - val_weighted_accuracy: 0.8550\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 61s 169us/step - loss: 0.0182 - acc: 0.8992 - weighted_accuracy: 0.8960 - val_loss: 0.3155 - val_acc: 0.8545 - val_weighted_accuracy: 0.8540\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 61s 169us/step - loss: 0.0180 - acc: 0.9012 - weighted_accuracy: 0.8981 - val_loss: 0.3104 - val_acc: 0.8586 - val_weighted_accuracy: 0.8575\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 61s 169us/step - loss: 0.0179 - acc: 0.9022 - weighted_accuracy: 0.8992 - val_loss: 0.3077 - val_acc: 0.8618 - val_weighted_accuracy: 0.8585\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 61s 169us/step - loss: 0.0176 - acc: 0.9033 - weighted_accuracy: 0.9006 - val_loss: 0.3067 - val_acc: 0.8627 - val_weighted_accuracy: 0.8600\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 61s 169us/step - loss: 0.0175 - acc: 0.9044 - weighted_accuracy: 0.9016 - val_loss: 0.2948 - val_acc: 0.8705 - val_weighted_accuracy: 0.8650\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 61s 169us/step - loss: 0.0173 - acc: 0.9054 - weighted_accuracy: 0.9032 - val_loss: 0.3008 - val_acc: 0.8671 - val_weighted_accuracy: 0.8627\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 61s 169us/step - loss: 0.0171 - acc: 0.9065 - weighted_accuracy: 0.9048 - val_loss: 0.3082 - val_acc: 0.8654 - val_weighted_accuracy: 0.8619\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 61s 169us/step - loss: 0.0169 - acc: 0.9076 - weighted_accuracy: 0.9060 - val_loss: 0.2923 - val_acc: 0.8695 - val_weighted_accuracy: 0.8647\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 61s 169us/step - loss: 0.0168 - acc: 0.9093 - weighted_accuracy: 0.9076 - val_loss: 0.3012 - val_acc: 0.8645 - val_weighted_accuracy: 0.8631\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 61s 169us/step - loss: 0.0167 - acc: 0.9095 - weighted_accuracy: 0.9080 - val_loss: 0.2931 - val_acc: 0.8717 - val_weighted_accuracy: 0.8666\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 61s 169us/step - loss: 0.0166 - acc: 0.9106 - weighted_accuracy: 0.9093 - val_loss: 0.3071 - val_acc: 0.8624 - val_weighted_accuracy: 0.8612\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 61s 169us/step - loss: 0.0164 - acc: 0.9117 - weighted_accuracy: 0.9109 - val_loss: 0.2884 - val_acc: 0.8715 - val_weighted_accuracy: 0.8636\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 61s 169us/step - loss: 0.0163 - acc: 0.9127 - weighted_accuracy: 0.9117 - val_loss: 0.2965 - val_acc: 0.8705 - val_weighted_accuracy: 0.8664\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 61s 169us/step - loss: 0.0162 - acc: 0.9139 - weighted_accuracy: 0.9132 - val_loss: 0.2897 - val_acc: 0.8726 - val_weighted_accuracy: 0.8652\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 61s 169us/step - loss: 0.0160 - acc: 0.9139 - weighted_accuracy: 0.9131 - val_loss: 0.2989 - val_acc: 0.8691 - val_weighted_accuracy: 0.8662\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 61s 169us/step - loss: 0.0159 - acc: 0.9147 - weighted_accuracy: 0.9140 - val_loss: 0.2946 - val_acc: 0.8709 - val_weighted_accuracy: 0.8653\n",
      "Epoch 20/500\n",
      "360609/360609 [==============================] - 61s 169us/step - loss: 0.0158 - acc: 0.9161 - weighted_accuracy: 0.9156 - val_loss: 0.2959 - val_acc: 0.8710 - val_weighted_accuracy: 0.8654\n",
      "Epoch 21/500\n",
      "360609/360609 [==============================] - 61s 169us/step - loss: 0.0158 - acc: 0.9158 - weighted_accuracy: 0.9153 - val_loss: 0.2998 - val_acc: 0.8656 - val_weighted_accuracy: 0.8603\n",
      "Epoch 22/500\n",
      "360609/360609 [==============================] - 61s 169us/step - loss: 0.0157 - acc: 0.9167 - weighted_accuracy: 0.9166 - val_loss: 0.3007 - val_acc: 0.8683 - val_weighted_accuracy: 0.8633\n",
      "Epoch 23/500\n",
      "360609/360609 [==============================] - 61s 169us/step - loss: 0.0155 - acc: 0.9174 - weighted_accuracy: 0.9173 - val_loss: 0.2915 - val_acc: 0.8735 - val_weighted_accuracy: 0.8671\n",
      "Epoch 24/500\n",
      "360609/360609 [==============================] - 61s 169us/step - loss: 0.0154 - acc: 0.9178 - weighted_accuracy: 0.9179 - val_loss: 0.2966 - val_acc: 0.8701 - val_weighted_accuracy: 0.8649\n",
      "Epoch 25/500\n",
      "360609/360609 [==============================] - 61s 169us/step - loss: 0.0154 - acc: 0.9190 - weighted_accuracy: 0.9189 - val_loss: 0.3084 - val_acc: 0.8632 - val_weighted_accuracy: 0.8590\n",
      "Epoch 26/500\n",
      "360609/360609 [==============================] - 61s 169us/step - loss: 0.0152 - acc: 0.9194 - weighted_accuracy: 0.9196 - val_loss: 0.2906 - val_acc: 0.8733 - val_weighted_accuracy: 0.8662\n",
      "Epoch 27/500\n",
      "360609/360609 [==============================] - 61s 169us/step - loss: 0.0152 - acc: 0.9201 - weighted_accuracy: 0.9204 - val_loss: 0.2942 - val_acc: 0.8714 - val_weighted_accuracy: 0.8658\n",
      "Epoch 28/500\n",
      "360609/360609 [==============================] - 61s 169us/step - loss: 0.0151 - acc: 0.9208 - weighted_accuracy: 0.9212 - val_loss: 0.2964 - val_acc: 0.8694 - val_weighted_accuracy: 0.8643\n",
      "Epoch 29/500\n",
      "360609/360609 [==============================] - 61s 169us/step - loss: 0.0150 - acc: 0.9210 - weighted_accuracy: 0.9215 - val_loss: 0.3051 - val_acc: 0.8655 - val_weighted_accuracy: 0.8630\n",
      "Epoch 30/500\n",
      "360609/360609 [==============================] - 61s 169us/step - loss: 0.0149 - acc: 0.9219 - weighted_accuracy: 0.9225 - val_loss: 0.3015 - val_acc: 0.8678 - val_weighted_accuracy: 0.8642\n",
      "Epoch 31/500\n",
      "360609/360609 [==============================] - 61s 169us/step - loss: 0.0149 - acc: 0.9222 - weighted_accuracy: 0.9225 - val_loss: 0.2938 - val_acc: 0.8743 - val_weighted_accuracy: 0.8683\n",
      "Epoch 32/500\n",
      "360609/360609 [==============================] - 61s 169us/step - loss: 0.0148 - acc: 0.9225 - weighted_accuracy: 0.9234 - val_loss: 0.3012 - val_acc: 0.8676 - val_weighted_accuracy: 0.8635\n",
      "Epoch 33/500\n",
      "360609/360609 [==============================] - 61s 169us/step - loss: 0.0147 - acc: 0.9230 - weighted_accuracy: 0.9237 - val_loss: 0.2900 - val_acc: 0.8759 - val_weighted_accuracy: 0.8674\n",
      "Epoch 34/500\n",
      "360609/360609 [==============================] - 61s 169us/step - loss: 0.0146 - acc: 0.9238 - weighted_accuracy: 0.9246 - val_loss: 0.2928 - val_acc: 0.8728 - val_weighted_accuracy: 0.8662\n",
      "Epoch 35/500\n",
      "360609/360609 [==============================] - 61s 169us/step - loss: 0.0145 - acc: 0.9244 - weighted_accuracy: 0.9251 - val_loss: 0.3015 - val_acc: 0.8683 - val_weighted_accuracy: 0.8635\n",
      "Epoch 36/500\n",
      "360609/360609 [==============================] - 61s 169us/step - loss: 0.0145 - acc: 0.9249 - weighted_accuracy: 0.9258 - val_loss: 0.2991 - val_acc: 0.8704 - val_weighted_accuracy: 0.8644\n",
      "Epoch 37/500\n",
      "360609/360609 [==============================] - 61s 169us/step - loss: 0.0144 - acc: 0.9253 - weighted_accuracy: 0.9262 - val_loss: 0.2897 - val_acc: 0.8739 - val_weighted_accuracy: 0.8670\n",
      "Epoch 38/500\n",
      "360609/360609 [==============================] - 61s 169us/step - loss: 0.0143 - acc: 0.9261 - weighted_accuracy: 0.9270 - val_loss: 0.3012 - val_acc: 0.8723 - val_weighted_accuracy: 0.8671\n",
      "Epoch 39/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0143 - acc: 0.9263 - weighted_accuracy: 0.9273 - val_loss: 0.3045 - val_acc: 0.8686 - val_weighted_accuracy: 0.8643\n",
      "Epoch 40/500\n",
      "360609/360609 [==============================] - 63s 175us/step - loss: 0.0143 - acc: 0.9267 - weighted_accuracy: 0.9278 - val_loss: 0.3079 - val_acc: 0.8638 - val_weighted_accuracy: 0.8574\n",
      "Epoch 41/500\n",
      "360609/360609 [==============================] - 63s 175us/step - loss: 0.0142 - acc: 0.9267 - weighted_accuracy: 0.9277 - val_loss: 0.3003 - val_acc: 0.8708 - val_weighted_accuracy: 0.8645\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_9 (Embedding)         (None, 30, 200)      20000000    first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_9 (SpatialDro (None, 30, 200)      0           embedding_9[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_10 (SpatialDr (None, 30, 200)      0           embedding_9[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_5 (TimeDistrib (None, 30, 200)      80400       spatial_dropout1d_9[0][0]        \n",
      "                                                                 spatial_dropout1d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 30, 200)      0           time_distributed_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 30, 200)      0           time_distributed_5[1][0]         \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_13 (Bidirectional (None, 30, 84)       61488       dropout_37[0][0]                 \n",
      "                                                                 dropout_38[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, 30, 84)       0           bidirectional_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, 30, 84)       0           bidirectional_13[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dot_37 (Dot)                    (None, 30, 30)       0           dropout_39[0][0]                 \n",
      "                                                                 dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_30 (Lambda)              (None, 30, 30)       0           dot_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_13 (Permute)            (None, 30, 30)       0           lambda_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_29 (Lambda)              (None, 30, 30)       0           dot_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_39 (Dot)                    (None, 30, 84)       0           permute_13[0][0]                 \n",
      "                                                                 dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_38 (Dot)                    (None, 30, 84)       0           lambda_29[0][0]                  \n",
      "                                                                 dropout_39[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_45 (Concatenate)    (None, 30, 368)      0           dropout_37[0][0]                 \n",
      "                                                                 dropout_39[0][0]                 \n",
      "                                                                 dot_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_46 (Concatenate)    (None, 30, 368)      0           dropout_38[0][0]                 \n",
      "                                                                 dropout_40[0][0]                 \n",
      "                                                                 dot_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_14 (Bidirectional (None, 30, 84)       103824      concatenate_45[0][0]             \n",
      "                                                                 concatenate_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)            (None, 30, 84)       0           bidirectional_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)            (None, 30, 84)       0           bidirectional_14[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dot_40 (Dot)                    (None, 30, 30)       0           dropout_41[0][0]                 \n",
      "                                                                 dropout_42[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_32 (Lambda)              (None, 30, 30)       0           dot_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_14 (Permute)            (None, 30, 30)       0           lambda_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_31 (Lambda)              (None, 30, 30)       0           dot_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_42 (Dot)                    (None, 30, 84)       0           permute_14[0][0]                 \n",
      "                                                                 dropout_42[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_41 (Dot)                    (None, 30, 84)       0           lambda_31[0][0]                  \n",
      "                                                                 dropout_41[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_47 (Concatenate)    (None, 30, 536)      0           concatenate_45[0][0]             \n",
      "                                                                 dropout_41[0][0]                 \n",
      "                                                                 dot_42[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_48 (Concatenate)    (None, 30, 536)      0           concatenate_46[0][0]             \n",
      "                                                                 dropout_42[0][0]                 \n",
      "                                                                 dot_41[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_15 (Bidirectional (None, 30, 84)       146160      concatenate_47[0][0]             \n",
      "                                                                 concatenate_48[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_43 (Dropout)            (None, 30, 84)       0           bidirectional_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_44 (Dropout)            (None, 30, 84)       0           bidirectional_15[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dot_43 (Dot)                    (None, 30, 30)       0           dropout_43[0][0]                 \n",
      "                                                                 dropout_44[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_34 (Lambda)              (None, 30, 30)       0           dot_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_15 (Permute)            (None, 30, 30)       0           lambda_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_33 (Lambda)              (None, 30, 30)       0           dot_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_45 (Dot)                    (None, 30, 84)       0           permute_15[0][0]                 \n",
      "                                                                 dropout_44[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_44 (Dot)                    (None, 30, 84)       0           lambda_33[0][0]                  \n",
      "                                                                 dropout_43[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_49 (Concatenate)    (None, 30, 704)      0           concatenate_47[0][0]             \n",
      "                                                                 dropout_43[0][0]                 \n",
      "                                                                 dot_45[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_50 (Concatenate)    (None, 30, 704)      0           concatenate_48[0][0]             \n",
      "                                                                 dropout_44[0][0]                 \n",
      "                                                                 dot_44[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_9 (Glo (None, 704)          0           concatenate_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_9 (GlobalM (None, 704)          0           concatenate_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_weighted_average_5 (A (None, 704)          704         concatenate_49[0][0]             \n",
      "                                                                 concatenate_50[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_10 (Gl (None, 704)          0           concatenate_50[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_10 (Global (None, 704)          0           concatenate_50[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_53 (Concatenate)    (None, 2112)         0           global_average_pooling1d_9[0][0] \n",
      "                                                                 global_max_pooling1d_9[0][0]     \n",
      "                                                                 attention_weighted_average_5[0][0\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_54 (Concatenate)    (None, 2112)         0           global_average_pooling1d_10[0][0]\n",
      "                                                                 global_max_pooling1d_10[0][0]    \n",
      "                                                                 attention_weighted_average_5[1][0\n",
      "__________________________________________________________________________________________________\n",
      "lambda_35 (Lambda)              (None, 2112)         0           concatenate_53[0][0]             \n",
      "                                                                 concatenate_54[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_5 (Multiply)           (None, 2112)         0           concatenate_53[0][0]             \n",
      "                                                                 concatenate_54[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_55 (Concatenate)    (None, 8448)         0           concatenate_53[0][0]             \n",
      "                                                                 concatenate_54[0][0]             \n",
      "                                                                 lambda_35[0][0]                  \n",
      "                                                                 multiply_5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_45 (Dropout)            (None, 8448)         0           concatenate_55[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 300)          2534700     dropout_45[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 3)            903         dense_9[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 22,928,179\n",
      "Trainable params: 2,928,179\n",
      "Non-trainable params: 20,000,000\n",
      "__________________________________________________________________________________________________\n",
      "Load weights from WordTC-DenseRNN-NoMeta-3P-NoEM-NoClassWeighted-3Layers4.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360609/360609 [==============================] - 65s 181us/step - loss: 0.0203 - acc: 0.8852 - weighted_accuracy: 0.8797 - val_loss: 0.3339 - val_acc: 0.8442 - val_weighted_accuracy: 0.8389\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 62s 172us/step - loss: 0.0199 - acc: 0.8884 - weighted_accuracy: 0.8837 - val_loss: 0.3381 - val_acc: 0.8419 - val_weighted_accuracy: 0.8400\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0195 - acc: 0.8908 - weighted_accuracy: 0.8866 - val_loss: 0.3260 - val_acc: 0.8493 - val_weighted_accuracy: 0.8437\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0192 - acc: 0.8928 - weighted_accuracy: 0.8888 - val_loss: 0.3424 - val_acc: 0.8396 - val_weighted_accuracy: 0.8384\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0189 - acc: 0.8942 - weighted_accuracy: 0.8906 - val_loss: 0.3125 - val_acc: 0.8577 - val_weighted_accuracy: 0.8514\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0187 - acc: 0.8964 - weighted_accuracy: 0.8928 - val_loss: 0.3174 - val_acc: 0.8511 - val_weighted_accuracy: 0.8437\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 61s 170us/step - loss: 0.0184 - acc: 0.8984 - weighted_accuracy: 0.8952 - val_loss: 0.3347 - val_acc: 0.8458 - val_weighted_accuracy: 0.8441\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0182 - acc: 0.8995 - weighted_accuracy: 0.8963 - val_loss: 0.3254 - val_acc: 0.8518 - val_weighted_accuracy: 0.8496\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0180 - acc: 0.9011 - weighted_accuracy: 0.8982 - val_loss: 0.3373 - val_acc: 0.8507 - val_weighted_accuracy: 0.8467\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 62s 172us/step - loss: 0.0178 - acc: 0.9024 - weighted_accuracy: 0.8998 - val_loss: 0.3194 - val_acc: 0.8533 - val_weighted_accuracy: 0.8494\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0176 - acc: 0.9031 - weighted_accuracy: 0.9009 - val_loss: 0.3115 - val_acc: 0.8583 - val_weighted_accuracy: 0.8529\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0174 - acc: 0.9045 - weighted_accuracy: 0.9023 - val_loss: 0.3215 - val_acc: 0.8560 - val_weighted_accuracy: 0.8529\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0172 - acc: 0.9061 - weighted_accuracy: 0.9041 - val_loss: 0.3054 - val_acc: 0.8627 - val_weighted_accuracy: 0.8578\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0171 - acc: 0.9069 - weighted_accuracy: 0.9053 - val_loss: 0.3226 - val_acc: 0.8561 - val_weighted_accuracy: 0.8520\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 62s 173us/step - loss: 0.0170 - acc: 0.9077 - weighted_accuracy: 0.9062 - val_loss: 0.3221 - val_acc: 0.8568 - val_weighted_accuracy: 0.8523\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0168 - acc: 0.9086 - weighted_accuracy: 0.9073 - val_loss: 0.3069 - val_acc: 0.8605 - val_weighted_accuracy: 0.8539\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 62s 172us/step - loss: 0.0167 - acc: 0.9093 - weighted_accuracy: 0.9081 - val_loss: 0.3025 - val_acc: 0.8644 - val_weighted_accuracy: 0.8588\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 62s 172us/step - loss: 0.0167 - acc: 0.9098 - weighted_accuracy: 0.9088 - val_loss: 0.3078 - val_acc: 0.8622 - val_weighted_accuracy: 0.8561\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0164 - acc: 0.9116 - weighted_accuracy: 0.9109 - val_loss: 0.3009 - val_acc: 0.8633 - val_weighted_accuracy: 0.8570\n",
      "Epoch 20/500\n",
      "360609/360609 [==============================] - 62s 173us/step - loss: 0.0164 - acc: 0.9119 - weighted_accuracy: 0.9114 - val_loss: 0.3041 - val_acc: 0.8639 - val_weighted_accuracy: 0.8581\n",
      "Epoch 21/500\n",
      "360609/360609 [==============================] - 62s 172us/step - loss: 0.0162 - acc: 0.9132 - weighted_accuracy: 0.9124 - val_loss: 0.2992 - val_acc: 0.8676 - val_weighted_accuracy: 0.8611\n",
      "Epoch 22/500\n",
      "360609/360609 [==============================] - 62s 172us/step - loss: 0.0161 - acc: 0.9137 - weighted_accuracy: 0.9131 - val_loss: 0.3047 - val_acc: 0.8649 - val_weighted_accuracy: 0.8583\n",
      "Epoch 23/500\n",
      "360609/360609 [==============================] - 62s 172us/step - loss: 0.0159 - acc: 0.9152 - weighted_accuracy: 0.9149 - val_loss: 0.3188 - val_acc: 0.8562 - val_weighted_accuracy: 0.8528\n",
      "Epoch 24/500\n",
      "360609/360609 [==============================] - 62s 172us/step - loss: 0.0158 - acc: 0.9155 - weighted_accuracy: 0.9152 - val_loss: 0.3023 - val_acc: 0.8640 - val_weighted_accuracy: 0.8585\n",
      "Epoch 25/500\n",
      "360609/360609 [==============================] - 62s 173us/step - loss: 0.0158 - acc: 0.9154 - weighted_accuracy: 0.9152 - val_loss: 0.3287 - val_acc: 0.8535 - val_weighted_accuracy: 0.8494\n",
      "Epoch 26/500\n",
      "360609/360609 [==============================] - 62s 173us/step - loss: 0.0157 - acc: 0.9169 - weighted_accuracy: 0.9171 - val_loss: 0.3145 - val_acc: 0.8615 - val_weighted_accuracy: 0.8554\n",
      "Epoch 27/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0156 - acc: 0.9170 - weighted_accuracy: 0.9170 - val_loss: 0.3122 - val_acc: 0.8607 - val_weighted_accuracy: 0.8564\n",
      "Epoch 28/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0155 - acc: 0.9181 - weighted_accuracy: 0.9184 - val_loss: 0.3127 - val_acc: 0.8628 - val_weighted_accuracy: 0.8589\n",
      "Epoch 29/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0154 - acc: 0.9186 - weighted_accuracy: 0.9188 - val_loss: 0.3061 - val_acc: 0.8648 - val_weighted_accuracy: 0.8579\n",
      "Epoch 30/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0153 - acc: 0.9191 - weighted_accuracy: 0.9192 - val_loss: 0.3036 - val_acc: 0.8667 - val_weighted_accuracy: 0.8594\n",
      "Epoch 31/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0152 - acc: 0.9201 - weighted_accuracy: 0.9205 - val_loss: 0.3160 - val_acc: 0.8634 - val_weighted_accuracy: 0.8575\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_11 (Embedding)        (None, 30, 200)      20000000    first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_11 (SpatialDr (None, 30, 200)      0           embedding_11[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_12 (SpatialDr (None, 30, 200)      0           embedding_11[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_6 (TimeDistrib (None, 30, 200)      80400       spatial_dropout1d_11[0][0]       \n",
      "                                                                 spatial_dropout1d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_46 (Dropout)            (None, 30, 200)      0           time_distributed_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_47 (Dropout)            (None, 30, 200)      0           time_distributed_6[1][0]         \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_16 (Bidirectional (None, 30, 84)       61488       dropout_46[0][0]                 \n",
      "                                                                 dropout_47[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_48 (Dropout)            (None, 30, 84)       0           bidirectional_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)            (None, 30, 84)       0           bidirectional_16[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dot_46 (Dot)                    (None, 30, 30)       0           dropout_48[0][0]                 \n",
      "                                                                 dropout_49[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_37 (Lambda)              (None, 30, 30)       0           dot_46[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_16 (Permute)            (None, 30, 30)       0           lambda_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_36 (Lambda)              (None, 30, 30)       0           dot_46[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_48 (Dot)                    (None, 30, 84)       0           permute_16[0][0]                 \n",
      "                                                                 dropout_49[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_47 (Dot)                    (None, 30, 84)       0           lambda_36[0][0]                  \n",
      "                                                                 dropout_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_56 (Concatenate)    (None, 30, 368)      0           dropout_46[0][0]                 \n",
      "                                                                 dropout_48[0][0]                 \n",
      "                                                                 dot_48[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_57 (Concatenate)    (None, 30, 368)      0           dropout_47[0][0]                 \n",
      "                                                                 dropout_49[0][0]                 \n",
      "                                                                 dot_47[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_17 (Bidirectional (None, 30, 84)       103824      concatenate_56[0][0]             \n",
      "                                                                 concatenate_57[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_50 (Dropout)            (None, 30, 84)       0           bidirectional_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_51 (Dropout)            (None, 30, 84)       0           bidirectional_17[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dot_49 (Dot)                    (None, 30, 30)       0           dropout_50[0][0]                 \n",
      "                                                                 dropout_51[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_39 (Lambda)              (None, 30, 30)       0           dot_49[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_17 (Permute)            (None, 30, 30)       0           lambda_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_38 (Lambda)              (None, 30, 30)       0           dot_49[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_51 (Dot)                    (None, 30, 84)       0           permute_17[0][0]                 \n",
      "                                                                 dropout_51[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_50 (Dot)                    (None, 30, 84)       0           lambda_38[0][0]                  \n",
      "                                                                 dropout_50[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_58 (Concatenate)    (None, 30, 536)      0           concatenate_56[0][0]             \n",
      "                                                                 dropout_50[0][0]                 \n",
      "                                                                 dot_51[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_59 (Concatenate)    (None, 30, 536)      0           concatenate_57[0][0]             \n",
      "                                                                 dropout_51[0][0]                 \n",
      "                                                                 dot_50[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_18 (Bidirectional (None, 30, 84)       146160      concatenate_58[0][0]             \n",
      "                                                                 concatenate_59[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_52 (Dropout)            (None, 30, 84)       0           bidirectional_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_53 (Dropout)            (None, 30, 84)       0           bidirectional_18[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dot_52 (Dot)                    (None, 30, 30)       0           dropout_52[0][0]                 \n",
      "                                                                 dropout_53[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_41 (Lambda)              (None, 30, 30)       0           dot_52[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_18 (Permute)            (None, 30, 30)       0           lambda_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_40 (Lambda)              (None, 30, 30)       0           dot_52[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_54 (Dot)                    (None, 30, 84)       0           permute_18[0][0]                 \n",
      "                                                                 dropout_53[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_53 (Dot)                    (None, 30, 84)       0           lambda_40[0][0]                  \n",
      "                                                                 dropout_52[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_60 (Concatenate)    (None, 30, 704)      0           concatenate_58[0][0]             \n",
      "                                                                 dropout_52[0][0]                 \n",
      "                                                                 dot_54[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_61 (Concatenate)    (None, 30, 704)      0           concatenate_59[0][0]             \n",
      "                                                                 dropout_53[0][0]                 \n",
      "                                                                 dot_53[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_11 (Gl (None, 704)          0           concatenate_60[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_11 (Global (None, 704)          0           concatenate_60[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_weighted_average_6 (A (None, 704)          704         concatenate_60[0][0]             \n",
      "                                                                 concatenate_61[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_12 (Gl (None, 704)          0           concatenate_61[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_12 (Global (None, 704)          0           concatenate_61[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_64 (Concatenate)    (None, 2112)         0           global_average_pooling1d_11[0][0]\n",
      "                                                                 global_max_pooling1d_11[0][0]    \n",
      "                                                                 attention_weighted_average_6[0][0\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_65 (Concatenate)    (None, 2112)         0           global_average_pooling1d_12[0][0]\n",
      "                                                                 global_max_pooling1d_12[0][0]    \n",
      "                                                                 attention_weighted_average_6[1][0\n",
      "__________________________________________________________________________________________________\n",
      "lambda_42 (Lambda)              (None, 2112)         0           concatenate_64[0][0]             \n",
      "                                                                 concatenate_65[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_6 (Multiply)           (None, 2112)         0           concatenate_64[0][0]             \n",
      "                                                                 concatenate_65[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_66 (Concatenate)    (None, 8448)         0           concatenate_64[0][0]             \n",
      "                                                                 concatenate_65[0][0]             \n",
      "                                                                 lambda_42[0][0]                  \n",
      "                                                                 multiply_6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_54 (Dropout)            (None, 8448)         0           concatenate_66[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 300)          2534700     dropout_54[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 3)            903         dense_11[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 22,928,179\n",
      "Trainable params: 2,928,179\n",
      "Non-trainable params: 20,000,000\n",
      "__________________________________________________________________________________________________\n",
      "Load weights from WordTC-DenseRNN-NoMeta-3P-NoEM-NoClassWeighted-3Layers5.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360609/360609 [==============================] - 65s 180us/step - loss: 0.0185 - acc: 0.8987 - weighted_accuracy: 0.8949 - val_loss: 0.3471 - val_acc: 0.8341 - val_weighted_accuracy: 0.8292\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 62s 172us/step - loss: 0.0183 - acc: 0.9000 - weighted_accuracy: 0.8961 - val_loss: 0.3210 - val_acc: 0.8482 - val_weighted_accuracy: 0.8354\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 62s 172us/step - loss: 0.0180 - acc: 0.9010 - weighted_accuracy: 0.8976 - val_loss: 0.3358 - val_acc: 0.8419 - val_weighted_accuracy: 0.8338\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0178 - acc: 0.9028 - weighted_accuracy: 0.8995 - val_loss: 0.3392 - val_acc: 0.8390 - val_weighted_accuracy: 0.8366\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 62s 173us/step - loss: 0.0176 - acc: 0.9045 - weighted_accuracy: 0.9015 - val_loss: 0.3160 - val_acc: 0.8543 - val_weighted_accuracy: 0.8411\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0174 - acc: 0.9052 - weighted_accuracy: 0.9028 - val_loss: 0.3331 - val_acc: 0.8455 - val_weighted_accuracy: 0.8389\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0172 - acc: 0.9069 - weighted_accuracy: 0.9044 - val_loss: 0.3191 - val_acc: 0.8541 - val_weighted_accuracy: 0.8430\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 62s 172us/step - loss: 0.0171 - acc: 0.9076 - weighted_accuracy: 0.9053 - val_loss: 0.3243 - val_acc: 0.8506 - val_weighted_accuracy: 0.8437\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 62s 172us/step - loss: 0.0169 - acc: 0.9086 - weighted_accuracy: 0.9069 - val_loss: 0.3214 - val_acc: 0.8510 - val_weighted_accuracy: 0.8417\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 63s 174us/step - loss: 0.0168 - acc: 0.9094 - weighted_accuracy: 0.9076 - val_loss: 0.3338 - val_acc: 0.8452 - val_weighted_accuracy: 0.8379\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 62s 173us/step - loss: 0.0167 - acc: 0.9100 - weighted_accuracy: 0.9083 - val_loss: 0.3208 - val_acc: 0.8519 - val_weighted_accuracy: 0.8427\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0166 - acc: 0.9103 - weighted_accuracy: 0.9089 - val_loss: 0.3427 - val_acc: 0.8413 - val_weighted_accuracy: 0.8394\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 62s 173us/step - loss: 0.0163 - acc: 0.9125 - weighted_accuracy: 0.9113 - val_loss: 0.3206 - val_acc: 0.8531 - val_weighted_accuracy: 0.8394\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0163 - acc: 0.9126 - weighted_accuracy: 0.9113 - val_loss: 0.3230 - val_acc: 0.8528 - val_weighted_accuracy: 0.8438\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0161 - acc: 0.9138 - weighted_accuracy: 0.9128 - val_loss: 0.3247 - val_acc: 0.8510 - val_weighted_accuracy: 0.8411\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0160 - acc: 0.9146 - weighted_accuracy: 0.9134 - val_loss: 0.3416 - val_acc: 0.8451 - val_weighted_accuracy: 0.8423\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0159 - acc: 0.9157 - weighted_accuracy: 0.9149 - val_loss: 0.3240 - val_acc: 0.8530 - val_weighted_accuracy: 0.8448\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0158 - acc: 0.9158 - weighted_accuracy: 0.9149 - val_loss: 0.3261 - val_acc: 0.8487 - val_weighted_accuracy: 0.8396\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0157 - acc: 0.9163 - weighted_accuracy: 0.9158 - val_loss: 0.3237 - val_acc: 0.8534 - val_weighted_accuracy: 0.8442\n",
      "Epoch 20/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0156 - acc: 0.9174 - weighted_accuracy: 0.9171 - val_loss: 0.3173 - val_acc: 0.8571 - val_weighted_accuracy: 0.8419\n",
      "Epoch 21/500\n",
      "360609/360609 [==============================] - 62s 172us/step - loss: 0.0154 - acc: 0.9184 - weighted_accuracy: 0.9182 - val_loss: 0.3163 - val_acc: 0.8594 - val_weighted_accuracy: 0.8468\n",
      "Epoch 22/500\n",
      "360609/360609 [==============================] - 62s 172us/step - loss: 0.0153 - acc: 0.9189 - weighted_accuracy: 0.9188 - val_loss: 0.3183 - val_acc: 0.8551 - val_weighted_accuracy: 0.8467\n",
      "Epoch 23/500\n",
      "360609/360609 [==============================] - 63s 174us/step - loss: 0.0153 - acc: 0.9192 - weighted_accuracy: 0.9187 - val_loss: 0.3212 - val_acc: 0.8549 - val_weighted_accuracy: 0.8435\n",
      "Epoch 24/500\n",
      "360609/360609 [==============================] - 63s 174us/step - loss: 0.0152 - acc: 0.9197 - weighted_accuracy: 0.9197 - val_loss: 0.3255 - val_acc: 0.8536 - val_weighted_accuracy: 0.8395\n",
      "Epoch 25/500\n",
      "360609/360609 [==============================] - 63s 174us/step - loss: 0.0151 - acc: 0.9212 - weighted_accuracy: 0.9211 - val_loss: 0.3209 - val_acc: 0.8548 - val_weighted_accuracy: 0.8415\n",
      "Epoch 26/500\n",
      "360609/360609 [==============================] - 62s 172us/step - loss: 0.0150 - acc: 0.9201 - weighted_accuracy: 0.9203 - val_loss: 0.3292 - val_acc: 0.8518 - val_weighted_accuracy: 0.8412\n",
      "Epoch 27/500\n",
      "360609/360609 [==============================] - 63s 174us/step - loss: 0.0149 - acc: 0.9218 - weighted_accuracy: 0.9219 - val_loss: 0.3350 - val_acc: 0.8522 - val_weighted_accuracy: 0.8403\n",
      "Epoch 28/500\n",
      "360609/360609 [==============================] - 63s 174us/step - loss: 0.0148 - acc: 0.9227 - weighted_accuracy: 0.9231 - val_loss: 0.3491 - val_acc: 0.8439 - val_weighted_accuracy: 0.8387\n",
      "Epoch 29/500\n",
      "360609/360609 [==============================] - 63s 174us/step - loss: 0.0148 - acc: 0.9226 - weighted_accuracy: 0.9230 - val_loss: 0.3255 - val_acc: 0.8546 - val_weighted_accuracy: 0.8404\n",
      "Epoch 30/500\n",
      "360609/360609 [==============================] - 63s 174us/step - loss: 0.0147 - acc: 0.9229 - weighted_accuracy: 0.9234 - val_loss: 0.3251 - val_acc: 0.8541 - val_weighted_accuracy: 0.8435\n",
      "Epoch 31/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0147 - acc: 0.9229 - weighted_accuracy: 0.9234 - val_loss: 0.3376 - val_acc: 0.8474 - val_weighted_accuracy: 0.8414\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_13 (Embedding)        (None, 30, 200)      20000000    first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_13 (SpatialDr (None, 30, 200)      0           embedding_13[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_14 (SpatialDr (None, 30, 200)      0           embedding_13[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_7 (TimeDistrib (None, 30, 200)      80400       spatial_dropout1d_13[0][0]       \n",
      "                                                                 spatial_dropout1d_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_55 (Dropout)            (None, 30, 200)      0           time_distributed_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_56 (Dropout)            (None, 30, 200)      0           time_distributed_7[1][0]         \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_19 (Bidirectional (None, 30, 84)       61488       dropout_55[0][0]                 \n",
      "                                                                 dropout_56[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_57 (Dropout)            (None, 30, 84)       0           bidirectional_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_58 (Dropout)            (None, 30, 84)       0           bidirectional_19[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dot_55 (Dot)                    (None, 30, 30)       0           dropout_57[0][0]                 \n",
      "                                                                 dropout_58[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_44 (Lambda)              (None, 30, 30)       0           dot_55[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_19 (Permute)            (None, 30, 30)       0           lambda_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_43 (Lambda)              (None, 30, 30)       0           dot_55[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_57 (Dot)                    (None, 30, 84)       0           permute_19[0][0]                 \n",
      "                                                                 dropout_58[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_56 (Dot)                    (None, 30, 84)       0           lambda_43[0][0]                  \n",
      "                                                                 dropout_57[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_67 (Concatenate)    (None, 30, 368)      0           dropout_55[0][0]                 \n",
      "                                                                 dropout_57[0][0]                 \n",
      "                                                                 dot_57[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_68 (Concatenate)    (None, 30, 368)      0           dropout_56[0][0]                 \n",
      "                                                                 dropout_58[0][0]                 \n",
      "                                                                 dot_56[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_20 (Bidirectional (None, 30, 84)       103824      concatenate_67[0][0]             \n",
      "                                                                 concatenate_68[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_59 (Dropout)            (None, 30, 84)       0           bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_60 (Dropout)            (None, 30, 84)       0           bidirectional_20[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dot_58 (Dot)                    (None, 30, 30)       0           dropout_59[0][0]                 \n",
      "                                                                 dropout_60[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_46 (Lambda)              (None, 30, 30)       0           dot_58[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_20 (Permute)            (None, 30, 30)       0           lambda_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_45 (Lambda)              (None, 30, 30)       0           dot_58[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_60 (Dot)                    (None, 30, 84)       0           permute_20[0][0]                 \n",
      "                                                                 dropout_60[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_59 (Dot)                    (None, 30, 84)       0           lambda_45[0][0]                  \n",
      "                                                                 dropout_59[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_69 (Concatenate)    (None, 30, 536)      0           concatenate_67[0][0]             \n",
      "                                                                 dropout_59[0][0]                 \n",
      "                                                                 dot_60[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_70 (Concatenate)    (None, 30, 536)      0           concatenate_68[0][0]             \n",
      "                                                                 dropout_60[0][0]                 \n",
      "                                                                 dot_59[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_21 (Bidirectional (None, 30, 84)       146160      concatenate_69[0][0]             \n",
      "                                                                 concatenate_70[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_61 (Dropout)            (None, 30, 84)       0           bidirectional_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_62 (Dropout)            (None, 30, 84)       0           bidirectional_21[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dot_61 (Dot)                    (None, 30, 30)       0           dropout_61[0][0]                 \n",
      "                                                                 dropout_62[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_48 (Lambda)              (None, 30, 30)       0           dot_61[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_21 (Permute)            (None, 30, 30)       0           lambda_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_47 (Lambda)              (None, 30, 30)       0           dot_61[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_63 (Dot)                    (None, 30, 84)       0           permute_21[0][0]                 \n",
      "                                                                 dropout_62[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_62 (Dot)                    (None, 30, 84)       0           lambda_47[0][0]                  \n",
      "                                                                 dropout_61[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_71 (Concatenate)    (None, 30, 704)      0           concatenate_69[0][0]             \n",
      "                                                                 dropout_61[0][0]                 \n",
      "                                                                 dot_63[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_72 (Concatenate)    (None, 30, 704)      0           concatenate_70[0][0]             \n",
      "                                                                 dropout_62[0][0]                 \n",
      "                                                                 dot_62[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_13 (Gl (None, 704)          0           concatenate_71[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_13 (Global (None, 704)          0           concatenate_71[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_weighted_average_7 (A (None, 704)          704         concatenate_71[0][0]             \n",
      "                                                                 concatenate_72[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_14 (Gl (None, 704)          0           concatenate_72[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_14 (Global (None, 704)          0           concatenate_72[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_75 (Concatenate)    (None, 2112)         0           global_average_pooling1d_13[0][0]\n",
      "                                                                 global_max_pooling1d_13[0][0]    \n",
      "                                                                 attention_weighted_average_7[0][0\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_76 (Concatenate)    (None, 2112)         0           global_average_pooling1d_14[0][0]\n",
      "                                                                 global_max_pooling1d_14[0][0]    \n",
      "                                                                 attention_weighted_average_7[1][0\n",
      "__________________________________________________________________________________________________\n",
      "lambda_49 (Lambda)              (None, 2112)         0           concatenate_75[0][0]             \n",
      "                                                                 concatenate_76[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_7 (Multiply)           (None, 2112)         0           concatenate_75[0][0]             \n",
      "                                                                 concatenate_76[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_77 (Concatenate)    (None, 8448)         0           concatenate_75[0][0]             \n",
      "                                                                 concatenate_76[0][0]             \n",
      "                                                                 lambda_49[0][0]                  \n",
      "                                                                 multiply_7[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_63 (Dropout)            (None, 8448)         0           concatenate_77[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 300)          2534700     dropout_63[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 3)            903         dense_13[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 22,928,179\n",
      "Trainable params: 2,928,179\n",
      "Non-trainable params: 20,000,000\n",
      "__________________________________________________________________________________________________\n",
      "Load weights from WordTC-DenseRNN-NoMeta-3P-NoEM-NoClassWeighted-3Layers6.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360609/360609 [==============================] - 65s 180us/step - loss: 0.0181 - acc: 0.9018 - weighted_accuracy: 0.8984 - val_loss: 0.3011 - val_acc: 0.8665 - val_weighted_accuracy: 0.8607\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 63s 174us/step - loss: 0.0178 - acc: 0.9031 - weighted_accuracy: 0.9000 - val_loss: 0.3018 - val_acc: 0.8664 - val_weighted_accuracy: 0.8616\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 63s 174us/step - loss: 0.0175 - acc: 0.9049 - weighted_accuracy: 0.9023 - val_loss: 0.3043 - val_acc: 0.8659 - val_weighted_accuracy: 0.8616\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 63s 175us/step - loss: 0.0173 - acc: 0.9064 - weighted_accuracy: 0.9039 - val_loss: 0.3034 - val_acc: 0.8645 - val_weighted_accuracy: 0.8608\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 63s 175us/step - loss: 0.0173 - acc: 0.9066 - weighted_accuracy: 0.9043 - val_loss: 0.3083 - val_acc: 0.8638 - val_weighted_accuracy: 0.8609\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0170 - acc: 0.9081 - weighted_accuracy: 0.9063 - val_loss: 0.2938 - val_acc: 0.8708 - val_weighted_accuracy: 0.8648\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0169 - acc: 0.9094 - weighted_accuracy: 0.9075 - val_loss: 0.3028 - val_acc: 0.8654 - val_weighted_accuracy: 0.8625\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0167 - acc: 0.9102 - weighted_accuracy: 0.9088 - val_loss: 0.2993 - val_acc: 0.8660 - val_weighted_accuracy: 0.8623\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0166 - acc: 0.9114 - weighted_accuracy: 0.9099 - val_loss: 0.2989 - val_acc: 0.8698 - val_weighted_accuracy: 0.8646\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0165 - acc: 0.9111 - weighted_accuracy: 0.9098 - val_loss: 0.2907 - val_acc: 0.8738 - val_weighted_accuracy: 0.8672\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0163 - acc: 0.9135 - weighted_accuracy: 0.9124 - val_loss: 0.3028 - val_acc: 0.8674 - val_weighted_accuracy: 0.8645\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0161 - acc: 0.9134 - weighted_accuracy: 0.9125 - val_loss: 0.2983 - val_acc: 0.8715 - val_weighted_accuracy: 0.8622\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0161 - acc: 0.9139 - weighted_accuracy: 0.9130 - val_loss: 0.2989 - val_acc: 0.8698 - val_weighted_accuracy: 0.8635\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0159 - acc: 0.9155 - weighted_accuracy: 0.9148 - val_loss: 0.3009 - val_acc: 0.8676 - val_weighted_accuracy: 0.8639\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0158 - acc: 0.9152 - weighted_accuracy: 0.9146 - val_loss: 0.2872 - val_acc: 0.8750 - val_weighted_accuracy: 0.8688\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0157 - acc: 0.9165 - weighted_accuracy: 0.9164 - val_loss: 0.2940 - val_acc: 0.8723 - val_weighted_accuracy: 0.8667\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 61s 170us/step - loss: 0.0156 - acc: 0.9172 - weighted_accuracy: 0.9168 - val_loss: 0.2989 - val_acc: 0.8741 - val_weighted_accuracy: 0.8654\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 61s 170us/step - loss: 0.0155 - acc: 0.9181 - weighted_accuracy: 0.9176 - val_loss: 0.2887 - val_acc: 0.8748 - val_weighted_accuracy: 0.8663\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 61s 170us/step - loss: 0.0154 - acc: 0.9188 - weighted_accuracy: 0.9187 - val_loss: 0.2938 - val_acc: 0.8728 - val_weighted_accuracy: 0.8665\n",
      "Epoch 20/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0153 - acc: 0.9193 - weighted_accuracy: 0.9193 - val_loss: 0.3019 - val_acc: 0.8699 - val_weighted_accuracy: 0.8650\n",
      "Epoch 21/500\n",
      "360609/360609 [==============================] - 61s 171us/step - loss: 0.0152 - acc: 0.9199 - weighted_accuracy: 0.9200 - val_loss: 0.3020 - val_acc: 0.8709 - val_weighted_accuracy: 0.8664\n",
      "Epoch 22/500\n",
      "360609/360609 [==============================] - 61s 170us/step - loss: 0.0151 - acc: 0.9205 - weighted_accuracy: 0.9207 - val_loss: 0.2985 - val_acc: 0.8727 - val_weighted_accuracy: 0.8682\n",
      "Epoch 23/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0150 - acc: 0.9206 - weighted_accuracy: 0.9210 - val_loss: 0.2901 - val_acc: 0.8750 - val_weighted_accuracy: 0.8676\n",
      "Epoch 24/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0150 - acc: 0.9219 - weighted_accuracy: 0.9220 - val_loss: 0.3078 - val_acc: 0.8668 - val_weighted_accuracy: 0.8629\n",
      "Epoch 25/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0148 - acc: 0.9222 - weighted_accuracy: 0.9227 - val_loss: 0.3006 - val_acc: 0.8719 - val_weighted_accuracy: 0.8659\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_15 (Embedding)        (None, 30, 200)      20000000    first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_15 (SpatialDr (None, 30, 200)      0           embedding_15[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_16 (SpatialDr (None, 30, 200)      0           embedding_15[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_8 (TimeDistrib (None, 30, 200)      80400       spatial_dropout1d_15[0][0]       \n",
      "                                                                 spatial_dropout1d_16[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_64 (Dropout)            (None, 30, 200)      0           time_distributed_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_65 (Dropout)            (None, 30, 200)      0           time_distributed_8[1][0]         \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_22 (Bidirectional (None, 30, 84)       61488       dropout_64[0][0]                 \n",
      "                                                                 dropout_65[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_66 (Dropout)            (None, 30, 84)       0           bidirectional_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_67 (Dropout)            (None, 30, 84)       0           bidirectional_22[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dot_64 (Dot)                    (None, 30, 30)       0           dropout_66[0][0]                 \n",
      "                                                                 dropout_67[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_51 (Lambda)              (None, 30, 30)       0           dot_64[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_22 (Permute)            (None, 30, 30)       0           lambda_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_50 (Lambda)              (None, 30, 30)       0           dot_64[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_66 (Dot)                    (None, 30, 84)       0           permute_22[0][0]                 \n",
      "                                                                 dropout_67[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_65 (Dot)                    (None, 30, 84)       0           lambda_50[0][0]                  \n",
      "                                                                 dropout_66[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_78 (Concatenate)    (None, 30, 368)      0           dropout_64[0][0]                 \n",
      "                                                                 dropout_66[0][0]                 \n",
      "                                                                 dot_66[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_79 (Concatenate)    (None, 30, 368)      0           dropout_65[0][0]                 \n",
      "                                                                 dropout_67[0][0]                 \n",
      "                                                                 dot_65[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_23 (Bidirectional (None, 30, 84)       103824      concatenate_78[0][0]             \n",
      "                                                                 concatenate_79[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_68 (Dropout)            (None, 30, 84)       0           bidirectional_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_69 (Dropout)            (None, 30, 84)       0           bidirectional_23[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dot_67 (Dot)                    (None, 30, 30)       0           dropout_68[0][0]                 \n",
      "                                                                 dropout_69[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_53 (Lambda)              (None, 30, 30)       0           dot_67[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_23 (Permute)            (None, 30, 30)       0           lambda_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_52 (Lambda)              (None, 30, 30)       0           dot_67[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_69 (Dot)                    (None, 30, 84)       0           permute_23[0][0]                 \n",
      "                                                                 dropout_69[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_68 (Dot)                    (None, 30, 84)       0           lambda_52[0][0]                  \n",
      "                                                                 dropout_68[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_80 (Concatenate)    (None, 30, 536)      0           concatenate_78[0][0]             \n",
      "                                                                 dropout_68[0][0]                 \n",
      "                                                                 dot_69[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_81 (Concatenate)    (None, 30, 536)      0           concatenate_79[0][0]             \n",
      "                                                                 dropout_69[0][0]                 \n",
      "                                                                 dot_68[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_24 (Bidirectional (None, 30, 84)       146160      concatenate_80[0][0]             \n",
      "                                                                 concatenate_81[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_70 (Dropout)            (None, 30, 84)       0           bidirectional_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_71 (Dropout)            (None, 30, 84)       0           bidirectional_24[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dot_70 (Dot)                    (None, 30, 30)       0           dropout_70[0][0]                 \n",
      "                                                                 dropout_71[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_55 (Lambda)              (None, 30, 30)       0           dot_70[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_24 (Permute)            (None, 30, 30)       0           lambda_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_54 (Lambda)              (None, 30, 30)       0           dot_70[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_72 (Dot)                    (None, 30, 84)       0           permute_24[0][0]                 \n",
      "                                                                 dropout_71[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_71 (Dot)                    (None, 30, 84)       0           lambda_54[0][0]                  \n",
      "                                                                 dropout_70[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_82 (Concatenate)    (None, 30, 704)      0           concatenate_80[0][0]             \n",
      "                                                                 dropout_70[0][0]                 \n",
      "                                                                 dot_72[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_83 (Concatenate)    (None, 30, 704)      0           concatenate_81[0][0]             \n",
      "                                                                 dropout_71[0][0]                 \n",
      "                                                                 dot_71[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_15 (Gl (None, 704)          0           concatenate_82[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_15 (Global (None, 704)          0           concatenate_82[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "attention_weighted_average_8 (A (None, 704)          704         concatenate_82[0][0]             \n",
      "                                                                 concatenate_83[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_16 (Gl (None, 704)          0           concatenate_83[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_16 (Global (None, 704)          0           concatenate_83[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_86 (Concatenate)    (None, 2112)         0           global_average_pooling1d_15[0][0]\n",
      "                                                                 global_max_pooling1d_15[0][0]    \n",
      "                                                                 attention_weighted_average_8[0][0\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_87 (Concatenate)    (None, 2112)         0           global_average_pooling1d_16[0][0]\n",
      "                                                                 global_max_pooling1d_16[0][0]    \n",
      "                                                                 attention_weighted_average_8[1][0\n",
      "__________________________________________________________________________________________________\n",
      "lambda_56 (Lambda)              (None, 2112)         0           concatenate_86[0][0]             \n",
      "                                                                 concatenate_87[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_8 (Multiply)           (None, 2112)         0           concatenate_86[0][0]             \n",
      "                                                                 concatenate_87[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_88 (Concatenate)    (None, 8448)         0           concatenate_86[0][0]             \n",
      "                                                                 concatenate_87[0][0]             \n",
      "                                                                 lambda_56[0][0]                  \n",
      "                                                                 multiply_8[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_72 (Dropout)            (None, 8448)         0           concatenate_88[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 300)          2534700     dropout_72[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 3)            903         dense_15[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 22,928,179\n",
      "Trainable params: 2,928,179\n",
      "Non-trainable params: 20,000,000\n",
      "__________________________________________________________________________________________________\n",
      "Load weights from WordTC-DenseRNN-NoMeta-3P-NoEM-NoClassWeighted-3Layers7.h5\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360609/360609 [==============================] - 65s 179us/step - loss: 0.0194 - acc: 0.8922 - weighted_accuracy: 0.8877 - val_loss: 0.2910 - val_acc: 0.8702 - val_weighted_accuracy: 0.8569\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 61s 171us/step - loss: 0.0190 - acc: 0.8954 - weighted_accuracy: 0.8913 - val_loss: 0.2946 - val_acc: 0.8661 - val_weighted_accuracy: 0.8560\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0187 - acc: 0.8963 - weighted_accuracy: 0.8928 - val_loss: 0.2840 - val_acc: 0.8729 - val_weighted_accuracy: 0.8587\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0185 - acc: 0.8982 - weighted_accuracy: 0.8948 - val_loss: 0.3011 - val_acc: 0.8643 - val_weighted_accuracy: 0.8531\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 61s 170us/step - loss: 0.0182 - acc: 0.8990 - weighted_accuracy: 0.8963 - val_loss: 0.2883 - val_acc: 0.8682 - val_weighted_accuracy: 0.8575\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0180 - acc: 0.9016 - weighted_accuracy: 0.8987 - val_loss: 0.3049 - val_acc: 0.8611 - val_weighted_accuracy: 0.8550\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0178 - acc: 0.9022 - weighted_accuracy: 0.8997 - val_loss: 0.2962 - val_acc: 0.8657 - val_weighted_accuracy: 0.8587\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0176 - acc: 0.9036 - weighted_accuracy: 0.9016 - val_loss: 0.3055 - val_acc: 0.8601 - val_weighted_accuracy: 0.8520\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0175 - acc: 0.9038 - weighted_accuracy: 0.9020 - val_loss: 0.2961 - val_acc: 0.8666 - val_weighted_accuracy: 0.8581\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0173 - acc: 0.9058 - weighted_accuracy: 0.9039 - val_loss: 0.3057 - val_acc: 0.8593 - val_weighted_accuracy: 0.8537\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0172 - acc: 0.9068 - weighted_accuracy: 0.9052 - val_loss: 0.3133 - val_acc: 0.8561 - val_weighted_accuracy: 0.8514\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0170 - acc: 0.9082 - weighted_accuracy: 0.9067 - val_loss: 0.2876 - val_acc: 0.8697 - val_weighted_accuracy: 0.8602\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0168 - acc: 0.9087 - weighted_accuracy: 0.9073 - val_loss: 0.2909 - val_acc: 0.8715 - val_weighted_accuracy: 0.8615\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0167 - acc: 0.9097 - weighted_accuracy: 0.9088 - val_loss: 0.2986 - val_acc: 0.8656 - val_weighted_accuracy: 0.8577\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 61s 171us/step - loss: 0.0165 - acc: 0.9108 - weighted_accuracy: 0.9101 - val_loss: 0.2957 - val_acc: 0.8671 - val_weighted_accuracy: 0.8586\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0164 - acc: 0.9118 - weighted_accuracy: 0.9114 - val_loss: 0.2967 - val_acc: 0.8670 - val_weighted_accuracy: 0.8596\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 61s 171us/step - loss: 0.0163 - acc: 0.9122 - weighted_accuracy: 0.9116 - val_loss: 0.2899 - val_acc: 0.8711 - val_weighted_accuracy: 0.8602\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 61s 170us/step - loss: 0.0162 - acc: 0.9125 - weighted_accuracy: 0.9120 - val_loss: 0.2950 - val_acc: 0.8674 - val_weighted_accuracy: 0.8582\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 61s 170us/step - loss: 0.0160 - acc: 0.9142 - weighted_accuracy: 0.9140 - val_loss: 0.2913 - val_acc: 0.8705 - val_weighted_accuracy: 0.8621\n",
      "Epoch 20/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0159 - acc: 0.9146 - weighted_accuracy: 0.9143 - val_loss: 0.2929 - val_acc: 0.8707 - val_weighted_accuracy: 0.8596\n",
      "Epoch 21/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0158 - acc: 0.9155 - weighted_accuracy: 0.9153 - val_loss: 0.2823 - val_acc: 0.8765 - val_weighted_accuracy: 0.8646\n",
      "Epoch 22/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0158 - acc: 0.9155 - weighted_accuracy: 0.9154 - val_loss: 0.2979 - val_acc: 0.8732 - val_weighted_accuracy: 0.8605\n",
      "Epoch 23/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0156 - acc: 0.9172 - weighted_accuracy: 0.9173 - val_loss: 0.2988 - val_acc: 0.8666 - val_weighted_accuracy: 0.8599\n",
      "Epoch 24/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0155 - acc: 0.9178 - weighted_accuracy: 0.9179 - val_loss: 0.2858 - val_acc: 0.8728 - val_weighted_accuracy: 0.8631\n",
      "Epoch 25/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0154 - acc: 0.9184 - weighted_accuracy: 0.9186 - val_loss: 0.2868 - val_acc: 0.8747 - val_weighted_accuracy: 0.8626\n",
      "Epoch 26/500\n",
      "360609/360609 [==============================] - 62s 171us/step - loss: 0.0153 - acc: 0.9186 - weighted_accuracy: 0.9191 - val_loss: 0.2921 - val_acc: 0.8708 - val_weighted_accuracy: 0.8620\n",
      "Epoch 27/500\n",
      "360609/360609 [==============================] - 63s 173us/step - loss: 0.0152 - acc: 0.9196 - weighted_accuracy: 0.9200 - val_loss: 0.2917 - val_acc: 0.8723 - val_weighted_accuracy: 0.8612\n",
      "Epoch 28/500\n",
      "360609/360609 [==============================] - 62s 172us/step - loss: 0.0152 - acc: 0.9200 - weighted_accuracy: 0.9204 - val_loss: 0.3130 - val_acc: 0.8617 - val_weighted_accuracy: 0.8560\n",
      "Epoch 29/500\n",
      "360609/360609 [==============================] - 63s 174us/step - loss: 0.0151 - acc: 0.9209 - weighted_accuracy: 0.9213 - val_loss: 0.2966 - val_acc: 0.8717 - val_weighted_accuracy: 0.8619\n",
      "Epoch 30/500\n",
      "360609/360609 [==============================] - 62s 173us/step - loss: 0.0150 - acc: 0.9219 - weighted_accuracy: 0.9226 - val_loss: 0.2948 - val_acc: 0.8735 - val_weighted_accuracy: 0.8630\n",
      "Epoch 31/500\n",
      "360609/360609 [==============================] - 62s 172us/step - loss: 0.0149 - acc: 0.9217 - weighted_accuracy: 0.9221 - val_loss: 0.3000 - val_acc: 0.8692 - val_weighted_accuracy: 0.8604\n",
      "score 0.8628048700321371\n",
      "Predicting training results...\n",
      "Predicting testing results...\n",
      "80126/80126 [==============================] - 8s 99us/step\n",
      "80126/80126 [==============================] - 8s 98us/step\n",
      "80126/80126 [==============================] - 8s 95us/step\n",
      "80126/80126 [==============================] - 7s 92us/step\n",
      "80126/80126 [==============================] - 8s 99us/step\n",
      "80126/80126 [==============================] - 7s 92us/step\n",
      "80126/80126 [==============================] - 8s 95us/step\n",
      "80126/80126 [==============================] - 8s 102us/step\n",
      "Predicting labeled testing results...\n"
     ]
    }
   ],
   "source": [
    "fold_count = 8\n",
    "#embedding_matrix = sgns_bigram_matrix\n",
    "embedding_matrix = tencent_ai_matrix\n",
    "EMBEDDING_DIM = 200\n",
    "\n",
    "for i in range(1, len(model_manager.models_tag)):\n",
    "    print(\"Work on model\", i)\n",
    "    model_tag = model_manager.models_tag[i]\n",
    "    model_func = model_manager.model_funcs[i]\n",
    "    #models_checkpoints_path = model_manager.models_checkpoints_pathes[i]\n",
    "    models_checkpoints_path = \"WordTC-DenseRNN-NoMeta-3P-NoEM-NoClassWeighted-3Layers\"\n",
    "\n",
    "    model_submit_prefix = model_manager.submit_predix[i]\n",
    "    model_class_weights = model_manager.model_class_weights[i]\n",
    "    model_scale_sample_weights = model_manager.model_scale_sample_weights[i]\n",
    "    model_patiences = model_manager.model_patiences[i]\n",
    "    \n",
    "    model_class_weights = None\n",
    "    \n",
    "    def _agent_get_model():\n",
    "        return get_darnn(NB_WORDS, EMBEDDING_DIM, embedding_matrix, MAX_SEQUENCE_LENGTH, OUT_SIZE)\n",
    "        return get_dense_cnn(NB_WORDS, EMBEDDING_DIM, embedding_matrix, MAX_SEQUENCE_LENGTH, OUT_SIZE)\n",
    "        return model_func(NB_WORDS, EMBEDDING_DIM, embedding_matrix, MAX_SEQUENCE_LENGTH, OUT_SIZE)\n",
    "    \n",
    "    test_predicts_list = []\n",
    "    oofs_predictions = []\n",
    "    pre_trained_models = []\n",
    "        \n",
    "    trainer = KerasModelTrainer(model_stamp=models_checkpoints_path, epoch_num=500)\n",
    "    models, score, folds_preds = trainer.train_folds(X=trains, y=labels, tests=tests, augments=None, fold_count=fold_count, batch_size=1024,\n",
    "        em_train_features=em_train_features, em_test_features=em_test_features, pseudo_labels=pseudo_labels,                                      \n",
    "        scale_sample_weight=model_scale_sample_weights, class_weight={0: 1/16, 1: 1/15, 2:1/5},\n",
    "        get_model_func=_agent_get_model, \n",
    "        patience=10)\n",
    "\n",
    "    print(\"score\", score)\n",
    "    oofs_dir = \"../data/pseudo/oofs/\"\n",
    "    output_dir = \"../data/pseudo/output/\"\n",
    "    onehot_pred_dir = \"../data/pseudo/one_hot_pred/\"\n",
    "\n",
    "    model_submit_prefix = \"PSWordTC-DenseRNN-NoMeta-3P-NoEM-NoClassWeighted-3Layers\"\n",
    "    \n",
    "    oofs_path = oofs_dir + model_submit_prefix\n",
    "    output_path = output_dir + model_submit_prefix\n",
    "    one_hot_pred_path = onehot_pred_dir + \"One-Hot\" + model_submit_prefix\n",
    "\n",
    "    print(\"Predicting training results...\")\n",
    "    train_predicts = np.concatenate(folds_preds, axis=0)\n",
    "    oofs = pd.DataFrame({\"unrelated\": train_predicts[:, 0], \"agreed\": train_predicts[:, 1], \"disagreed\": train_predicts[:, 2]})\n",
    "    submit_path = oofs_path + \"-Train-L{:4f}-NB{:d}.csv\".format(score, NB_WORDS)\n",
    "    oofs.to_csv(submit_path, index=False)\n",
    "\n",
    "    print(\"Predicting testing results...\")\n",
    "    test_predicts_list = []\n",
    "    for fold_id, model in enumerate(models):\n",
    "        test_predicts = model.predict({\"first_sentences\":tests[0],\n",
    "                                       \"second_sentences\":tests[1],\n",
    "                                       \"mata-features\":tests[2],\n",
    "                                       \"first_exact_match\": tests_1_ems,\n",
    "                                       \"second_exact_match\": tests_2_ems,\n",
    "                                      }, batch_size=128, verbose=1)\n",
    "\n",
    "        test_predicts_list.append(test_predicts)\n",
    "\n",
    "    test_predicts = np.zeros(test_predicts_list[0].shape)\n",
    "    for fold_predict in test_predicts_list:\n",
    "        test_predicts += fold_predict\n",
    "    test_predicts /= len(test_predicts_list)\n",
    "\n",
    "    test_predicts = pd.DataFrame({\"unrelated\": test_predicts[:, 0], \"agreed\": test_predicts[:, 1], \"disagreed\": test_predicts[:, 2]})\n",
    "    submit_path = output_path + \"-L{:4f}-NB{:d}.csv\".format(score, NB_WORDS)\n",
    "    test_predicts.to_csv(submit_path, index=False) # 0.3343\n",
    "    \n",
    "    print(\"Predicting labeled testing results...\")\n",
    "    ids = pd.read_csv(\"../data/dataset/test.csv\")\n",
    "    pred_labels = test_predicts.idxmax(axis=1)\n",
    "    sub = pd.DataFrame({\"Id\": ids['id'].values, \"Category\": pred_labels})\n",
    "    submit_path = one_hot_pred_path + \"-L{:4f}-NB{:d}.csv\".format(score, NB_WORDS)\n",
    "    sub.to_csv(submit_path, index=False)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weighted_accuracy(y_true, y_pred):\n",
    "    weight = np.array([[1/16, 1/15, 1/5]])\n",
    "    norm = [(1/16) + (1/15) + (1/5)]\n",
    "    weight_mask = weight * y_true\n",
    "    label_weights = K.max(K.cast(weight_mask, 'float32'), axis=-1)\n",
    "    \n",
    "    true_label = K.argmax(y_true, axis=-1)\n",
    "    pred_label = K.argmax(y_pred, axis=-1)\n",
    "    \n",
    "    res = K.cast(K.equal(true_label, pred_label), tf.float32) * label_weights / K.sum(label_weights)\n",
    "    res = K.sum(res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numpy_weighted_accuracy(labels, oofs[['unrelated', 'agreed', 'disagreed']].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import importlib\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from iwillwin.config import model_config\n",
    "\n",
    "class ModelTrainer(object):\n",
    "\n",
    "    def __init__(self, model_stamp, epoch_num, learning_rate=1e-3,\n",
    "                 shuffle_inputs=False, verbose_round=40, early_stopping_round=8):\n",
    "        self.models = []\n",
    "        self.model_stamp = model_stamp\n",
    "        self.val_loss = -1\n",
    "        self.auc = -1\n",
    "        self.epoch_num = epoch_num\n",
    "        self.learning_rate = learning_rate\n",
    "        self.eps = 1e-10\n",
    "        self.verbose_round = verbose_round\n",
    "        self.early_stopping_round = early_stopping_round\n",
    "        self.shuffle_inputs = shuffle_inputs\n",
    "\n",
    "    def train_folds(self, X, y, fold_count, em_train_features, tests, em_test_features, pseudo_labels, batch_size, get_model_func, augments=None, skip_fold=0, patience=10, scale_sample_weight=False,\n",
    "                    class_weight=None, self_aware=False, swap_input=False):\n",
    "        X1, X2, features, = X\n",
    "        em1, em2 = em_train_features\n",
    "        features = features\n",
    "        weight_val=scale_sample_weight\n",
    "\n",
    "        fold_size = len(X1) // fold_count\n",
    "        models = []\n",
    "        fold_predictions = []\n",
    "        score = 0\n",
    "\n",
    "        for fold_id in range(0, fold_count):\n",
    "            fold_start = fold_size * fold_id\n",
    "            fold_end = fold_start + fold_size\n",
    "\n",
    "            if fold_id == fold_count - 1:\n",
    "                fold_end = len(X1)\n",
    "\n",
    "            train_x1 = np.concatenate([X1[:fold_start], X1[fold_end:], tests[0]])\n",
    "            train_x2 = np.concatenate([X2[:fold_start], X2[fold_end:], tests[1]])\n",
    "            train_features = np.concatenate([features[:fold_start], features[fold_end:], tests[2]])\n",
    "            \n",
    "            train_em_1 = np.concatenate([em1[:fold_start], em1[fold_end:], em_test_features[0]])\n",
    "            train_em_2 = np.concatenate([em2[:fold_start], em2[fold_end:], em_test_features[1]])\n",
    "            \n",
    "            train_y = np.concatenate([y[:fold_start], y[fold_end:], pseudo_labels])\n",
    "            \n",
    "            val_x1 = X1[fold_start:fold_end]\n",
    "            val_x2 = X2[fold_start:fold_end]\n",
    "            val_features = features[fold_start:fold_end]\n",
    "            val_em1 = em1[fold_start:fold_end]\n",
    "            val_em2 = em2[fold_start:fold_end]\n",
    "            val_y = y[fold_start:fold_end]\n",
    "\n",
    "            fold_pos = (np.sum(train_y) / len(train_x1))\n",
    "\n",
    "            train_data = {\n",
    "                \"first_sentences\": train_x1,\n",
    "                \"second_sentences\": train_x2,\n",
    "                \"mata-features\": train_features,\n",
    "                \"first_exact_match\": train_em_1,\n",
    "                \"second_exact_match\": train_em_2,\n",
    "            }\n",
    "\n",
    "            val_data = {\n",
    "                \"first_sentences\": val_x1,\n",
    "                \"second_sentences\": val_x2,\n",
    "                \"mata-features\": val_features,\n",
    "                \"first_exact_match\": val_em1,\n",
    "                \"second_exact_match\": val_em2,\n",
    "            }\n",
    "\n",
    "            model, bst_val_score, fold_prediction = self._train_model_by_logloss(\n",
    "                get_model_func(), batch_size, train_data, train_y, val_data, val_y, fold_id, patience, class_weight, weight_val=weight_val)\n",
    "    \n",
    "            score += bst_val_score\n",
    "            models.append(model)\n",
    "            fold_predictions.append(fold_prediction)\n",
    "\n",
    "        self.models = models\n",
    "        self.val_loss = score / fold_count\n",
    "        return models, self.val_loss, fold_predictions\n",
    "\n",
    "    def _train_model_by_logloss(self, model, batch_size, train_x, train_y, val_x, val_y, fold_id, patience):\n",
    "        # return a list which holds [models, val_loss, auc, prediction]\n",
    "        raise NotImplementedError\n",
    "\n",
    "class KerasModelTrainer(ModelTrainer):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(KerasModelTrainer, self).__init__(*args, **kwargs)\n",
    "        pass\n",
    "\n",
    "    def _train_model_by_logloss(self, model, batch_size, train_x, train_y, val_x, val_y, fold_id, patience, class_weight, weight_val):\n",
    "        early_stopping = EarlyStopping(monitor='val_weighted_accuracy', patience=patience)\n",
    "        bst_model_path = self.model_stamp + str(fold_id) + '.h5'\n",
    "        print(\"Load weights from\", bst_model_path)\n",
    "        model.load_weights(bst_model_path)\n",
    "        bst_model_path = self.model_stamp + \"-pseudo-scaled-\" + str(fold_id) + '.h5'\n",
    "        \n",
    "        val_data =  (val_x, val_y)\n",
    "        model_checkpoint = ModelCheckpoint(bst_model_path, save_best_only=True, save_weights_only=True)\n",
    "        hist = model.fit(train_x, train_y,\n",
    "                         validation_data=val_data,\n",
    "                         epochs=self.epoch_num, batch_size=batch_size, shuffle=True,\n",
    "                         class_weight={0: 1/16, 1:1/15, 2:1/5},\n",
    "                         callbacks=[early_stopping, model_checkpoint],)\n",
    "        bst_val_score = max(hist.history['val_weighted_accuracy'])\n",
    "        model.load_weights(bst_model_path)\n",
    "        predictions = model.predict(val_x)\n",
    "\n",
    "        return model, bst_val_score, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_decomposable_attention(nb_words, embedding_dim, embedding_matrix, max_sequence_length, out_size,\n",
    "    projection_dim=50, projection_hidden=0, projection_dropout=0.2,\n",
    "    compare_dim=288, compare_dropout=0.2,\n",
    "    dense_dim=50, dense_dropout=0.2,\n",
    "    lr=1e-3, activation='relu'):\n",
    "\n",
    "    q1 = Input(shape=(max_sequence_length,), name='first_sentences')\n",
    "    q2 = Input(shape=(max_sequence_length,), name='second_sentences')\n",
    "    q1_exact_match = Input(shape=(max_sequence_length,), name='first_exact_match')\n",
    "    q2_exact_match = Input(shape=(max_sequence_length,), name='second_exact_match')    \n",
    "    input_layer_3 = Input(shape=(36,), name='mata-features', dtype=\"float32\")\n",
    "    \n",
    "    embedding = Embedding(nb_words, embedding_dim,\n",
    "                          weights=[embedding_matrix],\n",
    "                          input_length=max_sequence_length,\n",
    "                          trainable=False)\n",
    "    \n",
    "    em_embeddings = Embedding(2, 1,\n",
    "                     input_length=max_sequence_length,\n",
    "                     trainable=True)   \n",
    "    \n",
    "    #q1_embed = Concatenate()([embedding(q1), em_embeddings(q1_exact_match)])\n",
    "    q1_embed = embedding(q1)\n",
    "    q1_embed = SpatialDropout1D(0.1)(q1_embed)\n",
    "    \n",
    "    #q2_embed = Concatenate()([embedding(q2), em_embeddings(q2_exact_match)])\n",
    "    q2_embed = embedding(q2)\n",
    "    q2_embed = SpatialDropout1D(0.1)(q2_embed)\n",
    "\n",
    "    th = TimeDistributed(Highway(activation='relu'))\n",
    "    q1_embed = th(q1_embed)\n",
    "    q2_embed = th(q2_embed)\n",
    "        \n",
    "    q1_aligned, q2_aligned = soft_attention_alignment(q1_embed, q2_embed)\n",
    "    q1_vec = Concatenate()([q1_embed, q2_aligned, substract(q1_embed, q2_aligned), Multiply()([q1_embed, q2_aligned])])\n",
    "    q2_vec = Concatenate()([q2_embed, q1_aligned, substract(q2_embed, q1_aligned), Multiply()([q2_embed, q1_aligned])])\n",
    "    \n",
    "    dense_compares = [\n",
    "        Dense(300, activation='elu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(200, activation='elu'),\n",
    "        Dropout(0.2),\n",
    "    ]\n",
    "\n",
    "    q1_compared = time_distributed(q1_vec, dense_compares)\n",
    "    q2_compared = time_distributed(q2_vec, dense_compares)\n",
    "    \n",
    "    q1_rep = apply_multiple(q1_compared, [GlobalAvgPool1D(), GlobalMaxPool1D()])\n",
    "    q2_rep = apply_multiple(q2_compared, [GlobalAvgPool1D(), GlobalMaxPool1D()])    \n",
    "    \n",
    "    h_all = Concatenate()([q1_rep, q2_rep])\n",
    "    h_all = BatchNormalization()(h_all)\n",
    "    \n",
    "    h_all = Dense(256, activation='elu')(h_all)\n",
    "    h_all = Dropout(0.2)(h_all)\n",
    "    h_all = BatchNormalization()(h_all)\n",
    "\n",
    "    h_all = Dense(256, activation='elu')(h_all)\n",
    "    h_all = Dropout(0.2)(h_all)\n",
    "    h_all = BatchNormalization()(h_all)    \n",
    "    \n",
    "    out_ = Dense(3, activation='softmax')(h_all)\n",
    "    \n",
    "    model = Model(inputs=[q1, q2, input_layer_3, q1_exact_match, q2_exact_match], outputs=out_)\n",
    "    model.compile(optimizer=Adam(lr=lr, decay=1e-6, clipnorm=1.5, amsgrad=True), loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', weighted_accuracy])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tencent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Work on model 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zake7\\Anaconda3\\lib\\site-packages\\keras\\legacy\\layers.py:198: UserWarning: The `Highway` layer is deprecated and will be removed after 06/2017.\n",
      "  warnings.warn('The `Highway` layer is deprecated '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_11 (Embedding)        (None, 30, 200)      20000000    first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_21 (SpatialDr (None, 30, 200)      0           embedding_11[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_22 (SpatialDr (None, 30, 200)      0           embedding_11[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_11 (TimeDistri (None, 30, 200)      80400       spatial_dropout1d_21[0][0]       \n",
      "                                                                 spatial_dropout1d_22[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dot_121 (Dot)                   (None, 30, 30)       0           time_distributed_11[0][0]        \n",
      "                                                                 time_distributed_11[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_92 (Lambda)              (None, 30, 30)       0           dot_121[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_41 (Permute)            (None, 30, 30)       0           lambda_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_91 (Lambda)              (None, 30, 30)       0           dot_121[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_123 (Dot)                   (None, 30, 200)      0           permute_41[0][0]                 \n",
      "                                                                 time_distributed_11[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dot_122 (Dot)                   (None, 30, 200)      0           lambda_91[0][0]                  \n",
      "                                                                 time_distributed_11[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_93 (Lambda)              (None, 30, 200)      0           time_distributed_11[0][0]        \n",
      "                                                                 dot_123[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_11 (Multiply)          (None, 30, 200)      0           time_distributed_11[0][0]        \n",
      "                                                                 dot_123[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_94 (Lambda)              (None, 30, 200)      0           time_distributed_11[1][0]        \n",
      "                                                                 dot_122[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_12 (Multiply)          (None, 30, 200)      0           time_distributed_11[1][0]        \n",
      "                                                                 dot_122[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_111 (Concatenate)   (None, 30, 800)      0           time_distributed_11[0][0]        \n",
      "                                                                 dot_123[0][0]                    \n",
      "                                                                 lambda_93[0][0]                  \n",
      "                                                                 multiply_11[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_112 (Concatenate)   (None, 30, 800)      0           time_distributed_11[1][0]        \n",
      "                                                                 dot_122[0][0]                    \n",
      "                                                                 lambda_94[0][0]                  \n",
      "                                                                 multiply_12[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_12 (TimeDistri (None, 30, 300)      240300      concatenate_111[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_16 (TimeDistri (None, 30, 300)      240300      concatenate_112[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_13 (TimeDistri (None, 30, 300)      0           time_distributed_12[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_17 (TimeDistri (None, 30, 300)      0           time_distributed_16[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_14 (TimeDistri (None, 30, 200)      60200       time_distributed_13[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_18 (TimeDistri (None, 30, 200)      60200       time_distributed_17[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_15 (TimeDistri (None, 30, 200)      0           time_distributed_14[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_19 (TimeDistri (None, 30, 200)      0           time_distributed_18[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_21 (Gl (None, 200)          0           time_distributed_15[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_21 (Global (None, 200)          0           time_distributed_15[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_22 (Gl (None, 200)          0           time_distributed_19[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_22 (Global (None, 200)          0           time_distributed_19[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_113 (Concatenate)   (None, 400)          0           global_average_pooling1d_21[0][0]\n",
      "                                                                 global_max_pooling1d_21[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_114 (Concatenate)   (None, 400)          0           global_average_pooling1d_22[0][0]\n",
      "                                                                 global_max_pooling1d_22[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_115 (Concatenate)   (None, 800)          0           concatenate_113[0][0]            \n",
      "                                                                 concatenate_114[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 800)          3200        concatenate_115[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 256)          205056      batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 256)          0           dense_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 256)          1024        dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 256)          65792       batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 256)          0           dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 256)          1024        dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 3)            771         batch_normalization_3[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 20,657,767\n",
      "Trainable params: 655,143\n",
      "Non-trainable params: 20,002,624\n",
      "__________________________________________________________________________________________________\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360609/360609 [==============================] - 38s 105us/step - loss: 0.0181 - acc: 0.9004 - weighted_accuracy: 0.8984 - val_loss: 0.3212 - val_acc: 0.8558 - val_weighted_accuracy: 0.8513\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0179 - acc: 0.9024 - weighted_accuracy: 0.9005 - val_loss: 0.3023 - val_acc: 0.8649 - val_weighted_accuracy: 0.8575\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0176 - acc: 0.9039 - weighted_accuracy: 0.9023 - val_loss: 0.3025 - val_acc: 0.8644 - val_weighted_accuracy: 0.8595\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0175 - acc: 0.9049 - weighted_accuracy: 0.9032 - val_loss: 0.3053 - val_acc: 0.8621 - val_weighted_accuracy: 0.8573\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0173 - acc: 0.9064 - weighted_accuracy: 0.9052 - val_loss: 0.3121 - val_acc: 0.8606 - val_weighted_accuracy: 0.8573\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0171 - acc: 0.9077 - weighted_accuracy: 0.9065 - val_loss: 0.3114 - val_acc: 0.8578 - val_weighted_accuracy: 0.8551\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0170 - acc: 0.9086 - weighted_accuracy: 0.9076 - val_loss: 0.3169 - val_acc: 0.8576 - val_weighted_accuracy: 0.8553\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0169 - acc: 0.9091 - weighted_accuracy: 0.9080 - val_loss: 0.3228 - val_acc: 0.8576 - val_weighted_accuracy: 0.8531\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0167 - acc: 0.9106 - weighted_accuracy: 0.9097 - val_loss: 0.3195 - val_acc: 0.8549 - val_weighted_accuracy: 0.8527\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0166 - acc: 0.9112 - weighted_accuracy: 0.9106 - val_loss: 0.3157 - val_acc: 0.8620 - val_weighted_accuracy: 0.8568\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0164 - acc: 0.9123 - weighted_accuracy: 0.9119 - val_loss: 0.3146 - val_acc: 0.8626 - val_weighted_accuracy: 0.8577\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0164 - acc: 0.9124 - weighted_accuracy: 0.9119 - val_loss: 0.3193 - val_acc: 0.8563 - val_weighted_accuracy: 0.8530\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0162 - acc: 0.9127 - weighted_accuracy: 0.9125 - val_loss: 0.3386 - val_acc: 0.8488 - val_weighted_accuracy: 0.8477\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0162 - acc: 0.9144 - weighted_accuracy: 0.9142 - val_loss: 0.3246 - val_acc: 0.8592 - val_weighted_accuracy: 0.8535\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0161 - acc: 0.9149 - weighted_accuracy: 0.9146 - val_loss: 0.3025 - val_acc: 0.8667 - val_weighted_accuracy: 0.8592\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0160 - acc: 0.9150 - weighted_accuracy: 0.9147 - val_loss: 0.3194 - val_acc: 0.8603 - val_weighted_accuracy: 0.8568\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0159 - acc: 0.9160 - weighted_accuracy: 0.9160 - val_loss: 0.3204 - val_acc: 0.8590 - val_weighted_accuracy: 0.8557\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0158 - acc: 0.9174 - weighted_accuracy: 0.9174 - val_loss: 0.3571 - val_acc: 0.8431 - val_weighted_accuracy: 0.8434\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0157 - acc: 0.9176 - weighted_accuracy: 0.9177 - val_loss: 0.3272 - val_acc: 0.8538 - val_weighted_accuracy: 0.8518\n",
      "Epoch 20/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0156 - acc: 0.9178 - weighted_accuracy: 0.9177 - val_loss: 0.3106 - val_acc: 0.8617 - val_weighted_accuracy: 0.8572\n",
      "Epoch 21/500\n",
      "360609/360609 [==============================] - 34s 95us/step - loss: 0.0156 - acc: 0.9180 - weighted_accuracy: 0.9180 - val_loss: 0.3203 - val_acc: 0.8571 - val_weighted_accuracy: 0.8544\n",
      "Epoch 22/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0155 - acc: 0.9186 - weighted_accuracy: 0.9190 - val_loss: 0.3297 - val_acc: 0.8555 - val_weighted_accuracy: 0.8521\n",
      "Epoch 23/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0154 - acc: 0.9196 - weighted_accuracy: 0.9200 - val_loss: 0.3054 - val_acc: 0.8645 - val_weighted_accuracy: 0.8592\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_13 (Embedding)        (None, 30, 200)      20000000    first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_23 (SpatialDr (None, 30, 200)      0           embedding_13[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_24 (SpatialDr (None, 30, 200)      0           embedding_13[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_20 (TimeDistri (None, 30, 200)      80400       spatial_dropout1d_23[0][0]       \n",
      "                                                                 spatial_dropout1d_24[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dot_124 (Dot)                   (None, 30, 30)       0           time_distributed_20[0][0]        \n",
      "                                                                 time_distributed_20[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_96 (Lambda)              (None, 30, 30)       0           dot_124[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_42 (Permute)            (None, 30, 30)       0           lambda_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_95 (Lambda)              (None, 30, 30)       0           dot_124[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_126 (Dot)                   (None, 30, 200)      0           permute_42[0][0]                 \n",
      "                                                                 time_distributed_20[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dot_125 (Dot)                   (None, 30, 200)      0           lambda_95[0][0]                  \n",
      "                                                                 time_distributed_20[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_97 (Lambda)              (None, 30, 200)      0           time_distributed_20[0][0]        \n",
      "                                                                 dot_126[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_13 (Multiply)          (None, 30, 200)      0           time_distributed_20[0][0]        \n",
      "                                                                 dot_126[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_98 (Lambda)              (None, 30, 200)      0           time_distributed_20[1][0]        \n",
      "                                                                 dot_125[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_14 (Multiply)          (None, 30, 200)      0           time_distributed_20[1][0]        \n",
      "                                                                 dot_125[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_116 (Concatenate)   (None, 30, 800)      0           time_distributed_20[0][0]        \n",
      "                                                                 dot_126[0][0]                    \n",
      "                                                                 lambda_97[0][0]                  \n",
      "                                                                 multiply_13[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_117 (Concatenate)   (None, 30, 800)      0           time_distributed_20[1][0]        \n",
      "                                                                 dot_125[0][0]                    \n",
      "                                                                 lambda_98[0][0]                  \n",
      "                                                                 multiply_14[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_21 (TimeDistri (None, 30, 300)      240300      concatenate_116[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_25 (TimeDistri (None, 30, 300)      240300      concatenate_117[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_22 (TimeDistri (None, 30, 300)      0           time_distributed_21[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_26 (TimeDistri (None, 30, 300)      0           time_distributed_25[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_23 (TimeDistri (None, 30, 200)      60200       time_distributed_22[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_27 (TimeDistri (None, 30, 200)      60200       time_distributed_26[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_24 (TimeDistri (None, 30, 200)      0           time_distributed_23[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_28 (TimeDistri (None, 30, 200)      0           time_distributed_27[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_23 (Gl (None, 200)          0           time_distributed_24[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_23 (Global (None, 200)          0           time_distributed_24[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_24 (Gl (None, 200)          0           time_distributed_28[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_24 (Global (None, 200)          0           time_distributed_28[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_118 (Concatenate)   (None, 400)          0           global_average_pooling1d_23[0][0]\n",
      "                                                                 global_max_pooling1d_23[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_119 (Concatenate)   (None, 400)          0           global_average_pooling1d_24[0][0]\n",
      "                                                                 global_max_pooling1d_24[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_120 (Concatenate)   (None, 800)          0           concatenate_118[0][0]            \n",
      "                                                                 concatenate_119[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 800)          3200        concatenate_120[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 256)          205056      batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 256)          0           dense_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 256)          1024        dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 256)          65792       batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 256)          0           dense_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 256)          1024        dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 3)            771         batch_normalization_6[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 20,657,767\n",
      "Trainable params: 655,143\n",
      "Non-trainable params: 20,002,624\n",
      "__________________________________________________________________________________________________\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360609/360609 [==============================] - 37s 104us/step - loss: 0.0157 - acc: 0.9170 - weighted_accuracy: 0.9173 - val_loss: 0.2962 - val_acc: 0.8660 - val_weighted_accuracy: 0.8615\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0158 - acc: 0.9166 - weighted_accuracy: 0.9168 - val_loss: 0.3062 - val_acc: 0.8660 - val_weighted_accuracy: 0.8630\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0157 - acc: 0.9175 - weighted_accuracy: 0.9178 - val_loss: 0.2926 - val_acc: 0.8731 - val_weighted_accuracy: 0.8672\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0156 - acc: 0.9184 - weighted_accuracy: 0.9188 - val_loss: 0.2853 - val_acc: 0.8751 - val_weighted_accuracy: 0.8701\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0155 - acc: 0.9190 - weighted_accuracy: 0.9195 - val_loss: 0.2929 - val_acc: 0.8715 - val_weighted_accuracy: 0.8658\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0154 - acc: 0.9196 - weighted_accuracy: 0.9199 - val_loss: 0.2914 - val_acc: 0.8730 - val_weighted_accuracy: 0.8690\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0153 - acc: 0.9205 - weighted_accuracy: 0.9210 - val_loss: 0.2919 - val_acc: 0.8709 - val_weighted_accuracy: 0.8665\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0152 - acc: 0.9207 - weighted_accuracy: 0.9213 - val_loss: 0.2789 - val_acc: 0.8800 - val_weighted_accuracy: 0.8724\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0151 - acc: 0.9217 - weighted_accuracy: 0.9221 - val_loss: 0.2927 - val_acc: 0.8714 - val_weighted_accuracy: 0.8671\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 35s 96us/step - loss: 0.0151 - acc: 0.9216 - weighted_accuracy: 0.9223 - val_loss: 0.2881 - val_acc: 0.8720 - val_weighted_accuracy: 0.8662\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0150 - acc: 0.9225 - weighted_accuracy: 0.9232 - val_loss: 0.2948 - val_acc: 0.8691 - val_weighted_accuracy: 0.8663\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 34s 96us/step - loss: 0.0150 - acc: 0.9228 - weighted_accuracy: 0.9236 - val_loss: 0.3003 - val_acc: 0.8674 - val_weighted_accuracy: 0.8644\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0149 - acc: 0.9227 - weighted_accuracy: 0.9234 - val_loss: 0.2983 - val_acc: 0.8687 - val_weighted_accuracy: 0.8649\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0149 - acc: 0.9237 - weighted_accuracy: 0.9244 - val_loss: 0.2896 - val_acc: 0.8713 - val_weighted_accuracy: 0.8670\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0148 - acc: 0.9236 - weighted_accuracy: 0.9245 - val_loss: 0.2933 - val_acc: 0.8732 - val_weighted_accuracy: 0.8679\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 34s 95us/step - loss: 0.0147 - acc: 0.9246 - weighted_accuracy: 0.9258 - val_loss: 0.2841 - val_acc: 0.8738 - val_weighted_accuracy: 0.8678\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0147 - acc: 0.9248 - weighted_accuracy: 0.9258 - val_loss: 0.2912 - val_acc: 0.8732 - val_weighted_accuracy: 0.8666\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0147 - acc: 0.9246 - weighted_accuracy: 0.9254 - val_loss: 0.2885 - val_acc: 0.8734 - val_weighted_accuracy: 0.8678\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0146 - acc: 0.9255 - weighted_accuracy: 0.9264 - val_loss: 0.2822 - val_acc: 0.8757 - val_weighted_accuracy: 0.8691\n",
      "Epoch 20/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0146 - acc: 0.9253 - weighted_accuracy: 0.9262 - val_loss: 0.2876 - val_acc: 0.8743 - val_weighted_accuracy: 0.8695\n",
      "Epoch 21/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0145 - acc: 0.9263 - weighted_accuracy: 0.9271 - val_loss: 0.2881 - val_acc: 0.8753 - val_weighted_accuracy: 0.8692\n",
      "Epoch 22/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0144 - acc: 0.9267 - weighted_accuracy: 0.9278 - val_loss: 0.2999 - val_acc: 0.8672 - val_weighted_accuracy: 0.8641\n",
      "Epoch 23/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0144 - acc: 0.9271 - weighted_accuracy: 0.9281 - val_loss: 0.2962 - val_acc: 0.8720 - val_weighted_accuracy: 0.8674\n",
      "Epoch 24/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0143 - acc: 0.9271 - weighted_accuracy: 0.9283 - val_loss: 0.3073 - val_acc: 0.8691 - val_weighted_accuracy: 0.8663\n",
      "Epoch 25/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0143 - acc: 0.9272 - weighted_accuracy: 0.9282 - val_loss: 0.2921 - val_acc: 0.8756 - val_weighted_accuracy: 0.8690\n",
      "Epoch 26/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0143 - acc: 0.9275 - weighted_accuracy: 0.9285 - val_loss: 0.2784 - val_acc: 0.8784 - val_weighted_accuracy: 0.8711\n",
      "Epoch 27/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0142 - acc: 0.9279 - weighted_accuracy: 0.9291 - val_loss: 0.2982 - val_acc: 0.8712 - val_weighted_accuracy: 0.8666\n",
      "Epoch 28/500\n",
      "360609/360609 [==============================] - 35s 96us/step - loss: 0.0142 - acc: 0.9282 - weighted_accuracy: 0.9294 - val_loss: 0.2856 - val_acc: 0.8774 - val_weighted_accuracy: 0.8695\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_15 (Embedding)        (None, 30, 200)      20000000    first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_25 (SpatialDr (None, 30, 200)      0           embedding_15[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_26 (SpatialDr (None, 30, 200)      0           embedding_15[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_29 (TimeDistri (None, 30, 200)      80400       spatial_dropout1d_25[0][0]       \n",
      "                                                                 spatial_dropout1d_26[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dot_127 (Dot)                   (None, 30, 30)       0           time_distributed_29[0][0]        \n",
      "                                                                 time_distributed_29[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_100 (Lambda)             (None, 30, 30)       0           dot_127[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_43 (Permute)            (None, 30, 30)       0           lambda_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_99 (Lambda)              (None, 30, 30)       0           dot_127[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_129 (Dot)                   (None, 30, 200)      0           permute_43[0][0]                 \n",
      "                                                                 time_distributed_29[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dot_128 (Dot)                   (None, 30, 200)      0           lambda_99[0][0]                  \n",
      "                                                                 time_distributed_29[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_101 (Lambda)             (None, 30, 200)      0           time_distributed_29[0][0]        \n",
      "                                                                 dot_129[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_15 (Multiply)          (None, 30, 200)      0           time_distributed_29[0][0]        \n",
      "                                                                 dot_129[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_102 (Lambda)             (None, 30, 200)      0           time_distributed_29[1][0]        \n",
      "                                                                 dot_128[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_16 (Multiply)          (None, 30, 200)      0           time_distributed_29[1][0]        \n",
      "                                                                 dot_128[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_121 (Concatenate)   (None, 30, 800)      0           time_distributed_29[0][0]        \n",
      "                                                                 dot_129[0][0]                    \n",
      "                                                                 lambda_101[0][0]                 \n",
      "                                                                 multiply_15[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_122 (Concatenate)   (None, 30, 800)      0           time_distributed_29[1][0]        \n",
      "                                                                 dot_128[0][0]                    \n",
      "                                                                 lambda_102[0][0]                 \n",
      "                                                                 multiply_16[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_30 (TimeDistri (None, 30, 300)      240300      concatenate_121[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_34 (TimeDistri (None, 30, 300)      240300      concatenate_122[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_31 (TimeDistri (None, 30, 300)      0           time_distributed_30[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_35 (TimeDistri (None, 30, 300)      0           time_distributed_34[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_32 (TimeDistri (None, 30, 200)      60200       time_distributed_31[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_36 (TimeDistri (None, 30, 200)      60200       time_distributed_35[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_33 (TimeDistri (None, 30, 200)      0           time_distributed_32[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_37 (TimeDistri (None, 30, 200)      0           time_distributed_36[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_25 (Gl (None, 200)          0           time_distributed_33[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_25 (Global (None, 200)          0           time_distributed_33[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_26 (Gl (None, 200)          0           time_distributed_37[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_26 (Global (None, 200)          0           time_distributed_37[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_123 (Concatenate)   (None, 400)          0           global_average_pooling1d_25[0][0]\n",
      "                                                                 global_max_pooling1d_25[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_124 (Concatenate)   (None, 400)          0           global_average_pooling1d_26[0][0]\n",
      "                                                                 global_max_pooling1d_26[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_125 (Concatenate)   (None, 800)          0           concatenate_123[0][0]            \n",
      "                                                                 concatenate_124[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 800)          3200        concatenate_125[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 256)          205056      batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 256)          0           dense_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 256)          1024        dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_34 (Dense)                (None, 256)          65792       batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 256)          0           dense_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 256)          1024        dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_35 (Dense)                (None, 3)            771         batch_normalization_9[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 20,657,767\n",
      "Trainable params: 655,143\n",
      "Non-trainable params: 20,002,624\n",
      "__________________________________________________________________________________________________\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360609/360609 [==============================] - 37s 103us/step - loss: 0.0185 - acc: 0.8985 - weighted_accuracy: 0.8955 - val_loss: 0.2983 - val_acc: 0.8637 - val_weighted_accuracy: 0.8593\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0184 - acc: 0.8996 - weighted_accuracy: 0.8967 - val_loss: 0.3294 - val_acc: 0.8506 - val_weighted_accuracy: 0.8496\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 35s 96us/step - loss: 0.0181 - acc: 0.9016 - weighted_accuracy: 0.8992 - val_loss: 0.3208 - val_acc: 0.8563 - val_weighted_accuracy: 0.8543\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0178 - acc: 0.9031 - weighted_accuracy: 0.9011 - val_loss: 0.2982 - val_acc: 0.8649 - val_weighted_accuracy: 0.8611\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0177 - acc: 0.9043 - weighted_accuracy: 0.9022 - val_loss: 0.3154 - val_acc: 0.8572 - val_weighted_accuracy: 0.8555\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0175 - acc: 0.9064 - weighted_accuracy: 0.9044 - val_loss: 0.3130 - val_acc: 0.8589 - val_weighted_accuracy: 0.8572\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0173 - acc: 0.9074 - weighted_accuracy: 0.9059 - val_loss: 0.3487 - val_acc: 0.8442 - val_weighted_accuracy: 0.8453\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 35s 96us/step - loss: 0.0172 - acc: 0.9077 - weighted_accuracy: 0.9062 - val_loss: 0.3098 - val_acc: 0.8631 - val_weighted_accuracy: 0.8597\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0170 - acc: 0.9095 - weighted_accuracy: 0.9081 - val_loss: 0.3161 - val_acc: 0.8582 - val_weighted_accuracy: 0.8561\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 35s 96us/step - loss: 0.0168 - acc: 0.9105 - weighted_accuracy: 0.9096 - val_loss: 0.3367 - val_acc: 0.8454 - val_weighted_accuracy: 0.8467\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 35s 96us/step - loss: 0.0168 - acc: 0.9103 - weighted_accuracy: 0.9093 - val_loss: 0.3327 - val_acc: 0.8506 - val_weighted_accuracy: 0.8476\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 35s 96us/step - loss: 0.0166 - acc: 0.9118 - weighted_accuracy: 0.9109 - val_loss: 0.3134 - val_acc: 0.8558 - val_weighted_accuracy: 0.8534\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 35s 96us/step - loss: 0.0165 - acc: 0.9131 - weighted_accuracy: 0.9125 - val_loss: 0.3324 - val_acc: 0.8496 - val_weighted_accuracy: 0.8493\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 35s 96us/step - loss: 0.0164 - acc: 0.9135 - weighted_accuracy: 0.9127 - val_loss: 0.3007 - val_acc: 0.8654 - val_weighted_accuracy: 0.8608\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 35s 96us/step - loss: 0.0162 - acc: 0.9142 - weighted_accuracy: 0.9142 - val_loss: 0.3189 - val_acc: 0.8597 - val_weighted_accuracy: 0.8572\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 35s 96us/step - loss: 0.0162 - acc: 0.9143 - weighted_accuracy: 0.9140 - val_loss: 0.3143 - val_acc: 0.8618 - val_weighted_accuracy: 0.8583\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 35s 96us/step - loss: 0.0161 - acc: 0.9145 - weighted_accuracy: 0.9142 - val_loss: 0.3013 - val_acc: 0.8652 - val_weighted_accuracy: 0.8611\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 35s 96us/step - loss: 0.0160 - acc: 0.9161 - weighted_accuracy: 0.9155 - val_loss: 0.2978 - val_acc: 0.8666 - val_weighted_accuracy: 0.8612\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 35s 96us/step - loss: 0.0159 - acc: 0.9168 - weighted_accuracy: 0.9166 - val_loss: 0.3054 - val_acc: 0.8643 - val_weighted_accuracy: 0.8594\n",
      "Epoch 20/500\n",
      "360609/360609 [==============================] - 35s 96us/step - loss: 0.0159 - acc: 0.9169 - weighted_accuracy: 0.9167 - val_loss: 0.2989 - val_acc: 0.8678 - val_weighted_accuracy: 0.8629\n",
      "Epoch 21/500\n",
      "360609/360609 [==============================] - 35s 96us/step - loss: 0.0158 - acc: 0.9175 - weighted_accuracy: 0.9174 - val_loss: 0.3223 - val_acc: 0.8575 - val_weighted_accuracy: 0.8563\n",
      "Epoch 22/500\n",
      "360609/360609 [==============================] - 35s 96us/step - loss: 0.0157 - acc: 0.9178 - weighted_accuracy: 0.9177 - val_loss: 0.3028 - val_acc: 0.8651 - val_weighted_accuracy: 0.8595\n",
      "Epoch 23/500\n",
      "360609/360609 [==============================] - 35s 96us/step - loss: 0.0156 - acc: 0.9183 - weighted_accuracy: 0.9187 - val_loss: 0.3053 - val_acc: 0.8667 - val_weighted_accuracy: 0.8622\n",
      "Epoch 24/500\n",
      "360609/360609 [==============================] - 35s 96us/step - loss: 0.0155 - acc: 0.9194 - weighted_accuracy: 0.9194 - val_loss: 0.3063 - val_acc: 0.8636 - val_weighted_accuracy: 0.8600\n",
      "Epoch 25/500\n",
      "360609/360609 [==============================] - 35s 96us/step - loss: 0.0154 - acc: 0.9192 - weighted_accuracy: 0.9193 - val_loss: 0.2993 - val_acc: 0.8640 - val_weighted_accuracy: 0.8603\n",
      "Epoch 26/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0154 - acc: 0.9197 - weighted_accuracy: 0.9199 - val_loss: 0.3104 - val_acc: 0.8620 - val_weighted_accuracy: 0.8573\n",
      "Epoch 27/500\n",
      "360609/360609 [==============================] - 35s 96us/step - loss: 0.0153 - acc: 0.9205 - weighted_accuracy: 0.9207 - val_loss: 0.3063 - val_acc: 0.8639 - val_weighted_accuracy: 0.8602\n",
      "Epoch 28/500\n",
      "360609/360609 [==============================] - 35s 96us/step - loss: 0.0152 - acc: 0.9209 - weighted_accuracy: 0.9211 - val_loss: 0.3074 - val_acc: 0.8609 - val_weighted_accuracy: 0.8573\n",
      "Epoch 29/500\n",
      "360609/360609 [==============================] - 35s 96us/step - loss: 0.0152 - acc: 0.9212 - weighted_accuracy: 0.9215 - val_loss: 0.3183 - val_acc: 0.8558 - val_weighted_accuracy: 0.8543\n",
      "Epoch 30/500\n",
      "360609/360609 [==============================] - 35s 96us/step - loss: 0.0152 - acc: 0.9213 - weighted_accuracy: 0.9217 - val_loss: 0.3040 - val_acc: 0.8647 - val_weighted_accuracy: 0.8579\n",
      "Epoch 31/500\n",
      "360609/360609 [==============================] - 34s 96us/step - loss: 0.0151 - acc: 0.9220 - weighted_accuracy: 0.9223 - val_loss: 0.3020 - val_acc: 0.8659 - val_weighted_accuracy: 0.8609\n",
      "Epoch 32/500\n",
      "360609/360609 [==============================] - 35s 96us/step - loss: 0.0151 - acc: 0.9222 - weighted_accuracy: 0.9227 - val_loss: 0.3000 - val_acc: 0.8660 - val_weighted_accuracy: 0.8615\n",
      "Epoch 33/500\n",
      "360609/360609 [==============================] - 34s 96us/step - loss: 0.0150 - acc: 0.9225 - weighted_accuracy: 0.9230 - val_loss: 0.3095 - val_acc: 0.8633 - val_weighted_accuracy: 0.8603\n",
      "Epoch 34/500\n",
      "360609/360609 [==============================] - 35s 96us/step - loss: 0.0150 - acc: 0.9232 - weighted_accuracy: 0.9236 - val_loss: 0.3213 - val_acc: 0.8569 - val_weighted_accuracy: 0.8550\n",
      "Epoch 35/500\n",
      "360609/360609 [==============================] - 34s 96us/step - loss: 0.0149 - acc: 0.9238 - weighted_accuracy: 0.9244 - val_loss: 0.2973 - val_acc: 0.8686 - val_weighted_accuracy: 0.8615\n",
      "Epoch 36/500\n",
      "360609/360609 [==============================] - 35s 96us/step - loss: 0.0149 - acc: 0.9238 - weighted_accuracy: 0.9243 - val_loss: 0.3049 - val_acc: 0.8647 - val_weighted_accuracy: 0.8598\n",
      "Epoch 37/500\n",
      "360609/360609 [==============================] - 35s 96us/step - loss: 0.0148 - acc: 0.9246 - weighted_accuracy: 0.9253 - val_loss: 0.3022 - val_acc: 0.8658 - val_weighted_accuracy: 0.8599\n",
      "Epoch 38/500\n",
      "360609/360609 [==============================] - 35s 96us/step - loss: 0.0147 - acc: 0.9249 - weighted_accuracy: 0.9253 - val_loss: 0.3068 - val_acc: 0.8641 - val_weighted_accuracy: 0.8599\n",
      "Epoch 39/500\n",
      "360609/360609 [==============================] - 35s 96us/step - loss: 0.0147 - acc: 0.9252 - weighted_accuracy: 0.9258 - val_loss: 0.3138 - val_acc: 0.8601 - val_weighted_accuracy: 0.8570\n",
      "Epoch 40/500\n",
      "360609/360609 [==============================] - 35s 96us/step - loss: 0.0146 - acc: 0.9252 - weighted_accuracy: 0.9258 - val_loss: 0.3090 - val_acc: 0.8644 - val_weighted_accuracy: 0.8606\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 30)           0                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_17 (Embedding)        (None, 30, 200)      20000000    first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_27 (SpatialDr (None, 30, 200)      0           embedding_17[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_28 (SpatialDr (None, 30, 200)      0           embedding_17[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_38 (TimeDistri (None, 30, 200)      80400       spatial_dropout1d_27[0][0]       \n",
      "                                                                 spatial_dropout1d_28[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dot_130 (Dot)                   (None, 30, 30)       0           time_distributed_38[0][0]        \n",
      "                                                                 time_distributed_38[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_104 (Lambda)             (None, 30, 30)       0           dot_130[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_44 (Permute)            (None, 30, 30)       0           lambda_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_103 (Lambda)             (None, 30, 30)       0           dot_130[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_132 (Dot)                   (None, 30, 200)      0           permute_44[0][0]                 \n",
      "                                                                 time_distributed_38[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dot_131 (Dot)                   (None, 30, 200)      0           lambda_103[0][0]                 \n",
      "                                                                 time_distributed_38[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_105 (Lambda)             (None, 30, 200)      0           time_distributed_38[0][0]        \n",
      "                                                                 dot_132[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_17 (Multiply)          (None, 30, 200)      0           time_distributed_38[0][0]        \n",
      "                                                                 dot_132[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_106 (Lambda)             (None, 30, 200)      0           time_distributed_38[1][0]        \n",
      "                                                                 dot_131[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_18 (Multiply)          (None, 30, 200)      0           time_distributed_38[1][0]        \n",
      "                                                                 dot_131[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_126 (Concatenate)   (None, 30, 800)      0           time_distributed_38[0][0]        \n",
      "                                                                 dot_132[0][0]                    \n",
      "                                                                 lambda_105[0][0]                 \n",
      "                                                                 multiply_17[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_127 (Concatenate)   (None, 30, 800)      0           time_distributed_38[1][0]        \n",
      "                                                                 dot_131[0][0]                    \n",
      "                                                                 lambda_106[0][0]                 \n",
      "                                                                 multiply_18[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_39 (TimeDistri (None, 30, 300)      240300      concatenate_126[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_43 (TimeDistri (None, 30, 300)      240300      concatenate_127[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_40 (TimeDistri (None, 30, 300)      0           time_distributed_39[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_44 (TimeDistri (None, 30, 300)      0           time_distributed_43[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_41 (TimeDistri (None, 30, 200)      60200       time_distributed_40[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_45 (TimeDistri (None, 30, 200)      60200       time_distributed_44[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_42 (TimeDistri (None, 30, 200)      0           time_distributed_41[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_46 (TimeDistri (None, 30, 200)      0           time_distributed_45[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_27 (Gl (None, 200)          0           time_distributed_42[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_27 (Global (None, 200)          0           time_distributed_42[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_28 (Gl (None, 200)          0           time_distributed_46[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_28 (Global (None, 200)          0           time_distributed_46[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_128 (Concatenate)   (None, 400)          0           global_average_pooling1d_27[0][0]\n",
      "                                                                 global_max_pooling1d_27[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_129 (Concatenate)   (None, 400)          0           global_average_pooling1d_28[0][0]\n",
      "                                                                 global_max_pooling1d_28[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_130 (Concatenate)   (None, 800)          0           concatenate_128[0][0]            \n",
      "                                                                 concatenate_129[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 800)          3200        concatenate_130[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_38 (Dense)                (None, 256)          205056      batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 256)          0           dense_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 256)          1024        dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_39 (Dense)                (None, 256)          65792       batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 256)          0           dense_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 256)          1024        dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_40 (Dense)                (None, 3)            771         batch_normalization_12[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 20,657,767\n",
      "Trainable params: 655,143\n",
      "Non-trainable params: 20,002,624\n",
      "__________________________________________________________________________________________________\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360609/360609 [==============================] - 38s 104us/step - loss: 0.0165 - acc: 0.9113 - weighted_accuracy: 0.9105 - val_loss: 0.3020 - val_acc: 0.8662 - val_weighted_accuracy: 0.8613\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0166 - acc: 0.9106 - weighted_accuracy: 0.9101 - val_loss: 0.3340 - val_acc: 0.8538 - val_weighted_accuracy: 0.8542\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0165 - acc: 0.9121 - weighted_accuracy: 0.9114 - val_loss: 0.2863 - val_acc: 0.8761 - val_weighted_accuracy: 0.8669\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0163 - acc: 0.9129 - weighted_accuracy: 0.9123 - val_loss: 0.2999 - val_acc: 0.8693 - val_weighted_accuracy: 0.8649\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 37s 102us/step - loss: 0.0162 - acc: 0.9136 - weighted_accuracy: 0.9132 - val_loss: 0.3090 - val_acc: 0.8661 - val_weighted_accuracy: 0.8615\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 37s 101us/step - loss: 0.0161 - acc: 0.9154 - weighted_accuracy: 0.9151 - val_loss: 0.3173 - val_acc: 0.8598 - val_weighted_accuracy: 0.8583\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 36s 100us/step - loss: 0.0160 - acc: 0.9153 - weighted_accuracy: 0.9152 - val_loss: 0.2860 - val_acc: 0.8748 - val_weighted_accuracy: 0.8668\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0158 - acc: 0.9167 - weighted_accuracy: 0.9165 - val_loss: 0.3038 - val_acc: 0.8665 - val_weighted_accuracy: 0.8644\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0157 - acc: 0.9173 - weighted_accuracy: 0.9175 - val_loss: 0.2871 - val_acc: 0.8743 - val_weighted_accuracy: 0.8675\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0157 - acc: 0.9176 - weighted_accuracy: 0.9176 - val_loss: 0.2934 - val_acc: 0.8707 - val_weighted_accuracy: 0.8669\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 36s 100us/step - loss: 0.0156 - acc: 0.9186 - weighted_accuracy: 0.9188 - val_loss: 0.2919 - val_acc: 0.8721 - val_weighted_accuracy: 0.8672\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0155 - acc: 0.9190 - weighted_accuracy: 0.9193 - val_loss: 0.2972 - val_acc: 0.8704 - val_weighted_accuracy: 0.8665\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0154 - acc: 0.9196 - weighted_accuracy: 0.9200 - val_loss: 0.3018 - val_acc: 0.8687 - val_weighted_accuracy: 0.8653\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0154 - acc: 0.9199 - weighted_accuracy: 0.9202 - val_loss: 0.2883 - val_acc: 0.8747 - val_weighted_accuracy: 0.8679\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0152 - acc: 0.9201 - weighted_accuracy: 0.9205 - val_loss: 0.3083 - val_acc: 0.8658 - val_weighted_accuracy: 0.8623\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0152 - acc: 0.9212 - weighted_accuracy: 0.9216 - val_loss: 0.3154 - val_acc: 0.8622 - val_weighted_accuracy: 0.8602\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0152 - acc: 0.9212 - weighted_accuracy: 0.9216 - val_loss: 0.2989 - val_acc: 0.8696 - val_weighted_accuracy: 0.8647\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0151 - acc: 0.9217 - weighted_accuracy: 0.9223 - val_loss: 0.3174 - val_acc: 0.8614 - val_weighted_accuracy: 0.8599\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 35s 96us/step - loss: 0.0150 - acc: 0.9229 - weighted_accuracy: 0.9235 - val_loss: 0.3166 - val_acc: 0.8637 - val_weighted_accuracy: 0.8598\n",
      "Epoch 20/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0150 - acc: 0.9226 - weighted_accuracy: 0.9233 - val_loss: 0.3092 - val_acc: 0.8650 - val_weighted_accuracy: 0.8620\n",
      "Epoch 21/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0149 - acc: 0.9232 - weighted_accuracy: 0.9238 - val_loss: 0.3016 - val_acc: 0.8681 - val_weighted_accuracy: 0.8647\n",
      "Epoch 22/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0148 - acc: 0.9238 - weighted_accuracy: 0.9244 - val_loss: 0.2949 - val_acc: 0.8718 - val_weighted_accuracy: 0.8665\n",
      "Epoch 23/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0148 - acc: 0.9239 - weighted_accuracy: 0.9244 - val_loss: 0.2995 - val_acc: 0.8700 - val_weighted_accuracy: 0.8667\n",
      "Epoch 24/500\n",
      "360609/360609 [==============================] - 36s 100us/step - loss: 0.0148 - acc: 0.9236 - weighted_accuracy: 0.9241 - val_loss: 0.3054 - val_acc: 0.8694 - val_weighted_accuracy: 0.8659\n",
      "Epoch 25/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0147 - acc: 0.9249 - weighted_accuracy: 0.9257 - val_loss: 0.2952 - val_acc: 0.8699 - val_weighted_accuracy: 0.8658\n",
      "Epoch 26/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0146 - acc: 0.9251 - weighted_accuracy: 0.9259 - val_loss: 0.3017 - val_acc: 0.8681 - val_weighted_accuracy: 0.8639\n",
      "Epoch 27/500\n",
      "360609/360609 [==============================] - 35s 96us/step - loss: 0.0146 - acc: 0.9255 - weighted_accuracy: 0.9263 - val_loss: 0.2938 - val_acc: 0.8714 - val_weighted_accuracy: 0.8665\n",
      "Epoch 28/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0145 - acc: 0.9258 - weighted_accuracy: 0.9269 - val_loss: 0.2871 - val_acc: 0.8743 - val_weighted_accuracy: 0.8679\n",
      "Epoch 29/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0145 - acc: 0.9259 - weighted_accuracy: 0.9266 - val_loss: 0.2962 - val_acc: 0.8719 - val_weighted_accuracy: 0.8672\n",
      "Epoch 30/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0144 - acc: 0.9262 - weighted_accuracy: 0.9271 - val_loss: 0.3011 - val_acc: 0.8680 - val_weighted_accuracy: 0.8645\n",
      "Epoch 31/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0144 - acc: 0.9270 - weighted_accuracy: 0.9279 - val_loss: 0.2993 - val_acc: 0.8719 - val_weighted_accuracy: 0.8662\n",
      "Epoch 32/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0144 - acc: 0.9264 - weighted_accuracy: 0.9271 - val_loss: 0.2920 - val_acc: 0.8730 - val_weighted_accuracy: 0.8668\n",
      "Epoch 33/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0143 - acc: 0.9274 - weighted_accuracy: 0.9283 - val_loss: 0.3044 - val_acc: 0.8698 - val_weighted_accuracy: 0.8647\n",
      "Epoch 34/500\n",
      "360609/360609 [==============================] - 36s 98us/step - loss: 0.0144 - acc: 0.9271 - weighted_accuracy: 0.9279 - val_loss: 0.3151 - val_acc: 0.8629 - val_weighted_accuracy: 0.8612\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_19 (Embedding)        (None, 30, 200)      20000000    first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_29 (SpatialDr (None, 30, 200)      0           embedding_19[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_30 (SpatialDr (None, 30, 200)      0           embedding_19[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_47 (TimeDistri (None, 30, 200)      80400       spatial_dropout1d_29[0][0]       \n",
      "                                                                 spatial_dropout1d_30[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dot_133 (Dot)                   (None, 30, 30)       0           time_distributed_47[0][0]        \n",
      "                                                                 time_distributed_47[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_108 (Lambda)             (None, 30, 30)       0           dot_133[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_45 (Permute)            (None, 30, 30)       0           lambda_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_107 (Lambda)             (None, 30, 30)       0           dot_133[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_135 (Dot)                   (None, 30, 200)      0           permute_45[0][0]                 \n",
      "                                                                 time_distributed_47[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dot_134 (Dot)                   (None, 30, 200)      0           lambda_107[0][0]                 \n",
      "                                                                 time_distributed_47[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_109 (Lambda)             (None, 30, 200)      0           time_distributed_47[0][0]        \n",
      "                                                                 dot_135[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_19 (Multiply)          (None, 30, 200)      0           time_distributed_47[0][0]        \n",
      "                                                                 dot_135[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_110 (Lambda)             (None, 30, 200)      0           time_distributed_47[1][0]        \n",
      "                                                                 dot_134[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_20 (Multiply)          (None, 30, 200)      0           time_distributed_47[1][0]        \n",
      "                                                                 dot_134[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_131 (Concatenate)   (None, 30, 800)      0           time_distributed_47[0][0]        \n",
      "                                                                 dot_135[0][0]                    \n",
      "                                                                 lambda_109[0][0]                 \n",
      "                                                                 multiply_19[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_132 (Concatenate)   (None, 30, 800)      0           time_distributed_47[1][0]        \n",
      "                                                                 dot_134[0][0]                    \n",
      "                                                                 lambda_110[0][0]                 \n",
      "                                                                 multiply_20[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_48 (TimeDistri (None, 30, 300)      240300      concatenate_131[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_52 (TimeDistri (None, 30, 300)      240300      concatenate_132[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_49 (TimeDistri (None, 30, 300)      0           time_distributed_48[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_53 (TimeDistri (None, 30, 300)      0           time_distributed_52[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_50 (TimeDistri (None, 30, 200)      60200       time_distributed_49[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_54 (TimeDistri (None, 30, 200)      60200       time_distributed_53[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_51 (TimeDistri (None, 30, 200)      0           time_distributed_50[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_55 (TimeDistri (None, 30, 200)      0           time_distributed_54[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_29 (Gl (None, 200)          0           time_distributed_51[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_29 (Global (None, 200)          0           time_distributed_51[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_30 (Gl (None, 200)          0           time_distributed_55[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_30 (Global (None, 200)          0           time_distributed_55[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_133 (Concatenate)   (None, 400)          0           global_average_pooling1d_29[0][0]\n",
      "                                                                 global_max_pooling1d_29[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_134 (Concatenate)   (None, 400)          0           global_average_pooling1d_30[0][0]\n",
      "                                                                 global_max_pooling1d_30[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_135 (Concatenate)   (None, 800)          0           concatenate_133[0][0]            \n",
      "                                                                 concatenate_134[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 800)          3200        concatenate_135[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_43 (Dense)                (None, 256)          205056      batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 256)          0           dense_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 256)          1024        dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_44 (Dense)                (None, 256)          65792       batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 256)          0           dense_44[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 256)          1024        dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_45 (Dense)                (None, 3)            771         batch_normalization_15[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 20,657,767\n",
      "Trainable params: 655,143\n",
      "Non-trainable params: 20,002,624\n",
      "__________________________________________________________________________________________________\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360609/360609 [==============================] - 38s 105us/step - loss: 0.0178 - acc: 0.9035 - weighted_accuracy: 0.9012 - val_loss: 0.3189 - val_acc: 0.8541 - val_weighted_accuracy: 0.8500\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 36s 101us/step - loss: 0.0177 - acc: 0.9042 - weighted_accuracy: 0.9023 - val_loss: 0.3087 - val_acc: 0.8611 - val_weighted_accuracy: 0.8549\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 36s 101us/step - loss: 0.0174 - acc: 0.9057 - weighted_accuracy: 0.9039 - val_loss: 0.3179 - val_acc: 0.8505 - val_weighted_accuracy: 0.8479\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0173 - acc: 0.9075 - weighted_accuracy: 0.9060 - val_loss: 0.3110 - val_acc: 0.8585 - val_weighted_accuracy: 0.8526\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0171 - acc: 0.9083 - weighted_accuracy: 0.9069 - val_loss: 0.3275 - val_acc: 0.8504 - val_weighted_accuracy: 0.8456\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0169 - acc: 0.9095 - weighted_accuracy: 0.9083 - val_loss: 0.3250 - val_acc: 0.8502 - val_weighted_accuracy: 0.8487\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0168 - acc: 0.9109 - weighted_accuracy: 0.9097 - val_loss: 0.3125 - val_acc: 0.8573 - val_weighted_accuracy: 0.8530\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0166 - acc: 0.9112 - weighted_accuracy: 0.9102 - val_loss: 0.3201 - val_acc: 0.8559 - val_weighted_accuracy: 0.8527\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0165 - acc: 0.9121 - weighted_accuracy: 0.9112 - val_loss: 0.3061 - val_acc: 0.8593 - val_weighted_accuracy: 0.8540\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0164 - acc: 0.9129 - weighted_accuracy: 0.9122 - val_loss: 0.3082 - val_acc: 0.8580 - val_weighted_accuracy: 0.8538\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0162 - acc: 0.9136 - weighted_accuracy: 0.9131 - val_loss: 0.3263 - val_acc: 0.8513 - val_weighted_accuracy: 0.8490\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0162 - acc: 0.9147 - weighted_accuracy: 0.9142 - val_loss: 0.3167 - val_acc: 0.8579 - val_weighted_accuracy: 0.8542\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0160 - acc: 0.9148 - weighted_accuracy: 0.9144 - val_loss: 0.3247 - val_acc: 0.8543 - val_weighted_accuracy: 0.8521\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0160 - acc: 0.9155 - weighted_accuracy: 0.9150 - val_loss: 0.3041 - val_acc: 0.8609 - val_weighted_accuracy: 0.8545\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0159 - acc: 0.9165 - weighted_accuracy: 0.9163 - val_loss: 0.3228 - val_acc: 0.8534 - val_weighted_accuracy: 0.8505\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0158 - acc: 0.9173 - weighted_accuracy: 0.9169 - val_loss: 0.3303 - val_acc: 0.8503 - val_weighted_accuracy: 0.8500\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0158 - acc: 0.9175 - weighted_accuracy: 0.9173 - val_loss: 0.3245 - val_acc: 0.8554 - val_weighted_accuracy: 0.8523\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0157 - acc: 0.9183 - weighted_accuracy: 0.9182 - val_loss: 0.3134 - val_acc: 0.8591 - val_weighted_accuracy: 0.8541\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0156 - acc: 0.9187 - weighted_accuracy: 0.9189 - val_loss: 0.3038 - val_acc: 0.8602 - val_weighted_accuracy: 0.8542\n",
      "Epoch 20/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0155 - acc: 0.9193 - weighted_accuracy: 0.9192 - val_loss: 0.3139 - val_acc: 0.8599 - val_weighted_accuracy: 0.8547\n",
      "Epoch 21/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0154 - acc: 0.9199 - weighted_accuracy: 0.9201 - val_loss: 0.3172 - val_acc: 0.8591 - val_weighted_accuracy: 0.8548\n",
      "Epoch 22/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0154 - acc: 0.9200 - weighted_accuracy: 0.9200 - val_loss: 0.3180 - val_acc: 0.8562 - val_weighted_accuracy: 0.8539\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_21 (Embedding)        (None, 30, 200)      20000000    first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_31 (SpatialDr (None, 30, 200)      0           embedding_21[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_32 (SpatialDr (None, 30, 200)      0           embedding_21[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_56 (TimeDistri (None, 30, 200)      80400       spatial_dropout1d_31[0][0]       \n",
      "                                                                 spatial_dropout1d_32[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dot_136 (Dot)                   (None, 30, 30)       0           time_distributed_56[0][0]        \n",
      "                                                                 time_distributed_56[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_112 (Lambda)             (None, 30, 30)       0           dot_136[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_46 (Permute)            (None, 30, 30)       0           lambda_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_111 (Lambda)             (None, 30, 30)       0           dot_136[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_138 (Dot)                   (None, 30, 200)      0           permute_46[0][0]                 \n",
      "                                                                 time_distributed_56[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dot_137 (Dot)                   (None, 30, 200)      0           lambda_111[0][0]                 \n",
      "                                                                 time_distributed_56[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_113 (Lambda)             (None, 30, 200)      0           time_distributed_56[0][0]        \n",
      "                                                                 dot_138[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_21 (Multiply)          (None, 30, 200)      0           time_distributed_56[0][0]        \n",
      "                                                                 dot_138[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_114 (Lambda)             (None, 30, 200)      0           time_distributed_56[1][0]        \n",
      "                                                                 dot_137[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_22 (Multiply)          (None, 30, 200)      0           time_distributed_56[1][0]        \n",
      "                                                                 dot_137[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_136 (Concatenate)   (None, 30, 800)      0           time_distributed_56[0][0]        \n",
      "                                                                 dot_138[0][0]                    \n",
      "                                                                 lambda_113[0][0]                 \n",
      "                                                                 multiply_21[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_137 (Concatenate)   (None, 30, 800)      0           time_distributed_56[1][0]        \n",
      "                                                                 dot_137[0][0]                    \n",
      "                                                                 lambda_114[0][0]                 \n",
      "                                                                 multiply_22[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_57 (TimeDistri (None, 30, 300)      240300      concatenate_136[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_61 (TimeDistri (None, 30, 300)      240300      concatenate_137[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_58 (TimeDistri (None, 30, 300)      0           time_distributed_57[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_62 (TimeDistri (None, 30, 300)      0           time_distributed_61[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_59 (TimeDistri (None, 30, 200)      60200       time_distributed_58[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_63 (TimeDistri (None, 30, 200)      60200       time_distributed_62[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_60 (TimeDistri (None, 30, 200)      0           time_distributed_59[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_64 (TimeDistri (None, 30, 200)      0           time_distributed_63[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_31 (Gl (None, 200)          0           time_distributed_60[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_31 (Global (None, 200)          0           time_distributed_60[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_32 (Gl (None, 200)          0           time_distributed_64[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_32 (Global (None, 200)          0           time_distributed_64[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_138 (Concatenate)   (None, 400)          0           global_average_pooling1d_31[0][0]\n",
      "                                                                 global_max_pooling1d_31[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_139 (Concatenate)   (None, 400)          0           global_average_pooling1d_32[0][0]\n",
      "                                                                 global_max_pooling1d_32[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_140 (Concatenate)   (None, 800)          0           concatenate_138[0][0]            \n",
      "                                                                 concatenate_139[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 800)          3200        concatenate_140[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_48 (Dense)                (None, 256)          205056      batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 256)          0           dense_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 256)          1024        dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_49 (Dense)                (None, 256)          65792       batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 256)          0           dense_49[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 256)          1024        dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_50 (Dense)                (None, 3)            771         batch_normalization_18[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 20,657,767\n",
      "Trainable params: 655,143\n",
      "Non-trainable params: 20,002,624\n",
      "__________________________________________________________________________________________________\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360609/360609 [==============================] - 39s 107us/step - loss: 0.0167 - acc: 0.9103 - weighted_accuracy: 0.9094 - val_loss: 0.3437 - val_acc: 0.8437 - val_weighted_accuracy: 0.8420\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0167 - acc: 0.9100 - weighted_accuracy: 0.9088 - val_loss: 0.3276 - val_acc: 0.8496 - val_weighted_accuracy: 0.8415\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0165 - acc: 0.9118 - weighted_accuracy: 0.9108 - val_loss: 0.3308 - val_acc: 0.8493 - val_weighted_accuracy: 0.8405\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0163 - acc: 0.9128 - weighted_accuracy: 0.9119 - val_loss: 0.3381 - val_acc: 0.8462 - val_weighted_accuracy: 0.8396\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0163 - acc: 0.9138 - weighted_accuracy: 0.9130 - val_loss: 0.3339 - val_acc: 0.8469 - val_weighted_accuracy: 0.8400\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0160 - acc: 0.9150 - weighted_accuracy: 0.9144 - val_loss: 0.3297 - val_acc: 0.8498 - val_weighted_accuracy: 0.8436\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0159 - acc: 0.9162 - weighted_accuracy: 0.9157 - val_loss: 0.3294 - val_acc: 0.8513 - val_weighted_accuracy: 0.8432\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0158 - acc: 0.9171 - weighted_accuracy: 0.9167 - val_loss: 0.3458 - val_acc: 0.8438 - val_weighted_accuracy: 0.8392\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0157 - acc: 0.9177 - weighted_accuracy: 0.9174 - val_loss: 0.3314 - val_acc: 0.8486 - val_weighted_accuracy: 0.8417\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0156 - acc: 0.9180 - weighted_accuracy: 0.9176 - val_loss: 0.3266 - val_acc: 0.8518 - val_weighted_accuracy: 0.8429\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0156 - acc: 0.9187 - weighted_accuracy: 0.9184 - val_loss: 0.3399 - val_acc: 0.8462 - val_weighted_accuracy: 0.8376\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0155 - acc: 0.9185 - weighted_accuracy: 0.9184 - val_loss: 0.3378 - val_acc: 0.8480 - val_weighted_accuracy: 0.8408\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0154 - acc: 0.9196 - weighted_accuracy: 0.9197 - val_loss: 0.3421 - val_acc: 0.8444 - val_weighted_accuracy: 0.8362\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0153 - acc: 0.9207 - weighted_accuracy: 0.9207 - val_loss: 0.3511 - val_acc: 0.8378 - val_weighted_accuracy: 0.8353\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0152 - acc: 0.9206 - weighted_accuracy: 0.9206 - val_loss: 0.3537 - val_acc: 0.8422 - val_weighted_accuracy: 0.8349\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0151 - acc: 0.9216 - weighted_accuracy: 0.9219 - val_loss: 0.3351 - val_acc: 0.8466 - val_weighted_accuracy: 0.8420\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0151 - acc: 0.9215 - weighted_accuracy: 0.9218 - val_loss: 0.3279 - val_acc: 0.8513 - val_weighted_accuracy: 0.8400\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0151 - acc: 0.9217 - weighted_accuracy: 0.9218 - val_loss: 0.3391 - val_acc: 0.8474 - val_weighted_accuracy: 0.8427\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0150 - acc: 0.9222 - weighted_accuracy: 0.9227 - val_loss: 0.3404 - val_acc: 0.8452 - val_weighted_accuracy: 0.8423\n",
      "Epoch 20/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0149 - acc: 0.9229 - weighted_accuracy: 0.9234 - val_loss: 0.3313 - val_acc: 0.8506 - val_weighted_accuracy: 0.8424\n",
      "Epoch 21/500\n",
      "360609/360609 [==============================] - 36s 100us/step - loss: 0.0148 - acc: 0.9237 - weighted_accuracy: 0.9242 - val_loss: 0.3218 - val_acc: 0.8532 - val_weighted_accuracy: 0.8427\n",
      "Epoch 22/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0148 - acc: 0.9240 - weighted_accuracy: 0.9244 - val_loss: 0.3454 - val_acc: 0.8445 - val_weighted_accuracy: 0.8412\n",
      "Epoch 23/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0148 - acc: 0.9240 - weighted_accuracy: 0.9244 - val_loss: 0.3327 - val_acc: 0.8534 - val_weighted_accuracy: 0.8458\n",
      "Epoch 24/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0147 - acc: 0.9249 - weighted_accuracy: 0.9254 - val_loss: 0.3302 - val_acc: 0.8508 - val_weighted_accuracy: 0.8447\n",
      "Epoch 25/500\n",
      "360609/360609 [==============================] - 36s 100us/step - loss: 0.0146 - acc: 0.9257 - weighted_accuracy: 0.9263 - val_loss: 0.3580 - val_acc: 0.8377 - val_weighted_accuracy: 0.8332\n",
      "Epoch 26/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0146 - acc: 0.9254 - weighted_accuracy: 0.9260 - val_loss: 0.3313 - val_acc: 0.8512 - val_weighted_accuracy: 0.8446\n",
      "Epoch 27/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0146 - acc: 0.9258 - weighted_accuracy: 0.9265 - val_loss: 0.3279 - val_acc: 0.8527 - val_weighted_accuracy: 0.8438\n",
      "Epoch 28/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0145 - acc: 0.9259 - weighted_accuracy: 0.9264 - val_loss: 0.3252 - val_acc: 0.8545 - val_weighted_accuracy: 0.8436\n",
      "Epoch 29/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0144 - acc: 0.9266 - weighted_accuracy: 0.9273 - val_loss: 0.3253 - val_acc: 0.8534 - val_weighted_accuracy: 0.8453\n",
      "Epoch 30/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0144 - acc: 0.9269 - weighted_accuracy: 0.9276 - val_loss: 0.3346 - val_acc: 0.8528 - val_weighted_accuracy: 0.8436\n",
      "Epoch 31/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0143 - acc: 0.9274 - weighted_accuracy: 0.9282 - val_loss: 0.3410 - val_acc: 0.8457 - val_weighted_accuracy: 0.8417\n",
      "Epoch 32/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0143 - acc: 0.9272 - weighted_accuracy: 0.9280 - val_loss: 0.3349 - val_acc: 0.8506 - val_weighted_accuracy: 0.8426\n",
      "Epoch 33/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0143 - acc: 0.9279 - weighted_accuracy: 0.9288 - val_loss: 0.3222 - val_acc: 0.8564 - val_weighted_accuracy: 0.8472\n",
      "Epoch 34/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0142 - acc: 0.9277 - weighted_accuracy: 0.9286 - val_loss: 0.3316 - val_acc: 0.8524 - val_weighted_accuracy: 0.8463\n",
      "Epoch 35/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0142 - acc: 0.9278 - weighted_accuracy: 0.9287 - val_loss: 0.3281 - val_acc: 0.8544 - val_weighted_accuracy: 0.8470\n",
      "Epoch 36/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0142 - acc: 0.9291 - weighted_accuracy: 0.9298 - val_loss: 0.3460 - val_acc: 0.8470 - val_weighted_accuracy: 0.8414\n",
      "Epoch 37/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0142 - acc: 0.9288 - weighted_accuracy: 0.9295 - val_loss: 0.3376 - val_acc: 0.8515 - val_weighted_accuracy: 0.8450\n",
      "Epoch 38/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0141 - acc: 0.9287 - weighted_accuracy: 0.9296 - val_loss: 0.3326 - val_acc: 0.8540 - val_weighted_accuracy: 0.8460\n",
      "Epoch 39/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0141 - acc: 0.9289 - weighted_accuracy: 0.9297 - val_loss: 0.3340 - val_acc: 0.8516 - val_weighted_accuracy: 0.8462\n",
      "Epoch 40/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0140 - acc: 0.9296 - weighted_accuracy: 0.9305 - val_loss: 0.3465 - val_acc: 0.8470 - val_weighted_accuracy: 0.8426\n",
      "Epoch 41/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0140 - acc: 0.9298 - weighted_accuracy: 0.9307 - val_loss: 0.3318 - val_acc: 0.8504 - val_weighted_accuracy: 0.8443\n",
      "Epoch 42/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0140 - acc: 0.9301 - weighted_accuracy: 0.9309 - val_loss: 0.3519 - val_acc: 0.8427 - val_weighted_accuracy: 0.8378\n",
      "Epoch 43/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0138 - acc: 0.9308 - weighted_accuracy: 0.9319 - val_loss: 0.3291 - val_acc: 0.8559 - val_weighted_accuracy: 0.8449\n",
      "Epoch 44/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0139 - acc: 0.9303 - weighted_accuracy: 0.9313 - val_loss: 0.3397 - val_acc: 0.8487 - val_weighted_accuracy: 0.8429\n",
      "Epoch 45/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0138 - acc: 0.9309 - weighted_accuracy: 0.9318 - val_loss: 0.3334 - val_acc: 0.8537 - val_weighted_accuracy: 0.8450\n",
      "Epoch 46/500\n",
      "360609/360609 [==============================] - 36s 101us/step - loss: 0.0138 - acc: 0.9306 - weighted_accuracy: 0.9316 - val_loss: 0.3401 - val_acc: 0.8510 - val_weighted_accuracy: 0.8439\n",
      "Epoch 47/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0137 - acc: 0.9315 - weighted_accuracy: 0.9325 - val_loss: 0.3388 - val_acc: 0.8507 - val_weighted_accuracy: 0.8434\n",
      "Epoch 48/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0137 - acc: 0.9314 - weighted_accuracy: 0.9325 - val_loss: 0.3308 - val_acc: 0.8547 - val_weighted_accuracy: 0.8438\n",
      "Epoch 49/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0137 - acc: 0.9319 - weighted_accuracy: 0.9330 - val_loss: 0.3329 - val_acc: 0.8543 - val_weighted_accuracy: 0.8474\n",
      "Epoch 50/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0137 - acc: 0.9323 - weighted_accuracy: 0.9332 - val_loss: 0.3303 - val_acc: 0.8538 - val_weighted_accuracy: 0.8451\n",
      "Epoch 51/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0136 - acc: 0.9318 - weighted_accuracy: 0.9331 - val_loss: 0.3353 - val_acc: 0.8540 - val_weighted_accuracy: 0.8469\n",
      "Epoch 52/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0137 - acc: 0.9324 - weighted_accuracy: 0.9331 - val_loss: 0.3300 - val_acc: 0.8565 - val_weighted_accuracy: 0.8453\n",
      "Epoch 53/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0136 - acc: 0.9321 - weighted_accuracy: 0.9331 - val_loss: 0.3413 - val_acc: 0.8524 - val_weighted_accuracy: 0.8461\n",
      "Epoch 54/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0135 - acc: 0.9329 - weighted_accuracy: 0.9341 - val_loss: 0.3270 - val_acc: 0.8572 - val_weighted_accuracy: 0.8435\n",
      "Epoch 55/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0135 - acc: 0.9327 - weighted_accuracy: 0.9338 - val_loss: 0.3368 - val_acc: 0.8539 - val_weighted_accuracy: 0.8468\n",
      "Epoch 56/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0135 - acc: 0.9327 - weighted_accuracy: 0.9339 - val_loss: 0.3298 - val_acc: 0.8537 - val_weighted_accuracy: 0.8436\n",
      "Epoch 57/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0135 - acc: 0.9333 - weighted_accuracy: 0.9344 - val_loss: 0.3384 - val_acc: 0.8534 - val_weighted_accuracy: 0.8420\n",
      "Epoch 58/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0135 - acc: 0.9332 - weighted_accuracy: 0.9345 - val_loss: 0.3293 - val_acc: 0.8559 - val_weighted_accuracy: 0.8461\n",
      "Epoch 59/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0134 - acc: 0.9337 - weighted_accuracy: 0.9350 - val_loss: 0.3382 - val_acc: 0.8530 - val_weighted_accuracy: 0.8410\n",
      "Epoch 60/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0133 - acc: 0.9341 - weighted_accuracy: 0.9353 - val_loss: 0.3313 - val_acc: 0.8565 - val_weighted_accuracy: 0.8452\n",
      "Epoch 61/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0134 - acc: 0.9340 - weighted_accuracy: 0.9353 - val_loss: 0.3259 - val_acc: 0.8576 - val_weighted_accuracy: 0.8439\n",
      "Epoch 62/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0133 - acc: 0.9347 - weighted_accuracy: 0.9359 - val_loss: 0.3338 - val_acc: 0.8566 - val_weighted_accuracy: 0.8468\n",
      "Epoch 63/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0133 - acc: 0.9349 - weighted_accuracy: 0.9360 - val_loss: 0.3385 - val_acc: 0.8523 - val_weighted_accuracy: 0.8421\n",
      "Epoch 64/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0134 - acc: 0.9342 - weighted_accuracy: 0.9352 - val_loss: 0.3318 - val_acc: 0.8565 - val_weighted_accuracy: 0.8455\n",
      "Epoch 65/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0133 - acc: 0.9346 - weighted_accuracy: 0.9357 - val_loss: 0.3430 - val_acc: 0.8519 - val_weighted_accuracy: 0.8427\n",
      "Epoch 66/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0132 - acc: 0.9349 - weighted_accuracy: 0.9363 - val_loss: 0.3268 - val_acc: 0.8570 - val_weighted_accuracy: 0.8468\n",
      "Epoch 67/500\n",
      "360609/360609 [==============================] - 36s 100us/step - loss: 0.0132 - acc: 0.9346 - weighted_accuracy: 0.9359 - val_loss: 0.3281 - val_acc: 0.8589 - val_weighted_accuracy: 0.8477\n",
      "Epoch 68/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0132 - acc: 0.9355 - weighted_accuracy: 0.9366 - val_loss: 0.3360 - val_acc: 0.8523 - val_weighted_accuracy: 0.8434\n",
      "Epoch 69/500\n",
      "360609/360609 [==============================] - 36s 100us/step - loss: 0.0132 - acc: 0.9353 - weighted_accuracy: 0.9365 - val_loss: 0.3292 - val_acc: 0.8546 - val_weighted_accuracy: 0.8438\n",
      "Epoch 70/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0131 - acc: 0.9352 - weighted_accuracy: 0.9367 - val_loss: 0.3331 - val_acc: 0.8567 - val_weighted_accuracy: 0.8472\n",
      "Epoch 71/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0131 - acc: 0.9358 - weighted_accuracy: 0.9373 - val_loss: 0.3352 - val_acc: 0.8551 - val_weighted_accuracy: 0.8458\n",
      "Epoch 72/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0131 - acc: 0.9355 - weighted_accuracy: 0.9367 - val_loss: 0.3300 - val_acc: 0.8561 - val_weighted_accuracy: 0.8438\n",
      "Epoch 73/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0131 - acc: 0.9361 - weighted_accuracy: 0.9375 - val_loss: 0.3290 - val_acc: 0.8543 - val_weighted_accuracy: 0.8459\n",
      "Epoch 74/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0131 - acc: 0.9365 - weighted_accuracy: 0.9378 - val_loss: 0.3344 - val_acc: 0.8532 - val_weighted_accuracy: 0.8436\n",
      "Epoch 75/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0130 - acc: 0.9362 - weighted_accuracy: 0.9375 - val_loss: 0.3477 - val_acc: 0.8475 - val_weighted_accuracy: 0.8412\n",
      "Epoch 76/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0130 - acc: 0.9373 - weighted_accuracy: 0.9387 - val_loss: 0.3314 - val_acc: 0.8599 - val_weighted_accuracy: 0.8477\n",
      "Epoch 77/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0130 - acc: 0.9368 - weighted_accuracy: 0.9381 - val_loss: 0.3309 - val_acc: 0.8559 - val_weighted_accuracy: 0.8444\n",
      "Epoch 78/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0130 - acc: 0.9370 - weighted_accuracy: 0.9384 - val_loss: 0.3467 - val_acc: 0.8521 - val_weighted_accuracy: 0.8424\n",
      "Epoch 79/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0130 - acc: 0.9363 - weighted_accuracy: 0.9377 - val_loss: 0.3346 - val_acc: 0.8525 - val_weighted_accuracy: 0.8439\n",
      "Epoch 80/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0129 - acc: 0.9375 - weighted_accuracy: 0.9388 - val_loss: 0.3411 - val_acc: 0.8548 - val_weighted_accuracy: 0.8432\n",
      "Epoch 81/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0129 - acc: 0.9373 - weighted_accuracy: 0.9388 - val_loss: 0.3366 - val_acc: 0.8560 - val_weighted_accuracy: 0.8452\n",
      "Epoch 82/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0129 - acc: 0.9374 - weighted_accuracy: 0.9388 - val_loss: 0.3389 - val_acc: 0.8551 - val_weighted_accuracy: 0.8447  - \n",
      "Epoch 83/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0129 - acc: 0.9372 - weighted_accuracy: 0.9388 - val_loss: 0.3402 - val_acc: 0.8565 - val_weighted_accuracy: 0.8470\n",
      "Epoch 84/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0129 - acc: 0.9375 - weighted_accuracy: 0.9389 - val_loss: 0.3383 - val_acc: 0.8554 - val_weighted_accuracy: 0.8457\n",
      "Epoch 85/500\n",
      "360609/360609 [==============================] - 36s 100us/step - loss: 0.0129 - acc: 0.9375 - weighted_accuracy: 0.9389 - val_loss: 0.3337 - val_acc: 0.8544 - val_weighted_accuracy: 0.8440\n",
      "Epoch 86/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0128 - acc: 0.9380 - weighted_accuracy: 0.9395 - val_loss: 0.3381 - val_acc: 0.8559 - val_weighted_accuracy: 0.8451\n",
      "Epoch 87/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0128 - acc: 0.9381 - weighted_accuracy: 0.9394 - val_loss: 0.3333 - val_acc: 0.8591 - val_weighted_accuracy: 0.8477\n",
      "Epoch 88/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0128 - acc: 0.9388 - weighted_accuracy: 0.9403 - val_loss: 0.3380 - val_acc: 0.8579 - val_weighted_accuracy: 0.8478\n",
      "Epoch 89/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0128 - acc: 0.9386 - weighted_accuracy: 0.9399 - val_loss: 0.3430 - val_acc: 0.8546 - val_weighted_accuracy: 0.8451\n",
      "Epoch 90/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0128 - acc: 0.9379 - weighted_accuracy: 0.9392 - val_loss: 0.3338 - val_acc: 0.8574 - val_weighted_accuracy: 0.8466\n",
      "Epoch 91/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0128 - acc: 0.9386 - weighted_accuracy: 0.9401 - val_loss: 0.3358 - val_acc: 0.8578 - val_weighted_accuracy: 0.8464\n",
      "Epoch 92/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0127 - acc: 0.9383 - weighted_accuracy: 0.9398 - val_loss: 0.3334 - val_acc: 0.8577 - val_weighted_accuracy: 0.8477\n",
      "Epoch 93/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0127 - acc: 0.9389 - weighted_accuracy: 0.9402 - val_loss: 0.3317 - val_acc: 0.8595 - val_weighted_accuracy: 0.8490\n",
      "Epoch 94/500\n",
      "360609/360609 [==============================] - 36s 98us/step - loss: 0.0127 - acc: 0.9388 - weighted_accuracy: 0.9402 - val_loss: 0.3475 - val_acc: 0.8540 - val_weighted_accuracy: 0.8450\n",
      "Epoch 95/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0126 - acc: 0.9391 - weighted_accuracy: 0.9405 - val_loss: 0.3469 - val_acc: 0.8548 - val_weighted_accuracy: 0.8466\n",
      "Epoch 96/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0127 - acc: 0.9390 - weighted_accuracy: 0.9403 - val_loss: 0.3358 - val_acc: 0.8582 - val_weighted_accuracy: 0.8465\n",
      "Epoch 97/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0127 - acc: 0.9390 - weighted_accuracy: 0.9405 - val_loss: 0.3368 - val_acc: 0.8568 - val_weighted_accuracy: 0.8458\n",
      "Epoch 98/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0126 - acc: 0.9395 - weighted_accuracy: 0.9407 - val_loss: 0.3420 - val_acc: 0.8566 - val_weighted_accuracy: 0.8477\n",
      "Epoch 99/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0126 - acc: 0.9393 - weighted_accuracy: 0.9409 - val_loss: 0.3406 - val_acc: 0.8582 - val_weighted_accuracy: 0.8488\n",
      "Epoch 100/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0126 - acc: 0.9396 - weighted_accuracy: 0.9410 - val_loss: 0.3277 - val_acc: 0.8603 - val_weighted_accuracy: 0.8488\n",
      "Epoch 101/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0126 - acc: 0.9393 - weighted_accuracy: 0.9409 - val_loss: 0.3376 - val_acc: 0.8566 - val_weighted_accuracy: 0.8476\n",
      "Epoch 102/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0126 - acc: 0.9395 - weighted_accuracy: 0.9411 - val_loss: 0.3400 - val_acc: 0.8537 - val_weighted_accuracy: 0.8440\n",
      "Epoch 103/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0126 - acc: 0.9397 - weighted_accuracy: 0.9411 - val_loss: 0.3344 - val_acc: 0.8580 - val_weighted_accuracy: 0.8478\n",
      "Epoch 104/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0126 - acc: 0.9395 - weighted_accuracy: 0.9409 - val_loss: 0.3302 - val_acc: 0.8589 - val_weighted_accuracy: 0.8482\n",
      "Epoch 105/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0125 - acc: 0.9399 - weighted_accuracy: 0.9416 - val_loss: 0.3409 - val_acc: 0.8560 - val_weighted_accuracy: 0.8462\n",
      "Epoch 106/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0126 - acc: 0.9397 - weighted_accuracy: 0.9412 - val_loss: 0.3446 - val_acc: 0.8537 - val_weighted_accuracy: 0.8452\n",
      "Epoch 107/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0125 - acc: 0.9399 - weighted_accuracy: 0.9414 - val_loss: 0.3345 - val_acc: 0.8576 - val_weighted_accuracy: 0.8483\n",
      "Epoch 108/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0125 - acc: 0.9410 - weighted_accuracy: 0.9425 - val_loss: 0.3391 - val_acc: 0.8574 - val_weighted_accuracy: 0.8483\n",
      "Epoch 109/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0125 - acc: 0.9404 - weighted_accuracy: 0.9418 - val_loss: 0.3371 - val_acc: 0.8554 - val_weighted_accuracy: 0.8460\n",
      "Epoch 110/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0125 - acc: 0.9401 - weighted_accuracy: 0.9416 - val_loss: 0.3346 - val_acc: 0.8573 - val_weighted_accuracy: 0.8469\n",
      "Epoch 111/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0124 - acc: 0.9410 - weighted_accuracy: 0.9425 - val_loss: 0.3423 - val_acc: 0.8524 - val_weighted_accuracy: 0.8437\n",
      "Epoch 112/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0124 - acc: 0.9406 - weighted_accuracy: 0.9422 - val_loss: 0.3418 - val_acc: 0.8573 - val_weighted_accuracy: 0.8490\n",
      "Epoch 113/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0124 - acc: 0.9412 - weighted_accuracy: 0.9427 - val_loss: 0.3492 - val_acc: 0.8549 - val_weighted_accuracy: 0.8462\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_23 (Embedding)        (None, 30, 200)      20000000    first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_33 (SpatialDr (None, 30, 200)      0           embedding_23[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_34 (SpatialDr (None, 30, 200)      0           embedding_23[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_65 (TimeDistri (None, 30, 200)      80400       spatial_dropout1d_33[0][0]       \n",
      "                                                                 spatial_dropout1d_34[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dot_139 (Dot)                   (None, 30, 30)       0           time_distributed_65[0][0]        \n",
      "                                                                 time_distributed_65[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_116 (Lambda)             (None, 30, 30)       0           dot_139[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_47 (Permute)            (None, 30, 30)       0           lambda_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_115 (Lambda)             (None, 30, 30)       0           dot_139[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_141 (Dot)                   (None, 30, 200)      0           permute_47[0][0]                 \n",
      "                                                                 time_distributed_65[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dot_140 (Dot)                   (None, 30, 200)      0           lambda_115[0][0]                 \n",
      "                                                                 time_distributed_65[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_117 (Lambda)             (None, 30, 200)      0           time_distributed_65[0][0]        \n",
      "                                                                 dot_141[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_23 (Multiply)          (None, 30, 200)      0           time_distributed_65[0][0]        \n",
      "                                                                 dot_141[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_118 (Lambda)             (None, 30, 200)      0           time_distributed_65[1][0]        \n",
      "                                                                 dot_140[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_24 (Multiply)          (None, 30, 200)      0           time_distributed_65[1][0]        \n",
      "                                                                 dot_140[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_141 (Concatenate)   (None, 30, 800)      0           time_distributed_65[0][0]        \n",
      "                                                                 dot_141[0][0]                    \n",
      "                                                                 lambda_117[0][0]                 \n",
      "                                                                 multiply_23[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_142 (Concatenate)   (None, 30, 800)      0           time_distributed_65[1][0]        \n",
      "                                                                 dot_140[0][0]                    \n",
      "                                                                 lambda_118[0][0]                 \n",
      "                                                                 multiply_24[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_66 (TimeDistri (None, 30, 300)      240300      concatenate_141[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_70 (TimeDistri (None, 30, 300)      240300      concatenate_142[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_67 (TimeDistri (None, 30, 300)      0           time_distributed_66[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_71 (TimeDistri (None, 30, 300)      0           time_distributed_70[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_68 (TimeDistri (None, 30, 200)      60200       time_distributed_67[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_72 (TimeDistri (None, 30, 200)      60200       time_distributed_71[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_69 (TimeDistri (None, 30, 200)      0           time_distributed_68[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_73 (TimeDistri (None, 30, 200)      0           time_distributed_72[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_33 (Gl (None, 200)          0           time_distributed_69[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_33 (Global (None, 200)          0           time_distributed_69[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_34 (Gl (None, 200)          0           time_distributed_73[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_34 (Global (None, 200)          0           time_distributed_73[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_143 (Concatenate)   (None, 400)          0           global_average_pooling1d_33[0][0]\n",
      "                                                                 global_max_pooling1d_33[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_144 (Concatenate)   (None, 400)          0           global_average_pooling1d_34[0][0]\n",
      "                                                                 global_max_pooling1d_34[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_145 (Concatenate)   (None, 800)          0           concatenate_143[0][0]            \n",
      "                                                                 concatenate_144[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 800)          3200        concatenate_145[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_53 (Dense)                (None, 256)          205056      batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 256)          0           dense_53[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 256)          1024        dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_54 (Dense)                (None, 256)          65792       batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 256)          0           dense_54[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 256)          1024        dropout_38[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_55 (Dense)                (None, 3)            771         batch_normalization_21[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 20,657,767\n",
      "Trainable params: 655,143\n",
      "Non-trainable params: 20,002,624\n",
      "__________________________________________________________________________________________________\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360609/360609 [==============================] - 38s 105us/step - loss: 0.0176 - acc: 0.9042 - weighted_accuracy: 0.9022 - val_loss: 0.3037 - val_acc: 0.8649 - val_weighted_accuracy: 0.8644\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0175 - acc: 0.9051 - weighted_accuracy: 0.9034 - val_loss: 0.3081 - val_acc: 0.8658 - val_weighted_accuracy: 0.8636\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0173 - acc: 0.9061 - weighted_accuracy: 0.9041 - val_loss: 0.3042 - val_acc: 0.8684 - val_weighted_accuracy: 0.8646\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0171 - acc: 0.9082 - weighted_accuracy: 0.9067 - val_loss: 0.3208 - val_acc: 0.8559 - val_weighted_accuracy: 0.8586\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0170 - acc: 0.9094 - weighted_accuracy: 0.9080 - val_loss: 0.2872 - val_acc: 0.8744 - val_weighted_accuracy: 0.8677\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 36s 100us/step - loss: 0.0168 - acc: 0.9100 - weighted_accuracy: 0.9086 - val_loss: 0.2858 - val_acc: 0.8744 - val_weighted_accuracy: 0.8682\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 36s 100us/step - loss: 0.0167 - acc: 0.9110 - weighted_accuracy: 0.9100 - val_loss: 0.2999 - val_acc: 0.8681 - val_weighted_accuracy: 0.8664\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0166 - acc: 0.9117 - weighted_accuracy: 0.9107 - val_loss: 0.3010 - val_acc: 0.8680 - val_weighted_accuracy: 0.8651\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0164 - acc: 0.9128 - weighted_accuracy: 0.9119 - val_loss: 0.2869 - val_acc: 0.8759 - val_weighted_accuracy: 0.8693\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0163 - acc: 0.9138 - weighted_accuracy: 0.9132 - val_loss: 0.2876 - val_acc: 0.8750 - val_weighted_accuracy: 0.8684\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0162 - acc: 0.9145 - weighted_accuracy: 0.9141 - val_loss: 0.2993 - val_acc: 0.8672 - val_weighted_accuracy: 0.8645\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0161 - acc: 0.9150 - weighted_accuracy: 0.9144 - val_loss: 0.3027 - val_acc: 0.8666 - val_weighted_accuracy: 0.8629\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0160 - acc: 0.9154 - weighted_accuracy: 0.9148 - val_loss: 0.3131 - val_acc: 0.8660 - val_weighted_accuracy: 0.8640\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0159 - acc: 0.9164 - weighted_accuracy: 0.9160 - val_loss: 0.2908 - val_acc: 0.8730 - val_weighted_accuracy: 0.8682\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0158 - acc: 0.9169 - weighted_accuracy: 0.9167 - val_loss: 0.3010 - val_acc: 0.8702 - val_weighted_accuracy: 0.8667\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0157 - acc: 0.9179 - weighted_accuracy: 0.9177 - val_loss: 0.3086 - val_acc: 0.8638 - val_weighted_accuracy: 0.8623\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0157 - acc: 0.9185 - weighted_accuracy: 0.9183 - val_loss: 0.3015 - val_acc: 0.8685 - val_weighted_accuracy: 0.8658\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0156 - acc: 0.9190 - weighted_accuracy: 0.9188 - val_loss: 0.3000 - val_acc: 0.8653 - val_weighted_accuracy: 0.8631\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0156 - acc: 0.9183 - weighted_accuracy: 0.9181 - val_loss: 0.2995 - val_acc: 0.8660 - val_weighted_accuracy: 0.8639\n",
      "Epoch 20/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0154 - acc: 0.9196 - weighted_accuracy: 0.9199 - val_loss: 0.3211 - val_acc: 0.8592 - val_weighted_accuracy: 0.8593\n",
      "Epoch 21/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0154 - acc: 0.9200 - weighted_accuracy: 0.9202 - val_loss: 0.3004 - val_acc: 0.8676 - val_weighted_accuracy: 0.8637\n",
      "Epoch 22/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0153 - acc: 0.9206 - weighted_accuracy: 0.9210 - val_loss: 0.3020 - val_acc: 0.8675 - val_weighted_accuracy: 0.8631\n",
      "Epoch 23/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0153 - acc: 0.9207 - weighted_accuracy: 0.9209 - val_loss: 0.3010 - val_acc: 0.8684 - val_weighted_accuracy: 0.8655\n",
      "Epoch 24/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0152 - acc: 0.9212 - weighted_accuracy: 0.9215 - val_loss: 0.3051 - val_acc: 0.8679 - val_weighted_accuracy: 0.8643\n",
      "Epoch 25/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0151 - acc: 0.9219 - weighted_accuracy: 0.9222 - val_loss: 0.3016 - val_acc: 0.8682 - val_weighted_accuracy: 0.8658\n",
      "Epoch 26/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0151 - acc: 0.9217 - weighted_accuracy: 0.9220 - val_loss: 0.2964 - val_acc: 0.8690 - val_weighted_accuracy: 0.8650\n",
      "Epoch 27/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0150 - acc: 0.9228 - weighted_accuracy: 0.9234 - val_loss: 0.3039 - val_acc: 0.8704 - val_weighted_accuracy: 0.8665\n",
      "Epoch 28/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0149 - acc: 0.9242 - weighted_accuracy: 0.9245 - val_loss: 0.3056 - val_acc: 0.8677 - val_weighted_accuracy: 0.8646\n",
      "Epoch 29/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0149 - acc: 0.9232 - weighted_accuracy: 0.9238 - val_loss: 0.3021 - val_acc: 0.8678 - val_weighted_accuracy: 0.8655\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_25 (Embedding)        (None, 30, 200)      20000000    first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_35 (SpatialDr (None, 30, 200)      0           embedding_25[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_36 (SpatialDr (None, 30, 200)      0           embedding_25[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_74 (TimeDistri (None, 30, 200)      80400       spatial_dropout1d_35[0][0]       \n",
      "                                                                 spatial_dropout1d_36[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dot_142 (Dot)                   (None, 30, 30)       0           time_distributed_74[0][0]        \n",
      "                                                                 time_distributed_74[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_120 (Lambda)             (None, 30, 30)       0           dot_142[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_48 (Permute)            (None, 30, 30)       0           lambda_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_119 (Lambda)             (None, 30, 30)       0           dot_142[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_144 (Dot)                   (None, 30, 200)      0           permute_48[0][0]                 \n",
      "                                                                 time_distributed_74[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dot_143 (Dot)                   (None, 30, 200)      0           lambda_119[0][0]                 \n",
      "                                                                 time_distributed_74[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_121 (Lambda)             (None, 30, 200)      0           time_distributed_74[0][0]        \n",
      "                                                                 dot_144[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_25 (Multiply)          (None, 30, 200)      0           time_distributed_74[0][0]        \n",
      "                                                                 dot_144[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_122 (Lambda)             (None, 30, 200)      0           time_distributed_74[1][0]        \n",
      "                                                                 dot_143[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_26 (Multiply)          (None, 30, 200)      0           time_distributed_74[1][0]        \n",
      "                                                                 dot_143[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_146 (Concatenate)   (None, 30, 800)      0           time_distributed_74[0][0]        \n",
      "                                                                 dot_144[0][0]                    \n",
      "                                                                 lambda_121[0][0]                 \n",
      "                                                                 multiply_25[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_147 (Concatenate)   (None, 30, 800)      0           time_distributed_74[1][0]        \n",
      "                                                                 dot_143[0][0]                    \n",
      "                                                                 lambda_122[0][0]                 \n",
      "                                                                 multiply_26[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_75 (TimeDistri (None, 30, 300)      240300      concatenate_146[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_79 (TimeDistri (None, 30, 300)      240300      concatenate_147[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_76 (TimeDistri (None, 30, 300)      0           time_distributed_75[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_80 (TimeDistri (None, 30, 300)      0           time_distributed_79[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_77 (TimeDistri (None, 30, 200)      60200       time_distributed_76[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_81 (TimeDistri (None, 30, 200)      60200       time_distributed_80[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_78 (TimeDistri (None, 30, 200)      0           time_distributed_77[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_82 (TimeDistri (None, 30, 200)      0           time_distributed_81[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_35 (Gl (None, 200)          0           time_distributed_78[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_35 (Global (None, 200)          0           time_distributed_78[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_36 (Gl (None, 200)          0           time_distributed_82[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_36 (Global (None, 200)          0           time_distributed_82[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_148 (Concatenate)   (None, 400)          0           global_average_pooling1d_35[0][0]\n",
      "                                                                 global_max_pooling1d_35[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_149 (Concatenate)   (None, 400)          0           global_average_pooling1d_36[0][0]\n",
      "                                                                 global_max_pooling1d_36[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_150 (Concatenate)   (None, 800)          0           concatenate_148[0][0]            \n",
      "                                                                 concatenate_149[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 800)          3200        concatenate_150[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_58 (Dense)                (None, 256)          205056      batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)            (None, 256)          0           dense_58[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 256)          1024        dropout_41[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_59 (Dense)                (None, 256)          65792       batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)            (None, 256)          0           dense_59[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 256)          1024        dropout_42[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_60 (Dense)                (None, 3)            771         batch_normalization_24[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 20,657,767\n",
      "Trainable params: 655,143\n",
      "Non-trainable params: 20,002,624\n",
      "__________________________________________________________________________________________________\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360609/360609 [==============================] - 38s 105us/step - loss: 0.0169 - acc: 0.9091 - weighted_accuracy: 0.9084 - val_loss: 0.2934 - val_acc: 0.8694 - val_weighted_accuracy: 0.8609\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0168 - acc: 0.9093 - weighted_accuracy: 0.9090 - val_loss: 0.3071 - val_acc: 0.8625 - val_weighted_accuracy: 0.8570\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0167 - acc: 0.9104 - weighted_accuracy: 0.9099 - val_loss: 0.3036 - val_acc: 0.8655 - val_weighted_accuracy: 0.8610\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0166 - acc: 0.9111 - weighted_accuracy: 0.9106 - val_loss: 0.3101 - val_acc: 0.8608 - val_weighted_accuracy: 0.8568\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0164 - acc: 0.9124 - weighted_accuracy: 0.9122 - val_loss: 0.2898 - val_acc: 0.8729 - val_weighted_accuracy: 0.8626\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0162 - acc: 0.9132 - weighted_accuracy: 0.9131 - val_loss: 0.2999 - val_acc: 0.8640 - val_weighted_accuracy: 0.8572\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0161 - acc: 0.9148 - weighted_accuracy: 0.9147 - val_loss: 0.3060 - val_acc: 0.8639 - val_weighted_accuracy: 0.8595\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0160 - acc: 0.9152 - weighted_accuracy: 0.9152 - val_loss: 0.3020 - val_acc: 0.8660 - val_weighted_accuracy: 0.8595\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0160 - acc: 0.9160 - weighted_accuracy: 0.9160 - val_loss: 0.3123 - val_acc: 0.8650 - val_weighted_accuracy: 0.8603\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0158 - acc: 0.9164 - weighted_accuracy: 0.9168 - val_loss: 0.2812 - val_acc: 0.8752 - val_weighted_accuracy: 0.8654\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0157 - acc: 0.9172 - weighted_accuracy: 0.9173 - val_loss: 0.2927 - val_acc: 0.8693 - val_weighted_accuracy: 0.8643\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0157 - acc: 0.9178 - weighted_accuracy: 0.9182 - val_loss: 0.2969 - val_acc: 0.8707 - val_weighted_accuracy: 0.8635\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0156 - acc: 0.9179 - weighted_accuracy: 0.9183 - val_loss: 0.2954 - val_acc: 0.8704 - val_weighted_accuracy: 0.8633\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0155 - acc: 0.9192 - weighted_accuracy: 0.9197 - val_loss: 0.2920 - val_acc: 0.8712 - val_weighted_accuracy: 0.8654\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0154 - acc: 0.9198 - weighted_accuracy: 0.9203 - val_loss: 0.3009 - val_acc: 0.8660 - val_weighted_accuracy: 0.8606\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0153 - acc: 0.9206 - weighted_accuracy: 0.9211 - val_loss: 0.3123 - val_acc: 0.8641 - val_weighted_accuracy: 0.8592\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0153 - acc: 0.9208 - weighted_accuracy: 0.9214 - val_loss: 0.3032 - val_acc: 0.8651 - val_weighted_accuracy: 0.8592\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0152 - acc: 0.9208 - weighted_accuracy: 0.9216 - val_loss: 0.2997 - val_acc: 0.8688 - val_weighted_accuracy: 0.8628\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0151 - acc: 0.9216 - weighted_accuracy: 0.9223 - val_loss: 0.3124 - val_acc: 0.8634 - val_weighted_accuracy: 0.8588\n",
      "Epoch 20/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0151 - acc: 0.9220 - weighted_accuracy: 0.9226 - val_loss: 0.2841 - val_acc: 0.8734 - val_weighted_accuracy: 0.8657\n",
      "Epoch 21/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0150 - acc: 0.9231 - weighted_accuracy: 0.9238 - val_loss: 0.2945 - val_acc: 0.8672 - val_weighted_accuracy: 0.8614\n",
      "Epoch 22/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0150 - acc: 0.9229 - weighted_accuracy: 0.9237 - val_loss: 0.3019 - val_acc: 0.8689 - val_weighted_accuracy: 0.8624\n",
      "Epoch 23/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0149 - acc: 0.9228 - weighted_accuracy: 0.9238 - val_loss: 0.3050 - val_acc: 0.8667 - val_weighted_accuracy: 0.8613\n",
      "Epoch 24/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0149 - acc: 0.9233 - weighted_accuracy: 0.9241 - val_loss: 0.2954 - val_acc: 0.8703 - val_weighted_accuracy: 0.8634\n",
      "Epoch 25/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0148 - acc: 0.9240 - weighted_accuracy: 0.9248 - val_loss: 0.2943 - val_acc: 0.8703 - val_weighted_accuracy: 0.8628\n",
      "Epoch 26/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0147 - acc: 0.9241 - weighted_accuracy: 0.9251 - val_loss: 0.2905 - val_acc: 0.8736 - val_weighted_accuracy: 0.8652\n",
      "Epoch 27/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0147 - acc: 0.9245 - weighted_accuracy: 0.9253 - val_loss: 0.3132 - val_acc: 0.8633 - val_weighted_accuracy: 0.8590\n",
      "Epoch 28/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0146 - acc: 0.9250 - weighted_accuracy: 0.9261 - val_loss: 0.2996 - val_acc: 0.8692 - val_weighted_accuracy: 0.8622\n",
      "Epoch 29/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0146 - acc: 0.9256 - weighted_accuracy: 0.9267 - val_loss: 0.2905 - val_acc: 0.8743 - val_weighted_accuracy: 0.8658\n",
      "Epoch 30/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0146 - acc: 0.9255 - weighted_accuracy: 0.9265 - val_loss: 0.2853 - val_acc: 0.8742 - val_weighted_accuracy: 0.8656\n",
      "Epoch 31/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0145 - acc: 0.9260 - weighted_accuracy: 0.9273 - val_loss: 0.3010 - val_acc: 0.8696 - val_weighted_accuracy: 0.8631\n",
      "Epoch 32/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0145 - acc: 0.9266 - weighted_accuracy: 0.9275 - val_loss: 0.2963 - val_acc: 0.8702 - val_weighted_accuracy: 0.8639\n",
      "Epoch 33/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0144 - acc: 0.9266 - weighted_accuracy: 0.9276 - val_loss: 0.2950 - val_acc: 0.8704 - val_weighted_accuracy: 0.8633\n",
      "Epoch 34/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0144 - acc: 0.9266 - weighted_accuracy: 0.9278 - val_loss: 0.3018 - val_acc: 0.8688 - val_weighted_accuracy: 0.8617\n",
      "Epoch 35/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0143 - acc: 0.9271 - weighted_accuracy: 0.9284 - val_loss: 0.3019 - val_acc: 0.8687 - val_weighted_accuracy: 0.8602\n",
      "Epoch 36/500\n",
      "360609/360609 [==============================] - 35s 97us/step - loss: 0.0143 - acc: 0.9271 - weighted_accuracy: 0.9283 - val_loss: 0.2996 - val_acc: 0.8723 - val_weighted_accuracy: 0.8641\n",
      "Epoch 37/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0143 - acc: 0.9278 - weighted_accuracy: 0.9289 - val_loss: 0.2951 - val_acc: 0.8734 - val_weighted_accuracy: 0.8643\n",
      "Epoch 38/500\n",
      "360609/360609 [==============================] - 37s 103us/step - loss: 0.0143 - acc: 0.9281 - weighted_accuracy: 0.9292 - val_loss: 0.3056 - val_acc: 0.8686 - val_weighted_accuracy: 0.8624\n",
      "Epoch 39/500\n",
      "360609/360609 [==============================] - 36s 100us/step - loss: 0.0141 - acc: 0.9289 - weighted_accuracy: 0.9301 - val_loss: 0.3121 - val_acc: 0.8674 - val_weighted_accuracy: 0.8602\n",
      "Epoch 40/500\n",
      "360609/360609 [==============================] - 37s 102us/step - loss: 0.0141 - acc: 0.9288 - weighted_accuracy: 0.9301 - val_loss: 0.3022 - val_acc: 0.8686 - val_weighted_accuracy: 0.8626\n",
      "Epoch 41/500\n",
      "360609/360609 [==============================] - 36s 100us/step - loss: 0.0141 - acc: 0.9283 - weighted_accuracy: 0.9296 - val_loss: 0.3027 - val_acc: 0.8683 - val_weighted_accuracy: 0.8613\n",
      "Epoch 42/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0141 - acc: 0.9285 - weighted_accuracy: 0.9299 - val_loss: 0.2986 - val_acc: 0.8731 - val_weighted_accuracy: 0.8638\n",
      "Epoch 43/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0140 - acc: 0.9292 - weighted_accuracy: 0.9305 - val_loss: 0.2923 - val_acc: 0.8742 - val_weighted_accuracy: 0.8659\n",
      "Epoch 44/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0140 - acc: 0.9298 - weighted_accuracy: 0.9313 - val_loss: 0.3141 - val_acc: 0.8672 - val_weighted_accuracy: 0.8607\n",
      "Epoch 45/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0139 - acc: 0.9301 - weighted_accuracy: 0.9313 - val_loss: 0.3031 - val_acc: 0.8721 - val_weighted_accuracy: 0.8632\n",
      "Epoch 46/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0140 - acc: 0.9294 - weighted_accuracy: 0.9310 - val_loss: 0.3139 - val_acc: 0.8655 - val_weighted_accuracy: 0.8593\n",
      "Epoch 47/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0139 - acc: 0.9301 - weighted_accuracy: 0.9314 - val_loss: 0.3026 - val_acc: 0.8676 - val_weighted_accuracy: 0.8609\n",
      "Epoch 48/500\n",
      "360609/360609 [==============================] - 36s 100us/step - loss: 0.0139 - acc: 0.9300 - weighted_accuracy: 0.9314 - val_loss: 0.3038 - val_acc: 0.8695 - val_weighted_accuracy: 0.8629\n",
      "Epoch 49/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0138 - acc: 0.9311 - weighted_accuracy: 0.9324 - val_loss: 0.3071 - val_acc: 0.8689 - val_weighted_accuracy: 0.8618\n",
      "Epoch 50/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0138 - acc: 0.9309 - weighted_accuracy: 0.9322 - val_loss: 0.3016 - val_acc: 0.8698 - val_weighted_accuracy: 0.8629\n",
      "Epoch 51/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0138 - acc: 0.9307 - weighted_accuracy: 0.9320 - val_loss: 0.3081 - val_acc: 0.8687 - val_weighted_accuracy: 0.8625\n",
      "Epoch 52/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0138 - acc: 0.9314 - weighted_accuracy: 0.9325 - val_loss: 0.3072 - val_acc: 0.8689 - val_weighted_accuracy: 0.8604\n",
      "Epoch 53/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0137 - acc: 0.9313 - weighted_accuracy: 0.9327 - val_loss: 0.2886 - val_acc: 0.8758 - val_weighted_accuracy: 0.8663\n",
      "Epoch 54/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0136 - acc: 0.9324 - weighted_accuracy: 0.9338 - val_loss: 0.3105 - val_acc: 0.8686 - val_weighted_accuracy: 0.8602\n",
      "Epoch 55/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0137 - acc: 0.9321 - weighted_accuracy: 0.9335 - val_loss: 0.3108 - val_acc: 0.8688 - val_weighted_accuracy: 0.8615\n",
      "Epoch 56/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0137 - acc: 0.9321 - weighted_accuracy: 0.9334 - val_loss: 0.3124 - val_acc: 0.8688 - val_weighted_accuracy: 0.8614\n",
      "Epoch 57/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0136 - acc: 0.9321 - weighted_accuracy: 0.9334 - val_loss: 0.3125 - val_acc: 0.8648 - val_weighted_accuracy: 0.8581\n",
      "Epoch 58/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0136 - acc: 0.9326 - weighted_accuracy: 0.9341 - val_loss: 0.2999 - val_acc: 0.8731 - val_weighted_accuracy: 0.8643\n",
      "Epoch 59/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0136 - acc: 0.9327 - weighted_accuracy: 0.9340 - val_loss: 0.2965 - val_acc: 0.8752 - val_weighted_accuracy: 0.8665\n",
      "Epoch 60/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0136 - acc: 0.9327 - weighted_accuracy: 0.9341 - val_loss: 0.2889 - val_acc: 0.8772 - val_weighted_accuracy: 0.8677\n",
      "Epoch 61/500\n",
      "360609/360609 [==============================] - 37s 101us/step - loss: 0.0135 - acc: 0.9331 - weighted_accuracy: 0.9345 - val_loss: 0.3057 - val_acc: 0.8680 - val_weighted_accuracy: 0.8626\n",
      "Epoch 62/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0135 - acc: 0.9332 - weighted_accuracy: 0.9348 - val_loss: 0.2994 - val_acc: 0.8705 - val_weighted_accuracy: 0.8630\n",
      "Epoch 63/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0135 - acc: 0.9329 - weighted_accuracy: 0.9343 - val_loss: 0.3033 - val_acc: 0.8710 - val_weighted_accuracy: 0.8632\n",
      "Epoch 64/500\n",
      "360609/360609 [==============================] - 36s 100us/step - loss: 0.0134 - acc: 0.9337 - weighted_accuracy: 0.9349 - val_loss: 0.3160 - val_acc: 0.8671 - val_weighted_accuracy: 0.8610\n",
      "Epoch 65/500\n",
      "360609/360609 [==============================] - 36s 100us/step - loss: 0.0134 - acc: 0.9337 - weighted_accuracy: 0.9351 - val_loss: 0.3002 - val_acc: 0.8701 - val_weighted_accuracy: 0.8634\n",
      "Epoch 66/500\n",
      "360609/360609 [==============================] - 36s 100us/step - loss: 0.0134 - acc: 0.9333 - weighted_accuracy: 0.9349 - val_loss: 0.3009 - val_acc: 0.8719 - val_weighted_accuracy: 0.8646\n",
      "Epoch 67/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0134 - acc: 0.9338 - weighted_accuracy: 0.9354 - val_loss: 0.2947 - val_acc: 0.8741 - val_weighted_accuracy: 0.8662\n",
      "Epoch 68/500\n",
      "360609/360609 [==============================] - 37s 101us/step - loss: 0.0133 - acc: 0.9344 - weighted_accuracy: 0.9357 - val_loss: 0.2937 - val_acc: 0.8765 - val_weighted_accuracy: 0.8679\n",
      "Epoch 69/500\n",
      "360609/360609 [==============================] - 36s 101us/step - loss: 0.0133 - acc: 0.9344 - weighted_accuracy: 0.9359 - val_loss: 0.2977 - val_acc: 0.8748 - val_weighted_accuracy: 0.8665\n",
      "Epoch 70/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0133 - acc: 0.9346 - weighted_accuracy: 0.9361 - val_loss: 0.3073 - val_acc: 0.8720 - val_weighted_accuracy: 0.8638\n",
      "Epoch 71/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0133 - acc: 0.9345 - weighted_accuracy: 0.9359 - val_loss: 0.3063 - val_acc: 0.8716 - val_weighted_accuracy: 0.8639\n",
      "Epoch 72/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0132 - acc: 0.9349 - weighted_accuracy: 0.9364 - val_loss: 0.3013 - val_acc: 0.8741 - val_weighted_accuracy: 0.8655\n",
      "Epoch 73/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0132 - acc: 0.9352 - weighted_accuracy: 0.9367 - val_loss: 0.3069 - val_acc: 0.8693 - val_weighted_accuracy: 0.8624\n",
      "Epoch 74/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0132 - acc: 0.9353 - weighted_accuracy: 0.9368 - val_loss: 0.2987 - val_acc: 0.8741 - val_weighted_accuracy: 0.8648\n",
      "Epoch 75/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0132 - acc: 0.9353 - weighted_accuracy: 0.9370 - val_loss: 0.3003 - val_acc: 0.8724 - val_weighted_accuracy: 0.8645\n",
      "Epoch 76/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0132 - acc: 0.9351 - weighted_accuracy: 0.9368 - val_loss: 0.2932 - val_acc: 0.8764 - val_weighted_accuracy: 0.8665\n",
      "Epoch 77/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0132 - acc: 0.9350 - weighted_accuracy: 0.9364 - val_loss: 0.3112 - val_acc: 0.8698 - val_weighted_accuracy: 0.8628\n",
      "Epoch 78/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0132 - acc: 0.9357 - weighted_accuracy: 0.9373 - val_loss: 0.3087 - val_acc: 0.8704 - val_weighted_accuracy: 0.8640\n",
      "Epoch 79/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0131 - acc: 0.9361 - weighted_accuracy: 0.9375 - val_loss: 0.3007 - val_acc: 0.8746 - val_weighted_accuracy: 0.8663\n",
      "Epoch 80/500\n",
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0131 - acc: 0.9357 - weighted_accuracy: 0.9374 - val_loss: 0.2991 - val_acc: 0.8739 - val_weighted_accuracy: 0.8655\n",
      "Epoch 81/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360609/360609 [==============================] - 35s 98us/step - loss: 0.0130 - acc: 0.9364 - weighted_accuracy: 0.9380 - val_loss: 0.3103 - val_acc: 0.8713 - val_weighted_accuracy: 0.8650\n",
      "Epoch 82/500\n",
      "360609/360609 [==============================] - 36s 100us/step - loss: 0.0131 - acc: 0.9366 - weighted_accuracy: 0.9383 - val_loss: 0.3031 - val_acc: 0.8711 - val_weighted_accuracy: 0.8633\n",
      "Epoch 83/500\n",
      "360609/360609 [==============================] - 37s 102us/step - loss: 0.0131 - acc: 0.9362 - weighted_accuracy: 0.9377 - val_loss: 0.2949 - val_acc: 0.8785 - val_weighted_accuracy: 0.8671\n",
      "Epoch 84/500\n",
      "360609/360609 [==============================] - 36s 100us/step - loss: 0.0130 - acc: 0.9371 - weighted_accuracy: 0.9385 - val_loss: 0.3030 - val_acc: 0.8735 - val_weighted_accuracy: 0.8654\n",
      "Epoch 85/500\n",
      "360609/360609 [==============================] - 36s 100us/step - loss: 0.0130 - acc: 0.9365 - weighted_accuracy: 0.9382 - val_loss: 0.3088 - val_acc: 0.8717 - val_weighted_accuracy: 0.8637\n",
      "Epoch 86/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0130 - acc: 0.9368 - weighted_accuracy: 0.9385 - val_loss: 0.3073 - val_acc: 0.8707 - val_weighted_accuracy: 0.8635\n",
      "Epoch 87/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0130 - acc: 0.9365 - weighted_accuracy: 0.9382 - val_loss: 0.2983 - val_acc: 0.8753 - val_weighted_accuracy: 0.8659\n",
      "Epoch 88/500\n",
      "360609/360609 [==============================] - 36s 99us/step - loss: 0.0129 - acc: 0.9375 - weighted_accuracy: 0.9391 - val_loss: 0.2999 - val_acc: 0.8735 - val_weighted_accuracy: 0.8650\n",
      "score 0.8629848450517491\n",
      "Predicting training results...\n",
      "Predicting testing results...\n",
      "80126/80126 [==============================] - 3s 31us/step\n",
      "80126/80126 [==============================] - 3s 32us/step\n",
      "80126/80126 [==============================] - 3s 32us/step\n",
      "80126/80126 [==============================] - 3s 32us/step\n",
      "80126/80126 [==============================] - 3s 33us/step\n",
      "80126/80126 [==============================] - 3s 32us/step\n",
      "80126/80126 [==============================] - 3s 32us/step\n",
      "80126/80126 [==============================] - 3s 32us/step\n",
      "Predicting labeled testing results...\n"
     ]
    }
   ],
   "source": [
    "fold_count = 8\n",
    "#embedding_matrix = sgns_bigram_matrix\n",
    "embedding_matrix = tencent_ai_matrix\n",
    "EMBEDDING_DIM = 200\n",
    "\n",
    "for i in range(1, len(model_manager.models_tag)):\n",
    "    print(\"Work on model\", i)\n",
    "    model_tag = model_manager.models_tag[i]\n",
    "    model_func = model_manager.model_funcs[i]\n",
    "    #models_checkpoints_path = model_manager.models_checkpoints_pathes[i]\n",
    "    models_checkpoints_path = \"WordTC-DAttn-NoMeta-3P-NoEM-NoClassWeighted-3Layers\"\n",
    "\n",
    "    model_submit_prefix = model_manager.submit_predix[i]\n",
    "    model_class_weights = model_manager.model_class_weights[i]\n",
    "    model_scale_sample_weights = model_manager.model_scale_sample_weights[i]\n",
    "    model_patiences = model_manager.model_patiences[i]\n",
    "    \n",
    "    model_class_weights = None\n",
    "    \n",
    "    def _agent_get_model():\n",
    "        return get_decomposable_attention(NB_WORDS, EMBEDDING_DIM, embedding_matrix, MAX_SEQUENCE_LENGTH, OUT_SIZE)\n",
    "        return get_dense_cnn(NB_WORDS, EMBEDDING_DIM, embedding_matrix, MAX_SEQUENCE_LENGTH, OUT_SIZE)\n",
    "        return model_func(NB_WORDS, EMBEDDING_DIM, embedding_matrix, MAX_SEQUENCE_LENGTH, OUT_SIZE)\n",
    "    \n",
    "    test_predicts_list = []\n",
    "    oofs_predictions = []\n",
    "    pre_trained_models = []\n",
    "        \n",
    "    trainer = KerasModelTrainer(model_stamp=models_checkpoints_path, epoch_num=500)\n",
    "    models, score, folds_preds = trainer.train_folds(X=trains, y=labels, tests=tests, augments=None, fold_count=fold_count, batch_size=256,\n",
    "        em_train_features=em_train_features, em_test_features=em_test_features, pseudo_labels=pseudo_labels,                                      \n",
    "        scale_sample_weight=model_scale_sample_weights, class_weight={0: 1/16, 1: 1/15, 2:1/5},\n",
    "        get_model_func=_agent_get_model, \n",
    "        patience=20)\n",
    "\n",
    "    print(\"score\", score)\n",
    "    oofs_dir = \"../data/pseudo/oofs/\"\n",
    "    output_dir = \"../data/pseudo/output/\"\n",
    "    onehot_pred_dir = \"../data/pseudo/one_hot_pred/\"\n",
    "\n",
    "    model_submit_prefix = \"PSWordTC-DAttn-NoMeta-3P-NoEM-NoClassWeighted-3Layers\"\n",
    "    \n",
    "    oofs_path = oofs_dir + model_submit_prefix\n",
    "    output_path = output_dir + model_submit_prefix\n",
    "    one_hot_pred_path = onehot_pred_dir + \"One-Hot\" + model_submit_prefix\n",
    "\n",
    "    print(\"Predicting training results...\")\n",
    "    train_predicts = np.concatenate(folds_preds, axis=0)\n",
    "    oofs = pd.DataFrame({\"unrelated\": train_predicts[:, 0], \"agreed\": train_predicts[:, 1], \"disagreed\": train_predicts[:, 2]})\n",
    "    submit_path = oofs_path + \"-Train-L{:4f}-NB{:d}.csv\".format(score, NB_WORDS)\n",
    "    oofs.to_csv(submit_path, index=False)\n",
    "\n",
    "    print(\"Predicting testing results...\")\n",
    "    test_predicts_list = []\n",
    "    for fold_id, model in enumerate(models):\n",
    "        test_predicts = model.predict({\"first_sentences\":tests[0],\n",
    "                                       \"second_sentences\":tests[1],\n",
    "                                       \"mata-features\":tests[2],\n",
    "                                       \"first_exact_match\": tests_1_ems,\n",
    "                                       \"second_exact_match\": tests_2_ems,\n",
    "                                      }, batch_size=128, verbose=1)\n",
    "\n",
    "        test_predicts_list.append(test_predicts)\n",
    "\n",
    "    test_predicts = np.zeros(test_predicts_list[0].shape)\n",
    "    for fold_predict in test_predicts_list:\n",
    "        test_predicts += fold_predict\n",
    "    test_predicts /= len(test_predicts_list)\n",
    "\n",
    "    test_predicts = pd.DataFrame({\"unrelated\": test_predicts[:, 0], \"agreed\": test_predicts[:, 1], \"disagreed\": test_predicts[:, 2]})\n",
    "    submit_path = output_path + \"-L{:4f}-NB{:d}.csv\".format(score, NB_WORDS)\n",
    "    test_predicts.to_csv(submit_path, index=False) # 0.3343\n",
    "    \n",
    "    print(\"Predicting labeled testing results...\")\n",
    "    ids = pd.read_csv(\"../data/dataset/test.csv\")\n",
    "    pred_labels = test_predicts.idxmax(axis=1)\n",
    "    sub = pd.DataFrame({\"Id\": ids['id'].values, \"Category\": pred_labels})\n",
    "    submit_path = one_hot_pred_path + \"-L{:4f}-NB{:d}.csv\".format(score, NB_WORDS)\n",
    "    sub.to_csv(submit_path, index=False)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Work on model 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zake7\\Anaconda3\\lib\\site-packages\\keras\\legacy\\layers.py:198: UserWarning: The `Highway` layer is deprecated and will be removed after 06/2017.\n",
      "  warnings.warn('The `Highway` layer is deprecated '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_27 (Embedding)        (None, 30, 300)      30000000    first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_37 (SpatialDr (None, 30, 300)      0           embedding_27[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_38 (SpatialDr (None, 30, 300)      0           embedding_27[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_83 (TimeDistri (None, 30, 300)      180600      spatial_dropout1d_37[0][0]       \n",
      "                                                                 spatial_dropout1d_38[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dot_145 (Dot)                   (None, 30, 30)       0           time_distributed_83[0][0]        \n",
      "                                                                 time_distributed_83[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_124 (Lambda)             (None, 30, 30)       0           dot_145[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_49 (Permute)            (None, 30, 30)       0           lambda_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_123 (Lambda)             (None, 30, 30)       0           dot_145[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_147 (Dot)                   (None, 30, 300)      0           permute_49[0][0]                 \n",
      "                                                                 time_distributed_83[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dot_146 (Dot)                   (None, 30, 300)      0           lambda_123[0][0]                 \n",
      "                                                                 time_distributed_83[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_125 (Lambda)             (None, 30, 300)      0           time_distributed_83[0][0]        \n",
      "                                                                 dot_147[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_27 (Multiply)          (None, 30, 300)      0           time_distributed_83[0][0]        \n",
      "                                                                 dot_147[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_126 (Lambda)             (None, 30, 300)      0           time_distributed_83[1][0]        \n",
      "                                                                 dot_146[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_28 (Multiply)          (None, 30, 300)      0           time_distributed_83[1][0]        \n",
      "                                                                 dot_146[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_151 (Concatenate)   (None, 30, 1200)     0           time_distributed_83[0][0]        \n",
      "                                                                 dot_147[0][0]                    \n",
      "                                                                 lambda_125[0][0]                 \n",
      "                                                                 multiply_27[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_152 (Concatenate)   (None, 30, 1200)     0           time_distributed_83[1][0]        \n",
      "                                                                 dot_146[0][0]                    \n",
      "                                                                 lambda_126[0][0]                 \n",
      "                                                                 multiply_28[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_84 (TimeDistri (None, 30, 300)      360300      concatenate_151[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_88 (TimeDistri (None, 30, 300)      360300      concatenate_152[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_85 (TimeDistri (None, 30, 300)      0           time_distributed_84[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_89 (TimeDistri (None, 30, 300)      0           time_distributed_88[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_86 (TimeDistri (None, 30, 200)      60200       time_distributed_85[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_90 (TimeDistri (None, 30, 200)      60200       time_distributed_89[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_87 (TimeDistri (None, 30, 200)      0           time_distributed_86[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_91 (TimeDistri (None, 30, 200)      0           time_distributed_90[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_37 (Gl (None, 200)          0           time_distributed_87[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_37 (Global (None, 200)          0           time_distributed_87[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_38 (Gl (None, 200)          0           time_distributed_91[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_38 (Global (None, 200)          0           time_distributed_91[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_153 (Concatenate)   (None, 400)          0           global_average_pooling1d_37[0][0]\n",
      "                                                                 global_max_pooling1d_37[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_154 (Concatenate)   (None, 400)          0           global_average_pooling1d_38[0][0]\n",
      "                                                                 global_max_pooling1d_38[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_155 (Concatenate)   (None, 800)          0           concatenate_153[0][0]            \n",
      "                                                                 concatenate_154[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 800)          3200        concatenate_155[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_63 (Dense)                (None, 256)          205056      batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_45 (Dropout)            (None, 256)          0           dense_63[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 256)          1024        dropout_45[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_64 (Dense)                (None, 256)          65792       batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_46 (Dropout)            (None, 256)          0           dense_64[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 256)          1024        dropout_46[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_65 (Dense)                (None, 3)            771         batch_normalization_27[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 30,877,967\n",
      "Trainable params: 875,343\n",
      "Non-trainable params: 30,002,624\n",
      "__________________________________________________________________________________________________\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360609/360609 [==============================] - 48s 132us/step - loss: 0.0175 - acc: 0.9043 - weighted_accuracy: 0.9032 - val_loss: 0.3191 - val_acc: 0.8573 - val_weighted_accuracy: 0.8469\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 44s 122us/step - loss: 0.0172 - acc: 0.9069 - weighted_accuracy: 0.9061 - val_loss: 0.3036 - val_acc: 0.8696 - val_weighted_accuracy: 0.8587\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 44s 122us/step - loss: 0.0170 - acc: 0.9084 - weighted_accuracy: 0.9079 - val_loss: 0.2965 - val_acc: 0.8739 - val_weighted_accuracy: 0.8624\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 44s 122us/step - loss: 0.0166 - acc: 0.9107 - weighted_accuracy: 0.9104 - val_loss: 0.2970 - val_acc: 0.8655 - val_weighted_accuracy: 0.8577\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 44s 122us/step - loss: 0.0164 - acc: 0.9129 - weighted_accuracy: 0.9126 - val_loss: 0.2912 - val_acc: 0.8709 - val_weighted_accuracy: 0.8613\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0162 - acc: 0.9143 - weighted_accuracy: 0.9142 - val_loss: 0.3009 - val_acc: 0.8664 - val_weighted_accuracy: 0.8588\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0160 - acc: 0.9155 - weighted_accuracy: 0.9158 - val_loss: 0.3169 - val_acc: 0.8623 - val_weighted_accuracy: 0.8552\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0158 - acc: 0.9171 - weighted_accuracy: 0.9174 - val_loss: 0.3001 - val_acc: 0.8731 - val_weighted_accuracy: 0.8630\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0156 - acc: 0.9182 - weighted_accuracy: 0.9188 - val_loss: 0.3082 - val_acc: 0.8655 - val_weighted_accuracy: 0.8602\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0154 - acc: 0.9196 - weighted_accuracy: 0.9203 - val_loss: 0.3057 - val_acc: 0.8681 - val_weighted_accuracy: 0.8596\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0153 - acc: 0.9201 - weighted_accuracy: 0.9208 - val_loss: 0.3213 - val_acc: 0.8574 - val_weighted_accuracy: 0.8537\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0152 - acc: 0.9208 - weighted_accuracy: 0.9213 - val_loss: 0.2993 - val_acc: 0.8709 - val_weighted_accuracy: 0.8612\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0151 - acc: 0.9220 - weighted_accuracy: 0.9228 - val_loss: 0.2971 - val_acc: 0.8707 - val_weighted_accuracy: 0.8615\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0150 - acc: 0.9230 - weighted_accuracy: 0.9238 - val_loss: 0.2999 - val_acc: 0.8705 - val_weighted_accuracy: 0.8603\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0149 - acc: 0.9230 - weighted_accuracy: 0.9239 - val_loss: 0.2970 - val_acc: 0.8720 - val_weighted_accuracy: 0.8608\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0147 - acc: 0.9246 - weighted_accuracy: 0.9254 - val_loss: 0.3054 - val_acc: 0.8716 - val_weighted_accuracy: 0.8622\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0147 - acc: 0.9248 - weighted_accuracy: 0.9259 - val_loss: 0.2971 - val_acc: 0.8725 - val_weighted_accuracy: 0.8617\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0145 - acc: 0.9259 - weighted_accuracy: 0.9270 - val_loss: 0.3121 - val_acc: 0.8672 - val_weighted_accuracy: 0.8593\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0144 - acc: 0.9263 - weighted_accuracy: 0.9273 - val_loss: 0.3048 - val_acc: 0.8680 - val_weighted_accuracy: 0.8598\n",
      "Epoch 20/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0143 - acc: 0.9270 - weighted_accuracy: 0.9285 - val_loss: 0.3116 - val_acc: 0.8655 - val_weighted_accuracy: 0.8596\n",
      "Epoch 21/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0142 - acc: 0.9274 - weighted_accuracy: 0.9288 - val_loss: 0.3060 - val_acc: 0.8723 - val_weighted_accuracy: 0.8621\n",
      "Epoch 22/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0142 - acc: 0.9279 - weighted_accuracy: 0.9292 - val_loss: 0.3034 - val_acc: 0.8721 - val_weighted_accuracy: 0.8606\n",
      "Epoch 23/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0141 - acc: 0.9287 - weighted_accuracy: 0.9301 - val_loss: 0.3145 - val_acc: 0.8677 - val_weighted_accuracy: 0.8599\n",
      "Epoch 24/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0140 - acc: 0.9300 - weighted_accuracy: 0.9313 - val_loss: 0.3020 - val_acc: 0.8704 - val_weighted_accuracy: 0.8606\n",
      "Epoch 25/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0139 - acc: 0.9300 - weighted_accuracy: 0.9316 - val_loss: 0.3066 - val_acc: 0.8692 - val_weighted_accuracy: 0.8595\n",
      "Epoch 26/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0139 - acc: 0.9307 - weighted_accuracy: 0.9318 - val_loss: 0.3129 - val_acc: 0.8652 - val_weighted_accuracy: 0.8585\n",
      "Epoch 27/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0138 - acc: 0.9310 - weighted_accuracy: 0.9325 - val_loss: 0.3261 - val_acc: 0.8621 - val_weighted_accuracy: 0.8563\n",
      "Epoch 28/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0137 - acc: 0.9317 - weighted_accuracy: 0.9331 - val_loss: 0.3159 - val_acc: 0.8648 - val_weighted_accuracy: 0.8579\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_29 (Embedding)        (None, 30, 300)      30000000    first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_39 (SpatialDr (None, 30, 300)      0           embedding_29[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_40 (SpatialDr (None, 30, 300)      0           embedding_29[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_92 (TimeDistri (None, 30, 300)      180600      spatial_dropout1d_39[0][0]       \n",
      "                                                                 spatial_dropout1d_40[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dot_148 (Dot)                   (None, 30, 30)       0           time_distributed_92[0][0]        \n",
      "                                                                 time_distributed_92[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_128 (Lambda)             (None, 30, 30)       0           dot_148[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_50 (Permute)            (None, 30, 30)       0           lambda_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_127 (Lambda)             (None, 30, 30)       0           dot_148[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_150 (Dot)                   (None, 30, 300)      0           permute_50[0][0]                 \n",
      "                                                                 time_distributed_92[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dot_149 (Dot)                   (None, 30, 300)      0           lambda_127[0][0]                 \n",
      "                                                                 time_distributed_92[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_129 (Lambda)             (None, 30, 300)      0           time_distributed_92[0][0]        \n",
      "                                                                 dot_150[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_29 (Multiply)          (None, 30, 300)      0           time_distributed_92[0][0]        \n",
      "                                                                 dot_150[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_130 (Lambda)             (None, 30, 300)      0           time_distributed_92[1][0]        \n",
      "                                                                 dot_149[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_30 (Multiply)          (None, 30, 300)      0           time_distributed_92[1][0]        \n",
      "                                                                 dot_149[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_156 (Concatenate)   (None, 30, 1200)     0           time_distributed_92[0][0]        \n",
      "                                                                 dot_150[0][0]                    \n",
      "                                                                 lambda_129[0][0]                 \n",
      "                                                                 multiply_29[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_157 (Concatenate)   (None, 30, 1200)     0           time_distributed_92[1][0]        \n",
      "                                                                 dot_149[0][0]                    \n",
      "                                                                 lambda_130[0][0]                 \n",
      "                                                                 multiply_30[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_93 (TimeDistri (None, 30, 300)      360300      concatenate_156[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_97 (TimeDistri (None, 30, 300)      360300      concatenate_157[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_94 (TimeDistri (None, 30, 300)      0           time_distributed_93[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_98 (TimeDistri (None, 30, 300)      0           time_distributed_97[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_95 (TimeDistri (None, 30, 200)      60200       time_distributed_94[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_99 (TimeDistri (None, 30, 200)      60200       time_distributed_98[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_96 (TimeDistri (None, 30, 200)      0           time_distributed_95[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_100 (TimeDistr (None, 30, 200)      0           time_distributed_99[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_39 (Gl (None, 200)          0           time_distributed_96[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_39 (Global (None, 200)          0           time_distributed_96[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_40 (Gl (None, 200)          0           time_distributed_100[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_40 (Global (None, 200)          0           time_distributed_100[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_158 (Concatenate)   (None, 400)          0           global_average_pooling1d_39[0][0]\n",
      "                                                                 global_max_pooling1d_39[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_159 (Concatenate)   (None, 400)          0           global_average_pooling1d_40[0][0]\n",
      "                                                                 global_max_pooling1d_40[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_160 (Concatenate)   (None, 800)          0           concatenate_158[0][0]            \n",
      "                                                                 concatenate_159[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 800)          3200        concatenate_160[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_68 (Dense)                (None, 256)          205056      batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)            (None, 256)          0           dense_68[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 256)          1024        dropout_49[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_69 (Dense)                (None, 256)          65792       batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_50 (Dropout)            (None, 256)          0           dense_69[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 256)          1024        dropout_50[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_70 (Dense)                (None, 3)            771         batch_normalization_30[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 30,877,967\n",
      "Trainable params: 875,343\n",
      "Non-trainable params: 30,002,624\n",
      "__________________________________________________________________________________________________\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360609/360609 [==============================] - 48s 132us/step - loss: 0.0174 - acc: 0.9051 - weighted_accuracy: 0.9040 - val_loss: 0.2980 - val_acc: 0.8657 - val_weighted_accuracy: 0.8628\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0171 - acc: 0.9072 - weighted_accuracy: 0.9063 - val_loss: 0.2817 - val_acc: 0.8763 - val_weighted_accuracy: 0.8685\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0168 - acc: 0.9096 - weighted_accuracy: 0.9091 - val_loss: 0.2799 - val_acc: 0.8805 - val_weighted_accuracy: 0.8715\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0166 - acc: 0.9112 - weighted_accuracy: 0.9109 - val_loss: 0.2900 - val_acc: 0.8690 - val_weighted_accuracy: 0.8611\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0164 - acc: 0.9126 - weighted_accuracy: 0.9127 - val_loss: 0.2853 - val_acc: 0.8774 - val_weighted_accuracy: 0.8687\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0161 - acc: 0.9140 - weighted_accuracy: 0.9142 - val_loss: 0.2846 - val_acc: 0.8773 - val_weighted_accuracy: 0.8665\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0159 - acc: 0.9162 - weighted_accuracy: 0.9165 - val_loss: 0.2786 - val_acc: 0.8793 - val_weighted_accuracy: 0.8707\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0158 - acc: 0.9173 - weighted_accuracy: 0.9176 - val_loss: 0.2804 - val_acc: 0.8798 - val_weighted_accuracy: 0.8693\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0156 - acc: 0.9186 - weighted_accuracy: 0.9191 - val_loss: 0.2694 - val_acc: 0.8827 - val_weighted_accuracy: 0.8735\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0155 - acc: 0.9190 - weighted_accuracy: 0.9197 - val_loss: 0.2754 - val_acc: 0.8820 - val_weighted_accuracy: 0.8733\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0153 - acc: 0.9202 - weighted_accuracy: 0.9208 - val_loss: 0.2805 - val_acc: 0.8805 - val_weighted_accuracy: 0.8670\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 45s 126us/step - loss: 0.0152 - acc: 0.9205 - weighted_accuracy: 0.9212 - val_loss: 0.2725 - val_acc: 0.8822 - val_weighted_accuracy: 0.8729\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0150 - acc: 0.9215 - weighted_accuracy: 0.9224 - val_loss: 0.2713 - val_acc: 0.8815 - val_weighted_accuracy: 0.8702\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0150 - acc: 0.9222 - weighted_accuracy: 0.9230 - val_loss: 0.2835 - val_acc: 0.8795 - val_weighted_accuracy: 0.8703\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0148 - acc: 0.9231 - weighted_accuracy: 0.9241 - val_loss: 0.2767 - val_acc: 0.8830 - val_weighted_accuracy: 0.8724\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 46s 129us/step - loss: 0.0148 - acc: 0.9239 - weighted_accuracy: 0.9251 - val_loss: 0.2786 - val_acc: 0.8859 - val_weighted_accuracy: 0.8736\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0147 - acc: 0.9246 - weighted_accuracy: 0.9259 - val_loss: 0.2800 - val_acc: 0.8780 - val_weighted_accuracy: 0.8723\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0146 - acc: 0.9255 - weighted_accuracy: 0.9265 - val_loss: 0.2808 - val_acc: 0.8796 - val_weighted_accuracy: 0.8727\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0144 - acc: 0.9265 - weighted_accuracy: 0.9279 - val_loss: 0.2784 - val_acc: 0.8808 - val_weighted_accuracy: 0.8711\n",
      "Epoch 20/500\n",
      "360609/360609 [==============================] - 45s 123us/step - loss: 0.0144 - acc: 0.9264 - weighted_accuracy: 0.9278 - val_loss: 0.2754 - val_acc: 0.8835 - val_weighted_accuracy: 0.8728\n",
      "Epoch 21/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0143 - acc: 0.9268 - weighted_accuracy: 0.9282 - val_loss: 0.2751 - val_acc: 0.8844 - val_weighted_accuracy: 0.8749\n",
      "Epoch 22/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0142 - acc: 0.9283 - weighted_accuracy: 0.9296 - val_loss: 0.2806 - val_acc: 0.8838 - val_weighted_accuracy: 0.8722\n",
      "Epoch 23/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0141 - acc: 0.9282 - weighted_accuracy: 0.9295 - val_loss: 0.2844 - val_acc: 0.8791 - val_weighted_accuracy: 0.8694\n",
      "Epoch 24/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0141 - acc: 0.9285 - weighted_accuracy: 0.9298 - val_loss: 0.2799 - val_acc: 0.8846 - val_weighted_accuracy: 0.8739\n",
      "Epoch 25/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0140 - acc: 0.9289 - weighted_accuracy: 0.9302 - val_loss: 0.2794 - val_acc: 0.8834 - val_weighted_accuracy: 0.8711\n",
      "Epoch 26/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0140 - acc: 0.9295 - weighted_accuracy: 0.9309 - val_loss: 0.2850 - val_acc: 0.8809 - val_weighted_accuracy: 0.8730\n",
      "Epoch 27/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0139 - acc: 0.9304 - weighted_accuracy: 0.9316 - val_loss: 0.2850 - val_acc: 0.8791 - val_weighted_accuracy: 0.8715\n",
      "Epoch 28/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0138 - acc: 0.9313 - weighted_accuracy: 0.9328 - val_loss: 0.2851 - val_acc: 0.8823 - val_weighted_accuracy: 0.8735\n",
      "Epoch 29/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0138 - acc: 0.9314 - weighted_accuracy: 0.9328 - val_loss: 0.2826 - val_acc: 0.8826 - val_weighted_accuracy: 0.8719\n",
      "Epoch 30/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0137 - acc: 0.9315 - weighted_accuracy: 0.9331 - val_loss: 0.2866 - val_acc: 0.8791 - val_weighted_accuracy: 0.8696\n",
      "Epoch 31/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0136 - acc: 0.9317 - weighted_accuracy: 0.9334 - val_loss: 0.2856 - val_acc: 0.8816 - val_weighted_accuracy: 0.8717\n",
      "Epoch 32/500\n",
      "360609/360609 [==============================] - 45s 126us/step - loss: 0.0136 - acc: 0.9325 - weighted_accuracy: 0.9342 - val_loss: 0.2838 - val_acc: 0.8831 - val_weighted_accuracy: 0.8705\n",
      "Epoch 33/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0135 - acc: 0.9330 - weighted_accuracy: 0.9346 - val_loss: 0.2923 - val_acc: 0.8782 - val_weighted_accuracy: 0.8668\n",
      "Epoch 34/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0134 - acc: 0.9334 - weighted_accuracy: 0.9352 - val_loss: 0.2892 - val_acc: 0.8799 - val_weighted_accuracy: 0.8709\n",
      "Epoch 35/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0134 - acc: 0.9333 - weighted_accuracy: 0.9349 - val_loss: 0.2817 - val_acc: 0.8826 - val_weighted_accuracy: 0.8713\n",
      "Epoch 36/500\n",
      "360609/360609 [==============================] - 45s 123us/step - loss: 0.0133 - acc: 0.9336 - weighted_accuracy: 0.9353 - val_loss: 0.2858 - val_acc: 0.8822 - val_weighted_accuracy: 0.8717\n",
      "Epoch 37/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0132 - acc: 0.9351 - weighted_accuracy: 0.9366 - val_loss: 0.2883 - val_acc: 0.8829 - val_weighted_accuracy: 0.8712\n",
      "Epoch 38/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0132 - acc: 0.9350 - weighted_accuracy: 0.9366 - val_loss: 0.2861 - val_acc: 0.8825 - val_weighted_accuracy: 0.8723\n",
      "Epoch 39/500\n",
      "360609/360609 [==============================] - 44s 122us/step - loss: 0.0132 - acc: 0.9354 - weighted_accuracy: 0.9372 - val_loss: 0.2953 - val_acc: 0.8786 - val_weighted_accuracy: 0.8690\n",
      "Epoch 40/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0132 - acc: 0.9353 - weighted_accuracy: 0.9372 - val_loss: 0.2870 - val_acc: 0.8801 - val_weighted_accuracy: 0.8718\n",
      "Epoch 41/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0130 - acc: 0.9366 - weighted_accuracy: 0.9384 - val_loss: 0.2854 - val_acc: 0.8810 - val_weighted_accuracy: 0.8708\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_31 (Embedding)        (None, 30, 300)      30000000    first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_41 (SpatialDr (None, 30, 300)      0           embedding_31[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_42 (SpatialDr (None, 30, 300)      0           embedding_31[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_101 (TimeDistr (None, 30, 300)      180600      spatial_dropout1d_41[0][0]       \n",
      "                                                                 spatial_dropout1d_42[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dot_151 (Dot)                   (None, 30, 30)       0           time_distributed_101[0][0]       \n",
      "                                                                 time_distributed_101[1][0]       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_132 (Lambda)             (None, 30, 30)       0           dot_151[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_51 (Permute)            (None, 30, 30)       0           lambda_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_131 (Lambda)             (None, 30, 30)       0           dot_151[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_153 (Dot)                   (None, 30, 300)      0           permute_51[0][0]                 \n",
      "                                                                 time_distributed_101[1][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dot_152 (Dot)                   (None, 30, 300)      0           lambda_131[0][0]                 \n",
      "                                                                 time_distributed_101[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_133 (Lambda)             (None, 30, 300)      0           time_distributed_101[0][0]       \n",
      "                                                                 dot_153[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_31 (Multiply)          (None, 30, 300)      0           time_distributed_101[0][0]       \n",
      "                                                                 dot_153[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_134 (Lambda)             (None, 30, 300)      0           time_distributed_101[1][0]       \n",
      "                                                                 dot_152[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_32 (Multiply)          (None, 30, 300)      0           time_distributed_101[1][0]       \n",
      "                                                                 dot_152[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_161 (Concatenate)   (None, 30, 1200)     0           time_distributed_101[0][0]       \n",
      "                                                                 dot_153[0][0]                    \n",
      "                                                                 lambda_133[0][0]                 \n",
      "                                                                 multiply_31[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_162 (Concatenate)   (None, 30, 1200)     0           time_distributed_101[1][0]       \n",
      "                                                                 dot_152[0][0]                    \n",
      "                                                                 lambda_134[0][0]                 \n",
      "                                                                 multiply_32[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_102 (TimeDistr (None, 30, 300)      360300      concatenate_161[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_106 (TimeDistr (None, 30, 300)      360300      concatenate_162[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_103 (TimeDistr (None, 30, 300)      0           time_distributed_102[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_107 (TimeDistr (None, 30, 300)      0           time_distributed_106[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_104 (TimeDistr (None, 30, 200)      60200       time_distributed_103[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_108 (TimeDistr (None, 30, 200)      60200       time_distributed_107[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_105 (TimeDistr (None, 30, 200)      0           time_distributed_104[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_109 (TimeDistr (None, 30, 200)      0           time_distributed_108[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_41 (Gl (None, 200)          0           time_distributed_105[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_41 (Global (None, 200)          0           time_distributed_105[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_42 (Gl (None, 200)          0           time_distributed_109[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_42 (Global (None, 200)          0           time_distributed_109[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_163 (Concatenate)   (None, 400)          0           global_average_pooling1d_41[0][0]\n",
      "                                                                 global_max_pooling1d_41[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_164 (Concatenate)   (None, 400)          0           global_average_pooling1d_42[0][0]\n",
      "                                                                 global_max_pooling1d_42[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_165 (Concatenate)   (None, 800)          0           concatenate_163[0][0]            \n",
      "                                                                 concatenate_164[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 800)          3200        concatenate_165[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_73 (Dense)                (None, 256)          205056      batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_53 (Dropout)            (None, 256)          0           dense_73[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 256)          1024        dropout_53[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_74 (Dense)                (None, 256)          65792       batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_54 (Dropout)            (None, 256)          0           dense_74[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 256)          1024        dropout_54[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_75 (Dense)                (None, 3)            771         batch_normalization_33[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 30,877,967\n",
      "Trainable params: 875,343\n",
      "Non-trainable params: 30,002,624\n",
      "__________________________________________________________________________________________________\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360609/360609 [==============================] - 48s 133us/step - loss: 0.0178 - acc: 0.9030 - weighted_accuracy: 0.9014 - val_loss: 0.3609 - val_acc: 0.8333 - val_weighted_accuracy: 0.8369\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0175 - acc: 0.9052 - weighted_accuracy: 0.9038 - val_loss: 0.3132 - val_acc: 0.8630 - val_weighted_accuracy: 0.8510\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0171 - acc: 0.9083 - weighted_accuracy: 0.9074 - val_loss: 0.3027 - val_acc: 0.8668 - val_weighted_accuracy: 0.8607\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0168 - acc: 0.9100 - weighted_accuracy: 0.9093 - val_loss: 0.2933 - val_acc: 0.8713 - val_weighted_accuracy: 0.8641\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0166 - acc: 0.9118 - weighted_accuracy: 0.9112 - val_loss: 0.2978 - val_acc: 0.8681 - val_weighted_accuracy: 0.8614\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0163 - acc: 0.9132 - weighted_accuracy: 0.9128 - val_loss: 0.3007 - val_acc: 0.8685 - val_weighted_accuracy: 0.8622\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0162 - acc: 0.9146 - weighted_accuracy: 0.9144 - val_loss: 0.2996 - val_acc: 0.8697 - val_weighted_accuracy: 0.8633\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0160 - acc: 0.9152 - weighted_accuracy: 0.9153 - val_loss: 0.2977 - val_acc: 0.8689 - val_weighted_accuracy: 0.8636\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0158 - acc: 0.9165 - weighted_accuracy: 0.9170 - val_loss: 0.3150 - val_acc: 0.8619 - val_weighted_accuracy: 0.8599\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0156 - acc: 0.9179 - weighted_accuracy: 0.9183 - val_loss: 0.3061 - val_acc: 0.8670 - val_weighted_accuracy: 0.8611\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0155 - acc: 0.9194 - weighted_accuracy: 0.9199 - val_loss: 0.3029 - val_acc: 0.8679 - val_weighted_accuracy: 0.8626\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0154 - acc: 0.9197 - weighted_accuracy: 0.9199 - val_loss: 0.3017 - val_acc: 0.8697 - val_weighted_accuracy: 0.8632\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0152 - acc: 0.9212 - weighted_accuracy: 0.9219 - val_loss: 0.2993 - val_acc: 0.8713 - val_weighted_accuracy: 0.8646\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 45s 123us/step - loss: 0.0152 - acc: 0.9211 - weighted_accuracy: 0.9219 - val_loss: 0.3014 - val_acc: 0.8707 - val_weighted_accuracy: 0.8643\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0150 - acc: 0.9230 - weighted_accuracy: 0.9236 - val_loss: 0.2999 - val_acc: 0.8691 - val_weighted_accuracy: 0.8634\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0149 - acc: 0.9231 - weighted_accuracy: 0.9237 - val_loss: 0.2990 - val_acc: 0.8683 - val_weighted_accuracy: 0.8630\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0148 - acc: 0.9243 - weighted_accuracy: 0.9253 - val_loss: 0.3016 - val_acc: 0.8679 - val_weighted_accuracy: 0.8631\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0146 - acc: 0.9245 - weighted_accuracy: 0.9255 - val_loss: 0.3053 - val_acc: 0.8638 - val_weighted_accuracy: 0.8615\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0146 - acc: 0.9250 - weighted_accuracy: 0.9258 - val_loss: 0.3182 - val_acc: 0.8624 - val_weighted_accuracy: 0.8592\n",
      "Epoch 20/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0145 - acc: 0.9261 - weighted_accuracy: 0.9271 - val_loss: 0.2994 - val_acc: 0.8693 - val_weighted_accuracy: 0.8638\n",
      "Epoch 21/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0144 - acc: 0.9268 - weighted_accuracy: 0.9280 - val_loss: 0.3100 - val_acc: 0.8686 - val_weighted_accuracy: 0.8609\n",
      "Epoch 22/500\n",
      "360609/360609 [==============================] - 45s 123us/step - loss: 0.0144 - acc: 0.9270 - weighted_accuracy: 0.9281 - val_loss: 0.3018 - val_acc: 0.8694 - val_weighted_accuracy: 0.8623\n",
      "Epoch 23/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0142 - acc: 0.9284 - weighted_accuracy: 0.9295 - val_loss: 0.3040 - val_acc: 0.8692 - val_weighted_accuracy: 0.8637\n",
      "Epoch 24/500\n",
      "360609/360609 [==============================] - 45s 123us/step - loss: 0.0142 - acc: 0.9284 - weighted_accuracy: 0.9297 - val_loss: 0.3055 - val_acc: 0.8715 - val_weighted_accuracy: 0.8626\n",
      "Epoch 25/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0140 - acc: 0.9294 - weighted_accuracy: 0.9307 - val_loss: 0.3009 - val_acc: 0.8713 - val_weighted_accuracy: 0.8619\n",
      "Epoch 26/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0140 - acc: 0.9294 - weighted_accuracy: 0.9307 - val_loss: 0.3132 - val_acc: 0.8685 - val_weighted_accuracy: 0.8636\n",
      "Epoch 27/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0139 - acc: 0.9305 - weighted_accuracy: 0.9318 - val_loss: 0.3062 - val_acc: 0.8701 - val_weighted_accuracy: 0.8631\n",
      "Epoch 28/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0138 - acc: 0.9305 - weighted_accuracy: 0.9319 - val_loss: 0.3089 - val_acc: 0.8687 - val_weighted_accuracy: 0.8634\n",
      "Epoch 29/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0138 - acc: 0.9314 - weighted_accuracy: 0.9327 - val_loss: 0.3078 - val_acc: 0.8683 - val_weighted_accuracy: 0.8619\n",
      "Epoch 30/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0137 - acc: 0.9316 - weighted_accuracy: 0.9330 - val_loss: 0.3158 - val_acc: 0.8657 - val_weighted_accuracy: 0.8599\n",
      "Epoch 31/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0137 - acc: 0.9315 - weighted_accuracy: 0.9329 - val_loss: 0.3048 - val_acc: 0.8698 - val_weighted_accuracy: 0.8615\n",
      "Epoch 32/500\n",
      "360609/360609 [==============================] - 45s 123us/step - loss: 0.0136 - acc: 0.9323 - weighted_accuracy: 0.9339 - val_loss: 0.3091 - val_acc: 0.8692 - val_weighted_accuracy: 0.8618\n",
      "Epoch 33/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0135 - acc: 0.9336 - weighted_accuracy: 0.9352 - val_loss: 0.3074 - val_acc: 0.8694 - val_weighted_accuracy: 0.8624\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_33 (Embedding)        (None, 30, 300)      30000000    first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_43 (SpatialDr (None, 30, 300)      0           embedding_33[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_44 (SpatialDr (None, 30, 300)      0           embedding_33[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_110 (TimeDistr (None, 30, 300)      180600      spatial_dropout1d_43[0][0]       \n",
      "                                                                 spatial_dropout1d_44[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dot_154 (Dot)                   (None, 30, 30)       0           time_distributed_110[0][0]       \n",
      "                                                                 time_distributed_110[1][0]       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_136 (Lambda)             (None, 30, 30)       0           dot_154[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_52 (Permute)            (None, 30, 30)       0           lambda_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_135 (Lambda)             (None, 30, 30)       0           dot_154[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_156 (Dot)                   (None, 30, 300)      0           permute_52[0][0]                 \n",
      "                                                                 time_distributed_110[1][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dot_155 (Dot)                   (None, 30, 300)      0           lambda_135[0][0]                 \n",
      "                                                                 time_distributed_110[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_137 (Lambda)             (None, 30, 300)      0           time_distributed_110[0][0]       \n",
      "                                                                 dot_156[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_33 (Multiply)          (None, 30, 300)      0           time_distributed_110[0][0]       \n",
      "                                                                 dot_156[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_138 (Lambda)             (None, 30, 300)      0           time_distributed_110[1][0]       \n",
      "                                                                 dot_155[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_34 (Multiply)          (None, 30, 300)      0           time_distributed_110[1][0]       \n",
      "                                                                 dot_155[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_166 (Concatenate)   (None, 30, 1200)     0           time_distributed_110[0][0]       \n",
      "                                                                 dot_156[0][0]                    \n",
      "                                                                 lambda_137[0][0]                 \n",
      "                                                                 multiply_33[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_167 (Concatenate)   (None, 30, 1200)     0           time_distributed_110[1][0]       \n",
      "                                                                 dot_155[0][0]                    \n",
      "                                                                 lambda_138[0][0]                 \n",
      "                                                                 multiply_34[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_111 (TimeDistr (None, 30, 300)      360300      concatenate_166[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_115 (TimeDistr (None, 30, 300)      360300      concatenate_167[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_112 (TimeDistr (None, 30, 300)      0           time_distributed_111[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_116 (TimeDistr (None, 30, 300)      0           time_distributed_115[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_113 (TimeDistr (None, 30, 200)      60200       time_distributed_112[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_117 (TimeDistr (None, 30, 200)      60200       time_distributed_116[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_114 (TimeDistr (None, 30, 200)      0           time_distributed_113[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_118 (TimeDistr (None, 30, 200)      0           time_distributed_117[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_43 (Gl (None, 200)          0           time_distributed_114[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_43 (Global (None, 200)          0           time_distributed_114[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_44 (Gl (None, 200)          0           time_distributed_118[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_44 (Global (None, 200)          0           time_distributed_118[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_168 (Concatenate)   (None, 400)          0           global_average_pooling1d_43[0][0]\n",
      "                                                                 global_max_pooling1d_43[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_169 (Concatenate)   (None, 400)          0           global_average_pooling1d_44[0][0]\n",
      "                                                                 global_max_pooling1d_44[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_170 (Concatenate)   (None, 800)          0           concatenate_168[0][0]            \n",
      "                                                                 concatenate_169[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 800)          3200        concatenate_170[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_78 (Dense)                (None, 256)          205056      batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_57 (Dropout)            (None, 256)          0           dense_78[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 256)          1024        dropout_57[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_79 (Dense)                (None, 256)          65792       batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_58 (Dropout)            (None, 256)          0           dense_79[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 256)          1024        dropout_58[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_80 (Dense)                (None, 3)            771         batch_normalization_36[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 30,877,967\n",
      "Trainable params: 875,343\n",
      "Non-trainable params: 30,002,624\n",
      "__________________________________________________________________________________________________\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360609/360609 [==============================] - 48s 134us/step - loss: 0.0158 - acc: 0.9157 - weighted_accuracy: 0.9159 - val_loss: 0.3060 - val_acc: 0.8710 - val_weighted_accuracy: 0.8597\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0158 - acc: 0.9167 - weighted_accuracy: 0.9167 - val_loss: 0.3015 - val_acc: 0.8707 - val_weighted_accuracy: 0.8611\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0156 - acc: 0.9182 - weighted_accuracy: 0.9186 - val_loss: 0.3114 - val_acc: 0.8680 - val_weighted_accuracy: 0.8608\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0154 - acc: 0.9196 - weighted_accuracy: 0.9201 - val_loss: 0.3075 - val_acc: 0.8667 - val_weighted_accuracy: 0.8593\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0152 - acc: 0.9210 - weighted_accuracy: 0.9215 - val_loss: 0.3016 - val_acc: 0.8704 - val_weighted_accuracy: 0.8601\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0150 - acc: 0.9222 - weighted_accuracy: 0.9231 - val_loss: 0.3099 - val_acc: 0.8664 - val_weighted_accuracy: 0.8609\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0149 - acc: 0.9233 - weighted_accuracy: 0.9241 - val_loss: 0.3124 - val_acc: 0.8710 - val_weighted_accuracy: 0.8619\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0148 - acc: 0.9236 - weighted_accuracy: 0.9247 - val_loss: 0.3131 - val_acc: 0.8709 - val_weighted_accuracy: 0.8646\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0146 - acc: 0.9253 - weighted_accuracy: 0.9264 - val_loss: 0.3036 - val_acc: 0.8709 - val_weighted_accuracy: 0.8641\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0145 - acc: 0.9255 - weighted_accuracy: 0.9266 - val_loss: 0.3003 - val_acc: 0.8685 - val_weighted_accuracy: 0.8600\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0144 - acc: 0.9258 - weighted_accuracy: 0.9271 - val_loss: 0.3034 - val_acc: 0.8716 - val_weighted_accuracy: 0.8649\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0143 - acc: 0.9276 - weighted_accuracy: 0.9288 - val_loss: 0.3031 - val_acc: 0.8688 - val_weighted_accuracy: 0.8607\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0142 - acc: 0.9277 - weighted_accuracy: 0.9291 - val_loss: 0.3071 - val_acc: 0.8706 - val_weighted_accuracy: 0.8632\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0141 - acc: 0.9282 - weighted_accuracy: 0.9295 - val_loss: 0.3016 - val_acc: 0.8715 - val_weighted_accuracy: 0.8623\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0140 - acc: 0.9289 - weighted_accuracy: 0.9301 - val_loss: 0.3110 - val_acc: 0.8685 - val_weighted_accuracy: 0.8631\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0139 - acc: 0.9292 - weighted_accuracy: 0.9307 - val_loss: 0.3100 - val_acc: 0.8699 - val_weighted_accuracy: 0.8610\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0139 - acc: 0.9301 - weighted_accuracy: 0.9315 - val_loss: 0.3143 - val_acc: 0.8698 - val_weighted_accuracy: 0.8598\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0138 - acc: 0.9306 - weighted_accuracy: 0.9320 - val_loss: 0.3093 - val_acc: 0.8677 - val_weighted_accuracy: 0.8595\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0137 - acc: 0.9310 - weighted_accuracy: 0.9325 - val_loss: 0.3183 - val_acc: 0.8668 - val_weighted_accuracy: 0.8606\n",
      "Epoch 20/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0137 - acc: 0.9319 - weighted_accuracy: 0.9333 - val_loss: 0.3122 - val_acc: 0.8686 - val_weighted_accuracy: 0.8627\n",
      "Epoch 21/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0136 - acc: 0.9321 - weighted_accuracy: 0.9336 - val_loss: 0.3156 - val_acc: 0.8703 - val_weighted_accuracy: 0.8628\n",
      "Epoch 22/500\n",
      "360609/360609 [==============================] - 45s 123us/step - loss: 0.0135 - acc: 0.9329 - weighted_accuracy: 0.9346 - val_loss: 0.3158 - val_acc: 0.8691 - val_weighted_accuracy: 0.8618\n",
      "Epoch 23/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0135 - acc: 0.9329 - weighted_accuracy: 0.9346 - val_loss: 0.3107 - val_acc: 0.8672 - val_weighted_accuracy: 0.8613\n",
      "Epoch 24/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0134 - acc: 0.9337 - weighted_accuracy: 0.9354 - val_loss: 0.3093 - val_acc: 0.8679 - val_weighted_accuracy: 0.8606\n",
      "Epoch 25/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0132 - acc: 0.9342 - weighted_accuracy: 0.9361 - val_loss: 0.3116 - val_acc: 0.8674 - val_weighted_accuracy: 0.8604\n",
      "Epoch 26/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0133 - acc: 0.9343 - weighted_accuracy: 0.9360 - val_loss: 0.3078 - val_acc: 0.8689 - val_weighted_accuracy: 0.8631\n",
      "Epoch 27/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0132 - acc: 0.9342 - weighted_accuracy: 0.9357 - val_loss: 0.3092 - val_acc: 0.8690 - val_weighted_accuracy: 0.8611\n",
      "Epoch 28/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0131 - acc: 0.9357 - weighted_accuracy: 0.9374 - val_loss: 0.3166 - val_acc: 0.8694 - val_weighted_accuracy: 0.8629\n",
      "Epoch 29/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0131 - acc: 0.9360 - weighted_accuracy: 0.9375 - val_loss: 0.3115 - val_acc: 0.8702 - val_weighted_accuracy: 0.8607\n",
      "Epoch 30/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0131 - acc: 0.9358 - weighted_accuracy: 0.9374 - val_loss: 0.3219 - val_acc: 0.8712 - val_weighted_accuracy: 0.8620\n",
      "Epoch 31/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0130 - acc: 0.9365 - weighted_accuracy: 0.9384 - val_loss: 0.3161 - val_acc: 0.8701 - val_weighted_accuracy: 0.8637\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_35 (Embedding)        (None, 30, 300)      30000000    first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_45 (SpatialDr (None, 30, 300)      0           embedding_35[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_46 (SpatialDr (None, 30, 300)      0           embedding_35[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_119 (TimeDistr (None, 30, 300)      180600      spatial_dropout1d_45[0][0]       \n",
      "                                                                 spatial_dropout1d_46[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dot_157 (Dot)                   (None, 30, 30)       0           time_distributed_119[0][0]       \n",
      "                                                                 time_distributed_119[1][0]       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_140 (Lambda)             (None, 30, 30)       0           dot_157[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_53 (Permute)            (None, 30, 30)       0           lambda_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_139 (Lambda)             (None, 30, 30)       0           dot_157[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_159 (Dot)                   (None, 30, 300)      0           permute_53[0][0]                 \n",
      "                                                                 time_distributed_119[1][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dot_158 (Dot)                   (None, 30, 300)      0           lambda_139[0][0]                 \n",
      "                                                                 time_distributed_119[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_141 (Lambda)             (None, 30, 300)      0           time_distributed_119[0][0]       \n",
      "                                                                 dot_159[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_35 (Multiply)          (None, 30, 300)      0           time_distributed_119[0][0]       \n",
      "                                                                 dot_159[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_142 (Lambda)             (None, 30, 300)      0           time_distributed_119[1][0]       \n",
      "                                                                 dot_158[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_36 (Multiply)          (None, 30, 300)      0           time_distributed_119[1][0]       \n",
      "                                                                 dot_158[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_171 (Concatenate)   (None, 30, 1200)     0           time_distributed_119[0][0]       \n",
      "                                                                 dot_159[0][0]                    \n",
      "                                                                 lambda_141[0][0]                 \n",
      "                                                                 multiply_35[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_172 (Concatenate)   (None, 30, 1200)     0           time_distributed_119[1][0]       \n",
      "                                                                 dot_158[0][0]                    \n",
      "                                                                 lambda_142[0][0]                 \n",
      "                                                                 multiply_36[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_120 (TimeDistr (None, 30, 300)      360300      concatenate_171[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_124 (TimeDistr (None, 30, 300)      360300      concatenate_172[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_121 (TimeDistr (None, 30, 300)      0           time_distributed_120[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_125 (TimeDistr (None, 30, 300)      0           time_distributed_124[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_122 (TimeDistr (None, 30, 200)      60200       time_distributed_121[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_126 (TimeDistr (None, 30, 200)      60200       time_distributed_125[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_123 (TimeDistr (None, 30, 200)      0           time_distributed_122[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_127 (TimeDistr (None, 30, 200)      0           time_distributed_126[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_45 (Gl (None, 200)          0           time_distributed_123[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_45 (Global (None, 200)          0           time_distributed_123[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_46 (Gl (None, 200)          0           time_distributed_127[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_46 (Global (None, 200)          0           time_distributed_127[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_173 (Concatenate)   (None, 400)          0           global_average_pooling1d_45[0][0]\n",
      "                                                                 global_max_pooling1d_45[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_174 (Concatenate)   (None, 400)          0           global_average_pooling1d_46[0][0]\n",
      "                                                                 global_max_pooling1d_46[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_175 (Concatenate)   (None, 800)          0           concatenate_173[0][0]            \n",
      "                                                                 concatenate_174[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 800)          3200        concatenate_175[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_83 (Dense)                (None, 256)          205056      batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_61 (Dropout)            (None, 256)          0           dense_83[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 256)          1024        dropout_61[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_84 (Dense)                (None, 256)          65792       batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_62 (Dropout)            (None, 256)          0           dense_84[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 256)          1024        dropout_62[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_85 (Dense)                (None, 3)            771         batch_normalization_39[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 30,877,967\n",
      "Trainable params: 875,343\n",
      "Non-trainable params: 30,002,624\n",
      "__________________________________________________________________________________________________\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360609/360609 [==============================] - 49s 135us/step - loss: 0.0190 - acc: 0.8955 - weighted_accuracy: 0.8926 - val_loss: 0.3207 - val_acc: 0.8521 - val_weighted_accuracy: 0.8462\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0185 - acc: 0.8997 - weighted_accuracy: 0.8970 - val_loss: 0.3289 - val_acc: 0.8538 - val_weighted_accuracy: 0.8471\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0179 - acc: 0.9026 - weighted_accuracy: 0.9006 - val_loss: 0.3295 - val_acc: 0.8505 - val_weighted_accuracy: 0.8428\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0176 - acc: 0.9046 - weighted_accuracy: 0.9027 - val_loss: 0.3127 - val_acc: 0.8600 - val_weighted_accuracy: 0.8485\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0173 - acc: 0.9067 - weighted_accuracy: 0.9052 - val_loss: 0.3046 - val_acc: 0.8611 - val_weighted_accuracy: 0.8482\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0170 - acc: 0.9091 - weighted_accuracy: 0.9080 - val_loss: 0.3076 - val_acc: 0.8579 - val_weighted_accuracy: 0.8519\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0167 - acc: 0.9107 - weighted_accuracy: 0.9099 - val_loss: 0.3066 - val_acc: 0.8641 - val_weighted_accuracy: 0.8520\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0165 - acc: 0.9122 - weighted_accuracy: 0.9114 - val_loss: 0.3094 - val_acc: 0.8609 - val_weighted_accuracy: 0.8535\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0163 - acc: 0.9133 - weighted_accuracy: 0.9128 - val_loss: 0.3105 - val_acc: 0.8600 - val_weighted_accuracy: 0.8486\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0161 - acc: 0.9146 - weighted_accuracy: 0.9143 - val_loss: 0.3057 - val_acc: 0.8587 - val_weighted_accuracy: 0.8517\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0160 - acc: 0.9158 - weighted_accuracy: 0.9155 - val_loss: 0.3147 - val_acc: 0.8573 - val_weighted_accuracy: 0.8505\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0158 - acc: 0.9177 - weighted_accuracy: 0.9174 - val_loss: 0.3123 - val_acc: 0.8577 - val_weighted_accuracy: 0.8503\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0157 - acc: 0.9184 - weighted_accuracy: 0.9183 - val_loss: 0.3022 - val_acc: 0.8632 - val_weighted_accuracy: 0.8549\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0155 - acc: 0.9190 - weighted_accuracy: 0.9191 - val_loss: 0.3275 - val_acc: 0.8514 - val_weighted_accuracy: 0.8493\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0154 - acc: 0.9198 - weighted_accuracy: 0.9201 - val_loss: 0.3124 - val_acc: 0.8590 - val_weighted_accuracy: 0.8510\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0152 - acc: 0.9210 - weighted_accuracy: 0.9214 - val_loss: 0.3170 - val_acc: 0.8594 - val_weighted_accuracy: 0.8510\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 45s 123us/step - loss: 0.0152 - acc: 0.9221 - weighted_accuracy: 0.9224 - val_loss: 0.3117 - val_acc: 0.8606 - val_weighted_accuracy: 0.8497\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0150 - acc: 0.9229 - weighted_accuracy: 0.9234 - val_loss: 0.3197 - val_acc: 0.8552 - val_weighted_accuracy: 0.8500\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0149 - acc: 0.9243 - weighted_accuracy: 0.9250 - val_loss: 0.3180 - val_acc: 0.8589 - val_weighted_accuracy: 0.8511\n",
      "Epoch 20/500\n",
      "360609/360609 [==============================] - 44s 123us/step - loss: 0.0148 - acc: 0.9243 - weighted_accuracy: 0.9248 - val_loss: 0.3104 - val_acc: 0.8589 - val_weighted_accuracy: 0.8514\n",
      "Epoch 21/500\n",
      "360609/360609 [==============================] - 45s 123us/step - loss: 0.0147 - acc: 0.9251 - weighted_accuracy: 0.9258 - val_loss: 0.3146 - val_acc: 0.8595 - val_weighted_accuracy: 0.8498\n",
      "Epoch 22/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0145 - acc: 0.9258 - weighted_accuracy: 0.9266 - val_loss: 0.3139 - val_acc: 0.8608 - val_weighted_accuracy: 0.8535\n",
      "Epoch 23/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0145 - acc: 0.9264 - weighted_accuracy: 0.9272 - val_loss: 0.3165 - val_acc: 0.8608 - val_weighted_accuracy: 0.8508\n",
      "Epoch 24/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0144 - acc: 0.9271 - weighted_accuracy: 0.9279 - val_loss: 0.3202 - val_acc: 0.8604 - val_weighted_accuracy: 0.8533\n",
      "Epoch 25/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0143 - acc: 0.9282 - weighted_accuracy: 0.9290 - val_loss: 0.3154 - val_acc: 0.8612 - val_weighted_accuracy: 0.8541\n",
      "Epoch 26/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0142 - acc: 0.9287 - weighted_accuracy: 0.9297 - val_loss: 0.3147 - val_acc: 0.8622 - val_weighted_accuracy: 0.8520\n",
      "Epoch 27/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0141 - acc: 0.9289 - weighted_accuracy: 0.9298 - val_loss: 0.3222 - val_acc: 0.8619 - val_weighted_accuracy: 0.8521\n",
      "Epoch 28/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0140 - acc: 0.9295 - weighted_accuracy: 0.9304 - val_loss: 0.3145 - val_acc: 0.8604 - val_weighted_accuracy: 0.8523\n",
      "Epoch 29/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0139 - acc: 0.9301 - weighted_accuracy: 0.9311 - val_loss: 0.3149 - val_acc: 0.8641 - val_weighted_accuracy: 0.8551\n",
      "Epoch 30/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0139 - acc: 0.9312 - weighted_accuracy: 0.9322 - val_loss: 0.3286 - val_acc: 0.8604 - val_weighted_accuracy: 0.8524\n",
      "Epoch 31/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0139 - acc: 0.9309 - weighted_accuracy: 0.9320 - val_loss: 0.3188 - val_acc: 0.8604 - val_weighted_accuracy: 0.8514\n",
      "Epoch 32/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0138 - acc: 0.9315 - weighted_accuracy: 0.9325 - val_loss: 0.3223 - val_acc: 0.8564 - val_weighted_accuracy: 0.8504\n",
      "Epoch 33/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0136 - acc: 0.9321 - weighted_accuracy: 0.9333 - val_loss: 0.3265 - val_acc: 0.8559 - val_weighted_accuracy: 0.8471\n",
      "Epoch 34/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0136 - acc: 0.9323 - weighted_accuracy: 0.9336 - val_loss: 0.3206 - val_acc: 0.8580 - val_weighted_accuracy: 0.8499\n",
      "Epoch 35/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0136 - acc: 0.9327 - weighted_accuracy: 0.9338 - val_loss: 0.3301 - val_acc: 0.8595 - val_weighted_accuracy: 0.8467\n",
      "Epoch 36/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0135 - acc: 0.9334 - weighted_accuracy: 0.9347 - val_loss: 0.3261 - val_acc: 0.8583 - val_weighted_accuracy: 0.8519\n",
      "Epoch 37/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0135 - acc: 0.9334 - weighted_accuracy: 0.9347 - val_loss: 0.3228 - val_acc: 0.8621 - val_weighted_accuracy: 0.8520\n",
      "Epoch 38/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0134 - acc: 0.9335 - weighted_accuracy: 0.9348 - val_loss: 0.3226 - val_acc: 0.8621 - val_weighted_accuracy: 0.8538\n",
      "Epoch 39/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0134 - acc: 0.9348 - weighted_accuracy: 0.9359 - val_loss: 0.3246 - val_acc: 0.8628 - val_weighted_accuracy: 0.8523\n",
      "Epoch 40/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0132 - acc: 0.9351 - weighted_accuracy: 0.9364 - val_loss: 0.3208 - val_acc: 0.8606 - val_weighted_accuracy: 0.8515\n",
      "Epoch 41/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0132 - acc: 0.9356 - weighted_accuracy: 0.9370 - val_loss: 0.3267 - val_acc: 0.8614 - val_weighted_accuracy: 0.8502\n",
      "Epoch 42/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0132 - acc: 0.9352 - weighted_accuracy: 0.9367 - val_loss: 0.3211 - val_acc: 0.8604 - val_weighted_accuracy: 0.8490\n",
      "Epoch 43/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0131 - acc: 0.9360 - weighted_accuracy: 0.9373 - val_loss: 0.3245 - val_acc: 0.8616 - val_weighted_accuracy: 0.8516\n",
      "Epoch 44/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0130 - acc: 0.9368 - weighted_accuracy: 0.9382 - val_loss: 0.3238 - val_acc: 0.8610 - val_weighted_accuracy: 0.8504\n",
      "Epoch 45/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0130 - acc: 0.9369 - weighted_accuracy: 0.9384 - val_loss: 0.3292 - val_acc: 0.8608 - val_weighted_accuracy: 0.8492\n",
      "Epoch 46/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0129 - acc: 0.9374 - weighted_accuracy: 0.9388 - val_loss: 0.3354 - val_acc: 0.8543 - val_weighted_accuracy: 0.8485\n",
      "Epoch 47/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0129 - acc: 0.9377 - weighted_accuracy: 0.9392 - val_loss: 0.3224 - val_acc: 0.8647 - val_weighted_accuracy: 0.8530\n",
      "Epoch 48/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0129 - acc: 0.9377 - weighted_accuracy: 0.9391 - val_loss: 0.3257 - val_acc: 0.8615 - val_weighted_accuracy: 0.8509\n",
      "Epoch 49/500\n",
      "360609/360609 [==============================] - 45s 123us/step - loss: 0.0128 - acc: 0.9384 - weighted_accuracy: 0.9397 - val_loss: 0.3300 - val_acc: 0.8604 - val_weighted_accuracy: 0.8482\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_37 (Embedding)        (None, 30, 300)      30000000    first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_47 (SpatialDr (None, 30, 300)      0           embedding_37[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_48 (SpatialDr (None, 30, 300)      0           embedding_37[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_128 (TimeDistr (None, 30, 300)      180600      spatial_dropout1d_47[0][0]       \n",
      "                                                                 spatial_dropout1d_48[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dot_160 (Dot)                   (None, 30, 30)       0           time_distributed_128[0][0]       \n",
      "                                                                 time_distributed_128[1][0]       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_144 (Lambda)             (None, 30, 30)       0           dot_160[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_54 (Permute)            (None, 30, 30)       0           lambda_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_143 (Lambda)             (None, 30, 30)       0           dot_160[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_162 (Dot)                   (None, 30, 300)      0           permute_54[0][0]                 \n",
      "                                                                 time_distributed_128[1][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dot_161 (Dot)                   (None, 30, 300)      0           lambda_143[0][0]                 \n",
      "                                                                 time_distributed_128[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_145 (Lambda)             (None, 30, 300)      0           time_distributed_128[0][0]       \n",
      "                                                                 dot_162[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_37 (Multiply)          (None, 30, 300)      0           time_distributed_128[0][0]       \n",
      "                                                                 dot_162[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_146 (Lambda)             (None, 30, 300)      0           time_distributed_128[1][0]       \n",
      "                                                                 dot_161[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_38 (Multiply)          (None, 30, 300)      0           time_distributed_128[1][0]       \n",
      "                                                                 dot_161[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_176 (Concatenate)   (None, 30, 1200)     0           time_distributed_128[0][0]       \n",
      "                                                                 dot_162[0][0]                    \n",
      "                                                                 lambda_145[0][0]                 \n",
      "                                                                 multiply_37[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_177 (Concatenate)   (None, 30, 1200)     0           time_distributed_128[1][0]       \n",
      "                                                                 dot_161[0][0]                    \n",
      "                                                                 lambda_146[0][0]                 \n",
      "                                                                 multiply_38[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_129 (TimeDistr (None, 30, 300)      360300      concatenate_176[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_133 (TimeDistr (None, 30, 300)      360300      concatenate_177[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_130 (TimeDistr (None, 30, 300)      0           time_distributed_129[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_134 (TimeDistr (None, 30, 300)      0           time_distributed_133[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_131 (TimeDistr (None, 30, 200)      60200       time_distributed_130[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_135 (TimeDistr (None, 30, 200)      60200       time_distributed_134[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_132 (TimeDistr (None, 30, 200)      0           time_distributed_131[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_136 (TimeDistr (None, 30, 200)      0           time_distributed_135[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_47 (Gl (None, 200)          0           time_distributed_132[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_47 (Global (None, 200)          0           time_distributed_132[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_48 (Gl (None, 200)          0           time_distributed_136[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_48 (Global (None, 200)          0           time_distributed_136[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_178 (Concatenate)   (None, 400)          0           global_average_pooling1d_47[0][0]\n",
      "                                                                 global_max_pooling1d_47[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_179 (Concatenate)   (None, 400)          0           global_average_pooling1d_48[0][0]\n",
      "                                                                 global_max_pooling1d_48[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_180 (Concatenate)   (None, 800)          0           concatenate_178[0][0]            \n",
      "                                                                 concatenate_179[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 800)          3200        concatenate_180[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_88 (Dense)                (None, 256)          205056      batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_65 (Dropout)            (None, 256)          0           dense_88[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 256)          1024        dropout_65[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_89 (Dense)                (None, 256)          65792       batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_66 (Dropout)            (None, 256)          0           dense_89[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 256)          1024        dropout_66[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_90 (Dense)                (None, 3)            771         batch_normalization_42[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 30,877,967\n",
      "Trainable params: 875,343\n",
      "Non-trainable params: 30,002,624\n",
      "__________________________________________________________________________________________________\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360609/360609 [==============================] - 49s 137us/step - loss: 0.0169 - acc: 0.9093 - weighted_accuracy: 0.9081 - val_loss: 0.3420 - val_acc: 0.8494 - val_weighted_accuracy: 0.8404\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0167 - acc: 0.9103 - weighted_accuracy: 0.9095 - val_loss: 0.3276 - val_acc: 0.8526 - val_weighted_accuracy: 0.8392\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0163 - acc: 0.9128 - weighted_accuracy: 0.9122 - val_loss: 0.3398 - val_acc: 0.8422 - val_weighted_accuracy: 0.8395\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0161 - acc: 0.9138 - weighted_accuracy: 0.9137 - val_loss: 0.3350 - val_acc: 0.8494 - val_weighted_accuracy: 0.8424\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0158 - acc: 0.9157 - weighted_accuracy: 0.9157 - val_loss: 0.3320 - val_acc: 0.8532 - val_weighted_accuracy: 0.8412\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0157 - acc: 0.9168 - weighted_accuracy: 0.9168 - val_loss: 0.3272 - val_acc: 0.8531 - val_weighted_accuracy: 0.8448\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0156 - acc: 0.9179 - weighted_accuracy: 0.9181 - val_loss: 0.3329 - val_acc: 0.8546 - val_weighted_accuracy: 0.8461\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0154 - acc: 0.9196 - weighted_accuracy: 0.9200 - val_loss: 0.3307 - val_acc: 0.8505 - val_weighted_accuracy: 0.8425\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0152 - acc: 0.9199 - weighted_accuracy: 0.9203 - val_loss: 0.3366 - val_acc: 0.8524 - val_weighted_accuracy: 0.8445\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0151 - acc: 0.9210 - weighted_accuracy: 0.9217 - val_loss: 0.3337 - val_acc: 0.8500 - val_weighted_accuracy: 0.8419\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0149 - acc: 0.9222 - weighted_accuracy: 0.9228 - val_loss: 0.3323 - val_acc: 0.8524 - val_weighted_accuracy: 0.8425\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0149 - acc: 0.9227 - weighted_accuracy: 0.9235 - val_loss: 0.3373 - val_acc: 0.8508 - val_weighted_accuracy: 0.8422\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0147 - acc: 0.9242 - weighted_accuracy: 0.9250 - val_loss: 0.3413 - val_acc: 0.8514 - val_weighted_accuracy: 0.8425\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0146 - acc: 0.9243 - weighted_accuracy: 0.9250 - val_loss: 0.3414 - val_acc: 0.8502 - val_weighted_accuracy: 0.8420\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 45s 126us/step - loss: 0.0145 - acc: 0.9259 - weighted_accuracy: 0.9270 - val_loss: 0.3313 - val_acc: 0.8540 - val_weighted_accuracy: 0.8413\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0144 - acc: 0.9264 - weighted_accuracy: 0.9274 - val_loss: 0.3305 - val_acc: 0.8532 - val_weighted_accuracy: 0.8433\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0143 - acc: 0.9272 - weighted_accuracy: 0.9282 - val_loss: 0.3347 - val_acc: 0.8537 - val_weighted_accuracy: 0.8440\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 45s 126us/step - loss: 0.0142 - acc: 0.9276 - weighted_accuracy: 0.9285 - val_loss: 0.3369 - val_acc: 0.8513 - val_weighted_accuracy: 0.8438\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0141 - acc: 0.9284 - weighted_accuracy: 0.9295 - val_loss: 0.3470 - val_acc: 0.8507 - val_weighted_accuracy: 0.8414\n",
      "Epoch 20/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0140 - acc: 0.9294 - weighted_accuracy: 0.9304 - val_loss: 0.3358 - val_acc: 0.8519 - val_weighted_accuracy: 0.8429\n",
      "Epoch 21/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0140 - acc: 0.9292 - weighted_accuracy: 0.9304 - val_loss: 0.3354 - val_acc: 0.8523 - val_weighted_accuracy: 0.8436\n",
      "Epoch 22/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0138 - acc: 0.9306 - weighted_accuracy: 0.9318 - val_loss: 0.3342 - val_acc: 0.8503 - val_weighted_accuracy: 0.8429\n",
      "Epoch 23/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0138 - acc: 0.9306 - weighted_accuracy: 0.9320 - val_loss: 0.3420 - val_acc: 0.8502 - val_weighted_accuracy: 0.8402\n",
      "Epoch 24/500\n",
      "360609/360609 [==============================] - 45s 126us/step - loss: 0.0137 - acc: 0.9316 - weighted_accuracy: 0.9329 - val_loss: 0.3420 - val_acc: 0.8514 - val_weighted_accuracy: 0.8399\n",
      "Epoch 25/500\n",
      "360609/360609 [==============================] - 45s 126us/step - loss: 0.0136 - acc: 0.9319 - weighted_accuracy: 0.9331 - val_loss: 0.3437 - val_acc: 0.8523 - val_weighted_accuracy: 0.8382\n",
      "Epoch 26/500\n",
      "360609/360609 [==============================] - 45s 126us/step - loss: 0.0136 - acc: 0.9321 - weighted_accuracy: 0.9336 - val_loss: 0.3486 - val_acc: 0.8497 - val_weighted_accuracy: 0.8404\n",
      "Epoch 27/500\n",
      "360609/360609 [==============================] - 45s 126us/step - loss: 0.0135 - acc: 0.9324 - weighted_accuracy: 0.9339 - val_loss: 0.3511 - val_acc: 0.8487 - val_weighted_accuracy: 0.8408\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_39 (Embedding)        (None, 30, 300)      30000000    first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_49 (SpatialDr (None, 30, 300)      0           embedding_39[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_50 (SpatialDr (None, 30, 300)      0           embedding_39[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_137 (TimeDistr (None, 30, 300)      180600      spatial_dropout1d_49[0][0]       \n",
      "                                                                 spatial_dropout1d_50[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dot_163 (Dot)                   (None, 30, 30)       0           time_distributed_137[0][0]       \n",
      "                                                                 time_distributed_137[1][0]       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_148 (Lambda)             (None, 30, 30)       0           dot_163[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_55 (Permute)            (None, 30, 30)       0           lambda_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_147 (Lambda)             (None, 30, 30)       0           dot_163[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_165 (Dot)                   (None, 30, 300)      0           permute_55[0][0]                 \n",
      "                                                                 time_distributed_137[1][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dot_164 (Dot)                   (None, 30, 300)      0           lambda_147[0][0]                 \n",
      "                                                                 time_distributed_137[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_149 (Lambda)             (None, 30, 300)      0           time_distributed_137[0][0]       \n",
      "                                                                 dot_165[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_39 (Multiply)          (None, 30, 300)      0           time_distributed_137[0][0]       \n",
      "                                                                 dot_165[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_150 (Lambda)             (None, 30, 300)      0           time_distributed_137[1][0]       \n",
      "                                                                 dot_164[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_40 (Multiply)          (None, 30, 300)      0           time_distributed_137[1][0]       \n",
      "                                                                 dot_164[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_181 (Concatenate)   (None, 30, 1200)     0           time_distributed_137[0][0]       \n",
      "                                                                 dot_165[0][0]                    \n",
      "                                                                 lambda_149[0][0]                 \n",
      "                                                                 multiply_39[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_182 (Concatenate)   (None, 30, 1200)     0           time_distributed_137[1][0]       \n",
      "                                                                 dot_164[0][0]                    \n",
      "                                                                 lambda_150[0][0]                 \n",
      "                                                                 multiply_40[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_138 (TimeDistr (None, 30, 300)      360300      concatenate_181[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_142 (TimeDistr (None, 30, 300)      360300      concatenate_182[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_139 (TimeDistr (None, 30, 300)      0           time_distributed_138[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_143 (TimeDistr (None, 30, 300)      0           time_distributed_142[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_140 (TimeDistr (None, 30, 200)      60200       time_distributed_139[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_144 (TimeDistr (None, 30, 200)      60200       time_distributed_143[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_141 (TimeDistr (None, 30, 200)      0           time_distributed_140[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_145 (TimeDistr (None, 30, 200)      0           time_distributed_144[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_49 (Gl (None, 200)          0           time_distributed_141[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_49 (Global (None, 200)          0           time_distributed_141[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_50 (Gl (None, 200)          0           time_distributed_145[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_50 (Global (None, 200)          0           time_distributed_145[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_183 (Concatenate)   (None, 400)          0           global_average_pooling1d_49[0][0]\n",
      "                                                                 global_max_pooling1d_49[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_184 (Concatenate)   (None, 400)          0           global_average_pooling1d_50[0][0]\n",
      "                                                                 global_max_pooling1d_50[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_185 (Concatenate)   (None, 800)          0           concatenate_183[0][0]            \n",
      "                                                                 concatenate_184[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 800)          3200        concatenate_185[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_93 (Dense)                (None, 256)          205056      batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_69 (Dropout)            (None, 256)          0           dense_93[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 256)          1024        dropout_69[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_94 (Dense)                (None, 256)          65792       batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_70 (Dropout)            (None, 256)          0           dense_94[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 256)          1024        dropout_70[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_95 (Dense)                (None, 3)            771         batch_normalization_45[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 30,877,967\n",
      "Trainable params: 875,343\n",
      "Non-trainable params: 30,002,624\n",
      "__________________________________________________________________________________________________\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360609/360609 [==============================] - 49s 136us/step - loss: 0.0175 - acc: 0.9038 - weighted_accuracy: 0.9026 - val_loss: 0.3068 - val_acc: 0.8679 - val_weighted_accuracy: 0.8571\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0172 - acc: 0.9063 - weighted_accuracy: 0.9052 - val_loss: 0.3089 - val_acc: 0.8610 - val_weighted_accuracy: 0.8578\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 45s 126us/step - loss: 0.0169 - acc: 0.9083 - weighted_accuracy: 0.9077 - val_loss: 0.3161 - val_acc: 0.8640 - val_weighted_accuracy: 0.8565\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0167 - acc: 0.9100 - weighted_accuracy: 0.9095 - val_loss: 0.3024 - val_acc: 0.8669 - val_weighted_accuracy: 0.8566\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0164 - acc: 0.9121 - weighted_accuracy: 0.9118 - val_loss: 0.3176 - val_acc: 0.8628 - val_weighted_accuracy: 0.8528\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0162 - acc: 0.9133 - weighted_accuracy: 0.9135 - val_loss: 0.3076 - val_acc: 0.8673 - val_weighted_accuracy: 0.8607\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0159 - acc: 0.9158 - weighted_accuracy: 0.9160 - val_loss: 0.2954 - val_acc: 0.8703 - val_weighted_accuracy: 0.8596\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0158 - acc: 0.9159 - weighted_accuracy: 0.9162 - val_loss: 0.3100 - val_acc: 0.8650 - val_weighted_accuracy: 0.8570\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0156 - acc: 0.9173 - weighted_accuracy: 0.9178 - val_loss: 0.2980 - val_acc: 0.8679 - val_weighted_accuracy: 0.8610\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0155 - acc: 0.9187 - weighted_accuracy: 0.9193 - val_loss: 0.3005 - val_acc: 0.8726 - val_weighted_accuracy: 0.8645\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 45s 126us/step - loss: 0.0154 - acc: 0.9192 - weighted_accuracy: 0.9198 - val_loss: 0.2992 - val_acc: 0.8696 - val_weighted_accuracy: 0.8591\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0152 - acc: 0.9208 - weighted_accuracy: 0.9215 - val_loss: 0.3061 - val_acc: 0.8696 - val_weighted_accuracy: 0.8605\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0150 - acc: 0.9218 - weighted_accuracy: 0.9227 - val_loss: 0.2983 - val_acc: 0.8695 - val_weighted_accuracy: 0.8625\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0150 - acc: 0.9220 - weighted_accuracy: 0.9228 - val_loss: 0.3067 - val_acc: 0.8690 - val_weighted_accuracy: 0.8621\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0149 - acc: 0.9231 - weighted_accuracy: 0.9242 - val_loss: 0.3045 - val_acc: 0.8705 - val_weighted_accuracy: 0.8611\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0147 - acc: 0.9239 - weighted_accuracy: 0.9250 - val_loss: 0.3104 - val_acc: 0.8675 - val_weighted_accuracy: 0.8615\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0146 - acc: 0.9249 - weighted_accuracy: 0.9258 - val_loss: 0.3048 - val_acc: 0.8701 - val_weighted_accuracy: 0.8624\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0145 - acc: 0.9256 - weighted_accuracy: 0.9268 - val_loss: 0.3082 - val_acc: 0.8701 - val_weighted_accuracy: 0.8621\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0145 - acc: 0.9259 - weighted_accuracy: 0.9271 - val_loss: 0.3156 - val_acc: 0.8667 - val_weighted_accuracy: 0.8570\n",
      "Epoch 20/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0143 - acc: 0.9269 - weighted_accuracy: 0.9282 - val_loss: 0.3045 - val_acc: 0.8720 - val_weighted_accuracy: 0.8633\n",
      "Epoch 21/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0143 - acc: 0.9270 - weighted_accuracy: 0.9281 - val_loss: 0.3052 - val_acc: 0.8703 - val_weighted_accuracy: 0.8613\n",
      "Epoch 22/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0142 - acc: 0.9280 - weighted_accuracy: 0.9291 - val_loss: 0.3067 - val_acc: 0.8708 - val_weighted_accuracy: 0.8626\n",
      "Epoch 23/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0141 - acc: 0.9287 - weighted_accuracy: 0.9303 - val_loss: 0.3157 - val_acc: 0.8673 - val_weighted_accuracy: 0.8617\n",
      "Epoch 24/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0140 - acc: 0.9286 - weighted_accuracy: 0.9300 - val_loss: 0.3161 - val_acc: 0.8699 - val_weighted_accuracy: 0.8620\n",
      "Epoch 25/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0139 - acc: 0.9293 - weighted_accuracy: 0.9309 - val_loss: 0.3059 - val_acc: 0.8719 - val_weighted_accuracy: 0.8623\n",
      "Epoch 26/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0138 - acc: 0.9305 - weighted_accuracy: 0.9320 - val_loss: 0.3062 - val_acc: 0.8714 - val_weighted_accuracy: 0.8628\n",
      "Epoch 27/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0138 - acc: 0.9309 - weighted_accuracy: 0.9325 - val_loss: 0.3085 - val_acc: 0.8708 - val_weighted_accuracy: 0.8616\n",
      "Epoch 28/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0137 - acc: 0.9315 - weighted_accuracy: 0.9329 - val_loss: 0.3038 - val_acc: 0.8716 - val_weighted_accuracy: 0.8624\n",
      "Epoch 29/500\n",
      "360609/360609 [==============================] - 45s 124us/step - loss: 0.0136 - acc: 0.9319 - weighted_accuracy: 0.9334 - val_loss: 0.3165 - val_acc: 0.8708 - val_weighted_accuracy: 0.8607\n",
      "Epoch 30/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0136 - acc: 0.9321 - weighted_accuracy: 0.9336 - val_loss: 0.3134 - val_acc: 0.8697 - val_weighted_accuracy: 0.8602\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "first_sentences (InputLayer)    (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "second_sentences (InputLayer)   (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_41 (Embedding)        (None, 30, 300)      30000000    first_sentences[0][0]            \n",
      "                                                                 second_sentences[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_51 (SpatialDr (None, 30, 300)      0           embedding_41[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_52 (SpatialDr (None, 30, 300)      0           embedding_41[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_146 (TimeDistr (None, 30, 300)      180600      spatial_dropout1d_51[0][0]       \n",
      "                                                                 spatial_dropout1d_52[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dot_166 (Dot)                   (None, 30, 30)       0           time_distributed_146[0][0]       \n",
      "                                                                 time_distributed_146[1][0]       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_152 (Lambda)             (None, 30, 30)       0           dot_166[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_56 (Permute)            (None, 30, 30)       0           lambda_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_151 (Lambda)             (None, 30, 30)       0           dot_166[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_168 (Dot)                   (None, 30, 300)      0           permute_56[0][0]                 \n",
      "                                                                 time_distributed_146[1][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dot_167 (Dot)                   (None, 30, 300)      0           lambda_151[0][0]                 \n",
      "                                                                 time_distributed_146[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_153 (Lambda)             (None, 30, 300)      0           time_distributed_146[0][0]       \n",
      "                                                                 dot_168[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_41 (Multiply)          (None, 30, 300)      0           time_distributed_146[0][0]       \n",
      "                                                                 dot_168[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_154 (Lambda)             (None, 30, 300)      0           time_distributed_146[1][0]       \n",
      "                                                                 dot_167[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_42 (Multiply)          (None, 30, 300)      0           time_distributed_146[1][0]       \n",
      "                                                                 dot_167[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_186 (Concatenate)   (None, 30, 1200)     0           time_distributed_146[0][0]       \n",
      "                                                                 dot_168[0][0]                    \n",
      "                                                                 lambda_153[0][0]                 \n",
      "                                                                 multiply_41[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_187 (Concatenate)   (None, 30, 1200)     0           time_distributed_146[1][0]       \n",
      "                                                                 dot_167[0][0]                    \n",
      "                                                                 lambda_154[0][0]                 \n",
      "                                                                 multiply_42[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_147 (TimeDistr (None, 30, 300)      360300      concatenate_186[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_151 (TimeDistr (None, 30, 300)      360300      concatenate_187[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_148 (TimeDistr (None, 30, 300)      0           time_distributed_147[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_152 (TimeDistr (None, 30, 300)      0           time_distributed_151[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_149 (TimeDistr (None, 30, 200)      60200       time_distributed_148[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_153 (TimeDistr (None, 30, 200)      60200       time_distributed_152[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_150 (TimeDistr (None, 30, 200)      0           time_distributed_149[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_154 (TimeDistr (None, 30, 200)      0           time_distributed_153[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_51 (Gl (None, 200)          0           time_distributed_150[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_51 (Global (None, 200)          0           time_distributed_150[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_52 (Gl (None, 200)          0           time_distributed_154[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_52 (Global (None, 200)          0           time_distributed_154[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_188 (Concatenate)   (None, 400)          0           global_average_pooling1d_51[0][0]\n",
      "                                                                 global_max_pooling1d_51[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_189 (Concatenate)   (None, 400)          0           global_average_pooling1d_52[0][0]\n",
      "                                                                 global_max_pooling1d_52[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_190 (Concatenate)   (None, 800)          0           concatenate_188[0][0]            \n",
      "                                                                 concatenate_189[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 800)          3200        concatenate_190[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_98 (Dense)                (None, 256)          205056      batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_73 (Dropout)            (None, 256)          0           dense_98[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 256)          1024        dropout_73[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_99 (Dense)                (None, 256)          65792       batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_74 (Dropout)            (None, 256)          0           dense_99[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 256)          1024        dropout_74[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_100 (Dense)               (None, 3)            771         batch_normalization_48[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 30,877,967\n",
      "Trainable params: 875,343\n",
      "Non-trainable params: 30,002,624\n",
      "__________________________________________________________________________________________________\n",
      "Train on 360609 samples, validate on 40069 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360609/360609 [==============================] - 49s 137us/step - loss: 0.0184 - acc: 0.8983 - weighted_accuracy: 0.8964 - val_loss: 0.3013 - val_acc: 0.8655 - val_weighted_accuracy: 0.8571\n",
      "Epoch 2/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0181 - acc: 0.9002 - weighted_accuracy: 0.8985 - val_loss: 0.2835 - val_acc: 0.8764 - val_weighted_accuracy: 0.8601\n",
      "Epoch 3/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0176 - acc: 0.9040 - weighted_accuracy: 0.9029 - val_loss: 0.2911 - val_acc: 0.8722 - val_weighted_accuracy: 0.8606\n",
      "Epoch 4/500\n",
      "360609/360609 [==============================] - 45s 126us/step - loss: 0.0173 - acc: 0.9056 - weighted_accuracy: 0.9048 - val_loss: 0.2873 - val_acc: 0.8719 - val_weighted_accuracy: 0.8638\n",
      "Epoch 5/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0170 - acc: 0.9076 - weighted_accuracy: 0.9071 - val_loss: 0.2896 - val_acc: 0.8697 - val_weighted_accuracy: 0.8620\n",
      "Epoch 6/500\n",
      "360609/360609 [==============================] - 45s 126us/step - loss: 0.0167 - acc: 0.9099 - weighted_accuracy: 0.9095 - val_loss: 0.2851 - val_acc: 0.8734 - val_weighted_accuracy: 0.8640\n",
      "Epoch 7/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0165 - acc: 0.9114 - weighted_accuracy: 0.9114 - val_loss: 0.2809 - val_acc: 0.8773 - val_weighted_accuracy: 0.8642\n",
      "Epoch 8/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0163 - acc: 0.9127 - weighted_accuracy: 0.9126 - val_loss: 0.2818 - val_acc: 0.8736 - val_weighted_accuracy: 0.8642\n",
      "Epoch 9/500\n",
      "360609/360609 [==============================] - 45s 126us/step - loss: 0.0161 - acc: 0.9144 - weighted_accuracy: 0.9146 - val_loss: 0.2890 - val_acc: 0.8723 - val_weighted_accuracy: 0.8635\n",
      "Epoch 10/500\n",
      "360609/360609 [==============================] - 45s 126us/step - loss: 0.0159 - acc: 0.9162 - weighted_accuracy: 0.9166 - val_loss: 0.2801 - val_acc: 0.8787 - val_weighted_accuracy: 0.8662\n",
      "Epoch 11/500\n",
      "360609/360609 [==============================] - 46s 127us/step - loss: 0.0158 - acc: 0.9167 - weighted_accuracy: 0.9172 - val_loss: 0.2877 - val_acc: 0.8746 - val_weighted_accuracy: 0.8635\n",
      "Epoch 12/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0156 - acc: 0.9178 - weighted_accuracy: 0.9185 - val_loss: 0.2875 - val_acc: 0.8754 - val_weighted_accuracy: 0.8646\n",
      "Epoch 13/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0155 - acc: 0.9187 - weighted_accuracy: 0.9193 - val_loss: 0.2853 - val_acc: 0.8768 - val_weighted_accuracy: 0.8667\n",
      "Epoch 14/500\n",
      "360609/360609 [==============================] - 45s 126us/step - loss: 0.0154 - acc: 0.9199 - weighted_accuracy: 0.9207 - val_loss: 0.2884 - val_acc: 0.8765 - val_weighted_accuracy: 0.8641\n",
      "Epoch 15/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0152 - acc: 0.9203 - weighted_accuracy: 0.9210 - val_loss: 0.2854 - val_acc: 0.8757 - val_weighted_accuracy: 0.8653\n",
      "Epoch 16/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0151 - acc: 0.9214 - weighted_accuracy: 0.9224 - val_loss: 0.2863 - val_acc: 0.8746 - val_weighted_accuracy: 0.8624\n",
      "Epoch 17/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0150 - acc: 0.9221 - weighted_accuracy: 0.9230 - val_loss: 0.2868 - val_acc: 0.8752 - val_weighted_accuracy: 0.8654\n",
      "Epoch 18/500\n",
      "360609/360609 [==============================] - 45s 126us/step - loss: 0.0148 - acc: 0.9233 - weighted_accuracy: 0.9245 - val_loss: 0.2945 - val_acc: 0.8745 - val_weighted_accuracy: 0.8645\n",
      "Epoch 19/500\n",
      "360609/360609 [==============================] - 45s 126us/step - loss: 0.0148 - acc: 0.9235 - weighted_accuracy: 0.9248 - val_loss: 0.2893 - val_acc: 0.8760 - val_weighted_accuracy: 0.8649\n",
      "Epoch 20/500\n",
      "360609/360609 [==============================] - 45s 126us/step - loss: 0.0147 - acc: 0.9241 - weighted_accuracy: 0.9252 - val_loss: 0.2914 - val_acc: 0.8761 - val_weighted_accuracy: 0.8638\n",
      "Epoch 21/500\n",
      "360609/360609 [==============================] - 46s 126us/step - loss: 0.0146 - acc: 0.9250 - weighted_accuracy: 0.9263 - val_loss: 0.2950 - val_acc: 0.8762 - val_weighted_accuracy: 0.8639\n",
      "Epoch 22/500\n",
      "360609/360609 [==============================] - 45s 126us/step - loss: 0.0145 - acc: 0.9260 - weighted_accuracy: 0.9273 - val_loss: 0.2908 - val_acc: 0.8752 - val_weighted_accuracy: 0.8645\n",
      "Epoch 23/500\n",
      "360609/360609 [==============================] - 45s 126us/step - loss: 0.0144 - acc: 0.9263 - weighted_accuracy: 0.9277 - val_loss: 0.2908 - val_acc: 0.8770 - val_weighted_accuracy: 0.8645\n",
      "Epoch 24/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0143 - acc: 0.9271 - weighted_accuracy: 0.9283 - val_loss: 0.2877 - val_acc: 0.8800 - val_weighted_accuracy: 0.8663\n",
      "Epoch 25/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0142 - acc: 0.9273 - weighted_accuracy: 0.9287 - val_loss: 0.2916 - val_acc: 0.8766 - val_weighted_accuracy: 0.8651\n",
      "Epoch 26/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0141 - acc: 0.9285 - weighted_accuracy: 0.9300 - val_loss: 0.3015 - val_acc: 0.8696 - val_weighted_accuracy: 0.8619\n",
      "Epoch 27/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0141 - acc: 0.9285 - weighted_accuracy: 0.9300 - val_loss: 0.3021 - val_acc: 0.8718 - val_weighted_accuracy: 0.8639\n",
      "Epoch 28/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0140 - acc: 0.9289 - weighted_accuracy: 0.9305 - val_loss: 0.2948 - val_acc: 0.8754 - val_weighted_accuracy: 0.8617\n",
      "Epoch 29/500\n",
      "360609/360609 [==============================] - 45s 126us/step - loss: 0.0139 - acc: 0.9297 - weighted_accuracy: 0.9313 - val_loss: 0.2947 - val_acc: 0.8777 - val_weighted_accuracy: 0.8641\n",
      "Epoch 30/500\n",
      "360609/360609 [==============================] - 45s 126us/step - loss: 0.0138 - acc: 0.9306 - weighted_accuracy: 0.9322 - val_loss: 0.2917 - val_acc: 0.8781 - val_weighted_accuracy: 0.8652\n",
      "Epoch 31/500\n",
      "360609/360609 [==============================] - 45s 126us/step - loss: 0.0138 - acc: 0.9309 - weighted_accuracy: 0.9325 - val_loss: 0.2917 - val_acc: 0.8780 - val_weighted_accuracy: 0.8634\n",
      "Epoch 32/500\n",
      "360609/360609 [==============================] - 45s 125us/step - loss: 0.0136 - acc: 0.9315 - weighted_accuracy: 0.9331 - val_loss: 0.3043 - val_acc: 0.8743 - val_weighted_accuracy: 0.8623\n",
      "Epoch 33/500\n",
      "360609/360609 [==============================] - 45s 126us/step - loss: 0.0137 - acc: 0.9313 - weighted_accuracy: 0.9330 - val_loss: 0.2899 - val_acc: 0.8784 - val_weighted_accuracy: 0.8648\n",
      "score 0.862474109916959\n",
      "Predicting training results...\n",
      "Predicting testing results...\n",
      "80126/80126 [==============================] - 3s 42us/step\n",
      "80126/80126 [==============================] - 3s 42us/step\n",
      "80126/80126 [==============================] - 3s 42us/step\n",
      "80126/80126 [==============================] - 3s 42us/step\n",
      "80126/80126 [==============================] - 3s 42us/step\n",
      "80126/80126 [==============================] - 3s 42us/step\n",
      "80126/80126 [==============================] - 3s 42us/step\n",
      "80126/80126 [==============================] - 3s 42us/step\n",
      "Predicting labeled testing results...\n"
     ]
    }
   ],
   "source": [
    "fold_count = 8\n",
    "embedding_matrix = sgns_bigram_matrix\n",
    "#embedding_matrix = tencent_ai_matrix\n",
    "EMBEDDING_DIM = 300\n",
    "\n",
    "for i in range(1, len(model_manager.models_tag)):\n",
    "    print(\"Work on model\", i)\n",
    "    model_tag = model_manager.models_tag[i]\n",
    "    model_func = model_manager.model_funcs[i]\n",
    "    #models_checkpoints_path = model_manager.models_checkpoints_pathes[i]\n",
    "    models_checkpoints_path = \"WordSGNS-DAttn-NoMeta-3P-NoEM-NoClassWeighted-3Layers\"\n",
    "\n",
    "    model_submit_prefix = model_manager.submit_predix[i]\n",
    "    model_class_weights = model_manager.model_class_weights[i]\n",
    "    model_scale_sample_weights = model_manager.model_scale_sample_weights[i]\n",
    "    model_patiences = model_manager.model_patiences[i]\n",
    "    \n",
    "    model_class_weights = None\n",
    "    \n",
    "    def _agent_get_model():\n",
    "        return get_decomposable_attention(NB_WORDS, EMBEDDING_DIM, embedding_matrix, MAX_SEQUENCE_LENGTH, OUT_SIZE)\n",
    "        return get_dense_cnn(NB_WORDS, EMBEDDING_DIM, embedding_matrix, MAX_SEQUENCE_LENGTH, OUT_SIZE)\n",
    "        return model_func(NB_WORDS, EMBEDDING_DIM, embedding_matrix, MAX_SEQUENCE_LENGTH, OUT_SIZE)\n",
    "    \n",
    "    test_predicts_list = []\n",
    "    oofs_predictions = []\n",
    "    pre_trained_models = []\n",
    "        \n",
    "    trainer = KerasModelTrainer(model_stamp=models_checkpoints_path, epoch_num=500)\n",
    "    models, score, folds_preds = trainer.train_folds(X=trains, y=labels, tests=tests, augments=None, fold_count=fold_count, batch_size=256,\n",
    "        em_train_features=em_train_features, em_test_features=em_test_features, pseudo_labels=pseudo_labels,                                      \n",
    "        scale_sample_weight=model_scale_sample_weights, class_weight={0: 1/16, 1: 1/15, 2:1/5},\n",
    "        get_model_func=_agent_get_model, \n",
    "        patience=20)\n",
    "\n",
    "    print(\"score\", score)\n",
    "    oofs_dir = \"../data/pseudo/oofs/\"\n",
    "    output_dir = \"../data/pseudo/output/\"\n",
    "    onehot_pred_dir = \"../data/pseudo/one_hot_pred/\"\n",
    "\n",
    "    model_submit_prefix = \"PSWordSGNS-DAttn-NoMeta-3P-NoEM-NoClassWeighted-3Layers\"\n",
    "    \n",
    "    oofs_path = oofs_dir + model_submit_prefix\n",
    "    output_path = output_dir + model_submit_prefix\n",
    "    one_hot_pred_path = onehot_pred_dir + \"One-Hot\" + model_submit_prefix\n",
    "\n",
    "    print(\"Predicting training results...\")\n",
    "    train_predicts = np.concatenate(folds_preds, axis=0)\n",
    "    oofs = pd.DataFrame({\"unrelated\": train_predicts[:, 0], \"agreed\": train_predicts[:, 1], \"disagreed\": train_predicts[:, 2]})\n",
    "    submit_path = oofs_path + \"-Train-L{:4f}-NB{:d}.csv\".format(score, NB_WORDS)\n",
    "    oofs.to_csv(submit_path, index=False)\n",
    "\n",
    "    print(\"Predicting testing results...\")\n",
    "    test_predicts_list = []\n",
    "    for fold_id, model in enumerate(models):\n",
    "        test_predicts = model.predict({\"first_sentences\":tests[0],\n",
    "                                       \"second_sentences\":tests[1],\n",
    "                                       \"mata-features\":tests[2],\n",
    "                                       \"first_exact_match\": tests_1_ems,\n",
    "                                       \"second_exact_match\": tests_2_ems,\n",
    "                                      }, batch_size=128, verbose=1)\n",
    "\n",
    "        test_predicts_list.append(test_predicts)\n",
    "\n",
    "    test_predicts = np.zeros(test_predicts_list[0].shape)\n",
    "    for fold_predict in test_predicts_list:\n",
    "        test_predicts += fold_predict\n",
    "    test_predicts /= len(test_predicts_list)\n",
    "\n",
    "    test_predicts = pd.DataFrame({\"unrelated\": test_predicts[:, 0], \"agreed\": test_predicts[:, 1], \"disagreed\": test_predicts[:, 2]})\n",
    "    submit_path = output_path + \"-L{:4f}-NB{:d}.csv\".format(score, NB_WORDS)\n",
    "    test_predicts.to_csv(submit_path, index=False) # 0.3343\n",
    "    \n",
    "    print(\"Predicting labeled testing results...\")\n",
    "    ids = pd.read_csv(\"../data/dataset/test.csv\")\n",
    "    pred_labels = test_predicts.idxmax(axis=1)\n",
    "    sub = pd.DataFrame({\"Id\": ids['id'].values, \"Category\": pred_labels})\n",
    "    submit_path = one_hot_pred_path + \"-L{:4f}-NB{:d}.csv\".format(score, NB_WORDS)\n",
    "    sub.to_csv(submit_path, index=False)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 1,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
